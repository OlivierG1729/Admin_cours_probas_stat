---
output:
  pdf_document: default
  html_document: default
---
# Dénombrement et probabilités

## Rappels sur les opérations ensemblistes


\noindent Un ensemble est une collection d'objets, dont la nature peut être extrêment variée : des nombres, des droites, des matrices, etc. Pour $E$ un ensemble, la notation $x\in E$ signifie que $x$ est un élément de $E$, et se lit *x appartient à E*.

:::: {.defbox .def data-latex="important"}
<center>**Inclusion, réunion, intersection, complémentaire**</center>

\noindent Soient $E$ et $F$ deux ensembles quelconques. 

- **Ensemble vide.** L'ensemble vide est l'ensemble n'admettant aucun élément.

- **Inclusion.** On dit que $F$ est *inclus* dans $E$, et on note $F\subset E$ si dès que $x$ appartient à $F$, il appartient aussi à $E$ :

$$(F\subset E) \Leftrightarrow \left((x\in F)\Rightarrow (x\in E)\right)$$

- **Réunion.** $E\cup F$ est l'ensemble des éléments qui appartiennent à au moins l'un des deux ensembles $E$ et $F$ :

$$E\cup F=\{x, \, x\in E \text{ ou } x\in F\}$$

- **Intersection.** $E\cap F$ est l'ensemble des éléments qui appartiennent à la fois à $E$ et à $F$ :

$$E\cap F=\{x, \, x\in E \text{ et } x\in F\}$$

- **Complémentaire.** Si $F\subset E$, le **complémentaire** de $F$ dans $E$, noté $\overline{F}^E$ est défini par 
$$\overline{F}^E=\{x\in E, \, x\not\in F\}$$


\noindent Lorsque le contexte n'est pas ambigu, on allège la notation en l'écrivant plus simplement $\overline{F}$. D'autres notations existent : $F^c$, $E\backslash F$, etc.
::::

\noindent Toutes les propriétés qu'on présente ici (sans démonstration) sont d'un usage très fréquent dans les calculs des probabilités.


:::: {.thmbox .thm data-latex="important"}

**Commutativité de $\cup$ et $\cap$.** Soient $A$ et $B$ deux ensembles. Alors :

$$A\cup B=B\cup A$$

$$A\cap B=B\cap A$$

**Associativité de $\cup$ et $\cap$.** Soient $A, B, C$ trois ensembles. Alors on a :

$$A\cup(B\cup C)=(A\cup B)\cup C$$

$$A\cup(B\cap C)=(A\cap B)\cap C$$

\noindent Autrement dit, on peut calculer une succession de réunions ou d'intersections d'ensemble dans l'ordre qu'on veut, ce qui nous autorise à enlever les parenthèses :

$$A\cup B\cup C$$

$$A\cap B\cap C$$

\noindent Plus généralement, étant donné une famille quelconque d'ensembles $(E_i)_{i\in I}$, on peut définir de façon complètement analogue et sans amibuité leur réunion $\bigcup\limits_{i\in I}E_i$ et leur intersection $\bigcap\limits_{i\in I}E_i$

\noindent 

**L'ensemble vide est un minorant de tout ensemble.** Pour tout ensemble $E$, on a :

$$\emptyset\subset E$$

\noindent 

**L'ensemble vide est neutre pour la réunion.** Pour tout ensemble $E$, on a 

$$E\cup\emptyset=\emptyset\cup E=E$$

\noindent 

**L'ensemble vide est absorbant pour l'intersection.** Pour tout ensemble $E$, on a 

$$E\cap\emptyset=\emptyset\cap E=\emptyset$$

\noindent

**Le passage au complémentaire est involutif.** Pour tout ensemble $E$ et pour tout sous-ensemble $F$ de $E$, on a :

$$\overline{\overline{F}}=F$$
::::


\noindent Les propriétés suivantes précisent comment la réunion, l'intersection et le passage complémentaire interagissent :

:::: {.thmbox .thm data-latex="important"}

\noindent 

**Lois de Morgan.** Pour tout ensemble $E$, pour tout couple $(A, B)$ de sous-ensembles de $E$, on a :

$$\overline{A\cup B}=\overline{A}\cap\overline{B}$$
$$\overline{A\cap B}=\overline{A}\cup\overline{B}$$
\noindent Cette propriété se généralise à toute famille $(F_i)_{i\in, I}$ d'un ensemble $E$ quelconque :

$$\overline{\bigcup\limits_{i\in I} F_i}=\bigcap\limits_{i\in I}\overline{F_i}$$

$$\overline{\bigcap\limits_{i\in I} F_i}=\bigcup\limits_{i\in I}\overline{F_i}$$
\noindent On peut résumer ces propriétés que l'opération de passage au complémentaire inverse la réunion et l'intersection.

\noindent 

**Distributivité.** Soient $A, B, C$ trois ensembles. Alors on a :

$$A\cap(B\cup C)=(A\cap B)\cup(A\cap C)$$
$$A\cup(B\cap C)=(A\cup B)\cap(A\cup C)$$


::::



## Dénombrement

\noindent On commence par quelques éléments d'**analyse combinatoire**. Ces résultats sont utilisés dans le cas où, lors d'une expérience aléatoire, tous les *événements élémentaires* (on parle aussi d'*issues*) sont de même probabilité. On parle dans ce cas d'**équiprobabilité** ou d'**équirépartition** des résultats. 

\noindent
**Des exemples classiques de tirages équirépartis :** 

- lancer d'un dé à 6 faces non truqué. Dans ce cas, chaque face a une probabilité d'apparition de $\frac{1}{6}$.

- dans une urne composée de 10 boules rouges, 10 boules blanches et 10 boules noires, tirage au hasard d'une boule. Les trois couleurs que l'on peut obtenir sont équiprobables, de probabilité commune $\frac{1}{3}$.

\noindent L'utilité du dénombrement dans le cas équiprobable vient de la formule que l'on apprend au lycée :

$$\mathbb{P}(A)=\frac{\text{Nombre de cas favorables à } A}{\text{Nombre total de cas}}$$

\noindent Cette formule, **qui n'est valable que dans le cas équiréparti**, suppose de savoir compter le nombre de cas où l'événement $A$ se réalise ainsi que de savoir compter le nombre total d'issues de l'expérience aléatoire que l'on étudie, autrement dit il s'agit bien de savoir **dénombrer**.

\noindent Cette première partie présente les types de dénombrements les plus classiques. Si les concepts sont très simples (on reste vraiment sur du niveau lycée), on peut assez facilement mal s'y prendre (ce qui voudra dire essentiellement : oublier de compter des cas, ou au contraire compter plusieurs fois le même cas) et passer complètement à côté du résultat. Bref, malgré les apparences, les questions de dénombrement (assez peu courantes au concours ces dernières années cela dit) sont potentiellement piégeuses... C'est donc typiquement le genre de questions qu'il ne faut pas sous-estimer et qu'il faut traiter en prenant son temps, à plus forte raison si elle est posée en début de sujet, et qu'elle est donc potentiellement structurante pour la suite.


### Produit cartésien et principe multiplicatif

:::: {.defbox .def data-latex="important"}
<center>**Produit cartésien**</center> Soient $k$ un entier naturel non nul et $E_1,\dots E_k$ des ensembles finis de cardinaux respectifs $n_1,\dots, n_k$. Le **produit cartésien** de $E_1,\dots, E_k$ est l'ensemble noté $E_1\times\dots\times E_k$ de toutes les **listes ordonnées** $(x_1,\dots,x_k)$ telles que, pour tout $i\in\{1,\dots, k\}$ l'élément numéro $i$ noté $x_i$ appartient à l'ensemble $E_i$. On dit aussi que $(x_1,\dots, x_k)$ est un **k-uplet**.
\vspace{0.5cm}
\noindent 

**Cas particuliers : i.** Les listes ordonnées à 2 éléments sont appelées des **couples**, celles à 3 élements sont appelées des **triplets** et les listes à 4 éléments sont les **quadruplets**.

\noindent
**ii.** Lorsque tous les ensembles $E_1,\dots E_k$ sont égaux, i.e. $E_1=\dots=E_k=E$, le produit cartésien $E\times\dots\times E$ est noté plus simplement $E^k$.

::::

\noindent
**Remarques.** Le mot important dans cette définition est *ordonnée*. L'ordre a en effet une importance ici, autrement dit $(1, 2)\in\mathbb{R}^2$ et $(2, 1)\in\mathbb{R}^2$ sont bien considérés comme deux couples distincts de réels.

\noindent Le premier résultat de ce cours, qui est absolument fondamental lorsqu'on pratique le dénombrement, et donc lorsqu'on est en situation d'équiprobabilité, est le **principe multiplicatif**. Ce principe, à la fois très simple et très intuitif, répond à la question *Combien existe-t-il de k-uplets ?*

:::: {.thmbox .thm data-latex="important"}
**Principe multiplicatif :** Avec les notations de la définition précédente, le nombre d'élements du produit cartésien $E_1\times \dots\times E_k$ est égal à $n_1\times\dots\times E_k$. Formule que l'on peut aussi écrire (en notant $\text{Card}\,(E)$ le cardinal d'un ensemble $E$, i.e. le nombre d'éléments de $E$) :

$$\text{Card }(E_1\times\dots\times E_k)=\text{Card }(E_1)\times\dots\times\text{Card }(E_k)$$

\noindent Si on veut faire chic, on peut dire aussi que 

$$\textit{Le cardinal d'un produit est le produit des cardinaux}$$
::::

\noindent
**Exemple 1 : expériences aléatoires successives.** On réalise successivement les deux expériences aléatoires suivantes :

- lancer d'une pièce : 2 résultats possibles P ou F ;
- puis lancer d'un dé cubique : 6 résultats possibles notés de 1 à 6.

\noindent L'ensemble des issues de cette double expérience aléatoire peut être modélisé par le produit cartésien $\{P, F\}\times\{1,2,3,4,5,6\}$. C'est un ensemble à 12 éléments : 
$$(P,1), (P,2), (P,3), (P, 4), (P,5), (P, 6), (F,1), (F,2), (F,3), (F, 4), (F,5), (F, 6)$$

\noindent Cet ensemble peut facilement être représenté par un **arbre de dénombrement** :

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/arbre.svg") 
```
</center>


\noindent

**Exemple 2 : compter des poignées de mains.** Soit $n\geq 2$ un entier. Compter le nombre de poignées de mains possibles dans un groupe de $n$ personnes.

\noindent 

**Solution 2.a.** On note $1,\dots n$ les personnes de ce groupe, et le couple $(i, j)$ modélise le fait que $i$ sert la main de $j$. On compte alors successivement :

- le nombre de couples : il y en a $n^2$ d'après le principe multiplicatif ;
- le nombre de couples $(i, i)$ qui représenteraient le fait que $i$ se sert la man à lui-même, situtation qu'on ne veut pas dénombrer et dont il faut donc soustraire le nombre d'occurences au nombre précédent. Il y en a $n$, donc il y a $n^2-n=n(n-1)$ façons qu'une personne $i$ serre la main d'une autre personne $j$ du goupe ;
- le nombre de couples correspondant à *une* poignée de mains : il s'agit de $2$, puisque une poignée de mains entre deux personnes $i$ et $j$ correspond à exactement deux couples : $(i,j)$ et $(j,i)$. Il faut donc diviser par deux le nombre trouvé précédemment, ce qui fait un total de $\frac{n(n-1)}{2}$ poignées de mains.

\noindent

**Solution 2.b.(plus directe)**  Une poignée de mains implique deux personnes différentes. On a $n$ choix possibles pour la première personne, et $n-1$ choix possibles pour la deuxième personne, soit $n(n-1)$ choix de couples possibles. En l'état, on compte deux fois trop de poignées de mains (même raisonnement que dans l'exemple 2.a.), donc il y a en réalité $\frac{n(n-1)}{2}$ poignées de mans possibles.$


### Principe additif

\noindent Un deuxième grand principe de dénombrement, tout aussi intuitif et tout aussi fondamental, est le **principe additif** :

:::: {.thmbox .thm data-latex="important"}
**Principe additif :** Si $E_1,\dots E_k$ sont $k$ ensembles **deux à deux disjoints** (i.e. $i\neq j\Rightarrow E_i\cap E_j=\emptyset$) alors (en reprenant les mêmes notations que dans la définition précédente) leur union $E_1\cup\dots\cup E_k$ a pour cardinal $n_1+\dots+n_k$, ce que l'on peut aussi écrire :

$$\text{Card }\left(E_1\cup\dots\cup E_k\right)=\text{Card }(E_1)+\dots+\text{Card }(E_k)$$

\noindent On pourra retenir que :

$$\textit{Le cardinal d'une union disjointe est la somme des cardinaux}$$

\noindent

**Remarque.** Lorsqu'un ensemble $E$ peut s'écrire sous la forme 

$$E=E_1\cup E_2\cup\dots\cup E_k$$

\noindent avec $E_1, E_2, \dots, E_k$ deux à deux disjoints, on dit que $E_1, E_2,\dots E_k$ forment une **partition** de l'ensemble $E$.
::::

**Exemple 3 : compter des carrés.** Combien la figure suivante compte-t-elle de carrés ?

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/carres.png") 
```
</center>

\noindent

**Solution.** Tout carré de cette figure a pour côté 1, 2, 3 ou 4 (en supposant avoir fixé une unité de longueur, correspondant au côté d'un "petit" carré). L'ensemble $E$ des carrés de cette figure peut donc s'écrire

$$E=E_1\cup E_2\cup E_3\cup E_4$$

\noindent où, pour $k\in\{1,2,3,4\}$, $E_k$ désigne l'ensemble des carrés de côté $k$ de cette figure. Les $E_k$ sont deux à deux disjoints (un carré de la figure ne peut pas avoir un côté de deux longueurs différentes) et donc pour compter le nombre de carrés possibles, il suffit de compter les carrés de côté 1, de côté 2, de côté 3, de côté 4 et d'ajouter tous ces nombres. On trouve :

\begin{align}
\text{Card }(E_1) &= 16 \\
\text{Card }(E_2) &= 9 \\
\text{Card }(E_3) &= 4 \\
\text{Card }(E_4) &= 1 \\
\end{align}

\noindent d'où $\text{Card }(E)=16+9+4+1=30$.

\noindent 

**Exemple 4 (poignées de mains, à nouveau).** On peut répondre à cette question en utilisant le principe additif. On note $E_1$ l'ensemble des poignées de mains de la personne $1$. Puis on note $E_2$ l'ensemble des poignées de mains de la personne $2$, hormis celle avec la personne $1$ qui a déjà été comptée, $E_3$ l'ensemble des poignées de mains de la personne $3$ hormis celles avec les personnes $1$ et $2$ qui ont déjà été comptées, et ainsi de suite jusqu'à $E_{n}$. Alors, $E_1,E_2,\dots, E_n$ forment une partition de l'ensemble $E$ de toutes les poignées de mains du groupe, on va donc compter les cardinaux de $E_1,E_2,\dots, E_n$ et utiliser le principe additif :

- la personne $1$ serre la main des $2$ à $n$, donc $E_1=n-1$ ;
- les poignées de mains non encore comptées de la personne $2$ sont celles avec les personnes $3$ à $n$ donc  $E_2=n-2$ ;
- les poignées de mains non encore comptées de la personne $3$ sont celles avec les personnes $4$ à $n$ donc  $E_2=n-3$ ;
- ...
- une seule poignée de mains n'a pas été comptée pour la personne $n-1$, celle avec la personnes $n$ donc  $E_{n-1}=1$ ;
- enfin, toutes les poignées de mains de la personne $n$ ont été comptées, donc $E_n=0$.

\noindent En vertu du principe additif, le nombre de poignées de mains est donc égal à $$0+1+2+\dots+(n-1)=\frac{n(n-1)}{2}$$


### Formule de Poincaré

\noindent Il existe une formule lorsqu'on relâche l'hypothèse de non-djsjonction deux à deux, connue sous le nom de *formule de Poincaré*. C'est une formule que l'on utilise souvent dans le cas $k=2$, de temps en temps dans le cas $k=3$, plus rarement (mais ça peut arriver dans un sujet du concours) dans le cas $k\geq 4$ voire dans le cas général.


:::: {.thmbox .thm data-latex="important"}
**Formule de Poincaré.** Soit $E$ un ensemble fini, qui peut s'écrire sous la forme 

$$E=E_1\cup E_2\cup\dots\cup E_k$$

\noindent avec $E_1,E_2,\dots E_k$ des sous-ensembles de $E$ **non nécessairement disjoints deux à deux**. Alors :

$$\text{Card }(E)=\sum\limits_{i=1}^k (-1)^i \sum\limits_{1\leq j_1 < j_2 <...< j_i\leq n} \text{Card }\left(E_{j_1}\cap E_{j_2}\cap\dots\cap E_{j_i}\right)$$
\noindent
**Cas particulier $k=2$ :** 

$$\text{Card }(A\cup B)=\text{Card }(A)+\text{Card }(B)-\text{Card }(A\cap B)$$

\noindent 
**Cas particulier $k=3$ :** 

\begin{align}
\text{Card }(A\cup B\cup C)&=\text{Card }(A)+\text{Card }(B)+\text{Card }(C) \\
 &-\text{Card }(A\cap B)-\text{Card }(A\cap C)-\text{Card }(B\cap C) \\
 &+\text{Card }(A\cap B\cap C)
 \end{align}
::::

\noindent
**Démonstration dans le cas $k=2$.** L'intutition de la démonstration est évidente : pour compter tout ce qu'il y a dans la réunion de $A$ et $B$, on compte tout ce qu'il y a dans $A$, tout ce qu'il y a dans $B$ et on ajoute le tout. Mais en faisant cela, on compte deux fois - c'est-à-dire une fois de trop - tout ce qui est à la fois dans $A$ et dans $B$, donc on doit ensuite soustraire l'excédent.

\noindent Plus formellement, on écrit $A\cup B$ comme une union disjointe, puis on applique le principe additif. On a, en posant $A\backslash B=A\cap\overline{B}$ et $B\backslash A=B\cap\overline{A}$ :

$$A\cup B = (A\backslash B)\cup(A\cap B)\cup (B\backslash A)$$

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/Venn.png") 
```
</center>

\noindent Les trois ensembles du membre de droite de cette égalité dont deux à deux disjoints, donc on peut appliquer le principe additif :

$$\text{Card }(A\cup B)=\text{Card }(A\backslash B)+\text{Card }(A\cap B)+\text{Card }(B\backslash A)$$
\noindent Par ailleurs

$$A=(A\backslash B)\cup (A\cap B)$$

$$B=(B\backslash A)\cup (B\cap A)$$
\noindent avec à nouveau des ensembles deux à disjoints dans les membres de droite. Donc, en appliquant deux fois le principe additif 


$$\text{Card }(A\backslash B)=\text{Card }(A)-\text{Card }(A\cap B)$$

$$\text{Card }(B\backslash A)=\text{Card }(B)-\text{Card }(A\cap B)$$

\noindent et donc finalement

\begin{align}
\text{Card }(A\cup B)&=\text{Card }(A\backslash B)+\text{Card }(A\cap B)+\text{Card }(B\backslash A) \\
&=\text{Card }(A)-\text{Card }(A\cap B)+\text{Card }(A\cap B)+\text{Card }(B)-\text{Card }(A\cap B) \\
&=\text{Card }(A)+\text{Card }(B)-\text{Card }(A\cap B)
\end{align}

$\square$


### Dénombrement par bijection

\noindent Une technique classique de dénombrement d'un ensemble fini $E$ est l'utilisation d'un bijection entre $E$ et un ensemble fini $F$ dont on connaît le cardinal :

:::: {.thmbox .thm data-latex="important"}
**Conservation du cardinal par bijection.** Soient $E$ un ensemble, $F$ un ensemble fini. S'il existe une bijection $\varphi : E\longrightarrow F$, alors $E$ est un ensemble fini et il est de même cardinal que $F$.
::::

\noindent

**Application classique : nombre de parties d'un ensemble fini.** Soit $E$ un ensemble de cardinal $n$. Alors l'ensemble $\mathcal{P}(E)$ des parties de $E$ (i.e. l'ensemble de tous les sous-ensembles de $E$, y compris l'ensemble vide et $E$ lui-même) est égal à $2^n$ :

$$\text{Card }(E)=n\Rightarrow\text{Card }(\mathcal{P}(E))=2^n$$

\noindent En effet, notons $\{0,1\}^E$ l'ensemble de toutes les fonctions possibles de $E$ dans $\{0,1\}$. Soit alors $\varphi$ l'application $\varphi:\{0,1\}^E\longrightarrow\mathcal{P}(E)$ définie, pour toute fonction $f\in\{0,1\}^E$ par 

$$\varphi(f)=\{x\in E, \,f(x)=1\}$$

\noindent L'application $\varphi$ est bien définie (si $f=g$ on a clairement $\varphi(f)=\varphi(g)$). Elle est injective : si $\varphi(f)=\varphi(g)$, alors $f(x)=1$ si et seulement si $g(x)=1$, et donc $f$ et $g$ ne pouvant prendre que $0$ et $1$ comme valeurs on en déduit que $f=g$. Enfin, $\varphi$ est surjective. En effet, si $P\in\mathcal{P}(E)$, alors en posant, pour tout $x$ dans $E$, $f(x)=1$ si $x\in P$ et $f(x)=0$ si $x\not\in P$, on a $f\in\{0,1\}^E$ et $\varphi(f)=P$.

\noindent Enfin, en vertu du principe multiplicatif on a $\text{Card }(\{0,1\}^E)=2^n$. On en déduit que $\text{Card }(\mathcal{P}(E))=2^n$.

$\square$

\noindent Intutivement, la démonstration précédente montre que toute partie $P$ d'un ensemble fini $E$ peut être *codé* de façon unique en une fonction sur $E$ à valeurs dans $\{0,1\}$, prenant la valeur $1$ pour les éléments de $P$ et $0$ pour les élements qui ne sont pas dans $P$.

### Permutations

:::: {.defbox .def data-latex="important"}
<center>**Permutation d'un ensemble fini**</center> Soient $n$ un entier naturel non nul et $E=\{x_1,\dots, x_n\}$} un ensemble fini à $n$ éléments. On appelle **permutation** de $E$ tout  réarragement **ordonné** et **sans répétition** des éléments de $E$. De façon équivalente, une permutation est une bijection de $E$ dans lui-même. 
\vspace{0.5cm}
::::

\noindent 

**Notation.** L'ensemble des permutations d'un ensemble fini $E$ est noté $\mathfrak{S}(E)$. Dans le cas particulier où $E=\{1,2,\dots, n\}$, on le note plus simplement $\mathfrak{S}_n$.

\noindent 

**Exemple.** $E=\{a,b,c\}$, les permutations de $E$ sont 

$$(a,b,c), (a,c,b), (b,a,c), (b,c,a), (c,a,b), (c,b,a)$$

Ces permutations peuvent aussi s'écrire comme des bijections  $\sigma_1,\dots,\sigma_6$ de $E$ dans lui-même :

$$\sigma_1(a)=a,\,\sigma_1(b)=b,\,\sigma_1(c)=c$$
$$\sigma_2(a)=a,\,\sigma_2(b)=c,\,\sigma_2(c)=b$$
$$\sigma_3(a)=b,\,\sigma_3(b)=a,\,\sigma_3(c)=c$$
$$\sigma_4(a)=b,\,\sigma_4(b)=c,\,\sigma_4(c)=a$$
$$\sigma_5(a)=c,\,\sigma_5(b)=a,\,\sigma_5(c)=b$$
$$\sigma_6(a)=a,\,\sigma_6(b)=b,\,\sigma_6(c)=a$$

\noindent Le nombre de permutations d'un ensemble fini est facile à dénombrer :

:::: {.thmbox .thm data-latex="important"}
**Théorème (nombre de permutations) :** Soit $n$ un entier naturel non nul. Le nombre de permutations d'un ensemble fini à $n$ éléments est égal à $n!=1\times 2\times 3\times\dots\times n$.
::::

\noindent 

**Démonstration.** On note $x_1,\dots,x_n$ les éléments d'un ensemble de cardinal $n$. Choisir une permutation $\sigma$ de $E$, c'est choisir successivement :

- l'image $\sigma(x_1)$ parmi les $n$ éléments $x_1,\dots,x_n$ : $n$ choix possibles ;

- l'image $\sigma(x_2)$ parmi les $n-1$ éléments restants : $n-1$ choix possibles ;

- l'image $\sigma(x_3)$ parmi les $n-2$ éléments restants : $n-2$ choix possibles ;

- ...

- l'image $\sigma(x_n)$ parmi le seul élément de $x_1,\dots, x_n$ qui n'a pas encore été choisi : $1$ seul choix possible.

\noindent D'après le principe multiplicatif, le nombre de permutations de $E$ est donc égal à $$n\times(n-1)\times(n-2)\times\dots\times 1=n!$$

$\square$

\noindent

**Remarque.** En filigrane, le théorème précédént dit aussi que le nombre de permutations d'un ensemble fini $E$ ne dépend de $E$ qu'à travers son cardinal. Autrement dit, peu importe l'ensemble $E$ que l'on choisit, dès lors qu'il a $n$ éléments le nombre de permutations de cet ensemble est $n!$. Ce résultat est une simple conséquence du principe de dénombrement par bijection évoqué plus haut.

\noindent

**Exemple : nombre d'anagrammes.** Quel est le nombre d'anagrammes du mot MATHS ? Du mot ANAGRAMME ?

\noindent

**Solution. i.** Une anagramme du mot MATHS correspond à une permutation de l'ensemble $\{M,A,T,H,S\}$. Il y en a donc $5!=120$.

\noindent

**ii.** Pour le mot ANAGRAMME c'est un peu plus compliqué car certaines lettres apparaissent plusieurs fois. On commence par numéroter ces lettres-là, en les traitant comme des lettres différentes, autrement dit on commence par compter le nombre de permutations de l'ensemble $\{A_1,N,A_2,G,R,A_3,M_1,M_2,E\}$ : il y en a $9!$. Les lettres n'étant en réalité pas numérotées dans notre problème, il n'y a pas lieu de distinguer, par exemple, l'anagramme $A_1NA_2GRA_3M_1M_2E$ de l'anagramme $A_2NA_1GRA_3M_1M_2E$. Ainsi, la lettre $A$ étant de multiplicité $3$ dans le mot ANAGRAMME, chacune des $3!=6$ permutations de cette lettre fournit exactement le même mot, de sorte que la numérotation de la lettre $A$ conduit à compter $6$ fois plus de permutations qu'il n'y en a en réalité. De même, la lettre $M$ est de multiplicité $2$, et donc en la numérotant on compte $2!=2$ fois plus de permutations qu'il y en a réellement. Finalement, on en déduit que le nombre d'anagrammes du mot ANAGRAMME est égal à $\frac{9!}{3!2!}=3\780$



### Arrangements


:::: {.defbox .def data-latex="important"}
<center>**Arrangements**</center> 
Soient $n$ et $0\leq k\leq n$ deux entiers naturels, et $E$ un ensemble à $n$ éléments. On appelle **arrangement** de $k$ éléments pris parmi les $n$ éléments de $E$, tout sous-ensemble **ordonné** à $k$ éléments de $E$. 
::::

\noindent De la même façon qu'on peut définir les permutations par la notion de bijection, on peut définir les arrangements par la notion d'injection :

:::: {.defbox .def data-latex="important"}
<center>**Définition équivalente des arrangements**</center>
Soient $n$ et $0\leq k\leq n$ deux entiers naturels, et $E$ un ensemble à $n$ éléments. Un **arrangement** de $k$ éléments pris parmi les $n$ éléments de $E$ peut aussi être vu comme une **injection** de $\{1,2,\dots, k\}$ dans $E$.
::::

\noindent

**Exemple.** Si $E=\{1,2,3\}$, les arrangements à $2$ éléments de $E$ sont les couples $(1,2), (1,3), (2,1), (2,3), (3, 1), (3,2)$. On utilise bien la notion de couple pour modéliser les arrangements car l'ordre a une importance : les arrangements $(1,2)$ et $(2,1)$ sont bien considérés comme différents. Il y a donc six arrangements de $2$ éléments de $E$. 

\noindent Plus généralement, on a une formule qui permet de calculer le nombre d'arrangements de $k$ éléments pris parmi $n$ éléments :

:::: {.thmbox .thm data-latex="important"}
**Théorème (nombre d'arrangements).** On note $A_n^k$ le nombre d'arrangements à $k$ éléments pris dans un ensemble à $n$ éléments. Alors, on a la formule :

$$A_n^k=\frac{n!}{(n-k)!}$$
::::

\noindent
**Remarque.** Ici aussi, le nombre d'arrangements à $k$ éléments pris dans un ensemble à $n$ éléments ne dépend que de $n$ (et de $k$).

\noindent
**Démonstration.** C'est exactement la même démarche que pour le dénombrement des permutations :

- $n$ façons de choisir le premier élément ;
- $n-1$ façons de choisir le deuxième élément ;
- ...
- $n-k+1$ façons de choisir l'élément numéro $k$.

\noindent D'après le principe multiplicatif on a donc :

\begin{align}
A_n^k &= n(n-1)\dots(n-k+1) \\
&= \frac{n!}{(n-k)!}
\end{align}

$\square$

\noindent

**Remarque.** Dans le cas où $k=n$, on a $A_n^n=n!$. Ce résultat était prévisible, puisqu'un arrangement de $n$ éléments parmi $n$ éléments est une injection de $\{1,2,\dots, n\}$ dans lui-même, autrement dit une **bijection** de $\{1,2,\dots,n\}$ dans lui-même. Il s'agit donc d'une permutation de $\{1,2,\dots,n\}$.

### Combinaisons


\noindent Les combinaisons sont l'équivalent **non ordonné** des arrangements :

:::: {.defbox .def data-latex="important"}
<center>**Combinaisons**</center>
Soient $n$ et $0\leq k\leq n$ deux entiers naturels, et $E$ un ensemble à $n$ éléments. On appelle **combinaison** de $k$ éléments pris parmi les $n$ éléments de $E$, tout sous-ensemble **non ordonné** à $k$ éléments de $E$. 
::::

\noindent 

**Exemples.** Si $E=\{1,2,3\}$, on a vu que les arrangements à $2$ éléments de $E$ sont les couples 
$$(1,2), (1,3), (2,1), (2,3), (3, 1), (3,2)$$
Du point de vue des combinaisons, les couples $(1,2)$ et $(2,1)$ (resp. $(1,3)$ et $(3,1)$, $(2,3)$ et $(3,2)$) sont considérés comme équivalents.

Il y a donc trois combinaisons à $2$ éléments de $E$ : 

$$\{1,2\}, \{1,3\} \text{ et } \{2,3\}$$

\noindent 
**Remarque.** Bien faire attention à la différence de notation : la notation avec parenthèses $(a_1, a_2,\dots, a_n)$ désigne un $n-$uplet, c'est-à-dire un objet ordonné. Alors que la notation ensembliste $\{a_1,a_2,\dots a_n\}$ désigne un objet non ordonné. On a donc, pour toute permutation $\sigma\in\mathfrak{S}_n$ différente de l'identité :

$$(a_{\sigma(1)},a_{\sigma(Z)},\dots, a_{\sigma_(n)})\neq (a_1,a_2,\dots, a_n)$$
\noindent mais

$$\{a_{\sigma(1)},a_{\sigma(Z)},\dots, a_{\sigma_(n)}\}=\{a_1,a_2,\dots, a_n\}$$

\noindent Comme pour les permutations et les arrangements, on a une formule simple pour compter les combinaisons :

:::: {.thmbox .thm data-latex="important"}
**Théorème (nombre de combinaisons).** Soient $n$ et $0\leq k\leq n$ des entiers naturels. Le nombre de combinaisons de $k$ éléments pris parmi les $n$ éléments d'un ensemnble $E$ quelconque est noté $C_n^k$ ou $\binom{n}{k}$. Ce nombre, appelé **coefficient binomial**, est égal à :

$$\binom{n}{k}=\frac{n!}{k!\,(n-k)!}$$

\noindent On peut aussi définir de façon cohérente le coefficient binomial pour $k$ et $n$ des entiers naturels avec $k>n$ en posant 

$$\binom{n}{k}=0$$

::::

\noindent

**Démonstration.** On commence par compter les arrangements de $k$ éléments parmi $n$ : il y en a $A_n^k=\frac{n!}{(n-k)!}$. Par ailleurs, toute combinaison $(a_1,\dots, a_k)$ de $k$ éléments parmi $n$ génère $k!$ arrangements distincts $(a_{\sigma(1)},\dots, a_{\sigma(k)})$ distincts $(\sigma\in\mathfrak{S}_k)$. Il y a donc $k!$ fois plus d'arrangements que de combinaisons. D'où :

\begin{align}
\binom{n}{k} &= \frac{A_n^k}{k!} \\
&= \frac{n!}{k!(n-k)!}
\end{align}

$\square$

\noindent Plusieurs formules impliquent les combinaisons :

:::: {.thmbox .thm data-latex="important"}
**Formules usuelles sur les combinaisons.** Soient $n$ et $0\leq k\leq n$ deux entiers naturels. Alors :

\noindent

**i. (Cas particuliers)** 
$$\binom{n}{0}=1$$
$$\binom{n}{n}=1$$
$$\binom{n}{1}=n$$
$$\binom{n}{2}=\frac{n(n-1)}{2}$$

\noindent 

**ii. (Complémentaire)** 

$$\binom{n}{k}=\binom{n}{n-k}$$

\noindent

**iii. (Triangle de Pascal)**

$$\binom{n}{k}+\binom{n}{k+1}=\binom{n+1}{k+1}$$
\noindent

**iv. (Formule du binôme de Newton)** Sous la convention $0^0=1$, pour $a$ et $b$ des réels quelconques et $n$ un entier naturel :

$$(a+b)^n=\sum\limits_{k=0}^n \binom{n}{k}a^k b^{n-k}$$

\noindent (si on rejette la convention $0^0=1$, alors la formule est toujours vraie sauf dans le cas où $n=0$ et $a=-b$).

\noindent En particulier, pour $a=b=1$ on obtient :

$$\sum\limits_{k=0}^n \binom{n}{k}=2^n$$
\noindent Pour $a=-1$ et $b=1$ on obtient :

$$\sum\limits_{k=0}^n (-1)^k\binom{n}{k}=0$$

\noindent Pour $a=x$ et $b=1$ on obtient :

$$\sum\limits_{k=0}^n \binom{n}{k}x^k=(x+1)^n$$

\noindent Pour $a=-1$ et $b=x$ on obtient :

$$\sum\limits_{k=0}^n \binom{n}{k}(-1)^kx^{n-k}=(x-1)^n$$

::::

\noindent 

**Démonstration. i.** $\binom{n}{0}=\frac{n!}{0!(n-0)!}=\frac{n!}{n!}=1$

\noindent L'égalité $\binom{n}{n}=1$ est une conséquence de la formule précédente et de la formule ii. qui va être montrée après.

\noindent $\binom{n}{1}=\frac{n!}{1!(n-1)!}=\frac{n(n-1)!}{(n-1)!}=n$

\noindent $\binom{n}{2}=\frac{n!}{2! (n-2)!}=\frac{n(n-1)(n-2)!}{2(n-2)!}=\frac{n(n-1)}{2}$

\noindent

\vspace{0.5cm}

**Autre méthode.** Soit $E=\{1,2, \dots, n\}$. Le seul sous-ensemble de $E$ à zéro élément est $\emptyset$, donc $\binom{n}{0}=1$. 

\noindent Le seul sous-ensemble de $E$ à $n$ éléments est $E$ lui-même, donc $\binom{n}{n}=1$.

\noindent Les seuls sous-ensembles de $E$ à un élément sont les $n$ singletons $\{1\}, \{2\}, \dots, \{n\}$, donc $\binom{n}{1}=n$.

\noindent Enfin, les sous-ensembles à deux éléments de $E$ sont :

\begin{align}
&\{1,2\}, \{1,3\}, \dots, \{1,n\} \\
&\{2,3\}, \dots ,\{2,n\} \\
&\dots \\
&\{n-1, n\}
\end{align}

\noindent Il y en a donc $n+(n-1)+\dots+1=\frac{n(n-1)}{2}$


\noindent

**ii.** 
\begin{align} 
\binom{n}{k}&=\frac{n!}{k!(n-k)!} \\
&=\frac{n!}{(n-k)! k!} \\
&=\frac{n!}{(n-k)!(n-(n-k))!} \\
&=\binom{n}{n-k}
\end{align}

\noindent 

**Autre méthode.** Choisir un sous-ensemble $F\subset E$ à $k$ éléments revient à choisir son complémentaire $\overline{F}$ dans $E$, qui contient $n-k$ éléments. Donc $\binom{n}{k}=\binom{n}{n-k}$.

\noindent

**iii.** 

\begin{align}
\binom{n}{k}+\binom{n}{k+1}&=\frac{n!}{k!(n-k)!}+\frac{n!}{(k+1)!(n-k-1)!} \\
&=\frac{n!(k+1)}{(k+1)!(n-k)!}+\frac{n!(n-k)}{(k+1)!(n-k)!} \\
&=\frac{n!(k+1+n-k)}{(k+1)!(n-k)!} \\
&=\frac{n!(n+1)}{(k+1)!(n-k)!} \\
&=\frac{(n+1)!}{(k+1)!((n+1)-(k+1))!} \\
&=\binom{n+1}{k+1}
\end{align}


\noindent

**Autre méthode.** On sépare les sous-ensembles à $k+1$ éléments de $E=\{1,2,\dots, n, n+1\}$  en deux parties disjointes :

- les sous-ensembles $F$ qui contiennent $n+1$. Ils sont de la forme $\{x_1,\dots, x_k\}\cup\{n+1\}$, et il y en a donc autant que de façons de choisir un sous-ensemble à $k$ éléments $\{x_1,\dots, x_k\}$ de l'ensemble $E'=\{1,2,\dots, n\}$, i.e. il y en a exactement $\binom{n}{k}$.

- les sous-ensembles $F$ qui ne contiennent pas $n+1$. Ils s'écrivent donc sous la forme $F=\{x_1,x_2,\dots, x_{k+1}\}$, avec les $x_{k+1}$ pris dans $E'=\{1,2,\dots, n\}$. Il y en a donc exactement $\binom{n}{k+1}$.

\noindent Commes ces deux parties sont disjointes, on peut appliquer le principe additif, pour affirmer que le nombre de sous-ensembles à $k+1$ éléments d'un ensemble à $n+1$ éléments est égal à $\binom{n}{k}+\binom{n}{k+1}$.

\noindent Par ailleurs, le nombre de sous-ensembles à $k+1$ éléments d'un ensemble à $n+1$ éléments est égal à $\binom{n+1}{k+1}$ (par défintion des coefficients binomiaux). D'où l'égalité $\binom{n}{k}+\binom{n}{k+1}=\binom{n+1}{k+1}$.


\noindent 

**iv.** On montre la formule par récurrence sur $n$. 

\noindent Pour $n=0$, cette formule s'écrit $(a+b)^0=\binom{0}{0}a^0b^0$, soit $1=1$ (sous la convention $0^0=1$, on a quel que soit $x$ réel, $x^0=1$).

\noindent Supposons la formule établie pour un entier naturel $n$ donné. Alors :

\begin{align}
(a+b)^{n+1} &= (a+b)(a+b)^n \\
&= (a+b).\sum\limits_{k=0}^n \binom{n}{k} a^k b^{n-k} \\
&\text{(d'après l'hypothèse de récurrence)} \\
&= \sum\limits_{k=0}^n \binom{n}{k} a^{k+1} b^{n-k}+\sum\limits_{k=0}^n \binom{n}{k} a^{k} b^{n-k+1} \\
&=\sum\limits_{k=1}^{n+1} \binom{n}{k-1} a^{k} b^{n-k+1}+\sum\limits_{k=0}^n \binom{n}{k} a^{k} b^{n-k+1} \\
&=\binom{n}{n} a^{n+1}+\sum\limits_{k=1}^n \left(\binom{n}{k-1}+\binom{n}{k}\right) a^kb^{n-k+1}+\binom{n}{0}b^{n+1} \\
&=a^{n+1}+\sum\limits_{k=1}^n \binom{n+1}{k} a^k b^{n+1-k} +b^{n+1} \\
&\text{(d'après la formule du triangle de Pascal)} \\
&= \sum\limits_{k=0}^{n+1}\binom{n+1}{k} a^k b^{n+1-k} \\
\end{align}

\noindent qui est la formule attendue au rang $n+1$.

\noindent

**Autre méthode.** En développant le produit $$(a+b)^n=(a+b).(a+b)\dots (a+b)$$
on obtient une somme de termes de la forme $a^kb^{n-k}$. Pour obtenir un tel terme, on doit choisir $k$ fois le terme $a$ parmi les $n$ facteurs $(a+b)$ (et donc, de façon complémentaire, $n-k$ fois le terme $b$ parmi ces mêmes facteurs). On en déduit, par définition des coefficients binomiaux, que le terme $a^kb^{n-k}$ apparaît exactement $\binom{n}{k}$ fois dans la somme. Autrement dit on a bien $(a+b)^n=\sum\limits_{k=0}^n \binom{n}{k}a^k b^{n-k}$.
$\square$

\noindent

**Remarques. i.** Comme souvent en analyse combinatoire, la démonstration d'une égalité peut se faire soit par le calcul, soit en utilisant une approche de dénombrement pur (qui en général est plus élégante mais peut-être un peu moins évidente à trouver).

\noindent

**ii.** La deuxième démonstration de la formule du triangle de Pascal repose sur une approche classique en dénombrement : compter la même chose de deux façons différentes. 


## Langage et formalisme des probabilités

\noindent On introduit maintenant les notions de base des probabilités. Le but est de construire progressivement un triplet de la forme

$$(\Omega, \mathcal{A},\mathbb{P})$$
\noindent où :

- $\Omega$ s'appellera l'**univers** ;

- $\mathcal{A}$ s'appellera une **tribu** :  dans le cadre du programme c'est en fait un mot que nous n'utiliserons quasiment jamais, et sauf cas particulier nous n'expliciterons pas cet élément ;

- $\mathbb{P}$ s'appellera une **probabilité**.

\noindent On va donc construire successivement :

- l'univers $\Omega$ ;

- l'espace probablisable $(\Omega, \mathcal{A})$, qui est un enrichissement de $\Omega$ ;

- l'espace probabilisé $(\Omega, \mathcal{A}, \mathbb{P})$, qui est un enrichissement de $(\Omega, \mathcal{A})$.


### L'univers $\Omega$ d'une expérience aléatoire

\noindent Tout commence avec la notion d'**expérience aléatoire**, i.e. une expérience dont l'issue est incertaine. La première chose à faire est de dresser la liste de tous les résultats potentiellement réalisables à lorsqu'on effectue une telle expérience. Un tel résultat s'appelle une **issue** ou un **événement élémentaire**. L'ensemble des issues est appelé **univers** de l'expérience, il est généralement noté $\Omega$.

\noindent

**Exemples. i. Lancer d'un dé cubique.** On note ses faces par des entiers de $1$ à $6$. Dans ce cas, l'univers $\Omega$ est fini et $$\Omega=\{1,2,3,4,5,6\}$$

**ii. Echantillonnage d'une population.** Afin d'estimer les revenus moyens au sein d'une population $\mathcal{U}=\{1,2,\dots, N\}$, on tire un échantillon aléatoire de taille $n$ au sein de cette population. Pour l'expérience aléatoire consistant à tirer un tel échantillon, l'univers $\Omega$ est l'ensemble de toutes les parties de $\mathcal{U}$ à $n$ éléments :

$$\Omega=\{S\in\mathcal{P}(\mathcal{U}), \, \text{Card }(S)=n\}$$

\noindent L'univers $\Omega$ est fini et

$$\text{Card }(\Omega)=\binom{N}{n}$$

\noindent

**iii. Répétition de lancers avec condition d'arrêt.** On lance une pièce dont les faces sont notées $P$ et $F$. On relance la pièce tant que PILE n'est pas obtenue. Les issues de cette expérience sont tous les lancers possibles. Comme on ne sait pas à l'avance combien de lancers vont être nécessaires pour stoper l'expérience, il s'agit bien d'une expérience aléatoire. Son univers est infini dénombrable : 

$$\Omega=\{P, FP, FFP, FFFP, \dots, FFFFFFFFFP, \dots \}$$

**iv. Nombre de lancers.** On reprend l'expérience précédente, mais cette fois on s'intéresse au nombre de lancers effectués. Il s'agit toujours d'une expérience aléatoire, mais cette fois :

$$\Omega=\{1,2,3,4,\dots, 1\,000,\dots\}=\mathbb{N}^*$$

\noindent L'univers est donc là aussi infini dénombrable.

**v. Durée de vie d'une lampe.** On observe la durée de vie d'une lampe, exprimée en jours. On peut à nouveau assimiler cette expérience à une expérience aléatoire. Cette fois, l'univers associé n'est ni fini ni dénombrable :

$$\Omega=[0\,;\,+\infty[=\mathbb{R}_+$$

### L'espace probabilisable $(\Omega, \mathcal{A})$

\noindent Souvent, on définira des événements plus complexes que les événements élémentaires, par exemple des événements composites comme l'événement A : *Le nombre obtenu est un nombre impair* ou encore l'événement B: *Le nombre obtenu est un nombre premier*.

\noindent Il faut donc enrichir l'univers $\Omega$ d'un ensemble qui décrit précisément quels sont les événements observables associés à une expérience aléatoire.


:::: {.defbox .def data-latex="important"}
<center>**Evénements, tribu, espace probabilisable**</center>

\noindent Soit $\Omega$ l'univers d'une expérience aléatoire. On appelle **tribu** sur $\Omega$ tout sous-ensemble de l'ensemble des parties de $\Omega$ :

$$\mathcal{A}\subset\mathcal{P}(\Omega)$$

\noindent vérifiant les propriétés suivantes :

- $\Omega\in\mathcal{A}$

- si $(A_n)_{n\in\mathbb{N}}$ est une famille finie ou dénombrable d'éléments de $\mathcal{A}$ (i.e. chacun des $A_n$ est un élement de $\mathcal{A}$), alors leur réunion est encore dans $\mathcal{A}$ :

$$\bigcup\limits_{n} A_n\in\mathcal{A}$$

- si $A\in\mathcal{A}$ alors $\overline{A}\in\mathcal{A}$.

\noindent Les éléments de $\mathcal{A}$ sont appelés des **événements** ou des **observables**. En particulier :

- $\Omega$ s'appelle l'**événement certain** ;

- Pour tout événement $A$, l'événement $\overline{A}$ s'appelle l'**événement contraire** de $A$.

\noindent On dit que le couple $(\Omega, \mathcal{A})$ est un **espace probabilsable**.
::::


\noindent La famille $\mathcal{A}$ formalise tous les observables relatifs à une expérience aléatoire, autrement dit tout ce qu'on est susceptible d'observer relativement à cette expérience (et dont on aimerait ensuite mesurer le niveau de crédibilité).


\noindent 

**Exemples.** On reprend les exemples i. à v. de la section précédente. Dans les exemples i. et ii., $\Omega$ est fini. Dans les exemples iii. et iv., $\Omega$ est infini dénombrable. Dans ce cas on peut prendre $\mathcal{A}=\mathcal{P}(\Omega)$, comme c'est l'usage pour les univers finis ou dénombrables.

\noindent L'exemple v. est plus complexe car $\Omega$ est infini et **non dénombrable**. On pourrait prendre $\mathcal{A}=\mathbb{P}(\Omega)$, mais cela ferait une tribu extrêmement grande, sur laquelle il serait certainement plus difficile par la suite de définir une probabilté. Dans ce genre de cas, on essaie en général de réduire la taille de la tribu à quelque chose de plus raisonnable. De manière un peu floue, on définit une classe d'événemenents que l'on aimerait pouvoir mesurer (i.e. dont on aimerait pouvoir calculer la probabilité) et on définit notre tribu comme *la plus petite tribu* contenant cette classe d'ensembles (on parle alors de *tribu engendrée*). Dans le cas présent, comme souvent lorsque $\Omega$ est un sous-ensemble de $\mathbb{R}$ non dénombrable, on prend pour $\mathcal{A}$ la tribu engendrée par les *ouverts* de $\mathbb{R_+}$. Une telle tribu s'appelle une *tribu borélienne* (plus généralement, pour un espace topologique $(X, \mathcal{T})$ donné, la tribu borélienne est définie comme la tribu engendrée par les ouverts de cette topologie, i.e. les éléments de $\mathcal{T}$). Il est difficile, pour ne pas dire impossible, de se représenter exactement à quoi cette tribu ressemble. En pratique, on s'y intérresse de toute façon assez peu. Tout cela étant largement hors-programme du concours d'administrateur, vous n'aurez pas du tout à vous en soucier dans votre préparation !

\noindent

**D'autres exemples. i. Lancer d'une pièce.** L'univers associé au lancer d'une pièce est $\Omega=\{P,F\}$. On pose $\mathcal{A}=\left\{\emptyset, \{P\},\{F\}, \{P,F\}\right\}=\mathcal{P}(\Omega)$. Alors, $\mathcal{A}$ est une tribu et donc le couple $(\Omega, \mathcal{A})$ est un espace probabilisable.

\noindent

**ii.** Si $\Omega=\{1,2,3,4\}$ alors $\mathcal{A}=\left\{\emptyset, \{1\}, \{2,3,4\}, \Omega\right\}$ est une tribu. $\mathcal{A}'=\left\{\emptyset, \{1,2\}, \{3, 4\}, \Omega\right\}$ est une autre tribu.

\noindent 

**Remarques. i.** Pour tout ensemble $\Omega$ modélisant l'univers d'une expérience aléatoire, on peut toujours poser $\mathcal{A}=\mathcal{P}(\Omega)$ et défnir ainsi une tribu, et donc un espace probabilisable $(\Omega, \mathcal{P}(\Omega))$. C'est d'ailleurs assez souvent ce qui est fait lorsque l'ensemble $\Omega$ est fin ou dénombrable. Une telle tribu s'appelle la **tribu discrète**. Il s'agit de la plus grande tribu (au sens de l'inclusion) sur $\Omega$.

\noindent 

**ii.** On peut aussi définir la **tribu grossière** : 

$$\mathcal{A}=\{\emptyset, \Omega\}$$

\noindent Il s'agit de la plus petite tribu (au sens de l'inclusion) sur $\Omega$.


\noindent

**iii.** Même si la notion de tribu n'est pas explicitement au programme (voire même est explicitement hors-programme), il faut tout de même retenir que la notion d'événement est *stable* par réunion dénombrable et par passage au complémentaire. Autrement dit :

- on est toujours capable d'observer la survenue ou non de $\emptyset$ et $\Omega$ ;

- si on est capable d'observer la survenue d'un événement $A$, alors on est capable d'observer la survenue de l'événement contraire $\overline{A}$ ;

- si on est capable, pour tout entier naturel $n$, d'observer la survenue d'un événement $A_n$, alors on est capable d'observer la survenue de la réunion dénombrable $\bigcup\limits_{n\in\mathbb{N}} A_n$ (et donc, à plus forte raison on est capable d'observer la survenue d'une réunion finie $\bigcup\limits_{n=0}^N A_n$, puisqu'une réunion finie de $0$ à $N$ est un cas particulier d'une réunion finie sur $\mathbb{N}$ en posant $A_n=\emptyset$ pour $n\geq N+1$).

\noindent On peut en fait aller un peu plus loin : 

:::: {.thmbox .thm data-latex="important"}

\noindent

**Stabilité de la notion d'événement.** La notion d'événement est stable par toute opération de réunion finie ou dénombrable, d'intersection finie ou dénombrable et par passage au complémentaire. Autrement dit, si $(A_n)_{n\in \mathcal{I}}$ est une suite d'événements finie (cas où $\mathcal{I}$ est fini) ou infinie dénombrable (cas où $\mathcal{I}$ est infini dénombrable), alors $\bigcup\limits_{n\in\mathcal{I}} A_n$, $\bigcap\limits_{n\in\mathcal{I}} A_n$ et les $\overline{A_n}$ sont des événements.
::::

\noindent

**Démonstration.** La notion d'événement est, par définition, stable par réunion dénombrable et par passage au complémentaire. Il reste donc à démontrer qu'elle est aussi stable par intersection dénombrable. Or

$$\bigcap\limits_{n\in\mathcal{I}} A_n=\overline{\bigcup\limits_{n\in\mathcal{I}}\overline{A_n}}$$

\noindent En effet, d'après l'une des lois de Morgan on a

$$\overline{\bigcup\limits_{n\in\mathcal{I}}\overline{A_n}}=\bigcap\limits_{n\in\mathcal{I}} \overline{\overline{A_n}}$$

\noindent et comme $\overline{\overline{A_n}}=A_n$ on en déduit l'égalité annoncée. 

\noindent Par ailleurs :

- pour tout $n$ dans $\mathcal{I}$, $\overline{A_n}$ est un événement (stabilité par passage au complémentaire) 

- donc $\bigcup\limits_{n\in\mathcal{I}}\overline{A_n}$ est un événement  (stabilité par réunion dénombrable)

- d'où l'on déduit que $\overline{\bigcup\limits_{n\in\mathcal{I}}\overline{A_n}}$ est aussi un événement (stabilité par passage au complémentaire)

\noindent Avec l'égalité démontrée plus haut, on obtient finalement que $\bigcap\limits_{n\in\mathcal{I}} A_n$ est un événement.

$\square$


\noindent 

**Conséquence.** Cette proposition a pour conséquence immédiate que si les $(A_n)_{n\in \mathcal{I}}$ forment une suite finie ou dénombrable d'événements, alors toute combinaison - aussi complexe sot-elle - de ces événements à partir des opérateurs $\bigcup, \bigcap$ et de passage au complémentaire est encore un événement. Par exemple :

- $\overline{\bigcup_{n\in\mathcal{I}}\bigcap_{k\geq n}\overline{A_k}}$ est encore un événement ;

- $\bigcap\limits_{n\in\mathcal{I}}\overline{\bigcup_{k\leq 2n} \overline{A_k}}$ est encore un événement ;

- $\bigcup\limits_{n\in\mathcal{I}}\bigcup\limits_{5\leq p\leq n}\bigcap\limits_{k\geq p}\bigcup\limits_{l\leq k}\overline{A_l}$ est encore un événement.

\nondent On voit maintenant des exemples de combinaisons d'événements qui reviennent fréquemment dans les sujets du concours d'administrateur :

:::: {.defbox .def data-latex="important"}
<center>**Exemples classiques d'événements complexes**</center>

\noindent Soit $A_1,A_2,\dots,A_n,\dots$ une suite d'événements.

- $\bigcup\limits_{n=1}^{\infty}A_n$ est l'événement *L'un au moins des $A_n$ est réalisé*

- $\bigcup\limits_{n=1}^{\infty}\overline{A_n}$ est l'événement *L'un au moins des $A_n$ n'est pas réalisé*

- $\bigcap\limits_{n=1}^{\infty}A_n$ est l'événement *Tous les $A_n$ sont réalisés*

- $\bigcap\limits_{n=1}^{\infty}\overline{A_n}$ est l'événement *Aucun $A_n$ n'est réalisé*

- $\bigcup\limits_{n=0}^{\infty}\bigcap\limits_{k\geq n}A_k$ est l'événement *Tous les $A_n$ sont réalisés à partir d'un certain rang*. Cet événement est aussi la **limite inférieure** des $A_n$ :

$$\lim\inf\limits_{n\to\infty}A_n=\bigcup\limits_{n=0}^{\infty}\bigcap\limits_{k\geq n}A_k$$

- $\bigcap\limits_{n=0}^{\infty}\bigcup\limits_{k\geq n}A_k$ est l'événement *Les $A_n$ sont réalisés un nombre infini de fois*. Cet événement est aussi la **limite supérieure** des $A_n$ :

$$\lim\sup\limits_{n\to\infty}A_n=\bigcap\limits_{n=0}^{\infty}\bigcup\limits_{k\geq n}A_k$$
::::

\noindent 

**Exercice.** Ecrire l'événement *Les $A_n$ ne sont réalisés qu'un nombre fini de fois* à partir des $\overline{A_k}$.

\noindent

**Solution.** Soit $B$ l'événement *Les $A_n$ ne sont réalisés qu'un nombre fini de fois*. 

\noindent Avec ce qui précède, on a, par application des lois de Morgan :

\begin{align}
B &= \overline{\bigcap\limits_{n\to\infty}\bigcup\limits_{k\geq n}A_k} \\
&= \bigcup\limits_{n\to\infty}\bigcap\limits_{k\geq n}\overline{A_k}
\end{align}


\noindent



### L'espace probabilisé $(\Omega, \mathcal{A}, \mathbb{P})$

\noindent Maintenant qu'on a défini la notion d'événement, on a envie de pouvoir mesurer le niveau de crédibilité de survenue d'un événement donné. Pour cela, on part d'une expérience aléatoire et on définit une application sur l'ensemble de tous les événements associés à cette expérience, et à valeurs dans $[0,1]$. Cela revient à enrichir l'espace probabilisable $(\Omega, \mathcal{A})$ pour le transformer en un espace *probabilisé* $(\Omega, \mathcal{A}, \mathbb{P})$ : 

:::: {.defbox .def data-latex="important"}
<center>**Probabilité, espace probabilisé**</center>

\noindent

Soit $(\Omega,\mathcal{A})$ un espace probabilisable.

\noindent On appelle **probabilité** (ou **mesure de probabilité**) sur cet espace toute application $$\mathbb{P}:\mathcal{A}\longrightarrow [0,1]$$ vérifiant les axiomes suivants :

- **L'univers est certain : ** $\mathbb{P}(\Omega)=1$ 

- **$\sigma-$additivité : ** si $(A_n)_n$ est une suite d'événements **deux à deux incompatibles** (i.e. si $A_n\cap A_p=\emptyset$ dès que $n\neq p$) alors la série $\sum\limits_{n}\mathbb{P}(A_n)$ est convergente et 

$$\mathbb{P}\left(\bigcup\limits_{n\to\infty}A_n\right)=\sum\limits_{n=0}^{\infty}\mathbb{P}(A_n)$$

\noindent On dit alors que le triplet $(\Omega, \mathcal{A}, \mathbb{P})$ est un **espace probabilisé**.
::::

\noindent 

**Remarque.** Le $\sigma$ de la $\sigma-$additivité fait référence au caractère infini de la propriété additivité. On peut aussi parler d'additivité (sans le $\sigma$) d'une application $P$ mais dans ce cas on parle plutôt d'une application $P$ telle que 

$$P\left(\bigcup\limits_{n=0}^N A_n\right)=\sum\limits_{n=0}^N P(A_n)$$
\noindent La $\sigma-$additivité est  strictement plus forte que l'additivité :

$$(P \text{ est } \sigma-\text{ additive}) \Rightarrow (P \text{ est additive})$$

$$\text{mais}$$

$$(P \text{ est additive}) \not\Rightarrow (P \text{ est } \sigma-\text{ additive})$$

\noindent Comme on souhaite considérer des événements composites s'écrivant comme réunion disjointe d'un nombre *infini* d'événements, il est plus naturel d'exiger d'une mesure de probabilité la propriété de $\sigma-$additivité.

\noindent On déduit de façon immédiate un certain nombre de propriétés des mesures de probabilité :

:::: {.thmbox .thm data-latex="important"}
<center>**Propriétés élémentaires des mesures de probabilité**</center>

\noindent Soit $(\Omega, \mathcal{A}, \mathbb{P})$ un espace probabilisé. Alors :

- **L'événement impossible est de probabilité nulle.** Autrement dit : $$\mathbb{P}(\emptyset)=0$$

- **Probabilité de l'événement complémentaire.** Pour tout événement $A$, la probabilité de l'événement complémentaire $\overline{A}$ est donnée par

$$\mathbb{P}(\overline{A})=1-\mathbb{P}(A)$$

- **Croissance de la probablité.** Soient $A$ et $B$ deux événements tels que $A\subset B$. Alors :

$$\mathbb{P}(A)\leq\mathbb{P}(B)$$

- **Crible de Poincaré.** Soient $A$ et $B$ deux événements tels que $A\subset B$. Alors :

$$\mathbb{P}(A\cup B)=\mathbb{P}(A)+\mathbb{P}(B)-\mathbb{P}(A\cap B)$$

\noindent Plus généralement, étant donné une suite finie $A_1,A_2,\dots A_n$ d'événements, on a la formule

$$\mathbb{P}\left(\bigcup\limits_{k=1}^{n} A_k\right)=\sum\limits_{k=1}^{n}(-1)^{k+1}\sum\limits_{1\leq i_1<i_2<\dots <i_k}\mathbb{P}\left(\bigcap\limits_{j=1}^k A_{i_j}\right)$$

::::

\noindent 

**Démonstration.** 

- Pour tout événement $A$, $A$ et $\overline{A}$ sont incompatibles, et par ailleurs $A\cup\overline{A}=\Omega$, donc :

\begin{align}
1 &= \mathbb{P}(\Omega) \\
&= \mathbb{P}(A\cup\overline{A}) \\
&= \mathbb{P}(A)+\mathbb{P}(\overline{A})
\end{align}

\noindent et donc on a bien 

$$\mathbb{P}(\overline{A})=1-\mathbb{P}(A)$$
\noindent Par ailleurs, comme $\emptyset=\overline{\Omega}$ et $\mathbb{P}(\Omega)=1$, on en déduit que 

$$\mathbb{P}(\emptyset)=0$$

- la formule du crible de Poincaré se démontre exactement comme la formule déjà vue pour le cardinal. Le point important de la démonstration - celui qui fait que tout fonctionne bien - dans la formule avec le cardinal est le fait que l'application *cardinal* :

$$\text{Card }:A\in\mathcal{A}\mapsto\text{Card }(A)$$

est additive. Or, l'additivité (et même la $\sigma-$additivité) est au coeur même de la construction des probabilités : l'application

$$\mathbb{P}:A\in\mathcal{A}\longrightarrow\mathbb{P}(A)$$
\noindent est elle aussi additive (et même $\sigma-$additive). Donc la démonstration de la formule de Poincaré pour les probabilités est une recopie exacte de celle pour les cardinaux, en remplaçant simplement l'application $\text{Card}$ par l'application $\mathbb{P}$.

- enfin, soient $A$ et $B$ des événements tels que $A\subset B$. Alors :

$$B= A\cup (B\cap\overline{A})$$
$$A\cap(B\cap\overline{A})=\emptyset$$
\noindent Avec ce qui précède on a donc

\begin{align}
\mathbb{P}(B) &= \mathbb{P}(A)+\mathbb{P}(B\cap\overline{A}) \\
& \geq\mathbb{P}(A)
\end{align}

\noindent car $\mathbb{P}(B\cap\overline{A})\geq 0$ (une probabilté est toujours positive).

\noindent D'où le résultat.

$\square$

\noindent Un cas particulier important est celui de l'**équiprobabilité** :

:::: {.thmbox .def data-latex="important"}
<center>**Equiprobabilité**</center>
\noindent Soit $(\Omega, \mathcal{A}, \mathbb{P})$ un espace probabilisé tel que $\Omega$ soit fini à $n$ éléments. On dit qu'il y a **équiprobabilité** lorsque toutes les probabilités des événements élémentaires $\{\omega\}, \omega\in\Omega$ sont égales. Dans ce cas on a :

$$\forall\omega\in\Omega, \,\mathbb{P}(\{\omega\})=\frac{1}{n}$$
\noindent et plus généralement :

$$\text{Pour tout événement } A, \,\mathbb{P}(A)=\frac{\text{Card }(A)}{\text{Card }(\Omega)}=\frac{\text{Card }(A)}{n}$$
::::

\noindent

**Démonstration.** On note $\Omega=\{\omega_1,\dots,\omega_n\}$ et $p$ la probabilité commune des événements élémentaires $\{\omega_i\}$. Les $\{\omega_i\}$ étant deux à deux incompatibles, on a alors :

\begin{align}
1 &= \mathbb{P}(\Omega) \\
&= \mathbb{P}\left(\bigcup\limits_{i=1}^n \{\omega_i\}\right) \\
&= \sum\limits_{i=1}^n \mathbb{P}(\{\omega_i\}) \\
&= \sum\limits_{i=1}^n p \\
&= np \\
\end{align}

\noindent et donc 

$$\forall i\in\{1,\dots,n\}, \,\mathbb{P}(\{\omega_i\})=\frac{1}{n}$$
\noindent Soit maintenant $A=\{\omega_{i_1},\dots,\omega_{i_k}\}$ un événement (son cardinal est donc égal à $k$). Par un raisonnement analogue, on a :

\begin{align}
\mathbb{P}(A) &= \mathbb{P}\left(\bigcup\limits_{j=1}^k \{\omega_{i_j}\}\right) \\
&= \sum\limits_{j=1}^k \mathbb{P}(\{\omega_{i_j}\}) \\
&= \sum\limits_{i=1}^k \frac{1}{n}  \\
&= \frac{k}{n} \\
&= \frac{\text{Card }(A)}{\text{Card }(\Omega)} \\
\end{align}


$\square$

\noindent Cette formule montre donc que, en situtation d'équiprobabilité, calculer des probabilités revient à dénombrer. C'est typiquement la façon dont les probabilités étaient introduites avant dans les classes de lycée, avec les applications classiques  sur les  cartes, les boules dans des urnes, etc. 

\noindent

**Remarque.** Lorsqu'on effectue un tirage alétoire dans un ensemble fini de façon équiprobable, on dit souvent qu'on effectue un *tirage au hasard*.

\noindent

**Exemples. i. Course hippique.** Lors d'une course hippique, on suppose que les $n$ chevaux au départ ont la même probabilité de gagner. Quelle est la probabilité d'avoir un tiercé gagnant avec un ticket :

- dans l'ordre d'arrivée ?
- dans l'ordre d'arrivée ou dans un ordre différent ?
- dans un ordre différent ?

\noindent

**Solution.** On calcule d'abord le nombre de tiercés possibles. C'est le nombre de façons ordonnées de choisir tros chevaux parmi un ensemble de $n$ chevaux. Il y en a donc 

\begin{align}
A_n^3 &= \frac{n!}{(n-3)!} \\
&= n(n-1)(n-2) \\
\end{align}

- il n'y a qu'un seul tiercé gagnant dans l'ordre, la probabilité $p_1$ cherchée est 

$$p_1=\frac{1}{n(n-1)(n-2)}$$
- le nombre de tiercés gagnant dans l'ordre ou dans un ordre différent est égal au nombre de permutations d'un ensemble à trois éléments, soit $3!=6$. La probabilité $p_2$ cherchée est donc égale à 

$$p_2=\frac{6}{n(n-1)(n-2)}$$

- le nombre de tiercés gagnants dans le désordre est $6-1=5$ donc la probabilité $p_3$ cherchée est 

$$p_3=\frac{5}{n(n-1)(n-2)}$$

**ii. Permutations avec $n-2$ points fixes.** Soit $n$ entier naturel tel que $n\geq 3$. On tire au hasard une permutation aléatoire $\sigma$ de $\mathfrak{S}_n$. Quelle est la probablité qu'elle ait exactement $n-2$ points fixes ? (on dit qu'un entier $i\in\{1,2,\dots, n\}$ est un point fixe de $\sigma$ lorsque $\sigma(i)=i$).

\noindent

**Solution.** Soit $A_n$ l'événement *La permutation $\sigma$ a exactement $n-2$ points fixes*.

\noindent Choisir une telle permutation $\sigma$ revient exactement à :

- choisir $n-2$ points fixes parmi les $n$ entiers de $1$ à $n$ : il y a $\binom{n}{n-2}=\binom{n}{2}=\frac{n(n-1)}{2}$ choix possibles ;

- choisir les deux points non fixes : mais le choix des $n-2$ points fixes à l'étape précédente détermine de façon unique celui des deux points restants ;

- choisir les images des entiers $1,2,\dots, n$. Mais une fois qu'on a fait les choix précédents, il n'y a plus qu'une seule permutation $\sigma$ qui convienne :

  - pour les $n-2$ points fixes $i_1, i_2,\dots i_{n-2}$ on a, par définition $\sigma(i_j)=i_j$ ;
  
  - pour les deux points $(i_{n-1}, i_n)$ qui ne sont pas fixes, on a $\sigma(i_{n-1})=i_n$ et $\sigma(i_n)=i_{n-1}$.
  
\noindent D'après le principe multiplicatif, il y a donc $\frac{n(n-1)}{2}$ permutations de $\mathfrak{S}_n$ à $n-2$ points fixes. 

\noindent Par ailleurs, il y a exactement $n!$ permutations de $\mathfrak{S}_n$.

\noindent On en déduit que 

$$\mathbb{P}(A_n)=\frac{n(n-1)}{2\,n!}=\frac{1}{2\,(n-2)!}$$

## Indépendance

:::: {.defbox .def data-latex="important"}
<center>**Indépendance de deux événements**</center>

\noindent Soit $(\Omega, \mathcal{A},\mathbb{P})$ un espace probabilisé. Deux événements $A$ et $B$ sont dits **indépendants** si $\mathbb{P}(A\cap B)=\mathbb{P}(A)\,\mathbb{P}(B)$.
::::

\noindent 

**Remarque.** La notion d'indépendance est relative à un espace probabilisé $(\Omega, \mathcal{A},\mathbb{P})$. Dit autrement, si on a deux espaces probabilisés $(\Omega, \mathcal{A},\mathbb{P})$ et $(\Omega', \mathcal{A}',\mathbb{P}')$ et $A$ et $B$ qui sont des événements pour ces deux espaces probabilisés à la fois, alors $A$ et $B$ peuvent être indépendants pour l'un des espaces mais pas pour l'autre. Cela peut notamment arriver si on prend deux mesures de probabilité dfférentes $\mathbb{P}$ et $\mathbb{P}'$ pour un même espace probabilisable $(\Omega, \mathcal{A})$. 


\noindent

**Exemple.** On lance deux dés cubiques équilibrés. On note :

- $A$ l'événement *La somme des deux numéros obtenus est 7*
- $B$ l'événement *Le produit des deux nombres obtenus est 6*.

\noindent Les événements $A$ et $B$ sont-ils indépendants ?

\noindent

**Solution.** L'univers $\Omega$ de cette expérience aléatoire est $\Omega=\{1,2,3,4,5,6\}^2$, de cardinal $36$. Par ailleurs : 

$$A=\{(1,6),(2,5),(3,4),(4,3),(5,2), (6,1)\}$$
$$B=\{(1,6), (2,3), (3,2), (6,1)\}$$
$$A\cap B=\{(1,6), (6,1)\}$$

\noident Les dés étant équililibrés, les événements élémentaires de $\Omega$ ont tous la même probabilité $p=\frac{1}{36}$, donc :

$$\mathbb{P}(A\cap B)=\frac{2}{36}=\frac{1}{18}$$
$$\mathbb{P}(A)\mathbb{P}(B)=\frac{6}{36}\frac{4}{36}=\frac{1}{54}$$
\noindent Donc, $\mathbb{P}(A\cap B)\neq\mathbb{P}(A)\mathbb{P}(B)$ : les événements $A$ et $B$ ne sont pas indépendants.

\noindent Si on considère plus de deux événements, on peut définir deux notions d'indépendance :

:::: {.defbox .def data-latex="important"}
<center>**Indépendance mutuelle, indépendance deux à deux**</center>

\noindent Soient $(\Omega, \mathcal{A}, \mathbb{P})$ un espace probabilisé et $A_1,\dots A_m$ des événements. 

- $A_1,\dots, A_m$ sont dits **mutuellement indépendants** lorsque pour toute partie $\{i_1,\dots i_p\}\subset\{1,\dots, m\}$ on a 

$$\mathbb{P}\left(\bigcap\limits_{j=1}^p A_{i_j}\right)=\prod\limits_{j=1}^p\mathbb{P}(A_{i_j})$$

-  $A_1,\dots, A_m$ sont dits **deux à deux indépendants** lorsque pour tout couple $(j,k)\in\{1,\dots, m\}^2$ tel que $j\neq k$, on a

$$\mathbb{P}(A_j\cap A_k)=\mathbb{P}(A_j)\mathbb{P}(A_k)$$
::::

\noindent

**Remarques. i.** L'indépendance mutuelle est une notion plus forte que l'indépendance deux à deux :

- l'indépendance deux à deux dit que pour toute partie $\{i_1, i_2\}\subset\{1,\dots, m\}$, $\mathbb{P}(A_{i_1}\cap A_{i_2})=\mathbb{P}(A_{i_1})\mathbb{P}(A_{i_2})$, alors que l'indépendance mutuelle généralise ce type d'égalité à un nombre $p$ quelconque d'événements, $p$ étant compris entre $1$ et $n$. Autrement dit, l'indépendance mutuelle implique l'indépendance deux à deux.

- on peut trouver des exemples où trois événements $A_1, A_2, A_3$ sont deux à deux indépendants sans être mutuellement indépendants. Si on lance une pièce équilibrée deux fois, et que l'on note 

- $A_1$ l'événement *Obtenir PILE au premier lancer*
- $A_2$ l'événement *Obtenir FACE au deuxième lancer*
- $A_3$ l'événement *Obtenir le même résultat aux deux lancers*

\noindent alors on a 

$$\mathbb{P}(A_1)=\mathbb{P}(A_2)=\mathbb{P}(A_3)=\frac{1}{2}$$
$$\mathbb{P}(A_1\cap A_2)=\mathbb{P}(A_1\cap A_3)=\mathbb{P}(A_2\cap A_3)=\frac{1}{4}$$
$$\mathbb{P}(A_1\cap A_2\cap A_3)=0$$

\noindent Ainsi, pour $i\neq j$ :

$$\mathbb{P}(A_i\cap A_j)=\mathbb{P}(A_i)\mathbb{P}(A_j)=\frac{1}{4}$$
donc $A_1,A_2,A_3$ sont deux à deux indépendants. 

\noindent Mais 

$$\mathbb{P}(A_1\cap A_2\cap A_3)=0\neq\mathbb{P}(A_1)\mathbb{P}(A_2)\mathbb{P}(A_3)=\frac{1}{8}$$

\noindent donc $A_1, A_2, A_3$ ne sont pas mutuellement indépendants. 

\noindent L'indépendance deux à deux n'implique donc pas nécessairement l'indépendance mutuelle.

\noindent 

**ii.** Ces deux notions coïncident cependant de façon évidente pour deux événements.


## Probabilités conditionnelles

\noindent Supposons qu'on lance deux dés équilibrés et que l'on relève leurs numéros respectifs. La probabilité que leur somme soit égale à $8$ est égale à $\frac{5}{36}$. Si maintenant quelqu'un nous dit que leur produit est égal à $12$, alors avec la connaissance de cette information supplémentaire cette probabilité monte à $\frac{1}{2}$.

\noindent Dans le premier cas, l'univers est $\Omega=\{1,2,3,4,5,6\}^2$ (de cardinal $36$) et l'événement $A=$ *La somme vaut $8$* est réalisé par les couples $(2,6), (3,5), (4,4), (5,3)$ et $(6,2)$, et il est donc de cardinal $5$. Donc on a bien $\mathbb{P}(A)=\frac{5}{36}$.

\noindent Dans le second cas, l'information sur le produit nous fait changer d'univers. Le nouvel univers est l'événement $B=$ *Le produit vaut 12* $=B=\{(2,6), (3,4), (4,3), (6,2)\}$, de cardinal $4$. Dans ce nouvel univers, l'événement $A$ est réalisé par deux couples de $B$ : $(2, 6)$ et $(6, 2)$. La probabilité de $A$ est donc mise à jour suite à l'information apportée par la réalisation de $B$. Cette nouvelle probabilité est notée $\mathbb{P}(A|B)$ et elle vaut donc $\mathbb{P}(A|B)=\frac{1}{2}$. 

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/somme_des.png") 
```
</center>

\noindent Comment l'a-t'on-calculée ?

- on a compté le cardinal $\text{Card }(B)$ du nouvel univers $B$ ;

- on a compté le nombre d'événements élémentaires de $B$ qui réalisent l'événement $A$, autrement dit on a compté $\text{Card }(A\cap B)$ ;
- étant en situation d'équiprobabilité, on a calculé $\mathbb{P}(A|B)=\frac{\text{Card }(A\cap B)}{\text{Card }(B)}$, que l'on peut aussi écrire

$$\mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}$$
\noindent La définition qui suit est une extension de cette formule au cas général, i.e. sans faire d'hypothèse d'équirépartition des événements élémentaires.

:::: {.defbox .def data-latex="important"}
<center>**Probabilité conditionelle**</center>

\noindent Soient $(\Omega, \mathcal{A}, \mathbb{P})$ un espace probabilisé, et $A$ et $B$ deux événements tels que $\mathbb{P}(B)>0$. On appelle **probabilité conditionnelle de $B$ sachant $A$**, ou encore **probabilité de $B$ conditionnellement à $A$**, le nombre 

$$\mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}$$
\noindent Cette probabilité conditionnelle est parfois aussi notée $\mathbb{P}_B(A)$.
::::

\noindent Une probabilité conditionnelle est en fait une probabilité comme une autre :

:::: {.thmbox .def data-latex="important"}
\noindent

**Théorème.** Avec les notations précédentes, l'application

$$\mathbb{P}(\,.\,|B):A\in\mathcal{A}\mapsto\mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}$$
\noindent est une mesure de probabilité sur l'espace probabilisable $(\Omega, \mathcal{A})$ (et donc, $(\Omega, \mathcal{A}, \mathbb{P}(\,.\,|B))$ est un espace probabilisé).
::::

\noindent

**Démonstation.** Tout d'abord, on a 

\begin{align}
\mathbb{P}(\Omega|B) &= \frac{\mathbb{P}(\Omega\cap B)}{\mathbb{P}(B)} \\
&= \frac{\mathbb{P}(B)}{\mathbb{P}(B)} \\
&= 1
\end{align}

\noindent Par ailleurs, pour $(A_n)_n$ une suite d'événements deux à deux incompatibles, on a 

\begin{align}
\mathbb{P}\left(\bigcup\limits_{n=0}^{\infty} A_n\vert B\right) &=\frac{\mathbb{P}\left(\left(\bigcup\limits_{n=0}^{\infty} 
A_n\right)\cap B\right)}{\mathbb{P}(B)} \\
&=\frac{\mathbb{P}\left(\bigcup\limits_{n=0}^{\infty} \left(A_n\cap B\right)\right)}{\mathbb{P}(B)} \\
&= \frac{\sum\limits_{n=0}^{\infty}\mathbb{P}\left(A_n\cap B\right)}{\mathbb{P}(B)} \\
& \text{(car les } A_n\cap B \text{ sont deux à deux incompatibles)} \\
&=\sum\limits_{n=0}^{\infty}\frac{\mathbb{P}\left(A_n\cap B\right)}{\mathbb{P}(B)} \\
&=\sum\limits_{n=0}^{\infty}\mathbb{P}\left(A_n | B\right)
\end{align}

\noindent D'où le résultat.

$\square$

\noindent 

**Remarques. i.** On vient de montrer qu'une probabilité conditionnelle est une probabilité. La réciproque est également vraie : une probabilité est une probabilité conditionnelle. Plus précisément, pour tout espace probabilisé $(\Omega, \mathcal{A}, \mathbb{P})$, on a 

$$\mathbb{P}=\mathbb{P}(\,.\,\vert\Omega)$$

\noindent Les probabilités et les probabilités conditionnelles sont donc exactement les mêmes objets. Conditionner par $A$, c'est juste passer d'un univers $\Omega$ à l'univers $A$.

\noindent 

**ii.** Puisqu'une probabilité conditionnelle est une probabilité, toutes les propriétés des probabilités sont également vraies pour les probabilités conditionnelles. Par exemple, si $A$ et $B$ sont deux événements tels que $\mathbb{P}(B)>0$ (ce qui autorise à conditionner par $A$), alors $\mathbb{P}(\overline{A}\vert B)=1-\mathbb{P}(A\vert B)$.

\noindent

**iii.** Dans l'expression $\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}$, la partie $A$ que l'on mesure apparaît uniquement au numérateur. Le terme au dénominateur est uniquement un facteur de normalisation, qui permet de s'assurer que l'application $A\in\mathcal{A}\mapsto\mathbb{P}(A\vert B)$ somme bien à $1$.



\noindent La notion d'indépendance présentée plus haut s'interprète de façon très intuitive :

:::: {.thmbox .def data-latex="important"}
**Théorème (indépendance et conditionnement).** Soient $(\Omega, \mathcal{A}, \mathbb{P})$ un espace probabilisé, et $A$ et $B$ deux événements tels que $\mathbb{P}(A)>0$ et $\mathbb{P}(B)>0$. Alors :

$$\text{(}A \text{ et } B \text{ sont indépendants )} \Leftrightarrow\text{( }\mathbb{P}(A\vert B)=\mathbb{P}(A) \text{ et } \mathbb{P}(B\vert A)=\mathbb{P}(B)\text{ )}$$
::::

\noindent Autrement dit, dire que $A$ et $B$ sont indépendants revient à dire que l'information apportée par la survenue de l'un de ces deux événements n'affecte en rien celle de la survenue de l'autre.

\noindent 

**Démonstration.** Supposons $A$ et $B$ indépendants. Alors 

\begin{align}
\mathbb{P}(A\vert B) &= \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)} \\
&= \frac{\mathbb{P}(A)\mathbb{P}(B)}{\mathbb{P}(B)} \\
& \text{(par indépendance de} A \text{ et } B\text{)} \\
&= \mathbb{P}(A) \\
\end{align}

\noindent En inversant les rôles joués par $A$ et $B$ (et étant donné que $A\cap B=B\cap A$) on en déduit l'autre égalité $\mathbb{P}(B\vert A)=\mathbb{P}(B)$.

\noindent Réciproquement, supposons que  $\mathbb{P}(A\vert B)=\mathbb{P}(A)$ et $\mathbb{P}(B\vert A)=\mathbb{P}(B)$. De la première égalité on déduit que 

$$\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}=\mathbb{P}(A)$$
\noindent autrement dit 

$$\mathbb{P}(A\cap B)=\mathbb{P}(A)\mathbb{P}(B)$$

et $A$ et $B$ sont donc indépendants.

$\square$

\noindent La formule $\mathbb{P}(A\cap B)=\mathbb{P}(A\vert B)\mathbb{P}(B)$ (pour $B$ tel que $\mathbb{P}(B)>0$), qui découle de la définition de $\mathbb{P}(A\vert B)$, admet une généralisation au cas où l'on intersecte un nombre quelconque $n$ événements.

:::: {.thmbox .thm data-latex="important"}

\noindent

**Théorème (formule des probabilités composées).** Soient $(\Omega, \mathcal{A}, \mathbb{P})$ un espace probabilisé et $A_1, A_2,\dots, A_n$ des événements tels que $\mathbb{P}(A_1\cap A_2\cap\dots A_n)>0$. Alors on a la formule de chaînage :

$$\mathbb{P}(A_1\cap A_2\cap\dots\cap A_n)=\mathbb{P}(A_1)\mathbb{P}(A_2\vert A_1)\mathbb{P}(A_3\vert A_1\cap A_2)\dots\mathbb{P}(A_n\vert A_1\cap A_2\dots\cap A_{n-1})$$

\noindent ce que l'on peut écrire de façon condensée :

$$\mathbb{P}\left(\bigcap\limits_{i=1}^n A_i\right)=\prod\limits_{i=1}^n \mathbb{P}\left(A_i\vert\bigcap\limits_{j=1}^{i-1} A_j\right)$$
::::

\noindent

**Démonstration.** Par récurrence sur $n\in\mathbb{N}^*$ :

- pour $n=1$ c'est évident (l'égalité s'écrit $\mathbb{P}(A_1)=\mathbb{P}(A_1)$. Pour $n=2$, c'est une conséquence de la définition de $\mathbb{P}(A_1\vert A_2)$.

- supposons l'égalité vraie pour $n$ événements quelconques, montrons qu'elle est vraie pour $n+1$ événements quelconques. On considère donc $n+1$ événements $A_1, A_2,\dots, A_n, A_{n+1}$. Alors

\begin{align}
\mathbb{P}(A_1\cap\dots\cap A_n\dots\cap A_{n+1}) &= \mathbb{P}((A_1\cap A_2\dots\cap A_n)\cap A_{n+1}) \\
&= \mathbb{P}(A_{n+1} \cap (A_1\cap\dots\cap A_n)) \\
&= \mathbb{P}(A_{n+1}\vert A_1\dots\cap A_n)\mathbb{P}(A_1\cap\dots\cap A_n) \\
& \text{(formule pour deux événements)} \\
&= \mathbb{P}(A_{n+1}\vert A_1\cap\dots\cap A_n)\mathbb{P}(A_1)\mathbb{P}(A_2\vert A_1)\dots\mathbb{P}(A_n\vert A_1\cap\dots\cap A_{n-1}) \\
& \text{(hypothèse de récurrence)} \\
&= \mathbb{P}(A_1)\mathbb{P}(A_2\vert A_1)\dots\mathbb{P}(A_n\vert A_1\cap\dots\cap A_{n-1})\mathbb{P}(A_{n+1}\vert A_1\cap\dots\cap A_n) \\
\end{align}

\noindent ce qui permet de conclure.

$\square$

\noindent

**Exemple.** Une urne contient six boules rouges et quatre boules blanches. On tire successivement trois boules sans remise dans l'urne. Quelle est la probabilité d'avoir tiré trois boules blanches ?

\noindent

**Solution.** Pour $1\leq i\leq 3$, on note $A_i$ l'événement *La boule tirée lors du tirage numéro $i$ est blanche*. On veut donc calculer $\mathbb{P}(A_1\cap A_2\cap A_3)$. D'après la formule des probablités composées, on a 

$$\mathbb{P}(A_1\cap A_2\cap A_3)=\mathbb{P}(A_1)\mathbb{P}(A_2\vert A_1)\mathbb{P}(A_3\vert A_1\cap A_2)$$

\noindent Or :

- $\mathbb{P}(A_1)=\frac{4}{10}=\frac{2}{5}$
- $\mathbb{P}(A_2\vert A_1)=\frac{3}{9}=\frac{1}{3}$
- $\mathbb{P}(A_3\vert A_1\cap A_2)=\frac{2}{8}=\frac{1}{4}$

\noindent On a donc

\begin{align}
\mathbb{P}(A_1\cap A_2\cap A_3) &= \frac{2}{5}\times\frac{1}{3}\times\frac{1}{4} \\
& = \frac{1}{30} \\
& \approx 0,033
\end{align}


## Formule des probabilités totales

\noindent La formule des probabilités totales est très utile pour calculer une probabilité lorsque l'on dispose d'un **système complet d'événements** :

:::: {.defbox .def data-latex="important"}
<center>**Système complet d'événements**</center>

\noindent Soit $(\Omega, \mathcal{A}, \mathbb{P})$ un espace probabilisé. On dit qu'une suite finie ou dénombrable d'événements $(A_n)_n$ est un **système complet d'événements**, ou un **système exhaustif** lorsque :

- la réunion des $A_n$ recouvre complètement l'univers $\Omega$ :

$$\Omega=\bigcup\limits_{n}A_n$$

- les événements $A_n$ sont deux à deux incompatibles :

$$\forall (m,n) \text{ t.q. } m\neq n, \, A_m\cap A_n=\emptyset$$

::::

\noindent 

**Remarque.** Dans ce cas, pour tout événement $B$, on peut écrire 

$$B=\bigcup\limits_{n}(B\cap A_n)$$
\noindent et les événements $B\cap A_n$ sont deux à deux incompatibles.


\noindent 

**Exemples. i.** Pour tout événement $A$, le système $\{A, \overline{A}\}$ est un système complet d'événements.

\noindent

**ii.** On tire aléatoirement deux nombres $A$ et $B$ dans $\{0, 1, 2\}$ et on relève le couple $(A, B)$. L'univers associé à cette expérience est $\Omega=\{0, 1, 2\}^2$. On peut créer un système complet d'événements à partir de la somme $S$ de $A$ et $B$. Pour cela, on note $\{S=i\}$ l'événement 

$$\{S=i\}=\{(A, B)\in\Omega, \, S=A+B=i\}$$

\noindent Alors, le système

$$\left\{\{S=0\}, \{S=1\}, \{S=2\}, \{S=3\}, \{S=4\}\right\}$$ 

est un système complet d'événements de $\Omega$.

:::: {.thmbox .thm data-latex="important"}

\noindent 

**Formule des probabilités totales.** Soit $(\Omega, \mathcal{A}, \mathbb{P})$ un espace probabilisé. On suppose qu'on dispose d'un système complet d'événements $(A_n)_n$. Alors, pour tout événement $B$, on a 

$$\mathbb{P}(B)=\sum\limits_{n}\mathbb{P}(B\cap A_n)=\sum\limits_{n}\mathbb{P}(B\vert A_n)\mathbb{P}(A_n)$$
::::

\noindent

**Démonstration.** Comme dit précémment, les événements $B\cap A_n$ sont deux à deux incompatibles, donc 

\begin{align}
\mathbb{P}(B) &= \mathbb{P}\left(\bigcup\limits_{n} B\cap A_n\right) \\
&= \sum\limits_{n}\mathbb{P}(B\cap A_n) \\
& \text{(par } \sigma-\text{addivité)} \\
&= \sum\limits_{n}\mathbb{P}(B\vert A_n)\mathbb{P}(A_n) \\
& \text{(par définition de la probabilité conditionnelle)} \\ 
\end{align}
\noindent

$\square$

**Exemple.** On dispose de trois urnes $A$, $B$ et $C$ :

- l'urne $A$ contient $3$ boules blanches et $7$ boules noires ;
- l'urne $B$ contient $8$ boules blanches et $2$ boules noires ;
- l'urne $C$ contient $4$ boules blanches et $6$ boules noires.

On choisit aléatoirement une urne, avec la même probabilité pour toutes les urnes. On tire successivement et sans remise deux boules dans cette urne. Quelle est la probabilité d'avoir une boule blanche et une boule noire ?

\noindent

**Solution.** On note $A$ (resp. $B$, $C$), l'événement *l'urne choisie est $A$* (resp. $B$, $C$). Pour $i=1,2$, on note $N_i$ (resp. $B_i$) l'événement *la boule tirée au tirage numéro $i$ est noire* (resp. *la boule tirée au tirage numéro $i$ est blanche*). L'événement $E=$ *Avoir une boule blanche et une boule noire* s'écrit donc 

$$E=\left(B_1\cap N_2\right)\cup\left(N_1\cap B_2\right)$$
\noindent Les événements $B_1\cap N_2$ et $N_1\cap B_2$ sont incompatibles. On a donc 

\begin{align}
\mathbb{P}(E) &= \mathbb{P}\left(\left(B_1\cap N_2\right)\cup\left(N_1\cap B_2\right)\right) \\
&= \mathbb{P}(B_1\cap N_2)+\mathbb{P}(N_1\cap B_2) \\
\end{align}

\noindent $\{A, B, C\}$ est un système complet d'événements, donc d'après la formule des probabilités totales on a 

\begin{align}
\mathbb{P}(B_1\cap N_2) &= \mathbb{P}(B_1\cap N_2\vert A)\mathbb{P}(A)+\mathbb{P}(B_1\cap N_2\vert B)\mathbb{P}(B)+\mathbb{P}(B_1\cap N_2\vert C)\mathbb{P}(C) \\
&= \frac{1}{3}\left(\mathbb{P}(B_1\cap N_2\vert A)+ \mathbb{P}(B_1\cap N_2\vert B)+\mathbb{P}(B_1\cap N_2\vert C)\right) \\
&= \frac{1}{3}\left(\mathbb{P}(N_2\vert A\cap B_1)\mathbb{P}(B_1|A)+\mathbb{P}(N_2\vert B\cap B_1)\mathbb{P}(B_1|B)+\mathbb{P}(N_2\vert C\cap B_1)\mathbb{P}(B_1|C) \right) \\
&= \frac{1}{3}\left(\frac{7}{9}\times\frac{3}{10}+\frac{2}{9}\times\frac{8}{10}+\frac{6}{9}\times\frac{4}{10}\right) \\
&= \frac{61}{210} \\
\end{align}

\noindent et

\begin{align}
\mathbb{P}(N_1\cap B_2) &= \mathbb{P}(N_1\cap B_2\vert A)\mathbb{P}(A)+\mathbb{P}(N_1\cap B_2\vert B)\mathbb{P}(B)+\mathbb{P}(N_1\cap B_2\vert C)\mathbb{P}(C) \\
&= \frac{1}{3}\left(\mathbb{P}(N_1\cap B_2\vert A)+ \mathbb{P}(N_1\cap B_2\vert B)+\mathbb{P}(N_1\cap B_2\vert C)\right) \\
&= \frac{1}{3}\left(\mathbb{P}(B_2\vert A\cap N_1)\mathbb{P}(N_1|A)+\mathbb{P}(B_2\vert B\cap N_1)\mathbb{P}(N_1|B)+\mathbb{P}(B_2\vert C\cap N_1)\mathbb{P}(N_1|C) \right) \\
&= \frac{1}{3}\left(\frac{3}{9}\times\frac{7}{10}+\frac{8}{9}\times\frac{2}{10}+\frac{4}{9}\times\frac{6}{10}\right) \\
&= \frac{61}{210} \\
\end{align}

\noindent On en déduit que 

$$\mathbb{P}(E)=\frac{61}{105}\approx 0,58$$
\noindent 

**Autre méthode.** On peut aussi écrire 

$$\mathbb{P}(B_1\cap N_2)=\mathbb{P}(B_1\cap N_2\cap A)+\mathbb{P}(B_1\cap N_2\cap B)+\mathbb{P}(B_1\cap N_2\cap C)$$

\noindent d'après la formule des probabilités totales. 

\noindent Puis, on utilise la formule des proabilités composées pour en déduire que 

\begin{align}
\mathbb{P}(B_1\cap N_2) &= \mathbb{P}(A)\mathbb{P}(B_1\vert A)\mathbb{P}(N_2\vert B_1\cap A) +\mathbb{P}(B)\mathbb{P}(B_1\vert B)\mathbb{P}(N_2\vert B_1\cap B) \\

& +\mathbb{P}(C)\mathbb{P}(B_1\vert C)\mathbb{P}(N_2\vert B_1\cap C)
\end{align}


\noindent On fait ensuite exactement le même type de calcul pour $\mathbb{P}(N_1\cap B_2)$.

## Formule de Bayes

\noindent La formule de Bayes a ceci de particulier qu'elle est à la fois extrêmement simple et pourtant absolument fondamentale.

:::: {.defbox .def data-latex="important"}

\noindent 

**Formule de Bayes.** Soit $(\Omega, \mathcal{A}, \mathbb{P})$ un espace probabilisé.

\noindent Soient $A$ et $B$ deux événements tels que $\mathbb{P}(A)>0$ et $\mathbb{P}(B)>0$. Alors

$$\mathbb{P}(B\vert A)=\frac{\mathbb{P}(A\vert B)\,\mathbb{P}(B)}{\mathbb{P}(A)}$$
\noindent 

**Variantes. i.** On la trouve parfois sous cette forme :

$$\mathbb{P}(B\vert A)=\frac{\mathbb{P}(A\vert B)\,\mathbb{P}(B)}{\mathbb{P}(A\vert B)\,\mathbb{P}(B)+\mathbb{P}(A\vert\overline{B})\,\mathbb{P}(\overline{B})}$$

**ii.** Plus généralement, si l'on dispose d'un système complet d'événements $\{B_i\}_{i\in I}$, alors pour tout $i$ dans $I$ on a 

$$\mathbb{P}(B_i\vert A)=\frac{\mathbb{P}(A\vert B_i)\,\mathbb{P}(B_i)}{\sum\limits_{j\in I} \mathbb{P}(A\vert B_j)\,\mathbb{P}(B_j)}$$
::::

\noindent 

**Démonstration.** Comme $A\cap B=B\cap A$, on a 

\begin{align}
\mathbb{P}(A\vert B)\mathbb{P}(B) &= \mathbb{P}(A\cap B) \\
&= \mathbb{P}(B\cap A) \\
&= \mathbb{P}(B\vert A)\mathbb{P}(A) \\
\end{align}

\noindent d'où

$$\mathbb{P}(B\vert A)=\frac{\mathbb{P}(A\vert B)\,\mathbb{P}(B)}{\mathbb{P}(A)}$$

\noindent Si $\{B_i\}_{i\in I}$ est un système complet d'événements alors d'après la formule des probabilités totales

$$\mathbb{P}(A)=\sum\limits_{j\in I}\mathbb{P}(A\vert B_j)\mathbb{P}(B_j)$$
\noindent et donc en appliquant la formule de Bayes avec $B=B_i$ et en remplaçant $\mathbb{P}(A)$ par l'expression ci-dessus, on obtient

$$\mathbb{P}(B_i\vert A)=\frac{\mathbb{P}(A\vert B_i)\,\mathbb{P}(B_i)}{\sum\limits_{j\in I} \mathbb{P}(A\vert B_j)\,\mathbb{P}(B_j)}$$

\noindent En particulier, $\{B, \overline{B}\}$ étant un système complet d'événements, on a donc

$$\mathbb{P}(B\vert A)=\frac{\mathbb{P}(A\vert B)\,\mathbb{P}(B)}{\mathbb{P}(A\vert B)\,\mathbb{P}(B)+\mathbb{P}(A\vert\overline{B})\,\mathbb{P}(\overline{B})}$$

$\square$

\noindent

**Interprétation de la formule de Bayes.** On peut voir la formule de Bayes comme une mise à jour de nos croyances, lorsqu'on acquière de l'information. Pour illustrer ce point, on reprend l'exemple des trois urnes $A, B$ et $C$ vu plus haut. Imaginons un jeu dans lequel on doit deviner l'urne choisie secrètement par une autre personne. En l'absence de toute information, nous n'avons aucune raison de privilégier une urne à l'autre, et donc on décide de retenir un modèle de choix d'urne équiprobabiliste :

$$\mathbb{P}(A)=\mathbb{P}(B)=\mathbb{P}(C)=\frac{1}{3}$$
\noindent Imaginons maintenant qu'on nous donne une information supplémentaire. La personne qui a choisi l'urne y a tiré une boule au hasard, et elle a obtenu une boule blanche. Cette information va affecter notre modèle probabliste du choix de l'urne. Intutivement, sans faire explicitement de calcul, on a envie d'attribuer une probabilité plus grande à l'urne $B$. Plus formellement, les niveaux de crédibilité qu'on va attribuer aux trois urnes $A$, $B$ et $C$ sont désormais $\mathbb{P}(A\vert B_1)$, $\mathbb{P}(B\vert B_1)$ et $\mathbb{P}(C\vert B_1)$ et on a :

$$\mathbb{P}(B\vert B_1)>\mathbb{P}(C\vert B_1)>\mathbb{P}(A\vert B_1)$$

\noindent L'ajout de cette information a donc modifié notre système de croyances sur l'urne choisie, en mettant à jour les probabilités associées à chacune des urnes. Le calcul de ces probablités via l'utilisation de la formule de Bayes confirme notre intuition :


\begin{align}
\mathbb{P}(A\vert B_1) &= \frac{\mathbb{P}(B_1\vert A)\mathbb{P}(A)}{\mathbb{P}(B_1\vert A)\mathbb{P}(A)+\mathbb{P}(B_1\vert B)\mathbb{P}(B)+\mathbb{P}(B_1\vert C)\mathbb{P}(C)} \\
&= \frac{\mathbb{P}(B_1\vert A)}{\mathbb{P}(B_1\vert A)+\mathbb{P}(B_1\vert B)+\mathbb{P}(B_1\vert C)} \\
&= \frac{\frac{3}{10}}{\frac{3}{10}+\frac{8}{10}+\frac{4}{10}} \\
&= \frac{3}{15}
\end{align}


\begin{align}
\mathbb{P}(B\vert B_1) &= \frac{\mathbb{P}(B_1\vert B)\mathbb{P}(B)}{\mathbb{P}(B_1\vert A)\mathbb{P}(A)+\mathbb{P}(B_1\vert B)\mathbb{P}(B)+\mathbb{P}(B_1\vert C)\mathbb{P}(C)} \\
&= \frac{\mathbb{P}(B_1\vert B)}{\mathbb{P}(B_1\vert A)+\mathbb{P}(B_1\vert B)+\mathbb{P}(B_1\vert C)} \\
&= \frac{\frac{3}{10}}{\frac{3}{10}+\frac{8}{10}+\frac{4}{10}} \\
&= \frac{8}{15}
\end{align}

\begin{align}
\mathbb{P}(C\vert B_1) &= \frac{\mathbb{P}(B_1\vert C)\mathbb{P}(C)}{\mathbb{P}(B_1\vert A)\mathbb{P}(A)+\mathbb{P}(B_1\vert B)\mathbb{P}(B)+\mathbb{P}(B_1\vert C)\mathbb{P}(C)} \\
&= \frac{\mathbb{P}(B_1\vert C)}{\mathbb{P}(B_1\vert A)+\mathbb{P}(B_1\vert B)+\mathbb{P}(B_1\vert C)} \\
&= \frac{\frac{4}{10}}{\frac{3}{10}+\frac{8}{10}+\frac{4}{10}} \\
&= \frac{4}{15}
\end{align}

\noindent L'information apportée a donc modifié nos croyances de la façon suivante :

$$\mathbb{P}(A\vert B_1)=\frac{3}{15}$$
$$\mathbb{P}(B\vert B_1)=\frac{8}{15}$$
$$\mathbb{P}(C\vert B_1)=\frac{4}{15}$$
\noindent

:::: {.defbox .def data-latex="important"}
<center>**Probabilité a priori, probabilité a posteriori, vraisemblance**</center>

Dans la formule de Bayes

$$\mathbb{P}(B\vert A)=\frac{\mathbb{P}(A\vert B)\,\mathbb{P}(B)}{\mathbb{P}(A)}$$
\noindent chaque terme a un nom :

- $\mathbb{P}(B)$ est la **probabilité a priori de $B$** : ce terme  modélise notre croyance sur $B$ en l'absence de toute information ; 
- $\mathbb{P}(B\vert A)$ est la **probabilité a posteriori de $B$** sachant l'événement $A$ : il s'agit de notre niveau de notre confiance en $B$ après avoir pris connaissance de l'information $A$ ;

- $\mathbb{P}(A\vert B)$ est la **fonction de vraisemblance de $A$** : ce terme nous dit à quel point l'événement $B$ rend $A$ vraisemblable ;

- $\mathbb{P}(B)$ est la **marginale** ou **probabilité a priori de $B$** : il s'agit juste d'un terme de normalisation, qui est souvent ignoré en statistique bayésienne (les calculs étant alors faits à une constante près).
::::

**Remarques. i.** La mise à jour de la probabilité de $B$ repose donc sur deux termes : la probabilité *a priori* de $B$ et la fonction de vraisemblance. Ces deux termes ont des rôles bien spécfiques :

- une probabilité *a priori* élevée tend à augmenter la probabilité *a posteriori*. Ce terme favorise donc une persistance de nos croyances ;

- il peut être contrebalancé par une vraisemblance faible. Si je crois en $B$, mais que je sais par ailleurs que $B$ rend l'événement $A$ peu probable, toutes choses égales par ailleurs la survenue de $A$ va réduire mon niveau de croyance en $B$.

\noindent 

**ii.** La formule de Bayes est aussi appelée **formule de probabilité des causes**, car elle permet de calculer la probabilité d'une cause à partir de l'observation de ses conséquences. Cette formule est le point de départ de l'**inférence bayésienne**, qui envisage les probabilités comme des niveaux de croyance qui sont sans cesse remis à jour au fur et à mesure que de nouvelles données sont disponibles. Elle diffère de l'**inférence fréquentiste** qui considère une probabilité comme une fréquence limite, via l'utilisation de la loi des grands nombres. L'inférence bayésienne repose sur l'utilisation de probabilités *a priori*, qui sont souvent considérées comme des probabilités à dire d'expert.  Ses détracteurs y voient là une faiblesse de la théorie, qui laisse à leurs yeux une place trop importante à la subjectivité.
