# Variables aléatoires discrètes

\noindent Supposons que vous jouiez avec un ami au jeu suivant. Votre ami lance un dé équilibré et vous convenez des règles suivantes :

- si le dé tombe sur $1$ ou $2$, vous donnez $3$ euros à votre ami ;
- si le dé tombe sur $2$ ou $3$, votre ami vous donne $3$ euros ;
- si le dé tombe sur $5$ ou $6$, aucun de vous deux ne gagne ni ne perd d'argent.

\noindent On note $X$ votre gain algébrique. Alors, $X$ est un nombre aléatoire dont les valeurs possibles sont $-3, 3$ et $0$. L'expérience aléatoire qui consiste à lancer ce dé et à relever son numéro peut être modélisée par l'univers probabilisé $(\Omega, \mathcal{A}, \mathbb{P})$, où $\Omega=\{1,2,3,4,5,6\}$, $\mathcal{A}=\mathcal{P}(\Omega)$ et $\mathbb{P}$ est la mesure équirépartie : $\forall\omega\in\Omega, \,\mathbb{P}(\{\omega\})=\frac{1}{6}$. Dans ce cas, votre gain $X$ peut être vu comme une application

$$X:\Omega=\{1,2,3,4,5,6\}\longrightarrow\{-3, 0, 3\}$$
définie par 

$$X(1)=X(2)=-3$$
$$X(3)=X(4)=3$$
$$X(5)=X(6)=0$$

\noindent Imaginons maintenant qu'un ami commun prenne connaissance de votre gain à ce jeu, mais sans prendre connaissance du jeu lui-même (ni les issues possibles, ni les règles définissant le gain), et encore moins du numéro du dé que vous avez obtenu. De son point de vue, l'expérience qui aboutira à l'observation de votre gain sera également une expérience aléatoire, cependant l'espace probabilisé la modélisant ne sera plus $(\Omega, \mathcal{A}, \mathbb{P})$ mais plutôt $(\Omega_X, \mathcal{A}_X, \mathbb{P}_X)$, où

$$\Omega_X=X(\Omega)=\{-3, 0, 3\}$$
$$\mathcal{A}_X=\mathcal{P}(\{-3,0,3\})$$
$$\mathbb{P}_X \text{ donnée par } \mathbb{P}_X(\{-3\})=\mathbb{P}_X(\{0\})=\mathbb{P}_X(\{0\})=\frac{1}{3}$$
\noindent Dans ce genre de situation, on dit que $X$ est une **variable aléatoire**, et on appelle **loi de $X$** la mesure de probabilité $\mathbb{P}_X$. D'une certaine façon, la variable aléatoire $X$ a donc transformé l'espace probabilisé de départ $(\Omega, \mathcal{A}, \mathbb{P})$ en un nouvel espace probabilisé $(\Omega_X, \mathcal{A}_X,\mathbb{P}_X)$. Dans la plupart des expériences aléatoires, on cherchera à mesurer une grandeur (un gain à un jeu de hasard, la durée d'attente à un feu rouge, le nombre de coquilles dans un texte, le nombre buts marqués dans un match de foot, etc.), si bien que ce qui nous intéressera ne sera pas tant l'espace de départ $(\Omega, \mathcal{A}, \mathbb{P})$ mais plutôt son image $(\Omega_X, \mathcal{A}_X, \mathbb{P}_X)$ par cette grandeur. 

\noindent Cela a une conséquence pratique lorsqu'on résout un exercice de probabilités mettant en scène une variable aléatoire $X$ : sauf dans des cas très simples, on n'explicitera pas $\Omega$ qu'on supposera donné (un peu à la façon de votre ami commun qui est aveugle aux numéros du dé) mais on cherchera plutôt à déterminer $X(\Omega)$. La tribu $\mathcal{A}_X$ sera, elle, généralement passée sous silence (en pratique, on aura souvent $\mathcal{A}_X=\mathcal{P}(X(\Omega)$). Enfin, on accordera toute l'attention sur la **loi de $X$**, autrement dit sur la mesure de probabilité $\mathbb{P}_X$, à partir de laquelle on pourra calculer différents indicateurs (espérance, variance, quantiles etc.).

\noindent Ce chapitre s'intéresse aux **variables alétoires discrètes**, autrement dit les variables aléatoires dont les images forment un ensemble discret, soit parce que cet ensemble est **fini**, soit parce-qu'il est **infini** mais **dénombrable** (comme l'ensemble des entiers naturels ou des nombres rationnels). Le chapitre suivant traitera des **variables aléatoires continues** : ce sont les variables aléatoires dont l'ensemble des valeurs est **continu**, comme par exemple l'ensemble des nombres réels.

## Définition et premières propriétés

### Définition

:::: {.defbox .def data-latex="important"}
<center>**Variables aléatoires discrètes**</center>
Soit $(\Omega, \mathcal{A}, \mathbb{P})$ un espace probabilisé. On appelle **variable aléatoire discrète (réelle)** sur $\Omega$ toute application

$$X:\Omega\longrightarrow F=X(\Omega)\subset\mathbb{R}$$
\noindent où $F=X(\Omega)$ est :

- soit un ensemble fini : $F=\{x_1,\dots, x_n\}$
- soit un ensemble infini dénombrable : $F=\{x_n,\,n\in\mathbb{N}\}$

\noindent On dira alors que $F$ est au *plus dénombrable*, et on utilisera souvent la notation unifiée

$$F=X(\Omega)=\{x_i, \, i\in I\}, \, I\subset\mathbb{N}$$

\noindent De plus, pour tout $\omega\in\Omega$, on dira que $X(\omega)$ est une **réalisation** de $X$.
::::

\noindent

**Exemples. i.** On reprend l'exemple des deux dés équilibrés présenté dans le chapitre précédent :

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/somme_des.png") 
```
</center>

\noindent L'expérience aléatoire associée à cette expérience aléatoire est modélisée par l'espace probabilisé $(\Omega, \mathcal{A}, \mathbb{P})$, avec  $\Omega=\{1,2,3,4,5,6\}^2$, $\mathcal{A}=\mathcal{P}(\Omega)$ et $\mathbb{P}$ la mesure de probabilité équirépartie.

\noindent La somme $S$ des deux numéros obtenus est une variable aléatoire 

$$X:\Omega \longrightarrow X(\Omega)$$
\noindent définie, pour $\omega=(\omega_1, \omega_2)\in\Omega$, par $S(\omega)=\omega_1+\omega_2$. On a 

$$X(\Omega)=[\![2;12]\!]$$
\noindent où pour tout couple d'entiers $(a,b)$ tel que $a\leq b$, $[\![a;b]\!]$ désigne l'ensemble de tous les entiiers entre $a$ et $b$ (notation que nous réutiliserons régulièrement dans ce cours).

\noindent Ainsi, $X(\Omega)$ est fini, et donc $X$ est une variable aléatoire discrète.

\noindent

**ii.** Une urne contient $4$ boules blanches et $6$ boules noires. On tire une boule au hasard. Si elle est noire on s'arrête là, sinon on remet la boule dans l'urne, et on recommence jusqu'à obtenir une boule noire. On note $N$ le nombre de boules tirées. $N$ est une variable aléatoire, prenant des valeurs entières et non majorée. Ainsi $N(\Omega)=\mathbb{N}^*$ et $N$ est discrète.

**iii.** Dans une file d'attente, on note $T$ le temps de passage entre deux clients. $T$ est une variable aléatoire à valeurs dans $\mathbb{R}_+$. Elle n'est donc pas discrète, mais continue.


### Loi d'une variable aléatoire discrète

\noindent Pour une variable aléatoire discrète (réelle) définie sur un espace probabilisé $\left(\Omega, \, \mathcal{P}(\Omega), \, \mathbb{P}\right)$, on peut définir la *loi de $X$*.

:::: {.thmbox .def data-latex="important"}
**Théorème (Loi d'une variable aléatoire discrète).** Soit $X$ une variable aléatoire discrète définie sur un espace probabilisé $(\Omega,\, \mathcal{P}(\Omega),\, \mathbb{P})$, à valeurs dans $F=X(\Omega)$. Sur l'espace probabilisable $(F,\, \mathcal{P}(F))$ on peut alors définir une probabilité $\mathbb{P}_X$ en posant, pour tout $x_i$ dans $F$ :

$$\mathbb{P}_X(\{x_i\})=\mathbb{P}(X^{-1}(\{x_i\}))$$
\noindent On notera plus simplement $(X=x_i)$ l'événement $X^{-1}(\{x_i\})$.


\noindent La loi de $X$ est donc définie par :

- la donnée de $F=X(\Omega)$, i.e. l'ensemble de toutes les valeurs prises par $X$. Cet ensemble s'appelle le **support** de la loi de $X$ ;
- la donnée, pour tout $x_i$ dans $X(\Omega)$, de la probabilité $\mathbb{P}(X=x_i)$.

\noindent Cette loi est unique à des événements de probabilité nulle près.
::::

\noindent 

**Démonstration.** Admis.

\noindent

\noindent

**Remarques. i.** On définit $\mathbb{P}_X$ à partir des $\mathbb{P}_X(\{x_i\})$ :

- les $\{x_i\}$ sont des éléments de (la tribu) $\mathcal{P}(F)$, donc $\mathbb{P}_X$ est bien une mesure de probabilité sur l'espace probabilisable $(F,\,\mathcal{P}(F))$ ;

- par ailleurs, $\mathbb{P}_X(\{x_i\})$ est définie par $\mathbb{P}(X^{-1}(\{x_i\}))$ et $X^{-1}(\{x_i\})$ est un élément de la tribu $\mathcal{P}(\Omega)$ sur laquelle est définie la probabilité $\mathbb{P}$, donc cette définition a bien un sens.


\noindent

**ii.** La loi de $X$ est définie par la donnée des couples $(x_i, p_i)$ tels que $x_i\in X(\Omega)$ et $p_i=\mathbb{P}(X=x_i)$. Dans cette définition, on peut se restreindre aux couples $(x_i, p_i)$ pour lesquels $p_i>0$. La loi de $X$ n'est donc pas unique au sens strict du terme, mais elle l'est bien à des événements élémentaires de probabilité nulle près. Par exemple, dans l'exercice 2 du sujet du concours interne de 2012 (exercice 2.7. de ce cours) la variable aléatoire $X$ prend *a priori* les valeurs $0,1,2,3$, mais *a posteriori* on a $\mathbb{P}(X=0)=0$, donc on peut enlever $0$ de $X(\Omega)$.


**Exemple. i.** On reprend l'exemple sur la somme des deux dés. On a vu que $X(\Omega)=[\![2;12]\!]$. On calcule maintenant toutes les probablités $\mathbb{P}(X=i)$ pour $i\in [\![2;12]\!]$. On montre en fait facilement que

$$\forall i\in [\![2;6]\!],\, \mathbb{P}(X=i)=\frac{i-1}{36}$$
$$\forall i\in [\![7;12]\!], \, \mathbb{P}(X=i)=\frac{13-i}{36}$$
\noindent On peut vérifier la cohérence de ce résultat :

\begin{align}
\sum\limits_{i=2}^{6}\frac{i-1}{36}+\sum\limits_{i=7}^{12}\frac{13-i}{36} &= \sum\limits_{i=1}^{5}\frac{i}{36}+\sum\limits_{i=1}^{6}\frac{i}{36} \\
&= \frac{2\sum\limits_{i=1}^5 i +6}{36} \\
&= \frac{6\times 5+6}{36} \\
&= 1 \\
\end{align}

\noindent

**ii.** On reprend l'exemple de l'urne contenant $4$ boules blanches et $6$ boules noires. On répète des tirages successifs avec remise jusqu'à obtenir une boule noire, et $N\geq 1$ désigne le nombre de tirages. Pour $n\in\mathbb{N}^*$, l'événement $(N=n)$ est réalisé lorsque les $n-1$ premiers tirages amènent une boule blanche et le tirage numéro $n$ amène une boule noire. Les tirages étant effectués avec remise ils sont indépendants, donc

$$\mathbb{P}(N=n)=\left(\frac{2}{5}\right)^{n-1}\frac{3}{5}$$
\noindent ce qui définit complètement la loi de $N$.

\noindent 

**Remarques. i.** On peut vérifier de façon immédiate que la série $\sum\limits_{n}\mathbb{P}(N=n)$ est convergente de somme $1$ : c'est, au facteur $\frac{3}{5}$ près, une série géométrique de raison $\frac{2}{5}\in]-1;1[$, donc elle converge vers $\frac{3}{5}\frac{1}{1-\frac{2}{5}}=1$.


\noindent 

**ii.** $N$ suit une *loi géométrique* de paramètre $p=\frac{3}{5}$ (voir un peu plus loin la définition des lois géométriques).


### Calcul de $\mathbb{P}(X\in B)$


:::: {.thmbox .def data-latex="important"}
**Théorème (calcul de $\mathbb{P}(X\in B)$).** Soit $X:\Omega\longrightarrow X(\Omega)$ une variable aléatoire discrète (réelle), avec

$$X(\Omega)=\{x_i,\,\,i\in I\} \text{, où } I\subset\mathbb{N}$$

\noindent Pour $B\in\mathcal{P}(X(\Omega))$, on note $(X\in B)$ l'événement

$$(X\in B)=X^{-1}(B)=\left\{\omega\in\Omega, X(\omega)\in B\right\}$$
\noindent La probabilité d'un tel événement se calcule ainsi :

\begin{align}
\mathbb{P}(X\in B)&=\mathbb{P}\left(\bigsqcup\limits_{i\in I/ x_i\in B} (X=x_i)\right) \\
&=\sum\limits_{i\in I/ x_i\in B}\mathbb{P}(X=x_i)
\end{align}
::::

\noindent

**Démonstration.** Les événements $(X=x_i)$ tels que $i\in I, x_i\in B$ forment une partition de l'événement $(X\in B)$. On conclut en utilisant le fait qu'une probabilité d'une réunion disjointe d'événements $A_i$ est la somme des probablités $\mathbb{P}(A_i)$.

$\square$

\noindent 

**Exemple.** Dans l'exemple précédent de l'urne, on cherche maintenant la probabilité que $X$ soit impaire. On a 

\begin{align}
\mathbb{P}(X\in 2\mathbb{N}+1) &=  \sum\limits_{n=0}^{\infty}\mathbb{P}(X=2n+1) \\
&=\sum\limits_{n=0}^{\infty}\left(\frac{2}{5}\right)^{2n}\frac{3}{5} \\
&=\frac{3}{5}\sum\limits_{n=0}^{\infty}\left(\frac{4}{25}\right)^{n} \\
&=\frac{3}{5}\frac{1}{1-\frac{4}{25}} \\
&=\frac{5}{7} \\
\end{align}


### Fonction de répartition

\noindent La fonction de répartition d'une variable aléatoire discrète (ou même continue comme on le verra dans le prochain chapitre) réelle est définie par la donnée des probabilités $\mathbb{P}(X\leq x)=\mathbb{P}(X\in ]-\infty\,;\,x])$ :

:::: {.defbox .def data-latex="important"}
<center>**Fonction de répartition**</center>

\noindent Soit $X$ une variable aléatoire discrète (réelle). On appelle **fonction de répartition de $X$** la fonction $F_X$ définie sur $\mathbb{R}$ par 

$$\forall x\in\mathbb{R},\,F_X(x)=\mathbb{P}(X\leq x)$$

\noindent Quand le contexte le permet, on la note plus simplement $F$.

\noindent 

**Note :** cette définition de la fonction de répartition est valable pour toutes les variables aléatoires, qu'elles suivent ou non une loi discrète.
::::

\noindent

**Calcul pratique.** On note $x_1,\dots x_n$ (resp. $x_1,\dots, x_n, \dots$) les éléments de $X(\Omega)$ rangés dans l'ordre croissant si $X(\Omega)$ est fini (resp. infini dénombrable).

\noindent Soient $x\in\mathbb{R}$ et $i_0$ le plus grand entier tel que $x_{i_0}\leq x$. Alors, d'après le théorème précédent :

$$F(x)=\sum\limits_{i=1}^{i_0}\mathbb{P}(X=x_i)$$

\noindent

**Exemple.** On considère une variable aléatoire $X$ telle que $X(\Omega)=\{1,2,3,4\}$ et $\mathbb{P}(X=i)$ est proportionnel à $i$. 

\noindent On souhaite déterminer sa fonction de répartition.

\noindent

On note $\alpha=\mathbb{P}(X=1)$. On a donc $$\mathbb{P}(X=i)=\alpha\, i$$

\noindent On a donc $\alpha\sum\limits_{i=1}^4 i=1$, soit $\alpha=\frac{1}{10}$ et donc

$$\forall i\in [\![1;4]\!],\, \mathbb{P}(X=i)=\frac{i}{10}$$
\noindent La fonction de répartition $F$ de $X$ est alors donnée par

$$F(x)=\left \{
\begin{array}{lcl}
0&\text{ si }& x<1 \\
\frac{1}{10}&\text{ si }& 1\leq x<2 \\
\frac{3}{10}&\text{ si }& 2\leq x<3 \\
\frac{3}{5}&\text{ si }& 3\leq x<4 \\
1&\text{ si }& x\geq 4 \\
\end{array}
\right.$$


:::: {.thmbox .def data-latex="important"}
<center>**Propriétés des fonctions de répartition**</center>

\noindent

Soit $F$ la fonction de répartition d'une variable aléatoire réelle (discrète ou non). Alors :



**i.** $F$ est une fonction croissante sur $\mathbb{R}$


**ii.** $F$ est continue à droite

**iii.** $\lim\limits_{x\to -\infty}F(x)=0$

**iv.** $\lim\limits_{x\to +\infty}F(x)=1$

\noindent 

**Note :** ces propriétés résultent directement de la défintion précédente, et sont donc vraies pour toutes les variables aléatoires, qu'elles soient discrètes ou non.
::::

\noindent

**Démonstration.** On note $X$ une variable aléatoire réelle discrète ayant $F$ pour fonction de répartition. 

\noindent 

**i.** Soient $x,y$ deux réels tels que $x\leq y$. Alors l'événement $\{X\leq x\}$ est inclus dans l'événement $\{X\leq y\}$. Par croissance des probabilités on a donc $\mathbb{P}(X\leq x)\leq\mathbb{P}(X\leq y)$, i.e. $F(x)\leq F(y)$. On en déduit que $F$ est croissante.

\noindent

**ii.** Soit $x$ un réel. Les événements $\left\{X\in\left]-\infty\,;\,x+\frac{1}{n}\right]\right\}$ forment une suite décroissante (par rapport à $n$) pour l'inclusion, donc d'après la propriété de continuité décroissante des probabilités, on a 

$$\mathbb{P}\left(\bigcap_{n=1}^{\infty}\left\{X\in\left]-\infty\,;\,x+\frac{1}{n}\right]\right\}\right)=\lim\limits_{n\to\infty}\mathbb{P}\left(X\in\left]-\infty\,;\,x+\frac{1}{n}\right]\right)$$

\noindent i.e.

$$\mathbb{P}\left(X\in \bigcap_{n=1}^{\infty}\left]-\infty\,;\,x+\frac{1}{n}\right]\right)=\lim\limits_{n\to\infty}\mathbb{P}\left(X\in\left]-\infty\,;\,x+\frac{1}{n}\right]\right)$$

\noindent Or, $\bigcap\limits_{n=1}^{\infty}\left]-\infty\,;\,x+\frac{1}{n}\right]=]-\infty ; x]$, donc le terme de gauche est égal à $\mathbb{P}(X\leq x)=F(x)$. Par ailleurs le terme de droite est égal à $\lim\limits_{n\to\infty}F\left(x+\frac{1}{n}\right)$, et donc :

$$F(x)=\lim\limits_{n\to\infty}F\left(x+\frac{1}{n}\right)$$
\noindent ce qui traduit exactement la continuité à droite de $F$.

\noindent 

**iii.** La suite d'événements $\left\{X\leq -n\right\}_n$ est décroissante, donc d'après la propriété de continuité décroissante

\begin{align}
\lim\limits_{n\to\infty}F(-n)&=\mathbb{P}\left(\bigcap\limits_{n=0}^{\infty}\{X\leq -n\}\right) \\
&=\mathbb{P}(\emptyset) \\
&=0 \\
\end{align}

\noindent Par croissance de $F$, on en déduit que $\lim\limits_{x\to -\infty}F(x)=0$.

\noindent

**iv.** On utilise exactement le même raisonnement avec la suite croissante $\left\{X\geq n\right\}_n$.

\noindent 

$\square$

\noindent

**Remarque.** L'hypothèse d'une loi discrète n'étant utilisée nulle part dans cette démonstration, ces propriétés sont donc effectivement vraies pour toutes les lois de probabilités, discrètes ou non.

\noindent Nous avons montré que les fonctions de répartition (de lois discrètes ou non) étaient toujours continues à droite. Pour avoir une propriété de continuité, il faudrait donc qu'elles soient également continues à gauche (rappel d'analyse : $f$ est continue en $a$ si et seulement si elle est continue à droite et à gauche en $a$). Mais cette propriété n'est pas vraie en toute généralité :


:::: {.thmbox .def data-latex="important"}
\noindent 
**Théorème (discontinuités d'une fonction de répartition).** Soit $X$ une variable aléatoire réelle (discrète ou non) définie sur un espace probabilisé $(\Omega, \, \mathcal{P}(\Omega), \, \mathbb{P})$. Pour tout réel $x$ on a :

$$F(x)=F(x^{-})+\mathbb{P}(X=x)$$
\noindent où $F(x^{-})=\lim\limits_{t\to x^{-}}F(t)$.

\noindent Autrement dit, la fonction de répartition de $F$ est continue partout, sauf aux points $x$ tels que $p_x:=\mathbb{P}(X=x)>0$ en lesquels elle présente un saut d'amplitude $p_x$.

\noindent En particulier, si $X$ est discrète sa fonction de répartition présente en chaque point $x$ de son support un saut d'amplitude $p_x$.
::::

\noindent

**Démonstration.** Pour tout réel $x$ on a 

$$F(x)=\mathbb{P}(X<x)+\mathbb{P}(X=x)$$

\noindent Or, $(X<x)=\bigcup\limits_{n=1}^{\infty} \left(X\in\left]-\infty\,;\, x-\frac{1}{n}\right]\right)$, et les événements $\left(X\in\left]-\infty\,;\, x-\frac{1}{n}\right]\right)_{n\geq 1}$ forment une suite croissante pour l'inclusion, donc par continuité croissante de $\mathbb{P}$ on a :

\begin{align}
\mathbb{P}(X<x)&=\mathbb{P}\left(\bigcup_{n=1}^{\infty}\left(X\in\left]-\infty\,;\,x-\frac{1}{n}\right]\right)\right) \\
&=\lim\limits_{n\to\infty}\mathbb{P}\left(X\in\left]-\infty\,;\,x-\frac{1}{n}\right]\right) \\
&=\lim\limits_{n\to\infty}F\left(x-\frac{1}{n}\right) \\
&=F(x^{-})
\end{align}

\noindent ce qui montre l'égalité annoncée et permet de conclure.

$\square$

\noindent

**Remarque.** Les variables aléatoires ayant une fonction de répartition continue sont appelées des *lois continues*. Elles font l'objet du chapitre suivant (on se restreindra au cas où l'espace d'arrivée est l'ensemble des réels). D'après le résultat précédent, si $X$ est une variable aléatoire de loi continue on a donc $\mathbb{P}(X=x)=0$ pour tout réel $x$.


:::: {.thmbox .def data-latex="important"}
\noindent
**Théorème (fonction de répartition et loi).** Soit $X$ une variable aléatoire réelle discrète définie sur un espace probabilisé $(\Omega, \,\mathcal{P}(\Omega), \mathbb{P})$ et de fonction de répartition $F$. Alors :

- si $a$ et $b$ sont des nombres réels tels que $a\leq b$ on a

$$\mathbb{P}(X\in]a\,;\,b])=F(b)-F(a)$$

- supposons que $X(\Omega)=\{x_i,\,i\in I\}$ avec les $x_i$ rangés dans l'ordre croissant. Alors

$$\mathbb{P}(X=x_0)=F(x_0)$$
\noindent et 
$$\forall i\geq 1,\, \mathbb{P}(X=x_i)=F(x_i)-F(x_{i-1})$$
::::

\noindent

**Démonstration.** On a 

$$]-\infty\,;\,b]=]-\infty\,;\,a]\,\sqcup\,]a\,;\,b]$$

\noindent donc 

$$F(b)=F(a)+\mathbb{P}(X\in ]a\,;\,b])$$
\noindent ce qui montre la première égalité.

\noindent Comme $x_0=\inf X(\Omega)$, on a $(X=x_0)=(X\leq x_0)$ et donc ces deux événements ont la même probabilité, i.e. $\mathbb{P}(X=x_0)=F(x_0)$.

\noindent Soit $i\geq 1$. D'après le théorème précédent, on a 

\begin{align}
\mathbb{P}(X=x_i)&=F(x_i)-F(x_i^{-}) \\
&=F(x_i)-\mathbb{P}(X<x_i) \\
&=F(x_i)-\mathbb{P}(X\leq x_{i-1}) \\
&=F(x_i)-F(x_{i-1}) \\
\end{align}

$\square$

\noindent On déduit du résultat précédent :

:::: {.thmbox .def data-latex="important"}
**Théorème.** La fonction de répartition d'une variable aléatoire réelle discrète caractérise sa loi.

\noindent Autrement dit, si $X$ et $Y$ sont deux variables aléatoires réelles discrètes, on a 

$$F_X=F_Y \text{ ssi } \mathbb{P}_X=\mathbb{P}_Y$$
::::

\noindent

**Démonstration.** La loi d'une variable aléatoire réelle discrète $X$ est complètement définie par la donnée des probabilités $\mathbb{P}(X=x_i)$, qui elles-mêmes sont complètement définies par la fonction $F$ d'après le théorème précédent, d'où le résultat.

$\square$

\noindent

**Remarque.** Le résultat précédent autorise donc à parler de fonction de répartition associée à une loi, ou même réciproquement de loi associée à une fonction de répartition.

### Quantiles

\noindent Pour définir la notion de quantile, on a besoin de définir la notion d'inverse généralisé à gauche.

:::: {.defbox .def data-latex="important"}
<center>**Inverse généralisé à gauche**</center>

\noindent

Soit $F$ une fonction définie sur $\mathbb{R}$ et à valeurs dans $[0,1]$, croissante et continue à droite. 

On adopte les conventions suivantes :

$$F(-\infty)=\lim\limits_{x\to -\infty}F(x)$$
$$F(+\infty)=1$$

$$\inf\,\emptyset=+\infty$$
\noindent On appelle alors **fonction inverse généralisée à gauche de $F$**, et on note $F^{-1}$, la fonction définie sur $[0,1]$ par

$$\forall p\in [0,1],\, F^{-1}(p)=\inf\{x\in\mathbb{R},\,F(x)\geq p\}$$
\noindent Il s'agit d'une fonction croissante sur $\mathbb{R}$.
::::

\noindent

**Démonstration.** Soient $p$ et $q$ deux réels tels que $p\leq q$. 

- si $\{x\in\mathbb{R},\,F(x)\geq p\}=\emptyset$, alors $\{x\in\mathbb{R}, \, F(x)\geq q\}=\emptyset$ et donc $F^{-1}(p)=F^{-1}(q)=+\infty$.

- supposons maintenant que $\{x\in\mathbb{R},\,F(x)\geq p\}\neq\emptyset$ : il existe donc un réel $x$ tel que $F^{-1}(p)=x$. On distingue deux cas :

  - si $\{x\in\mathbb{R}, \, F(x)\geq q\}=\emptyset$, alors $F^{-1}(q)=+\infty$, et donc $F^{-1}(p)=x<+\infty=F^{-1}(q)$.
  
  - si $\{x\in\mathbb{R},\,F(x)\geq q\}\neq\emptyset$, alors il existe un réel $y$ tel que $y=F^{-1}(q)$. Par définition de $y$, on a $F(y)\geq q$. Mais comme $q\geq p$, on en déduit que $F(y)\geq p$. Par définition de $x$, on en déduit que $y\geq x$, i.e. que $F^{-1}(q)\geq F^{-1}(p)$.
  
Ainsi, dans tous les cas, si $p\leq q$ alors $F^{-1}(p)\leq F^{-1}(q)$, ce qui montre que $F^{-1}$ est croissante.

$\square$

\noindent 

**Remarque.** Cette notion d'inverse généralisé à gauche permet de définir un pseudo-inverse pour des fonctions qui ne sont pas inversibles (on en verra un exemple un peu plus bas en application de la définition de la fonction quantile). Dans le cas où la fonction $F$ est strictement croissante et continue, elle est inversible, et son inverse et son inverse généralisé à gauche coïncident. Il s'agit donc bien d'une généralisation de l'inverse d'une fonction croissante et continue à droite.

\noindent La **fonction quantile** d'une variable aléatoire réelle $X$ se définit alors ainsi :

:::: {.defbox .def data-latex="important"}
<center>**Fonction quantile, quantiles**</center>
\noindent Soient $X$ une variable aléatoire réelle (discrète ou non) et $F$ sa fonction de répartition. On appelle **fonction quantile de $X$** la fonction inverse généralisée à gauche $F^{-1}$ de $F$.

\noindent De plus, pour tout réel $p$ dans $[0,1]$, on appelle  **quantile d'ordre $p$** le réel $F^{-1}(p)$.

\noindent

**Exemples usuels de quantiles :**

- $m_e=F^{-1}\left(\frac{1}{2}\right)$ est la **médiane** de $X$ ;

- $Q_1=F^{-1}\left(\frac{1}{4}\right)$ et $Q_3=F^{-1}\left(\frac{3}{4}\right)$ sont les **quartiles** de $X$ ;

- pour $i=1,\dots,9$, les $D_i=F^{-1}\left(\frac{i}{10}\right)$ sont les **déciles** de $X$.
::::


\noindent Dans un exemple précédent, on a introduit une variable aléatoire discrète $X$ de fonction de répartition $F$ donnée par 

$$F(x)=\left \{
\begin{array}{lcl}
0&\text{ si }& x<1 \\
\frac{1}{10}&\text{ si }& 1\leq x<2 \\
\frac{3}{10}&\text{ si }& 2\leq x<3 \\
\frac{3}{5}&\text{ si }& 3\leq x<4 \\
1&\text{ si }& x\geq 4 \\
\end{array}
\right.$$

\noindent Déterminons sa médiane et ses quartiles :

- $F(x)\geq\frac{1}{2}\Leftrightarrow x\geq 3$, donc $m_e=3$ ;

- $F(x)\geq\frac{1}{4}\Leftrightarrow x\geq 2$, donc $Q_1=2$ ;

- $F(x)\geq\frac{3}{4}\Leftrightarrow x\geq 4$, donc $Q_3=4$.

\noindent

**Un intérêt des quantiles.** Il est fréquent de vouloir résumer une distribution statistique à l'aide d'indicateurs. Un indicateur couramment utilisé est la moyenne. Il présente toutefois pour inconvénient majeur d'être fortement sensible aux valeurs extrêmes. Ainsi, une seule valeur atypique d'une distribution suffit à perturber considérablement la moyenne. Une alternative est alors de recourir à un quantile, comme par exemple la médiane, qui est plus robuste aux valeurs atypiques.

\noindent 

### Exemples classiques de lois discrètes

\noindent Pour $X$ une variable aléatoire réelle discrète et $\mathcal{L}$ une loi de probabilité, la notation $X\sim\mathcal{L}$ signfiera que $X$ suit la loi $\mathcal{L}$.

**Exemple 1 : loi uniforme sur un ensemble fini.** La loi uniforme affecte les mêmes probabilités à tous les éléments d'un ensemble fini $X(\Omega)=\{x_1,\dots, x_n\}$ :

$$\forall 1\leq i\leq n,\, \mathbb{P}(X=x_i)=\frac{1}{n}$$
\noindent C'est cette loi à laquelle on doit penser lorsqu'on parle de *tirer au hasard* parmi un ensemble fini. C'est aussi cette loi qu'on utilise si on veut modéliser un phénomène aléatoire sur un ensemble fini en l'absence de toute information sur le tirage.

\noindent On suppose les $x_i$ rangés dans l'ordre croissant. Alors, la fonction de répartition de cette loi est la fonction $F$ donnée par

$$F(x)=\left \{
\begin{array}{lcl}
0&\text{ si }& x<x_1 \\
\frac{i}{n}&\text{ si }& x_i\leq x<x_{i+1}\, \text{, avec } 1\leq i\leq n-1 \\
1&\text{ si }& x\geq x_n \\
\end{array}
\right.$$

\noindent

\vspace{0.5cm}

**Exemple 2 : loi de Bernoulli $\mathcal{B}(p)$.** Ici, $p\in[0,1]$. Cette loi est généralement mobilisée lorsque l'on souhaite modéliser l'issue d'une **expérience de Bernoulli**, autrement dit une expérience ayant deux issues nommées *réussite* et *échec*. Il s'agit donc d'une loi à deux issues, généralement notées $0$ (représentant généralement l'échec) et $1$ (représentant généralement la réussite) :

$$X(\Omega)=\{0,1\}$$

\noindent Une telle loi est définie de façon unique à partir du paramètre $p=\mathbb{P}(X=1)$. De façon immédiate, on a $\mathbb{P}(X=0)=1-p$. On note souvent $q=1-p$.

\noindent La fonction de répartition de la loi de Benoulli $\mathcal{B}(p)$ est donnée par

$$F(x)=\left \{
\begin{array}{lcl}
0&\text{ si }& x<0 \\
p&\text{ si }& 0\leq x<1 \\
1&\text{ si }& x\geq 1 \\
\end{array}
\right.$$

\noindent

**Exemple 3 : loi binomiale $\mathcal{B}(n,p)$.** $n$ est un entier naturel non nul et $p\in [0,1]$. La loi binomiale sert à modéliser le nombre de succès lors de la répétition de $n$ expériences de Bernoulli identiques et indépendantes. On a donc 

$$X(\Omega)=\{0,1,\dots, n\}$$

\noindent Les probabilités de la loi binomiale $\mathcal{B}(n,p)$ font intervenir les coefficients binomiaux $\binom{n}{k}$ :

:::: {.thmbox .def data-latex="important"}
\noindent 
**Probabilités d'une loi binomiale.** Soit $X$ une variable aléatoire telle que $X\sim\mathcal{B}(n,p)$. Alors, pour tout entier $0\leq k\leq n$, on a

$$\mathbb{P}(X=k)=\binom{n}{k}\,p^k\,(1-p)^{n-k}$$
:::

\noindent

**Démonstration.** Cette formule est une conséquence de la définition de la loi $\mathcal{B}(n,p)$. On peut écrire 
$$X=\sum\limits_{i=1}^n X_i$$
\noindent où les $X_i$ sont des variables aléatoires de Bernoulli de paramètre $\mathcal{B}(p)$, représentant l'issue de l'expérience de Bernoulli numéro $i$. 

\noindent Soit $k$ un entier tel que $0\leq k\leq n$. Notons 

$$E_k=\left\{(x_1,\dots, x_n)\in\{0,1\}^n,\, \sum\limits_{i=1}^n x_i=k\right\}$$

\noindent Pour $(x_1,\dots, x_n)\in E_k$, les événements $(X_1=x_1),\dots,(X_n=x_n)$ sont indépendants, puisque les expériences de Bernoulli associées aux $X_i$ sont indépendantes. Par conséquent, on a 

\begin{align}
\mathbb{P}(X_1=x_1,\dots, X_n=x_n)&=\prod\limits_{i=1}^n\mathbb{P}(X=x_i) \\
&=p^k\,(1-p)^{n-k} \\
\end{align}

\noindent puisque le vecteur $(x_1,\dots, x_n)$ est constitué de $k$ composantes égales à $1$ et $n-k$ composantes égales à $0$.

\noindent Par ailleurs, $\text{Card }(E_k)=\binom{n}{k}$ donc :

\begin{align}
\mathbb{P}(X=k)&=\mathbb{P}\left(\sum\limits_{i=1}^n X_i=k\right) \\
&=\mathbb{P}\left(\bigsqcup\limits_{(x_1,\dots, x_n)\in E_k} (X_1=x_1,\dots, X_n=x_n)\right) \\
&=\sum\limits_{(x_1,\dots,x_n)\in E_k}\mathbb{P}\left(X_1=x_1,\dots, X_n=x_n\right) \\
&=\sum\limits_{(x_1,\dots, x_n)\in E_k} p^k\,(1-p)^{n-k} \\
&=\text{Card }(E_k)\,p^k\,(1-p)^{n-k} \\
&=\binom{n}{k}\,p^k\,(1-p)^{n-k} \\
\end{align}

$\square$

\noindent

**Remarque.** On déduit de l'expression des $\mathbb{P}(X=k)$ l'identité 

$$\sum\limits_{k=0}^n\binom{n}{k}\,p^k\,(1-p)^{n-k}=1$$
\noindent qui n'est autre qu'un cas particulier de la formule du binôme de Newton :

$$(p+(1-p))^n=\sum\limits_{k=0}^n\binom{n}{k}\,p^k\,(1-p)^{n-k}$$
\noindent La fonction de répartition de la loi binomiale $\mathcal{B}(n,p)$ est donnée par

$$F(x)=\left \{
\begin{array}{lcl}
0&\text{ si }& x<0 \\
\sum\limits_{k=0}^l \binom{n}{k}\,p^k\,(1-p)^{n-k} &\text{ si }& l\leq x<l+1, \,0\leq l<n \\
1&\text{ si }& x\geq n \\
\end{array}
\right.$$

\noindent 

**Exemple 4 : loi de Poisson $\mathcal{P}(\lambda)$.** $\lambda$ est un réel strictement positif. La loi de Poisson $\mathcal{P}(\lambda)$ permet de modéliser le nombre (aléatoire) $X$ d'événements se produisant sur une période $T$, lorsqu'on sait qu'en moyenne $\lambda$ événements se produisent sur une telle période. Elle est généralement appliquée pour des événements rares (accidents, fautes dans un texte, etc.). On peut aussi l'utiliser pour des domaines spatiaux plutôt que des intervalles temporels. On a 

$$X(\Omega)=\mathbb{N}$$
\noindent et les probabilités $\mathbb{P}(X=n)$ pour $n\in\mathbb{N}$ sont données par la formule suivante :

:::: {.thmbox .def data-latex="important"}
\noindent
**Probabilités d'une loi de Poisson $\mathcal{P}(\lambda)$.** Soit $X$ une variable aléatoire telle que $X\sim\mathcal{P}(\lambda)$. Alors :

$$\forall k\in\mathbb{N}, \, \mathbb{P}(X=k)=e^{-\lambda}\frac{\lambda^k}{k!}$$
::::

\noindent
**Justification de cette formule.** On considère un événement qui se produit aléatoirement et de façon répétée dans le temps, selon les règles suivantes :

- sur tout intervalle de temps de longueur (petite) $\Delta t$ :

  - cet événement se produit une fois avec une probabilité $p$ très petite ;
  
  - pour tout $k\geq 2$, la probabilité qu'il se produise $k$ fois est négligeable ;
  
- sur deux intervalles de temps disjoints de longueur $\Delta t$, les survenues (ou non) de cet événement sont indépendantes.

On compte alors le nombre d'occurences $X$ de cet événement sur un intervalle de temps $[a\,;\,a+n\Delta t]$, avec $a>0$ et $n$ un entier très grand. Pour tout entier $k$, on note $X_k$ la variable aléatoire prenant la valeur $1$ si l'événement s'est produit sur l'intervalle de temps $[a+k\Delta t \, ; \, a+(k+1)\Delta t[$ et $0$ sinon, de sorte que 

$$X=\sum\limits_{k=0}^{n-1}X_k$$
\noindent D'après les hypothèses faites plus haut, les variables $X_k$ suivent toutes la loi de Bernoulli $\mathcal{B}(p)$ et les événements $(X_1=\varepsilon_1),\dots,(X_n=\varepsilon_n)$ sont indépendantes pour tout $(\varepsilon_1,\dots,\varepsilon_n)\in\{0,1\}^n$, donc  $X$ suit une loi binomiale $\mathcal{B}(n,p)$. Ainsi

$$\forall k\in\{0,1,\dots, n\}, \,\mathbb{P}(X=k)=\binom{n}{k}\,p^k\,(1-p)^{n-k}$$
\noindent La loi de Poisson découle alors d'une approximation de la formule précédente pour de très grandes valeurs de $n$ et une très petite valeur de $p$. En posant $\lambda = np$, on a en effet :

\begin{align}
\mathbb{P}(X=k)&=\binom{n}{k}\,\left(\frac{\lambda}{n}\right)^k\,\left(1-\frac{\lambda}{n}\right)^{n-k} \\
&=\frac{n(n-1)\dots(n-k+1)}{n^k} \frac{\lambda^k}{k!}\left(1-\frac{\lambda}{n}\right)^{n-k} \\
&=\left(1-\frac{1}{n}\right)\dots \left(1-\frac{k-1}{n}\right) \frac{\lambda^k}{k!}e^{(n-k)\,\log\left(1-\frac{\lambda}{n}\right)} \\
&\approx \left(1-\frac{1}{n}\right)\dots \left(1-\frac{k-1}{n}\right) \frac{\lambda^k}{k!}e^{-(n-k)\,\left(\frac{\lambda}{n}+o\left(\frac{1}{n} \right)\right)} \\
&\approx \left(1-\frac{1}{n}\right)\dots \left(1-\frac{k-1}{n}\right) \frac{\lambda^k}{k!}e^{-\lambda+O\left(\frac{1}{n}\right)} \\
&\to \frac{\lambda^k}{k!}e^{-\lambda}\, \text{ lorsque } n\to\infty 
\end{align}

**Remarque.** Comme $X$ suit une loi binomiale $\mathcal{B}(n,p)$, on a $\mathbb{E}(X)=np$. Le paramètre $\lambda$ d'une loi de Poisson $\mathcal{P}(\lambda)$ s'interprète donc comme le nombre moyen d'événements ayant lieu pendant une période de référence.

**Exemple 5 : loi géométrique $\mathcal{G}(p)$.** $p$ est un réel appartenant à $]0\,;\,1[$ et on considère une succession d'épreuves de Bernoulli indépendantes (donc se soldant par un succès ou un échec). On dit que $X$ suit la loi géométrique de paramètre $p$ si $X\in\mathbb{N}^{*}$ est le numéro du premier succès.

:::: {.thmbox .def data-latex="important"}
**Probabilités d'une loi géométrique.** Soit $X$ une variable aléatoire telle que $X\sim\mathcal{G}(p)$. Alors, pour tout entier $k\geq 1$ on a 

$$\mathbb{P}(X=k)=(1-p)^{k-1}p$$
::::

\noindent 
**Démonstration.** Soit $k$ un entier supérieur ou égal à $1$. Dire que $X=k$ revient à dire que les $k-1$ premières expériences se sont soldées par des échecs et que l'expérience numéro $k$ a été un succès. En notant $S_k$ l'événement *L'expérience numéro $k$ s'est soldée par un succès* et $E_k$ l'événement *L'expérience numéro $k$ s'est soldée par un échec*, on a donc 

\begin{align}
\mathbb{P}(X=k)&=\mathbb{P}(S_1\cap S_2\cap\dots\cap S_{k-1}\cap E_k) \\
&=\mathbb{P}(S_1)\mathbb{P}(S_2)\dots\mathbb{P}(S_{k-1})\mathbb{P}(E_k) \, \text{ par indépendance} \\
&=(1-p)^{k-1}p \\
\end{align}

$\square$

**Exemple 6 : loi hypergéométrique.** La loi hypergéométrique est, comme la loi binomiale, utilisée dans un contexte où l'on souhaite compter le nombre de succès dans une succession d'épreuves de Bernoulli. La différence avec la loi binomiale étant que maintenant, ces épreuves de Bernoulli ne sont plus identiques ni indépendantes. 

On suppose qu'une population de taille $N$, exactement $D$ individus possèdent une certaine caractéristique $\mathcal{C}$ (donc $0\leq D\leq N$). On tire un échantillon de taille $n$ dans cette population, **sans remise** (donc $0\leq n\leq N$) et de façon équiprobable. On compte le nombre $X$ d'individus de l'échantillon possédant la caractéristique $\mathcal{C}$. On dit alors que $X$ suit la **loi hypergéométrique $\mathcal{H}(N,D,n)$**. On a alors : 


:::: {.thmbox .def data-latex="important"}
**Support et probabilités d'une loi hypergéométrique.** Pour $X\sim\mathcal{H}(N,D,n)$, on a :

\noindent 

**i. Support de X.** $$\max(0 \,; \,n-N+D)\leq X\leq \min(n\,;\,D)$$

\noindent

**ii. Probabilités.** Pour tout entier $\max(0 \,; \,n-N+D)\leq k\leq \min(n\,;\,D)$ :

$$\mathbb{P}(X=k)=\frac{\binom{D}{k}\binom{N-D}{n-k}}{\binom{N}{n}}$$
::::

\noindent 

**Démonstration. i.** On a nécessairement :

- $0\leq X\leq n$ : l'échantillon étant de taille $n$, on tire au plus $n$ individus ayant la propriété $\mathcal{C}$ ;

- $0\leq X\leq D$ : le tirage de l'échantillon étant sans remise, on ne peut pas tirer plus d'unités ayant la propriété $\mathcal{C}$ qu'il n'y en a dans la population.

\noindent De façon symétrique, on fait exactement le même raisonnement pour le tirage des individus n'ayant pas la propriété $\mathcal{C}$ :

- $0\leq n-X\leq n$ : l'échantillon étant de taille $n$, on tire au plus $n$ individus n'ayant pas la propriété $\mathcal{C}$. On remarque que cet encadrement est automatiquement vérifié dès que le premier encadrement (sa version symétrique) l'est ;

- $0\leq n-X \leq N-D$ : on ne peut pas tirer plus d'individus n'ayant pas la propriété $\mathcal{C}$ qu'il n'y en a dans la population.

\noindent Les deux premiers encadrements s'écrivent plus simplement $$0\leq X\leq \min(n,D)$$ et le dernier encadrement s'écrit $$\max(0,n-N+D)\leq X\leq n$$

\noindent Enfin, ces deux encadrements s'écrivent 

$$\max(0,n-N+D)\leq X\leq\min(n,D)$$

\noindent

**ii.** Soit $k\in R_X$. Dénombrons le nombre d'échantillons de taille $n$ satisfaisant la condition $X=k$. La donnée d'un tel échantillon repose sur :

- le choix de $k$ individus parmi les $D$ ayant la caractéristique $\mathcal{C}$, soit $\binom{D}{k}$ choix possibles ;

- le choix de $n-k$ individus parmi les $N-D$ n'ayant pas la caractéristique $\mathcal{C}$, soit $\binom{N-D}{n-k}$ choix possibles.

\noindent Pour $k$ fixé, ces deux choix sont complètement indépendants, donc le nomnre $N_k$ de choix d'un tel échantillon s'obtient par produit : $N_k=\binom{D}{k}\binom{N-D}{n-k}$. Enfin, tous ces échantillons sont équiprobables, donc 

$$\mathbb{P}(X=k)=\frac{\binom{D}{k}\binom{N-D}{n-k}}{\binom{N}{n}}$$
$\square$

**Exemple.** Une urne contient $20$ boules, parmi lesquelles $14$ exactement sont rouges. On tire $12$ boules dans l'urne, **sans remise**, et on compte le nombre $X$ de boules rouges obtenues. Alors, $X\sim\mathcal{H}(20, 8, 5)$. Le support de $X$ est $R_X= [\![6;12]\!]$ et

$$\forall k\in R_X, \, \mathbb{P}(X=k)=\frac{\binom{14}{k}\binom{6}{12-k}}{\binom{20}{12}}$$




### Simulation d'une variable aléatoire réelle



### Moments d'une variable aléatoire

:::: {.defbox .def data-latex="important"}
<center>**Espérance d'une variable aléatoire réelle discrète**</center>

\noindent Soit $X$ une variable aléatoire réelle de **support fini** $X(\Omega)=\{x_1,\dots,x_n\}$. On appelle **espérance** de $X$ le nombre réel 

$$\mathbb{E}(X)=\sum\limits_{k=1}^n \mathbb{P}(X=x_k)\,x_k$$

\noindent 


Pour une variable aléatoire réelle discrète de **support infini dénombrable** $X(\Omega)=\{x_1,\dots, x_n\dots\}$, l'existence d'une espérance n'est pas systématique. On dit qu'une telle variable $X$ admet une espérance finie si la série $\sum\limits_{n}\mathbb{P}(X=x_n)\,x_n$ est asbolument convergente. Dans ce cas, l'espérance $\mathbb{E}(X)$ de $X$ est la somme de cette série :

$$\mathbb{E}(X)=\sum\limits_{n=0}^{\infty}\mathbb{P}(X=x_n)\,x_n$$

\noindent 

**Notation unifiée.** Pour ne pas avoir à distinguer le cas fini / infini dénombrable, on peut aussi utiliser une notation englobant les deux cas :

$$\mathbb{E}(X)=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,x$$
::::

\noindent

**Remarque.** L'espérance d'une variable est donc une moyenne de ses valeurs, pondérée par les probabilités qui leur sont associées.

\noindent Cette expression de l'espérance s'écrit à partir des valeurs $x$ prises par $X:\Omega\longrightarrow\mathbb{R}$, c'est-à-dire les éléments de l'**espace d'arrivée** de $X$. On peut aussi exprimer l'espérance à partir des éléments de l'**espace de départ** de $X$ :

:::: {.defbox .def data-latex="important"}
<center>**Espérance d'une variable aléatoire réelle discrète (variante)**</center>
Soit $X:\Omega\longrightarrow\mathbb{R}$ une variable aléatoire réelle discrète d'espérance finie. Alors :

$$\mathbb{E}(X)=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})X(\omega)$$
::::

\noindent

**Démonstration.** L'univers $\Omega$ peut se décomposer en 

$$\Omega=\bigsqcup\limits_{x\in X(\Omega)}\bigsqcup\limits_{\omega\in X^{-1}(\{x\})}\{\omega\}$$
\noindent On a donc, sous réserve d'existence :

\begin{align}
\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})X(\omega)&=\sum\limits_{x\in X(\Omega)}\sum\limits_{\omega\in X^{-1}(\{x\})}\mathbb{P}(\{\omega\})X(\omega) \\
&=\sum\limits_{x\in X(\Omega)}\left(\sum\limits_{\omega\in X^{-1}(\{x\})}\mathbb{P}(\{\omega\})\right)x \\
&=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,x \\
&=\mathbb{E}(X) \\
\end{align}

$\square$


\noindent 

**Exemple.** Le résultat précédent énonce l'égalité suivante :

$$\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,X(\omega)=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,x$$
\noindent Il nous dit que l'espérance de $X$ peut être vue comme une moyenne sur l'espace de départ de $X$, ou comme une moyenne sur l'espace d'arrivée de $X$. L'équivalence entre ces deux points de vue est facile à saisir sur un exemple. 

\noindent Soient $(\Omega, \mathcal{P}(\Omega), \mathbb{P})$ un espace probabilisé tel que $\Omega=\{a,b,c,d\}$ et $X$ une variable aléatoire réelle discrète sur cet espace. On donne le tableau suivant :

<center>
```{r, echo = FALSE, out.width="80%", out.height="80%"}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/probas_univers.PNG") 
```
</center>

\noindent Pour calculer $\mathbb{E}(X)$, on peut utiliser l'expression de l'espérance utilisant les éléments de l'univers $\Omega$ :

\begin{align}
\mathbb{E}(X)&=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,X(\omega) \\
&=0,3\times 1+0,1\times 1+0,4\times 2+0,2\times 2 \\
&=1,6 \\
\end{align}

\noindent Mais on peut aussi regrouper les valeurs de $\omega$ ayant des images communes par $X$, et raisonner directement sur ces images (et leurs probabilités associées) :

<center>
```{r, echo = FALSE, out.width="50%", out.height="50%"}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/probas_image.PNG") 
```
</center>

\noindent Dans ce cas, on fait plutôt le calcul :

\begin{align}
\mathbb{E}(X)&=0,4\times 1+0,6\times 2 \\
&=1,6 \\
\end{align}

\noindent On obtient alors bien le même résultat.

<br>

 \noindent Une application de ce résultat est le **théorème de transfert** :
 
:::: {.thmbox .def data-latex="important"}
**Théorème de transfert.** Soient $X:\Omega\longrightarrow\mathbb{R}$ une variable aléatoire réelle discrète et $\phi:X(\Omega)\longrightarrow\mathbb{R}$. On suppose que $\phi(X)$ admet une espérance finie. Alors, on a 

$$\mathbb{E}(\phi(X))=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\phi(x)$$
\noindent En particulier, pour $\phi(x)=x^m$, avec $m$ entier naturel, on a donc (sous réserve d'existence) :

$$\mathbb{E}(X^m)=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,x^m$$
::::

\noindent

**Démonstration.** Avec les mêmes notations que pour le résultat précédent, on a 

\begin{align}
\mathbb{E}(\phi(X))&=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\phi(X(\omega)) \\
&=\sum\limits_{x\in X(\Omega)}\phi(x)\sum\limits_{\omega\in X^{-1}(\{x\})}\mathbb{P}(\{\omega\}) \\
&=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\phi(x) \\
\end{align}

$\square$

\noindent

**Inteprétation du théorème de transfert.** Ce résultat nous dit que pour calculer l'espérance de $\phi(X)$, la connaissance de la loi de $\phi(X)$ - qui dans certains cas peut être couteuse à acquérir - est inutile : la loi de $X$ suffit.

\noindent 

**Exemple.** Soit $X$ une variable aléatoire de support $X(\Omega)=\mathbb{N}^*$ et telle que 

$$\forall n\in\mathbb{N}^*,\,\mathbb{P}(X=n)=\frac{1}{n(n+1)}$$
\noindent Nous allons montrer :

- qu'on définit ainsi bien la loi de probabilité d'une variable aléatoire ;

- que $X$ n'admet pas d'espérance finie ;

- que $\frac{X+1}{X}$ admet une espérance finie, et que celle-ci est donnée par

$$\mathbb{E}(X)=\frac{\pi^2}{6}$$
\noindent Soit $n$ un entier naturel non nul. On a 

\begin{align}
\sum\limits_{k=1}^n\frac{1}{k(k+1)}&=\sum\limits_{k=1}^n\left(\frac{1}{k}-\frac{1}{k+1}\right) \\
&= 1-\frac{1}{n+1} \\
& \text{(somme télescopique)} \\
\end{align}

\noindent La série de terme général $\frac{1}{n(n+1)}$ est donc convergente, et sa somme vaut $1$ :

$$\sum\limits_{n=1}^{\infty}\frac{1}{n(n+1)}=1$$
\noindent On a donc bien défini la loi d'une variable aléatoire.

\noindent Par ailleurs, la série de terme général $n\,\mathbb{P}(X=n)=\frac{1}{n+1}$ n'est pas (absolument) convergente, donc $X$ n'admet pas d'espérance finie.

\noindent Enfin, pour démontrer que $\frac{X+1}{X}$ admet une espérance finie, il suffit d'après le théorème de transfert de montrer que la série de terme $\sum\limits_{n}\mathbb{P}(X=n)\,\frac{n+1}{n}$ est convergente. Si c'est bien le cas, son espérance sera égale à la somme de cette série.

\noindent Or, on a :

\begin{align}
\mathbb{P}(X=n)\,\frac{n+1}{n}&=\frac{1}{n(n+1)}\frac{n+1}{n} \\
&=\frac{1}{n^2} \\
\end{align}

\noindent La série $\sum\limits_{n}\frac{1}{n^2}$ est convergente, de somme

$$\sum\limits_{n=1}^{\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$$
\noindent On en déduit le résultat.

<br>

\noindent L'espérance, vue comme un opérateur, possède les propriétés suivantes :

:::: {.thmbox .def data-latex="important"}
**Propriétés de l'espérance.** $X$ et $Y$ désignent des variables aléatoires réelles discrètes admettant une espérance, $\lambda$ est un réel. On a :

**i. Espérance d'une constante.** Si $X=a$ est constante, alors $\mathbb{E}(X)=a$.

**ii. Linéarité de l'espérance.** $\mathbb{E}(X+\lambda Y)=\mathbb{E}(X)+\lambda\,\mathbb{E}(Y)$

**iii. Positivité de l'espérance.** Si $X\geq 0$, alors $\mathbb{E}(X)\geq 0$.

**iv. Croissance de l'espérance.** Si $X\leq Y$, alors $\mathbb{E}(X)\leq\mathbb{E}(Y)$.

::::

\noindent

**Démonstration. i.** Si $X=a$ est constante, alors elle a pour support $R_x=\{a\}$ et donc $\mathbb{E}(X)=\mathbb{P}(X=a).a=1.a=a$.

\noindent

**ii.** Ici, il est plus simple d'utiliser la variante de la définition de l'espérance puisque dans ce cas la linéarité de l'espérance n'est rien d'autre qu'une traduction de la linéarité de l'opérateur $\Sigma$ :

\begin{align}
\mathbb{E}(X+\lambda Y)&=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\left(X(\omega)+\lambda\,Y(\omega)\right) \\
&=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})X(\omega)+\lambda\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})Y(\omega) \\
&=\mathbb{E}(X)+\lambda\,\mathbb{E}(Y) \\
\end{align}

\noindent

**iii.** $X$ étant positive, on a $\mathbb{E}(X)=\sum\limits_{\omega}\mathbb{P}(\{\omega\})X(\omega)\geq 0$.

**iv.** $Y-X\geq 0$ donc par positivité de l'espérance on a $\mathbb{E}(Y-X)\geq 0$, et par linéarité on en déduit que $\mathbb{E}(X)\leq\mathbb{E}(Y)$.

$\square$


**Exemples. i. Espérance d'une loi uniforme finie.** Sot $X$ une loi uniforme sur $R_X=\{x_1,\dots,x_n\}$. On a donc $\mathbb{P}(X=x_k)=\frac{1}{n}$, pour tout entier $1\leq k\leq n$. D'où

$$\mathbb{E}(X)=\frac{1}{n}\sum\limits_{k=1}^n x_k=\overline{x_n}$$
 \noindent autrement dit, $\mathbb{E}(X)$ est la moyenne arithmétique des réels $x_1,\dots, x_n$.
 
 \noindent
 
 **ii. Espérance d'une loi de Bernoulli $\mathcal{B}(p)$.** On a 
 
 \begin{align}
 \mathbb{E}(X)&=0\times (1-p)+1\times p \\
 &= p
 \end{align}
 
 \noindent On en profite pour signaler une égalité extrêment simple mais souvent utile en pratique :
 
:::: {.thmbox .def data-latex="important"}
**Espérance d'une indicatrice.** Pour tout événement $A$, on note $\mathbb{1}_A$ la variable aléatoire appelée **indicatrice de $A$**, définie par 

$$\mathbb{1}_A=
\left \{
\begin{array}{c @{=} c}
    1 & \text{ si } A \text{ est réalisé } \\
    0 & \text{ sinon}
\end{array}
\right.
$$
autrement dit, pour tout $\omega\in\Omega$ :


$$\mathbb{1}_A(\omega)=
\left \{
\begin{array}{c @{=} c}
    1 & \text{ si } \omega\in A \\
    0 & \text{ sinon}
\end{array}
\right.
$$
\noindent $\mathbb{1}_A$ suit une loi de Bernoulli de paramètre $p=\mathbb{P}(A)$, donc en particulier on a

$$\mathbb{E}(\mathbb{1}_A)=\mathbb{P}(A)$$
::::
 
 \noindent Un exemple classique d'application de cette égalité est l'**inégalité de Markov**, qui est démontrée un peu plus bas. 
 
 **iii. Espérance d'une loi binomiale $\mathcal{B}(n,p)$.** Pour $X\sim\mathcal{B}(n,p)$, on peut écrire $X=\sum\limits_{i=1}^n X_i$ avec $X_i\sim\mathcal{B}(p)$. On a donc 
\begin{align}
\mathbb{E}\left(\sum\limits_{i=1}^n X_i\right) &= \sum\limits_{i=1}^n \mathbb{E}(X_i) \\
&=np \\
\end{align}

\noindent d'après ii.

\noindent

**iv. Espérance d'une loi de Poisson $\mathcal{P}(\lambda)$.** Soit $X\sim\mathcal{P}(\lambda)$ avec $\lambda>0$. La série $\sum\limits_{k}\frac{\lambda^k}{k!}k$ est convergente, de somme

\begin{align}
\sum\limits_{k=0}^{\infty}\frac{\lambda^k}{k!}k &= \sum\limits_{k=1}^{\infty}\frac{\lambda^k}{(k-1)!} \\
&= \lambda \sum\limits_{k=1}^{\infty}\frac{\lambda^{k-1}}{(k-1)!} \\
&= \lambda\sum\limits_{k=0}^{\infty}\frac{\lambda^k}{k!} \\
&= \lambda e^{\lambda} \\
\end{align}

\noindent Par conséquent, $X$ admet une espérance et $\mathbb{E}(X)=\lambda$.

\noindent

**v. Espérance d'une loi géométrique $\mathcal{G}(p)$.** On montre que si $X\sim\mathcal{G}(p)$, avec $p\in ]0;1[$ alors $X$ admet une espérance et $$\mathbb{E}(X)=\frac{1}{p}$$

\noindent Pour cela on utilise le résultat suivant (seule l'égalité ii. est utile pour le calcul de l'espérance) :

:::: {.thmbox .thm data-latex="important"}
<center>**Série géométrique, séries géométriques dérivées**</center>

\noindent 

Soit $x$ un réel tel que $|x|<1$. Alors :

\noindent

**i.** $\sum\limits_{n=0}^{\infty}x^n=\frac{1}{1-x}$

\noindent

**ii.** $\sum\limits_{n=1}^{\infty}nx^{n-1}=\frac{1}{(1-x)^2}$

\noindent

**iii.** $\sum\limits_{n=2}^{\infty}n(n-1)x^{n-2}=\frac{2}{(1-x)^3}$

::::

\noindent

**Démonstration. i.** Il s'agit de la somme d'une série géométrique de raison $x$ tel que $|x|<1$. Pour $n$ un entier tel que $n\geq 1$, on a $\sum\limits_{k=0}^n x^k=\frac{1-x^{n+1}}{1-x}$. Comme $|x|<1$ on a $x^{n+1}\to 0$ lorsque $n\to\infty$. Donc la série $\sum\limits_{n}x^n$ est convergente, de somme $\frac{1}{1-x}$.

\noindent

**ii.** Pour $n$ entier supérieur ou égal à $1$, on pose $S_n(x)=\sum\limits_{k=1}^n kx^{k-1}$. On a $S_n=T_n^{'}$, avec $T_n(x)=\sum\limits_{k=0}^n x^k=\frac{1-x^{n+1}}{1-x}$. On a donc, pour $x$ réel tel que $|x|<1$ :

\begin{align}
S_n(x)&=T_n^{'}(x) \\
&=\frac{-(n+1)x^n+(n+1)x^{n+1}+1-x^{n+1}}{(1-x)^2} \\
&=\frac{1-(n+1)x^n+nx^{n+1}}{(1-x)^2} \\
&\to\frac{1}{(1-x)^2}\, \text{ lorsque } n\to\infty \\ 
\end{align}

\noindent par croissances comparées. La série $\sum\limits_{n}nx^{n-1}$ est donc convergente de somme $\frac{1}{(1-x)^2}$, ce qui permet de conclure.

\noindent

**iii.** L'égalité se montre exactement de la même façon que l'égalité ii. 

$\square$

\noindent Avec ce qui précède, la série $\sum\limits_{n}\mathbb{P}(X=n)n=\sum\limits_{n}p\,n\,(1-p)^{n-1}$ est convergente, de somme $\frac{p}{(1-(1-p))^2}=\frac{1}{p}$. Autrement dit, $X$ admet une espérance et $\mathbb{E}(X)=\frac{1}{p}$.

\noindent

**vi. Espérance d'une loi hypergéométrique $\mathcal{H}(N,D,n)$.** On note $X$ le nombre de boules blanches tirées lors de $n$ tirages successifs sans remise dans une urne contenant $D$ boules blanches et $N-D$ boules rouges. On a 

$$X=\sum\limits_{i=1}^n X_i$$
\noindent avec $X_i=1$ si lors du tirage numéro $i$ la boule est blanche, et $X_i=0$ si elle est rouge. On a $X_i\sim\mathcal{B}(p_i)$, avec $p_i=\mathbb{P}(X=i)$, et donc 

$$\mathbb{E}(X)=\sum\limits_{k=1}^n\mathbb{E}(X_i)=\sum\limits_{i=1}^n p_i$$
\noindent Montrons que $p_i$ est constant : $p_i=p$. Pour cela, on note $a_i$ (resp. $b_i$) le nombre de boules blanches (resp. rouges) restantes dans l'urne au moment du tirage numéro $i$. Alors $p_i=\frac{a_i}{b_i}$ et :

- si $X_i=1$, on a $(a_{i+1},b_{i+1})=(a_i-1,b_i)$

- si $X_i=0$, on a $(a_{i+1},b_{i+1})=(a_i,b_i-1)$

D'où 

\begin{align}
p_{i+1}&=\mathbb{P}(X_{i+1}=1|X_i=1)\,p_i+\mathbb{P}(X_{i+1}=1|X_i=0)\frac{b_i}{a_i+b_i}(1-p_i) \\
&=\frac{a_i-1}{a_i+b_i-1}\frac{a_i}{a_i+b_i}+\frac{a_i}{a_i+b_i-1}\frac{b_i}{a_i+b_i} \\
&=\frac{a_i(a_i+b_i-1)}{(a_i+b_i-1)(a_i+b_i)} \\
&=\frac{a_i}{a_i+b_i} \\
&=p_i
\end{align}

\noindent Ainsi, $p_i$ ne dépend pas de $i$ : $p_i=p=p_1=\frac{N}{D}$, et donc 

$$\mathbb{E}(X)=np$$

\noindent Plus généralement, on peut définir la notion de **moment** :

:::: {.defbox .thm data-latex="important"}
<center>**Moments d'une variable aléatoire**</center>

\noindent Soient $X$ une variable aléatoire et $r\in\mathbb{N}$. Si $X^r$ admet une espérance finie, alors 

$$m_r=\mathbb{E}(X^r)$$
\noindent s'appelle **moment d'ordre $r$** de $X$.

\noindent De même, en notant $\mu=\mathbb{E}(X)$, si $(X-\mu)^r$ admet une espérance finie alors on appelle **moment centré d'ordre $r$** le réel

$$\mu_r=\mathbb{E}\left((X-\mu)^r\right)$$
\noindent 

**Cas $r=1$ et $r=2$ (toujours sous réserve d'existence) :**

- $\mu_1=0$
- $\mu_2$ s'appelle la **variance** de $X$, notée $\mathbb{V}(X)$ :

$$\mathbb{V}(X)=\mathbb{E}\left((X-\mu)^2\right)$$
\noindent Si $X$ admet une variance, on appelle **écart-type** de $X$ le réel positif

$$\sigma_X=\sqrt{\mathbb{V}(X)}$$
::::

\noindent

**Remarques. i.** La formule $\mu_1=0$ est une conséquence directe de la linéarité de l'espérance : $\mu_1=\mathbb{E}(X-\mu)=\mathbb{E}(X)-\mu=0$.

\noindent

**ii.** L'espérance est un indicateur de position d'une variable aléatoire, alors que la variance et l'écart-type sont des indicateurs de dispersion. L'écart-type présente l'avantage sur la variance d'être de même dimension que la variable (tout comme l'espérance).

\noindent La formule de König-Huygens permet d'exprimer la variance à partir des moments d'ordre 1 et 2 :

:::: {.thmbox .thm data-latex="important"}
<center>**Formule de König-Huygens**</center>
\noindent
Soit $X$ une variable aléatoire réelle discrète admettant une variance. Alors

$$\mathbb{V}(X)=\mathbb{E}(X^2)-\mathbb{E}(X)^2$$
::::

\noindent

**Démonstration.** En posant $\mu=\mathbb{E}(X)$, on a 

$$(x-\mu)^2=X^2-2\mu X+\mu^2$$
\noident En passant à l'espérance :

\begin{align}
\mathbb{V}(X)&=\mathbb{E}(X^2)-2\mu^2+\mu^2 \\
&=\mathbb{E}(X^2)-\mu^2 \\
\end{align}
\noindent d'où le résultat.
$\square$

\noindent

**Remarque.** En pratique, c'est souvent cette formule que l'on utilise pour calculer une variance, qui est plus simple que celle de la définition.

:::: {.thmbox .thm data-latex="important"}
<center>**Propriétés de la variance**</center>
\noindent Soient $X$ une variable aléatoire réelle discrète admettant une variance, et $a$ et $b$ deux réels. Alors :

\noindent

**i.** $\mathbb{V}(X)\geq 0$ avec égalité si et seulement si $X$ est constante.

\noindent

**ii.** $\mathbb{V}(aX+b)=a^2\mathbb{V}(X)$.
::::

\noindent 

**Démonstration. i.** On note $\{x_k\,;\,k\in K\subset\mathbb{N}\}$ les valeurs prises par $X$ et $p_k=\mathbb{P}(X=x_k)>0$.

$\mathbb{V}(X)=\sum\limits_{k\in K}p_k\,(x_k-\mu)^2=0$ si et seulement si $x_k=\mu$ pour tout $k$ dans $K$, autrement dit si et seulement si $X$ est constante, égale à son espérance $\mu$.

\noindent

**ii.** $\mathbb{E}(aX+b)=a\mu+b$, donc $\left(aX+b-\mathbb{E}(aX+b)\right)^2=a^2(X-\mu)^2$, et en passant à l'espérance on en déduit que $\mathbb{V}(aX+b)=a^2\,\mathbb{V}(X)$.

$\square$

**Exemples. i. Variance d'une loi uniforme.** Soit $X$ uniforme sur l'ensemble fini $\{x_1,\dots,x_n\}$. Alors

$$\mathbb{E}(X^2)=\frac{1}{n}\sum\limits_{k=1}^n x_k^2$$
\noindent et donc

$$\mathbb{V}(X)=\frac{1}{n}\sum\limits_{k=1}^n x_k^2-\left(\frac{1}{n}\sum\limits_{k=1}^n x_k\right)^2$$

\noindent

**ii. Variance d'une loi de Bernoulli $\mathcal{B}(p)$.** Si $X\sim\mathcal{B}(p)$, alors $X^2=X$ (car $X\in\{0,1\}$) donc $\mathbb{E}(X^2)=\mathbb{E}(X)=p$, d'où

$$\mathbb{V}(X)=p\,(1-p)$$

\noindent

**iii. Variance d'une loi binomiale $\mathcal{B}(n,p)$.** On démontrera un peu plus loin que, si $X\sim\mathcal{B}(n,p)$, alors 

$$\mathbb{V}(X)=n\,p\,(1-p)$$

\noindent

**iv. Variance d'une loi de Poisson $\mathcal{P}(\lambda)$.** Soit $X\sim\mathcal{P}(\lambda)$. Soit $n\geq 1$ un entier. On a 

\begin{align}
\sum\limits_{k=0}^n\frac{\lambda^k}{k!}k^2&=\sum\limits_{k=2}^n\frac{\lambda^k}{k!}k(k-1)+\sum\limits_{k=2}^n\frac{\lambda^k}{k!}k \\
&=\lambda^2\sum\limits_{k=2}^n\frac{\lambda^{k-2}}{(k-2)!}+\lambda\sum\limits_{k=1}^n\frac{\lambda^{k-1}}{(k-1)!} \\
&=\lambda^2\sum\limits_{k=0}^{n-2}\frac{\lambda^k}{k!}+\lambda^k\sum\limits_{k=0}^{n-1}\frac{\lambda^k}{k!} \\
&\to (\lambda^2+\lambda)e^{\lambda} \\
\end{align}

\noindent La série $\sum\limits_{n}\frac{\lambda^n}{n!}n^2$ est donc convergente de somme $(\lambda^2+\lambda)e^{\lambda}$. On en déduit que $X^2$ admet une espérance, et que 

$$\mathbb{E}(X^2)=\lambda^2+\lambda$$

\noindent Comme $\mathbb{E}(X)=\lambda$, on en déduit que 

$$\mathbb{V}(X)=\lambda$$

\noindent

**v. Variance d'une loi géométrique $\mathcal{G}(p)$.** Pour $p\in ]0\,;\,1[$, on a

$$\sum\limits_{n=2}^{\infty}n(n-1)(1-p)^{n-2}=\frac{2}{p^3}$$

\noindent soit

$$\sum\limits_{n=1}^{\infty}n(n+1)(1-p)^{n-1}=\frac{2}{p^3}$$
\noindent et donc

\begin{align}
\mathbb{E}(X^2)&=p\sum\limits_{n=1}^{\infty}n^2(1-p)^{n-1} \\
&=\frac{2}{p^2}-p\sum\limits_{n=1}^{\infty}n(1-p)^{n-1} \\
&=\frac{2}{p^2}-\mathbb{E}(X) \\
&=\frac{2}{p^2}-\frac{1}{p} \\
&=\frac{2-p}{p^2}
\end{align}

\noindent d'où

\begin{align}
\mathbb{V}(X)&=\mathbb{E}(X^2)-\mathbb{E}(X)^2 \\
&=\frac{2-p}{p^2}-\frac{1}{p^2}\\
&=\frac{1-p}{p^2}
\end{align}

\noindent

**vi. Variance d'une loi hypergéométrique $\mathcal{H}(N,D,n)$.** Si $X\sim\mathcal{H}(N,D,n)$ alors $X$ admet une variance et 

$$\mathbb{V}(X)=\frac{N-n}{N-1}\times\frac{nD}{N}\left(1-\frac{D}{N}\right)$$

\noindent (formule admise pour le moment)

### Quelques inégalités classiques

\noindent Les inégalités qui suivent reviennent souvent dans les exercices et problèmes du concours.

:::: {.thmbox .thm data-latex="important"}
**Inégalité triangulaire.** Soit $X$ une variable aléatoire réelle discrète telle que $|X|$ est d'espérance finie. Alors $X$ est d'espérance finie et

$$|\mathbb{E}(X)|\leq\mathbb{E}(|X|)$$

::::

\noindent

**Démonstration.** Par définition, $X$ est d'espérance finie si et seulement si $|X|$ est d'espérance finie. On a alors :

\begin{align}
|\mathbb{E}(X)|&=\left|\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})X(\omega)\right| \\
&\leq\sum\limits_{\omega\in\Omega}|\mathbb{P}(\{\omega\})X(\omega)| \\
&=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})|X(\omega)| \\
&=\mathbb{E}(|X|)
\end{align}

$\square$

\noindent L'inégalité triangulaire est un cas particulier d'une inégalité beaucoup plus générale, appelée **inégalité de Jensen**. 

\noindent

**Rappel (fonction convexe) :** Soit $I\subset\mathbb{R}$ un intervalle. Une fonction $\varphi:I\longrightarrow\mathbb{R}$ est dite **convexe** si pour tout couple $(x,y)\in I^2$ et pour tout réel $t\in [0,1]$ on a

$$\varphi(tx+(1-t)y)\leq t\,\varphi(x)+(1-t)\,\varphi(y)$$

\noindent Cette définition admet une interprétation graphique simple : $\varphi$ est convexe si et seulement si sa courbe représentative est située **en-dessous** de chacune de ses **cordes**.

\noindent On peut montrer que cette définition de la convexité est équivalente à la définition suivante : $\varphi:I\longrightarrow\mathbb{R}$ est convexe si et seulement si pour tout $n-$uplet $(t_1,\dots t_n)$ de réels positifs tels que $t_1+\dots t_n=1$, pour tout $n-$uplet $(x_1,\dots, x_n)$ de réels, on a 

$$\varphi(t_1x_1+\dots t_n x_n)\leq t_1\,\varphi(x_1)+\dots t_n\,\varphi(x_n)$$

\noindent Dans le cas où $\varphi$ est dérivable sur $I$, elle est convexe si et seulement si sa dérivée $\varphi^{'}$ est croissante sur $I$, autrement dit si la pente de sa courbe représentative est croissante. On peut montrer que cela revient encore à dire que la courbe représentative de $\varphi$ est située **au-dessus** de chacune de ses tangentes.

\noindent Dans le cas où $\varphi$ est deux fois dérivable sur $I$, avec ce qui précède on obtient immédiatement que $\varphi$ est convexe si et seulement si $\varphi^{''}\geq 0$ sur $I$.

\noindent Enfin, on dit que $\varphi:I\longrightarrow\mathbb{R}$ est **concave** sur $I$ si et seulement si $-\varphi$ est convexe sur $I$.

:::: {.thmbox .thm data-latex="important"}
**Inégalité de Jensen.** Soient $I$ un intervalle réel, $\varphi:I\longrightarrow\mathbb{R}$ une fonction convexe et $X:\Omega\longrightarrow I$ une variable aléatoire discrète à valeurs dans $I$, admettant une espérance et telle que $\varphi(X)$ admet une espérance. Alors

$$\varphi\left(\mathbb{E}(X)\right)\leq\mathbb{E}\left(\varphi(X)\right)$$

::::

\noindent 

**Démonstration.** On démontre l'inégalité dans le cas où $\varphi$ est dérivable. Dans ce cas, la convexité de $\varphi$ signifie que la courbe représentative de $f$ est située au-dessus de chacune de ses **tangentes**. Pour tout réel $a$ dans $I$, on a donc

$$\forall x\in I,\, \varphi(x)\geq \varphi(a)+(x-a)\,\varphi'(a)$$
\noindent et donc en particulier pour $a=\mathbb{E}(X)$ et $x=X$ on obtient

$$\varphi(X)\geq\varphi\left(\mathbb{E}(X)\right)+\left(X-\mathbb{E}(X)\right)\,\varphi'\left(\mathbb{E}(X)\right)$$
\noindent En passant à l'espérance, on obtient

\begin{align}
\mathbb{E}(\varphi(X))&\geq\mathbb{E}\left(\varphi(\mathbb{E}(X))+\left(X-\mathbb{E}(X)\right)\,\varphi'(\mathbb{E}(X))\right) \\
&=\varphi(\mathbb{E}(X))+(\mathbb{E}(X)-\mathbb{E}(X))\,\varphi'(\mathbb{E}(X)) \\
&=\varphi(\mathbb{E}(X))
\end{align}

\noindet par croissance et linéarité de l'espérance.

$\square$

\noindent 

**Remarque.** Dans le cas où $X$ est à support fini $\{x_1,\dots, x_n\}$ on a 

\begin{align}
\varphi(\mathbb{E}(X))&=\varphi\left(\sum\limits_{k=1}^n\mathbb{P}(X=x_k)\,x_k\right) \\
&\leq\sum\limits_{k=1}^n\mathbb{P}(X=x_k)\,\varphi(x_k) \,\text{ ; par convexité} \\
&=\mathbb{E}\left(\varphi(X)\right) \\
\end{align}

\noindent Le cas discret infini revient à étendre cette inégalité à des sommes infinies (sous réserve d'existence), autrement dit à écrire que

$$\varphi\left(\sum\limits_{k=1}^{\infty}\mathbb{P}(X=x_k)\,x_k\right)\leq\sum\limits_{k=1}^{\infty}\mathbb{P}(X=x_k)\,\varphi(x_k)$$
\noindent

**Exemples. i.** L'inégalité triangulaire est un cas particulier d'application de l'inégalité de Jensen à la fonction valeur absolue, qui est bien convexe sur $\mathbb{R}$. 

\noindent 

**ii.** La fonction $x\mapsto x^2$ est convexe sur $\mathbb{R}$, donc, sous réserve d'existence des espérances, on a 

$$\mathbb{E}(X)^2\leq\mathbb{E}(X^2)$$
\noindent Les deux inégalités qui suivent sont des **inégalités de concentration**. Une inégalité de concentration donne un majorant à la probabilité qu'une variable aléatoire positive s'écarte d'une certaine valeur.

\noindent L'inégalité de Markov est à la fois très utile et très facile à démontrer. Il faut retenir qu'elle permet de montrer l'inégalité de Bieanymé-Tchébychev. 

:::: {.thmbox .thm data-latex="important"}
**Inégalité de Markov.** Soit $X$ une variable aléatoire **positive** admettant une espérance. Alors, pour tout réel $a$ positif :

$$\mathbb{P}(X\geq a)\leq\frac{\mathbb{E}(X)}{a}$$
::::

\noindent

**Démonstration.** Soit $a$ un réel positif. Toute réalisation $X(\omega)$ est soit supérieure ou égale à $a$, soit strictement inférieure à $a$. On a donc l'égalité

$$X=X.\mathbb{1}_{X\geq a}+X.\mathbb{1}_{X<a}$$

\noindent d'où 

\begin{align}
\mathbb{E}(X)&=\mathbb{E}(X.\mathbb{1}_{X\geq a}+X.\mathbb{1}_{X<a}) \\
&=\mathbb{E}(X.\mathbb{1}_{X\geq a})+\mathbb{E}(X.\mathbb{1}_{X<a}) \\
&\geq a\mathbb{E}(\mathbb{1}_{X\geq a}) \\
&=a\mathbb{P}(X\geq a)
\end{align}

\noindent d'où (puisque $a>0$) :

$$\mathbb{P}(X\geq a)\leq\frac{\mathbb{E}(X)}{a}$$
$\square$

\noindent

**Exemples. i.** Démontrer que pour toute variable aléatoire $X$ et pour tout réel $a$, on a $\mathbb{P}(X\geq a)\leq\mathbb{E}(e^{X-a})$.

\noindent 

**Solution.** Posons $Y=e^{X-a}$ : il s'agit d'une variable aléatoire positive. Par ailleurs, l'événement $(X\geq a)$ peut aussi s'écrire $(Y\geq 1)$. Donc, par application de l'inégalité de Markov :

\begin{align}
\mathbb{P}(X\geq a)&=\mathbb{P}(Y\geq 1) \\
&\leq\frac{\mathbb{E}(Y)}{1} \\
&=\mathbb{E}(e^{X-a})
\end{align}

\noindent 

**ii.** Soient $X$ une variable aléatoire et $f:\mathbb{R}_+\longrightarrow\mathbb{R}_+$ une fonction strictement croissante. Démontrer :

$$\forall a>0,\,\mathbb{P}(|X|\geq a)\leq\frac{\mathbb{E}(f(|X|))}{f(a)}$$
\noindent

**Solution.** On pose $Y=f(|X|)$ : on a $Y\geq 0$, puisque $f$ est une fonction de $\mathbb{R}_+$ dans lui-même. Comme $f$ est croissante, les événements $(|X|\geq a)$ et $(Y\geq f(a))$ sont égaux. D'où, par l'inégalité de Markov :

\begin{align}
\mathbb{P}(|X|\geq a)&=\mathbb{P}(Y\geq f(a)) \\
&\leq\frac{\mathbb{E}(Y)}{f(a)} \\
&=\frac{\mathbb{E}(f(|X|))}{f(a)}
\end{align}

$\square$

\noindent Lorsque $X$ admet des moments d'ordres $1$ et $2$, on peut appliquer l'**inégalité de Bienaymé-Tchebychev**, qui se déduit de façon immédiate de l'inégalité de Markov :

:::: {.thmbox .thm data-latex="important"}
**Inégalité de Bienaymé-Tchebychev.** Soit $X$ une variable aléatoire admettant une espérance et une variance. Alors, pour tout réel $a$ strictement positif :

$$\mathbb{P}\left(|X-\mathbb{E}(X)|\geq a\right)\leq\frac{\mathbb{V}(X)}{a^2}$$
::::

\noindent

**Démonstration.** On pose $Y=\left(X-\mathbb{E}(X)\right)^2\geq 0$. On a $|X-\mathbb{E}(X)|\geq a\Leftrightarrow Y\geq a^2$. D'après l'inégalité de Markov :

\begin{align}
\mathbb{P}(|X-\mathbb{E}(X)|\geq a)&=\mathbb{P}(Y\geq a^2) \\
&\leq\frac{\mathbb{E}(Y)}{a^2} \\
&=\frac{\mathbb{V}(X)}{a^2} \\
\end{align}

$\square$

\noindent

**Interprétation.** L'inégalité de Bienaymé-Tchebychev nous dit qu'une variable aléatoire ne peut s'éloigner de son espérance qu'avec une faible probabilité :  $\mathbb{P}(|X-\mathbb{E}(X)|\geq a)$ est coincé entre $0$ et $\frac{\mathbb{V}(X)}{a^2}$, qui devient de plus en plus proche de $0$ au fur et à mesure que $a$ augmente.

\noindent

**Application de l'inégalité de Bienaymé-Tchebychev :** la loi faible des grands nombres, qui sera abordée plus tard.

\noindent

**Exemple.** On joue $1\,000$ fois à pile ou face avec une pièce équilibrée. Montrer que la probabilité d'obtenir entre $480$ et $520$ faces est supérieure ou égale à $0,375$.

\noindent

**Solution.** On note $X$ le nombre de faces obtenues. $X$ est une variable aléatoire suivant la loi de Benoulli $\mathcal{B}\left(1\,000\,;\,\frac{1}{2}\right)$. On a $\mathbb{E}(X)=500$ et $\mathbb{V}(X)=250$. Donc, d'après l'inégalité de Bienaymé-Tchebcychev :

\begin{align}
\mathbb{P}\left(X\in[480\,;\,520]\right)&=\mathbb{P}(|X-\mathbb{E}(X)|\leq 20) \\
&=1-\mathbb{P}(|X-\mathbb{E}(X)|>20) \\
&\geq 1-\mathbb{P}(|X-\mathbb{E}(X)|\geq 20) \\
&\geq 1-\frac{\mathbb{V}(X)}{20^2} \\
&=1-\frac{250}{400} \\
&=0,375
\end{align}

\noindent d'où le résultat.




\noindent Une autre inégalité classique est l'inégalité de Cauchy-Schwarz. Elle sera présentée un peu plus bas, dans la section consacrée aux vecteurs aléatoires.



## Transformation d'une variable aléatoire discrète

\noindent Il arrive souvent dans les exercices qu'on étudie des variables aléatoires s'écrivant comme fonctions de variables aléatoires plus simples, ou dont la loi est connue.

\noindent Soient $D$ un sous-ensemble au plus dénombrable de $\mathbb{R}$, $X:\Omega\longrightarrow D$ une variable aléatoire réelle discrète de support $D$, et $\varphi:D\longrightarrow\mathbb{R}$ une fonction injective. Elle réalise donc une bijection de $D$ sur $\varphi(D)=\{\varphi(x),\,x\in D\}$.

\noindent On pose $Y=\varphi(X)$ : il s'agit d'une variable aléatoire réelle discrète, définie sur $\Omega$ et de support $\varphi(D)$.

\noindent La loi de $Y$ se déduit facilement de celle de $X$. Pour tout $y\in\varphi(D)$ :

\begin{align}
\mathbb{P}(Y=y)&=\mathbb{P}(\varphi(X)=y)\\
&=\mathbb{P}(X=\varphi^{-1}(y))
\end{align}

\noindent

**Exemple.** Soit $X\sim\mathcal{P}(\lambda)$, où $\lambda>0$. Déterminer la loi de $\ln(X+1)$.

\noindent

**Solution.** $X$ est à support dans $\mathbb{N}$, donc $Y=\ln(X+1)$ est à support dans $\{\ln(k),\,k\in\mathbb{N}^*\}\subset\mathbb{R}_+$ et, pour tout $k\in\mathbb{N}^*$ :

\begin{align}
\mathbb{P}(\ln(X+1)=\ln k)&=\mathbb{P}(X=k-1) \\
&=e^{-\lambda}\frac{\lambda^{k-1}}{(k-1)!}
\end{align}



## Vecteurs aléatoires

### Couple aléatoire : loi conjointe, lois marginales

:::: {.defbox .def data-latex="important"}
<center>**Couple de variables aléatoires, loi conjointe, lois marginales**</center>
\noindent Soient $X$ et $Y$ deux variables aléatoires réelles discrètes définies sur le même espace probabilisé $(\Omega,\mathcal{P}(\Omega),\mathbb{P})$.

\noindent La variable aléatoire

$$(X,Y):\omega\in\Omega\longrightarrow (X(\omega), Y(\omega))\in\mathbb{R}^2$$
\noindent est également une variable aléatoire discrète.
Sa loi, appelée **loi conjointe** de $X$ et $Y$, est définie par la donnée des probabilités $\mathbb{P}(\{X=x\}\cap\{Y=y\})$ pour tous les couples $(x,y)\in X(\Omega)\times Y(\Omega)$. Ces probabilités seront notées par la suite plus simplement $\mathbb{P}(X=x,Y=y)$.

\noindent Par ailleurs, les lois de $X$ et de $Y$ sont appelées les **lois marginales** du couple $(X,Y)$.

\noindent Les lois marginales se déduisent de la loi conjointe :

$$\forall x\in X(\Omega),\, \mathbb{P}(X=x)=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(X=x, Y=y)$$
$$\forall y\in Y(\Omega),\, \mathbb{P}(Y=y)=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x, Y=y)$$
::::

\noindent

**Démonstration.** Soit $x\in X(\Omega)$. Les événements $(Y=y), \, y\in Y(\Omega)$ forment un système complet d'événements, donc les événements $(X=x, Y=y),\, y\in Y(\Omega)$ constituent une partition de l'événement $(X=x)$. D'après la formule des probabilités totales, on a donc

$$\mathbb{P}(X=x)=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(X=x,Y=y)$$
\noindent En échangeant les rôles de $X$ et $Y$, on obtient la deuxième formule.

$\square$

\noindent

**Notation.** Soient $x_i, \, i\in I$ et $y_j,\,j\in J$ les valeurs prises par $X$ et $Y$ (avec $I,J\subset\mathbb{N}$ puisque $X$ et $Y$ sont discrètes). Dans la suite, on notera souvent, pour $(i,j)\in I\times J$ :

\begin{align}
p_{ij}&=\mathbb{P}(X=x_i, Y=y_j) \\
p_{i.}&=\mathbb{P}(X=x_i) \\
p_{.j}&=\mathbb{P}(Y=y_j)
\end{align}

\noindent Avec ces notations, a donc, pour tout couple $(i,j)\in I\times J$ :

$$p_{i.}=\sum\limits_{j\in J}p_{ij}$$
$$p_{.j}=\sum\limits_{i\in I}p_{ij}$$
\noindent

**Tableau de contingence.** Un tableau de contingence d'un couple de variables aléatoires contient toutes les informations sur la loi de ce couple :

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/tableau_contingence.PNG") 
```
</center>

On y trouve :

- la loi du couple $(X,Y)$, donnée par les cellules du tableau, en nombre $\text{Card}(X(\Omega))\times\text{Card}(Y(\Omega))$ (éventuellement infini). La probabilité $p_{ij}=\mathbb{P}(X=i, Y=j)$ se trouve dans la cellule située à la ligne $i$ et la colonne $j$  ;

- la loi marginale $\mathbb{P}_Y$ de $Y$ sur la ligne des totaux (en bleu) ;

- la loi marginale $\mathbb{P}_X$ de $X$ sur la colonne des totaux (en rouge).


\noindent Ce tableau doit aussi servir de mise en garde sur le fait que, sauf cas trivial (variable(s) aléatoire(s) constante(s)) :

<center>**La connaissance des lois marginales ne suffit pas à caractériser la loi du couple**</center>

<br>



\noindent En effet, les lois marginales correspondent à la ligne des totaux (en bleu) et la colonne des totaux (en rouge). Or, il n'y a pas unicité des nombres $p_{ij}$ permettant de générer cette ligne et cette colonne. La connaissance des $p_{i.}$ et des $p_{.j}$ ne suffit donc pas à reconstruire les $p_{ij}$. Le premier (contre-)exemple ci-dessous permet de s'en convaincre.

**Exemples.i.** On considère les couples de variables aléatoires $(X_1, Y_1)$ et $(X_2, Y_2)$ dont les lois sont données par les tableaux ci-dessous :

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/contingence_exemples.PNG") 
```
</center>

\noindent $(X_1, Y_1)$ et $(X_2, Y_2)$ ont les même lois marginales :

- $X_1$ et $X_2$ ont pour support commun $\{x_1, x_2\}$ et :

$$\mathbb{P}(X_1=x_1)=\mathbb{P}(X_2=x_1)=0,6$$

$$\mathbb{P}(X_1=x_2)=\mathbb{P}(X_2=x_2)=0,4$$

- $Y_1$ et $Y_2$ ont pour support commun $\{y_1, y_2\}$ et :

$$\mathbb{P}(Y_1=y_1)=\mathbb{P}(Y_2=y_1)=0,3$$

$$\mathbb{P}(X_1=x_2)=\mathbb{P}(X_2=x_2)=0,7$$

\noindent Pourtant, $(X_1, Y_1)$ et $(X_2, Y_2)$ n'ont pas les mêmes lois conjointes. Par exemple :

$$\mathbb{P}(X_1=x_1, Y_1=y_1)=0,2$$
$$\mathbb{P}(X_2=x_1, Y_2=y_1)=0,25$$


**ii.** On suppose que le couple $(X,Y)$ est à valeurs dans $E=\{x_1\dots x_n\}\times\{y_1\dots y_p\}$ et que

$$\forall 1\leq i\leq n, \, \forall 1\leq j\leq p,\,\mathbb{P}(X=x_i, Y=y_j)=\frac{1}{np}$$

\noindent autrement dit $(X,Y)$ consiste en un tirage uniforme dans $E$. Intuitivement, on devine que $X$ (resp. $Y$) correspond à un tirage uniforme dans $\{x_1,\dots,x_n\}$ (resp. dans $\{y_1,\dots y_p\}$). La démonstration est évidente :

\begin{align}
\mathbb{P}(X=x_i)&=\sum\limits_{j=1}^p\mathbb{P}(X=x_i, Y=y_j) \\
&=\sum\limits_{j=1}^p\frac{1}{np} \\
&=\frac{1}{n}
\end{align}

\noindent et symétriquement on a évidemment

$$\mathbb{P}(Y=y_j)=\frac{1}{p}$$
\noindent

**iii.** Soient $X$ et $Y$ deux variables aléatoires à valeurs dans $\mathbb{N}$. On suppose que la loi conjointe de $(X,Y)$ est donnée par

$$\mathbb{P}(X=i, Y=j)=\frac{a}{i!\,j!}$$
\noindent avec $a$ un réel.

\noindent Nous allons déterminer les lois marginales de $X$ et $Y$. Pour cela, on constate d'abord que la valeur de $a$ est contrainte par l'égalité

$$\sum\limits_{i=0}^{\infty}\sum\limits_{j=0}^{\infty}\mathbb{P}(X=i, Y=j)=1$$
\noindent qui s'écrit

$$a\sum\limits_{i=0}^{\infty}\frac{1}{i!}.\sum\limits_{j=0}^{\infty}\frac{1}{j!}=1$$
\noident et qui permet de trouver que

$$a=\frac{1}{e^2}$$
\noindent On en déduit que, pour tout entier naturel $i$, on a :

\begin{align}
\mathbb{P}(X=i&)=\sum\limits_{j=0}^{\infty}\mathbb{P}(X=i, Y=j) \\
&= \frac{1}{e^2}\sum\limits_{j=0}^{\infty}\frac{1}{i!\,j!} \\
&=\frac{1}{e.i!}
\end{align}

\noindent On reconnaît la loi de Poisson $\mathcal{P}(1)$. 

\noindent $X$ et $Y$ jouant des rôles symétriques, on a donc

$$X\sim\mathcal{P}(1)$$
$$Y\sim\mathcal{P}(1)$$

### $n-$uplets aléatoires

\noindent Ce qui précède se généralise sans difficulté aux vecteurs aléatoires de taille quelconque, i.e. aux $n-$uplets $(X_1,\dots,X_n)$ de variables aléatoires discrètes réelles définies sur un même espace probabilisé $(\Omega, \mathcal{P}(\Omega), \mathbb{P})$.

\noindent La loi conjointe d'un tel vecteur est définie par la donnée de son support $X_1(\Omega)\times\dots\times X_n(\Omega)$ et des probabilités

$$\mathbb{P}(X_1=x_1,\dots,X_n=x_n)$$
\noindent pour tous les $n-$uplets $(x_1,\dots,x_n)\in X_1(\Omega)\times\dots\times X_n(\Omega)$.

\noindent Le vecteur $(X_1,\dots,X_n)$ possède $n$ lois marginales, qui sont les lois $\mathbb{P}_{X_1},\dots,\mathbb{P}_{X_n}$ des variables $X_1,\dots,X_n$. 

\noindent La loi conjointe d'un vecteur de taille quelconque définit complètement les lois marginales, mais à nouveau les lois marginales ne suffisent pas à définir la loi conjointe.


## Loi conditionnelle $\mathbb{P}_{X|Y=y_j}$

\noindent Soit $(X,Y)$ un couple aléatoire dont la loi est donnée par le tableau de contingence suivant :

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/tableau_contingence.PNG") 
```
</center>

\noindent La colonne numéro $j$ fixe la valeur de $Y$ à $Y=y_j$. Considérons la liste des probabilités apparaissant dans cette colonne :

$$p_{1j},\dots,p_{nj}$$
\noindent Cette série de valeurs somme à $p_{.j}$ :

$$\sum\limits_{i\in I}p_{ij}=p_{.j}$$
\noindent Donc, en divisant toutes ces probabilités par $p_{.j}$, on obtient des nombres compris entre $0$ et $1$ et qui somment à $1$ :

$$\sum\limits_{i\in I}\frac{p_{ij}}{p_{.j}}=1$$
\noindent de sorte que le vecteur $\left(\frac{p_{1j}}{p_{.j}},\dots,\frac{p_{nj}}{p_{.j}},\dots\right)$ peut s'interpréter comme une loi de probabilité. Mais ces valeurs caractérisent la distribution de $X$ lorsqu'on se place dans la colonne numéro $j$, autrement dit lorsqu'on fait l'hypothèse $Y=j$. Il est donc naturel d'appeler cette distribution la **loi de $X$ conditionnellement à $(Y=y_j)$**.

\noindent L'ensemble des lois conditionnelles $\mathbb{P}(X|Y=y_j)$ sont données par le tableau suivant (lecture en colonnes) :

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/tableau_x_sachant_y.PNG") 
```
</center>


:::: {.defbox .def data-latex="important"}
**Loi conditionnelle de $X$ sachant $Y=y_j$.** Avec les notations précédentes, et sous réserve que $\mathbb{P}(Y=y_j)>0$, on pose, pour tout $x_i\in X(\Omega)$ :

$$\mathbb{P}(X=x_i|Y=y_j)=\frac{\mathbb{P}(X=x_i, Y=y_j)}{\mathbb{P}(Y=y_j)}$$

\noindent On définit ainsi une loi de probabilité, appelée **loi conditionnelle de $X$ sachant que $Y=y_j$**, et notée $\mathbb{P}_{X|Y=y_j}$.
::::

\noindent

**Remarques. i.** De façon symétrique, on définit des lois conditionnelles $\mathbb{P}_{Y|X=x_i}$ pour toutes les valeurs de $i$ telles que $\mathbb{P}(X=x_i)>0$. Cette loi est définie par la donnée des probabilités

$$\mathbb{P}(Y=y_j|X=x_i)=\frac{\mathbb{P}(X=x_i, Y=y_j)}{\mathbb{P}(X=x_i)}$$
\noindent pour tous les $y_j\in Y(\Omega)$.

\noindent L'ensemble de ces lois conditionnelles $\mathbb{P}_{Y|X=x_i}$ sont représentées dans le tableau suivant (lecture en lignes) :

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/tableau_y_sachant_x.PNG") 
```
</center>

\noindent

**ii.** On peut aussi introduire la notion de loi conditionnelle en utilisant directement la définion de probabilité conditionnelle faite au chapitre précédent. Pour deux événements $A$ et $B$ tels que $\mathbb{P}(B)>0$, on définit la probabilité de $A$ sachant $B$ en posant 

$$\mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}$$
\noindent En posant $A=(X=x_i)$ et $B=(Y=y_j)$, on a donc

$$\mathbb{P}(X=x_i|Y=y_j)=\frac{\mathbb{P}(X=x_i, Y=y_j)}{\mathbb{P}(Y=y_j)}$$
\noindent L'approche par tableau de contingence présente toutefois l'avantage d'être un peu plus intuitive.

\noindent 

**Exemples. i.** On tire aléatoirement deux nombres $X$ et $Y$ selon la règle suivante :

- tirage de $X$ selon une loi de Bernoulli de paramètre $p\in ]0,1[$ ;

- puis tirage de $Y$ :

  - si $X=0$, on tire $Y$ selon une loi de Poisson $\mathcal{P}(\lambda)$, avec $\lambda>0$ ;
  
  - si $X=1$, on tire $Y$ selon une loi uniforme sur $\{0,1,2,3\}$.
  

\noindent On connait donc la loi de $X$ : 
$$X\sim\mathcal{B}(p)$$
\noindent et on connait les lois de $Y$ sachant $X=0$ et de $Y$ sachant $X=1$ :

$$Y|X=0\sim\mathcal{P}(\lambda)$$
$$Y|X=1\sim\mathcal{U}\left(\{0,1,2,3\}\right)$$
\noindent On peut en déduire facilement les lois $\mathbb{P}_Y$ et $\mathbb{P}_{(X,Y)}$.

**Commençons par la loi de $Y$.**

- **Support de $Y$ :** $Y(\Omega)=\mathbb{N}$
- **Probabilités $\mathbb{P}(Y=j)$ :** pour tout entier naturel $j$, on a

\begin{align}
\mathbb{P}(Y=j)&=\mathbb{P}(Y=j|X=0)\mathbb{P}(X=0)+\mathbb{P}(Y=j|X=1)\mathbb{P}(X=1) \\
&=(1-p).\mathbb{P}(Y=j|X=0)+p.\mathbb{P}(Y=j|X=1)
\end{align}

\noindent On en déduit que :

- si $0\leq j\leq 3$, alors

$$\mathbb{P}(Y=j)=(1-p)\,e^{-\lambda}\frac{\lambda^j}{j!}+\frac{p}{4}$$

- si $j\geq 4$, alors

$$\mathbb{P}(Y=j)=(1-p)\,e^{-\lambda}\frac{\lambda^j}{j!}$$
\noindent **On détermine maintenant la loi conjointe de $(X,Y)$**

- **Support de $(X,Y)$ :** $(X,Y)(\Omega)=\{0,1\}\times\mathbb{N}$

- **Probabilités $\mathbb{P}(X=i, Y=j)$ :** pour $(i,j)\in\{0,1\}\times\mathbb{N}$, on a 

- pour $i=0$ :

\begin{align}
\mathbb{P}(X=0,Y=j)&=\mathbb{P}(Y=j|X=0)\mathbb{P}(X=0) \\
&= (1-p)e^{-\lambda}\frac{\lambda^j}{j!} \\
\end{align}

- pour $i=1$, on a 

\begin{align}
\mathbb{P}(X=1,Y=j)&=\mathbb{P}(Y=j|X=1)\mathbb{P}(X=1) \\
&=\left \{
\begin{array}{c @{=} c}
    \frac{p}{4} & \text{ si } 0\leq j\leq 3 \\
    0 & \text{ si } j\geq 4
\end{array}
\right.
\end{align}

\noindent On peut donner l'expression générale de $\mathbb{P}(X=i, Y=j)$ :

$$\mathbb{P}(X=i, Y=j)=i\,\frac{p}{4}.\mathbb{1}_{0\leq j\leq 3}+(1-i)(1-p)e^{-\lambda}\frac{\lambda^j}{j!}$$

\noindent 

**On en déduit alors la loi de $Y$.**

- **Support de $Y$ :** $Y(\Omega)=\mathbb{N}$
- **Probabilités $\mathbb{P}(Y=j)$ :** pour tout entier naturel $j$, on a, d'après la formule des probabilités totales :

\begin{align}
\mathbb{P}(Y=j)&=\mathbb{P}(Y=j,X=0)+\mathbb{P}(Y=j,X=1) \\
&=(1-p)e^{-\lambda}\frac{\lambda^j}{j!}+\frac{p}{4}\mathbb{1}_{0\leq j\leq 3}
\end{align}


\noindent 

## Indépendance de deux variables aléatoires

\noindent Dans un exemple précédent, on a défini la loi d'un couple aléatoire $(X,Y)$ par

$$\forall (i,j)\in\mathbb{N}^2,\,\mathbb{P}(X=i, Y=j)=\frac{1}{e^2\,i!\,j!}$$
\noindent et on a montré que les lois marginales sont toutes les deux égales à la loi de Poisson $\mathcal{P}(1)$ :

$$\forall i\in\mathbb{N},\,\mathbb{P}(X=i)=\mathbb{P}(Y=i)=\frac{1}{e.i!}$$
\noindent On en déduit que

\begin{align}
\mathbb{P}(X=i|Y=j)&=\frac{\mathbb{P}(X=i, Y=j)}{\mathbb{P}(Y=j)}\\
&=\frac{\frac{1}{e^2\,i!\,j!}}{\frac{1}{e\,j!}} \\
&=\frac{1}{e\,i!} \\
&=\mathbb{P}(X=i)
\end{align}

\noindent De façon analogue :

$$\mathbb{P}(Y=j|X=i)=\mathbb{P}(Y=j)$$

\noindent Ces deux égalités signifient :

- pour la première, que l'information de la valeur prise par $Y$ n'a aucun impact sur la loi de $X$ ;

- pour la deuxième, que l'information de la valeur prise par $X$ n'a aucun impact sur la loi de $Y$.

\noindent Dans une telle situation, on dit que les variables aléatoires $X$ et $Y$ sont indépendantes. 

\noindent De façon générale, l'indépendance de deux variables aléatoires est définie de façon simple par une égalité (ou plutôt une série d'égalités) :

:::: {.defbox .def data-latex="important"}
<center>**Indépendance de deux variables aléatoires**</center>

Deux variables aléatoires réelles discrètes $X$ et $Y$ définies sur un même espace probabilisé $(\Omega, \mathcal{P}(\Omega),\mathbb{P})$ sont dites **indépendantes** lorsque

$$\forall (x,y)\in X(\Omega)\times Y(\Omega),\, \mathbb{P}(X=x, Y=y)=\mathbb{P}(X=x)\,\mathbb{P}(Y=y)$$
\noindent 
**Notation :** $X\perp\!\!\!\perp Y$
::::

\noindent

**Remarques. i.** Tout variable aléatoire constante est donc, selon cette définition, indépendante de n'importe quelle variable aléatoire (y compris elle-même !). En effet, soient $X=a$ ($a\in\mathbb{R}$) une variable aléatoire constante et $Y$ une variable aléatoire quelconque.

\noindent On a, pour $x\in\mathbb{R}$ :

$$(X=x)=\left \{
\begin{array}{c @{=} c}
    \Omega & \text{ si } x=a \\
    \emptyset & \text{ si } x\neq a
\end{array}
\right.$$

\noindent donc 

\begin{align}
\mathbb{P}(X=x)\,\mathbb{P}(Y=y)&=\left \{
\begin{array}{c @{=} c}
    \mathbb{P}(Y=y) & \text{ si } x=a \\
    0 & \text{ si } x\neq a
\end{array}
\right. \\
&=\mathbb{P}(X=x, Y=y) \\
\end{align}

\noindent

**ii.** Si deux variables aléatoires  sont indépendantes, leur loi conjointe peut donc être reconstruite à partir des lois marginales. Toutefois, à l'exception du cas trivial ou l'une au moins des deux variables est constante, la connaissance du caractère indépendant ou non de ces variables ne peut être acquise à l'aide de la seule information des lois marginales : la propriété d'indépendance est bien une propriété du couple, et non une propriété des lois marginales.


**Exemples. i.** On considère deux variables aléatoires sont la loi conjointe est donnée par le tableau de contingence suivant :

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/tableau_exemple_loi.PNG") 
```
</center>

\noindent Pour déterminer si $X$ et $Y$ sont ou non indépendantes, on peut ajouter à ce tableau les probabilités marginales :

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/tableau_exemple_c.PNG") 
```
</center>

\noindent On constate par exemple que $\mathbb{P}(X=1,Y=1)=0$, mais $\mathbb{P}(X=1)\,\mathbb{P}(Y=1)\neq 0$ : donc $X$ et $Y$ ne sont donc pas indépendantes.

\noindent

**ii.** Cette fois, le couple $(X,Y)$ a pour tableau de contingence :

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/tableau_exemple2.PNG") 
```
</center>

\noindent Comme dans l'exemple précédent, on le complète des probabilités marginales :


<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/tableau_exemple2_c.PNG") 
```
</center>

\noindent Cette fois, on constate que chaque probabilité conjointe est égale au produit des probabilités marginales correspondantes, donc $X$ et $Y$ sont indépendantes.

<br>

\noindent 



\noindent Par définition de l'indépendance de deux variables, l'expression de chaque probabilité conjointe $\mathbb{P}(X=x,Y=y)$ peut s'écrire comme un produit de deux termes : un premier terme qui est une fonction de $x$ uniquement, et un deuxième terme qui est une fonction de $y$ uniquement. Cette possibilité de séparer en un terme en $x$ et en un terme en $y$ a pour conséquence que l'espérance d'un produit de deux variables indépendantes est le produit de leurs espérances :

:::: {.thmbox .thm data-latex="important"}
**Théorème.** Soient $X$ et $Y$ deux variables aléatoires définies sur un espace probabilisé $(\Omega, \mathcal{P}(\Omega), \mathbb{P})$.

\noindent Si $X$ et $Y$ sont indépendantes, alors, sous réserve d'existence de ces espérances :

$$\mathbb{E}(XY)=\mathbb{E}(X)\,\mathbb{E}(Y)$$
::::

\noindent

**Démonstration.** 

\begin{align}
\mathbb{E}(XY)&=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,X(\omega)\,Y(\omega) \\
&=\sum\limits_{x\in X(\Omega)}\sum\limits_{y\in Y(\omega)}\mathbb{P}(X=x, Y=y)\,x\,y \\
&=\sum\limits_{x\in X(\Omega)}\sum\limits_{y\in Y(\omega)}\mathbb{P}(X=x)\,\mathbb{P}(Y=y)\,x\,y \\
&\text{(indépendance de } X \text{ et } Y \text{)} \\
&\\
&=\left(\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\, x\right).\left(\sum\limits_{y\in Y(\omega)}\mathbb{P}(Y=y)\,y\right) \\
&=\mathbb{E}(X)\,\mathbb{E}(Y) \\
\end{align}

$\square$

\noindent

**Exemple.** On reprend l'exemple précédent, dans lequel nous avons montré l'indépendance entre $X$ et $Y$.

\noindent On a :

\begin{align}
\mathbb{E}(X)&=0,4\times 1+0,2\times 2+0,4\times 3 \\
&=2 \\
\end{align}

\noindent et

\begin{align}
\mathbb{E}(Y)&=0,2\times 1+0,1\times 2+0,4\times 3+0,3\times 4 \\
&=2,8 \\
\end{align}

\noindent Par indépendance de $X$ et $Y$, on en déduit que 

$$\mathbb{E}(XY)=\mathbb{E}(X)\,\mathbb{E}(Y)=5,6$$

## Covariance et coefficient de corrélation de deux variables aléatoires

\noindent La **covariance** de deux variables aléatoires mesure à quel point on s'éloigne de l'égalité $\mathbb{E}(XY)=\mathbb{E}(X)\,\mathbb{E}(Y)$.

:::: {.defbox .def data-latex="important"}
**Covariance de deux variables aléatoires.** La **covariance** de deux variables aléatoires $X$ et $Y$ est l'espérance, si elle existe, de $\left(X-\mathbb{E}(X)\right).\left(Y-\mathbb{E}(Y)\right)$ :

$$\text{Cov}(X,Y)=\mathbb{E}\left(\left(X-\mathbb{E}(X)\right).\left(Y-\mathbb{E}(Y)\right)\right)$$

\noindent Elle admet également pour expression :

$$\text{Cov}(X,Y)=\mathbb{E}(XY)-\mathbb{E}(X).\mathbb{E}(Y)$$


\noindent En particulier, donc, la covariance d'une variance avec elle-même est égale à sa variance :

$$\text{Cov}(X,X)=\mathbb{V}(X)$$

\noindent 

**Remarque. :** la covariance de $X$ et $Y$ est également parfois notée $\sigma_{XY}$.
::::

\noindent

**Démonstration de la deuxième formule de la covariance.** On utilise la linéarité de l'espérance :

\begin{align}
\text{Cov}(X,Y)&=\mathbb{E}\left((X-\mathbb{E}(X)).(Y-\mathbb{E}(Y))\right) \\
&=\mathbb{E}(XY)-\mathbb{E}(X)\mathbb{E}(Y)-\mathbb{E}(X)\mathbb{E}(Y)+\mathbb{E}(X)\mathbb{E}(Y) \\
&=\mathbb{E}(XY)-\mathbb{E}(X)\mathbb{E}(Y) \\
\end{align}

$\square$

\noindent 

**Remarque.** La deuxième expression de la covariance est généralement préférable car moins coûteuse en calculs.

\noindent 

**Interprétation de la covariance.** Comme son nom l'indique, la covariance mesure à quel point, en moyenne, les (versions centrées des) variables $X$ et $Y$ covarient. Intuitivement, dire que deux variables ont un lien (que ce lien soit causal ou non), c'est dire que les variations de l'une et celles de l'autre sont concomitantes. Au contraire, si on imagine que l'une de ces deux variables bouge beaucoup alors que l'autre reste constante, on s'attend à ce qu'elles ne soient pas liées l'une à l'autre. La covariance est une simple formalisation de cette idée. 

<br>



\noindent La covariance présente l'inconvénient de dépendre de l'échelle des valeurs prises par $X$ et $Y$. Pour neutraliser cet effet d'échelle, on peut utiliser la **corrélation** :

:::: {.defbox .def data-latex="important"}
<center>**Corrélation linéaire**</center>

\noindent Soient $X$ et $Y$ deux variables aléatoires. Sous réserve d'existence, on appelle **coefficient de corrélation linéaire** entre $X$ et $Y$, le nombre

$$\rho_{XY}=\frac{\text{Cov}(X,Y)}{\sigma_X\,\sigma_Y}$$
\noindent où $\sigma_X$ et $\sigma_Y$ sont les écarts-types de $X$ et $Y$.

\noindent On a l'encadrement suivant :

$$-1\leq\rho_{XY}\leq 1$$
::::

\noindent Pour démontrer cet encadrement, on peut utiliser l'inégalité de Cauchy-Schwarz dans l'espace $L^2$. Cette inégalité, en toute généralité, s'applique dans le cadre théorique des espaces préhilbertiens : des rappels sont en annexe.


\noindent 

**L'espace $L^2(\Omega)$.** On note $L^2(\Omega, \mathcal{P}(\Omega),\mathbb{P})$, ou plus simplement $L^2(\Omega)$, l'ensemble des variables aléatoires $X:(\Omega,\mathcal{P}(\Omega),\mathbb{P})\longrightarrow\mathbb{R}$ telles que $\mathbb{E}(X^2)<\infty$. Cet espace peut être muni d'un produit scalaire :

$$\forall X,Y\in L^2(\Omega),\, <X\,,\,Y>=\mathbb{E}(XY)$$
\noindent La norme associée est définie par :

$$\forall X\in L^2(\Omega),\,||X||=\sqrt{\mathbb{E}(X^2)}$$

\noindent Dans $L^2(\Omega)$, l'inégalité de Cauchy-Schwarz prend donc la forme suivante :

:::: {.thmbox .thm data-latex="important"}
**Inégalité de Cauchy-Schwarz dans $L^2(\Omega)$.** Soient $X,Y\in L^2(\Omega)$ deux variables aléatoires discrètes. Alors :

$$|\mathbb{E}(XY)|\leq\sqrt{\mathbb{E}(X^2)}\,\sqrt{\mathbb{E}(Y^2)}$$
\noindent Cette inégalité s'écrit aussi :

$$\left|\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,X(\omega)\,Y(\omega)\right|\leq\sqrt{\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,X^2(\omega)}\sqrt{\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,Y^2(\omega)}$$
\noindent Avec le théorème de transfert, on peut aussi écrire :

$$\left|\sum\limits_{k\in K}\sum\limits_{l\in L}\mathbb{P}(X=x_k, Y=y_l)\,x_k\,y_l\right|\leq\sqrt{\sum\limits_{k\in K}\mathbb{P}(X=x_k)\,x_k^2}\,\sqrt{\sum\limits_{l\in L}\mathbb{P}(Y=y_l)\,y_l^2}$$
::::

\noindent 

**Démonstration de l'encadrement $-1\leq\rho_{XY}\leq 1$.**

\noindent L'encadrement du coefficient de corrélation linéaire se montre alors en appliquant l'inégalité de Cauchy-Schwarz à $X-\mathbb{E}(X)$ et $Y-\mathbb{E}(Y)$, sous réserve que ces variables sont bien dans $L^2(\Omega)$ :

\begin{align}
\left|\mathbb{E}((X-\mathbb{E}(X)).(Y-\mathbb{E}(Y)))\right|&\leq\sqrt{\mathbb{E}(X-\mathbb{E}(X))^2}\,\sqrt{\mathbb{E}(Y-\mathbb{E}(Y))^2} \\
&=\sqrt{\mathbb{V}(X)}.\sqrt{\mathbb{V}(Y)} \\
&=\sigma_X\,\sigma_Y
\end{align}

d'où le résultat.

$\square$

\noindent Nous avons vu que pour deux variables aléatoires indépendantes $X$ et $Y$ on a $\mathbb{E}(XY)=\mathbb{E}(X)\mathbb{E}(Y)$. On peut donc formuler ce résultat ainsi :


:::: {.thmbox .thm data-latex="important"}
\noindent
**Théorème.** Soient $X$ et $Y$ deux variables aléatoires indépendantes. Alors :

$$\text{Cov}(X,Y)=0$$

\noindent soit encore, de façon équivalente :

$$\rho_{XY}=0$$
::::

\noindent

**Remarques. i.** L'indépendance implique donc la non-corrélation.

\noindent

**ii.** La réciproque est fausse : deux variables aléatoires peuvent être de corrélation nulle sans être indépendantes. 

\noindent

**iii. Interprétation du coefficient de corrélation linéaire.** Le coefficient de corrélation linéaire mesure la dépendance linéaire entre deux variables. On a vu en effet que d'après l'inégalité de Cauchy-Schwarz appliquée aux variables centrées $X-\mathbb{E}(X)$ et $Y-\mathbb{E}-Y)$ on a  $-1\leq\rho_{XY}\leq 1$. Les cas d'égalité se produisent lorsque ces deux variables sont colinéaires, autrement dit :

$$\rho_{XY}=\pm 1 \Leftrightarrow\exists (a,b,c)\in\mathbb{R}^3,\, aX+bY+c=0$$ 
\noindent Au contraire, plus $\rho_{XY}$ s'éloigne de $-1$ et $1$ et moins $X$ et $Y$ sont linéairement liées. Dans le cas extrême où $X$ et $Y$ sont indépendantes, elles sont en particulier linéairement indépendantes, et  leur coefficient de corrélation est nul.

**iv.** Dire que deux variables sont non corrélées revient à dire que leur produit scalaire dans l'espace préhlibertien $\left(L^2(\Omega), <.\,,\,.>\right)$ est nul. On dit alors que ces deux variables sont **orthogonales**, ce qui est donc synonyme de "sans dépendance linéaire."

<br>

Nous avons vu que l'application

\begin{align}
L^2(\Omega)\times L^2(\Omega)&\longrightarrow\mathbb{R} \\
(X,Y)&\mapsto\mathbb{E}(XY)
\end{align}

\noidnent est un produit scalaire sur $L^2(\Omega)$. 

\noindent La fonction de covariance

\begin{align}
L^2(\Omega)\times L^2(\Omega)&\longrightarrow\mathbb{R} \\
(X,Y)&\mapsto\text{Cov}(XY)
\end{align}

\noindent n'est pas un produit scalaire, mais elle s'en approche grandement :

:::: {.thmbox .thm data-latex="important"}
\noindent
**Propriétés de la covariance.** L'application

\begin{align}
L^2(\Omega)\times L^2(\Omega)&\longrightarrow\mathbb{R} \\
(X,Y)&\mapsto\text{Cov}(XY)
\end{align}

\noindent est :

- **bilinéaire :** $\forall (X,Y,Z)\in L^2(\Omega)\times L^2(\Omega)\times L^2(\Omega), \forall\alpha\in\mathbb{R}$ :

$$\text{Cov}(\alpha X+Y,Z)=\alpha\text{Cov}(X,Z)+\text{Cov}(Y,Z)$$
$$\text{Cov}(X,\alpha Y+Z)=\alpha\text{Cov}(X,Z)+\alpha\text{Cov}(Y,Z)$$

- **symétrique :** $\forall (X,Y)\in L^2(\Omega)\times L^2(\Omega), \text{Cov}(X,Y)=\text{Cov}(Y,X)$

- **positive :** $\forall $X\in L^2(\Omega)$ :

$$\text{Cov}(X,X)\geq 0$$
\noindent Sa **forme quadratique** associée est la fonction de variance $$X\in L^2(\Omega)\mapsto\mathbb{V}(X)$$
::::

\noindent

**Démonstration.** Exactement le même type de calculs que pour l'application  $(X,Y)\in L^2(\Omega)\times L^2(\Omega)\mapsto\mathbb{E}(XY)$ (voir annexe).

$\square$

\noindent

**Remarque.** Cette application est ainsi une forme bilinaire symétrique positive, mais elle n'est pas définie positive. Autrement dit, il existe $X\in L^2(\Omega)$ telle que $\mathbb{V}(X)=0$ sans pour autant que $X$ soit nulle. Il suffit de prendre $X=a$ une constante réelle non nulle. La fonction de covariance n'est donc pas un produit scalaire sur $L^2(\Omega)$, même si elle en satisfait de nombreuses propriétés (en fait, toutes sauf une).

\noindent Il découle du résultat précédent une formule pour la variance d'une somme de variables aléatoires :

:::: {.thmbox .thm data-latex="important"}
\noindent
**Variance d'une somme.** Soient $X_1,\dots,X_n$ des variables aléatoires réelles discrètes. La variance de leur somme est donnée par la formule 

$$\mathbb{V}\left(\sum\limits_{i=1}^n X_i\right)=\sum\limits_{i=1}^n\mathbb{V}(X_i)+2\sum\limits_{1\leq i<j\leq n}\text{Cov}(X_i, X_j)$$
\noindent En particulier, si les variables aléatoires $X_1,\dots, X_n$ sont deux à deux indépendantes (i.e. si $X_i$ est indépendante de $X_j$ dès que $i\neq j$), la variance de la somme est égale à la somme des variances :

$$\mathbb{V}\left(\sum\limits_{i=1}^n X_i\right)=\sum\limits_{i=1}^n\mathbb{V}(X_i)$$
::::

\noindent

**Démonstration.** La première égalité est une simple traduction du fait que la fonction de covariance est une forme bilinéaire de forme quadratique associée $\text{Cov}(X,X)=\mathbb{V}(X)$.

\noindent La deuxième égalité provient du fait que la covariance de deux variables aléatoires indépendantes est nulle.

$\square$




## Espérance conditionnelle $\mathbb{E}(Y|X=x)$

\noindent On a défini la loi conditionnelle $\mathbb{P}_{Y|X=x}$. L'espérance $\mathbb{E}(Y|X=x)$, si elle existe, est l'espérance de $Y$ sous cette loi. 

:::: {.defbox .def data-latex="important"}
<center>**Espérance conditionnelle $\mathbb{E}(Y|X=x)$**</center>

Soient $X$ et $Y$ deux variables aléatoires réelles discrètes sur un espace probabilisé $(\Omega, \mathcal{P}(\Omega), \mathbb{P})$. Soit $x\in X(\Omega)$. On suppose que 

$$\forall y\in Y(\Omega),\,\mathbb{P}(Y|X=x)>0$$
\noindent L'**espérance conditionnelle de $Y$ sachant $X=x$**, notée $\mathbb{E}(Y|X=x)$, est définie par

$$\mathbb{E}(Y|X=x)=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y|X=x)\,y$$
::::

\noindent

**Exemple.** On reprend l'exemple du couple aléatoire $(X,Y)$ de loi conjointe donnée par le tableau suivant :

<center>
```{r, echo = FALSE}
knitr::include_graphics("C:/Users/olivier.guin/Travail/Formation_Administrateur/Cours/Cours_probabilités_statistique/images/tableau_exemple_c.PNG") 
```
</center>

\noindent Calculons les espérances conditionnelles $\mathbb{E}(Y|X=i)$ pour $1\leq i\leq 3$ :

\begin{align}
\mathbb{E}(Y|X=1)&=\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=1)\,i \\
&=\frac{1}{\mathbb{P}(X=1)}\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=1)\,i \\
&=\frac{\frac{1}{12}\times 0+0\times 1+\frac{1}{12}\times 2}{\frac{2}{12}} \\
&= 1 \\
\end{align}

\begin{align}
\mathbb{E}(Y|X=2)&=\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=2)\,i \\
&=\frac{1}{\mathbb{P}(X=2)}\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=2)\,i \\
&=\frac{\frac{2}{12}\times 0+\frac{1}{12}\times 1+\frac{1}{12}\times 2}{\frac{4}{12}} \\
&= \frac{3}{4} \\
\end{align}

\begin{align}
\mathbb{E}(Y|X=3)&=\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=3)\,i \\
&=\frac{1}{\mathbb{P}(X=3)}\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=3)\,i \\
&=\frac{\frac{3}{12}\times 0+\frac{2}{12}\times 1+\frac{1}{12}\times 2}{\frac{6}{12}} \\
&= \frac{2}{3} \\
\end{align}


<br>

\noindent Les espérances conditionnelles permettent de reconstruire l'espérance :

:::: {.thmbox .thm data-latex="important"}
\noindent
**Théorème.** Sous les hypothèses et notations précédentes, on a

$$\mathbb{E}(Y)=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\mathbb{E}(Y|X=x)$$
\noindent Autrement dit, en notant $\mathbb{E}(Y|X)$ la variable aléatoire

$$\mathbb{E}(Y|X)(\omega)=\mathbb{E}(Y|X=X(\omega))$$
\noindent on a 

$$\mathbb{E}\left(\mathbb{E}(Y|X)\right)=\mathbb{E}(Y)$$
::::

\noindent

**Remarque.** L'espérance conditionnelle $\mathbb{E}(Y|X)$ est donc une **variable aléatoire** et pas un nombre dans le cas général (elle peut l'être par exemple si $X$ et $Y$ sont indépendantes : exercice !). Son support est constitué des espérances conditionnelles $\mathbb{E}(Y|X=x)$ (ici ce sont bien des nombres !), pour $x\in X(\Omega)$.

\noindent


**Démonstration.** On a :

\begin{align}
\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\mathbb{E}(Y|X=x) &= \sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y|X=x)\,y \\
&=\sum\limits_{x\in X(\Omega)}\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y,X=x)\,y \\
\end{align}

\noindent Montrons que l'on peut intervertir des deux sommes sans changer le résultat. Si $X(\Omega)$ et $Y(\Omega)$ sont des ensembles finis, il n'y a pas de problème. Sinon, on utilise le théorème de Fubini pour les séries à double indice, dont l'énoncé est rappelé en annexe. On peut appliquer ce théorème car :

- pour tout $y$ dans $Y(\Omega)$, la série $\sum\limits_{x\in X(\Omega)}\mathbb{P}(Y=y, X=x)$ est convergente (et même absolument convergente car son terme générique est positif) puisque, par $\sigma-$additivté, on a

$$\sum\limits_{x\in X(\Omega)}\mathbb{P}(Y=y, X=x)=\mathbb{P}(Y=y)$$

- \begin{align}
\sum\limits_{y\in Y(\Omega)}\left(\sum\limits_{x\in X(\Omega)}\mathbb{P}(Y=y,X=x)\right)\,y &=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y)\,y \\
&=\mathbb{E}(Y) \\
\end{align}

\noindent On obtient donc :

\begin{align}
\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\mathbb{E}(Y|X=x) &=\sum\limits_{y\in Y(\Omega)}\left(\sum\limits_{x\in X(\Omega)}\mathbb{P}(Y=y,X=x)\right)\,y \\
&=\mathbb{E}(Y) \\
\end{align}

\noindent On en déduit que :

\begin{align}
\mathbb{E}(\mathbb{E}(Y|X))&=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,\mathbb{E}(Y|X=X(\omega)) \\
&=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\mathbb{E}(Y|X=x) \\
&=\mathbb{E}(Y)
\end{align}

\noindent d'après ce qui précède.

$\square$

\noindent

**Interprétation de ce résultat.** Elle est extrêmement simple : une moyenne $\mathbb{E}(Y)$ peut s'obtenir de la façon suivante :

- dans un premier temps on calcule des moyennes par groupes :  $\mathbb{E}(Y|X=x)$. Ici, les groupes sont les événements $(X=x)$, pour $x\in X(\Omega)$) ;

- dans un second temps, puis on calcule la moyenne (pondérée) de ces moyennes : $\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\mathbb{E}(Y|X=x)$.

\noindent

**Exemple.** On reprend l'exemple précédent :

$$\mathbb{E}(Y|X=1)=1$$
$$\mathbb{E}(Y|X=2)=\frac{3}{4}$$
$$\mathbb{E}(Y|X=3)=\frac{2}{3}$$
\noindent

**Déterminons la loi de $Z=\mathbb{E}(Y|X)$.** Son support est

$$Z(\Omega)=\left\{1,\frac{3}{4},\frac{2}{3}\right\}$$

\noindent Par ailleurs, on a

$$\mathbb{P}(Z=1)=\mathbb{P}(X=1)=\frac{2}{12}$$
$$\mathbb{P}\left(Z=\frac{3}{4}\right)=\mathbb{P}(X=2)=\frac{4}{12}$$
$$\mathbb{P}\left(Z=\frac{2}{3}\right)=\mathbb{P}(X=3)=\frac{6}{12}$$
\noindent 

**Calculons maintenant son espérance.** On peut le faire de deux faons différentes :

- **Méthode 1 :** on utilise la loi de $Z$ :

\begin{align}
\mathbb{E}(Z)&=\sum\limits_{z\in Z(\Omega)}\mathbb{P}(Z=z)\,z \\
&=\frac{2}{12}\times 1+\frac{4}{12}\times\frac{3}{4}+\frac{6}{12}\times\frac{2}{3} \\
&=\frac{3}{4} \\
\end{align}

- **Méthode 2 :** on utilise l'égalité $\mathbb{E}(Z)=\mathbb{E}(\mathbb{E}(Y|X))=\mathbb{E}(Y)$ :

\begin{align}
\mathbb{E}(Z)&=\mathbb{E}(Y) \\
&=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\mathbb{E}(Y|X=x) \\
&=\frac{2}{12}\times 1+\frac{4}{12}\times\frac{3}{4}+\frac{6}{12}\times\frac{2}{3} \\
&=\frac{3}{4} \\
\end{align}

\noindent

- **Méthode 3** : on utilise l'égalité $\mathbb{E}(Z)=\mathbb{E}(Y)$, que l'on calcule à partir de la loi de $Y$ :

\begin{align}
\mathbb{E}(Z)&=\mathbb{E}(Y) \\
&=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y)\,y \\
&=\frac{6}{12}\times 0+\frac{3}{12}\times 1+\frac{3}{12}\times 2 \\
&=\frac{3}{4} \\
\end{align}

\noindent Les trois méthodes aboutissent bien au même résultat.

<br>

### Variance conditionnelle

- variance conditionnelle
- théorème de la variance totale 

### Somme de deux VA indépendantes (produit de convolution discret)

## Annexes

### Inégalité de Cauchy-Schwarz

\noindent L'inégalité de Cauchy-Schwarz est un résultat important d'algèbre. On rappelle d'abord la notion de **produit scalaire** sur un espace vectoriel.

\noindent

**Rappel : produit scalaire.** Dans un espace-vectoriel $E$, on appelle *produit scalaire* toute application $\phi:E\times E\longrightarrow\mathbb{R}$ vérifiant les propriétés suivantes :

- **Bilinéarité :** $\phi$ est linéaire à gauche et linéaire à droite :

  - **Linéarité à gauche :** $\forall x,y,z\in E,\, \forall\lambda\in\mathbb{R}, \, \phi(x+\lambda y, z)=\phi(x,z)+\lambda\phi(y,z)$
  
  - **linéarité à droite :** $\forall x,y,z\in E,\, \forall\lambda\in\mathbb{R}, \, \phi(x, y+\lambda z)=\phi(x,y)+\lambda\phi(x,z)$
  
- **Symétrie :** $\forall x,y\in E,\, \phi(x,y)=\phi(y,x)$

- **Définie positive :** $\forall x\in E, \phi(x,x)\geq 0$, avec égalité si et seulement si $x=0$.

\noindent Une notation courante pour un produit scalaire est $<.\,,\,.>$. De plus, pour $x\in E$, on note $||x||=\sqrt{<x\,,\,x>}$. Il s'agit d'une **norme** sur $E$, i.e. une application de $E$ dans $\mathbb{R}$ vérifiant les propriétés suivantes :

- pour tout $x$ dans $E$, $||x||=0$ si et seulement si $x=0$ ;

- pour tout $x$ dans $E$ et pour tout réel $\lambda$ : $||\lambda x||=|\lambda|.||x||$ ;

- pour tous $x,y$ dans $E$, $||x+y||\leq ||x||+||y||$.

\noindent L'inégalité de Cauchy-Schwarz établit une majoration du produit scalaire (et même de sa valeur absolue) par le produit des normes :

:::: {.thmbox .thm data-latex="important"}
**Inégalité de Cauchy-Schwarz.** Soient $(E\,,\,<\,,\,>)$ un espace préhilbertien réel et $||.||$ la norme associée au produit scalaire $<\,,\,>$. Alors, on a 

$$\forall x,y\in E,\,|<x\,,y>|\leq ||x||\,||y||$$
 \noindent avec égalité si et seulement si $x$ et $y$ sont colinéaires.
::::

\noindent

**Démonstration.** Soient $x,y\in E$. Pour tout réel $t$, on a 

\begin{align}
0&\leq||x-ty||^2 \\
&=||y||^2t^2-2<x\,,\,y>t+||x||^2 \\
\end{align}

\noindent On peut voir $||y||^2t^2-2<x\,,\,y>t+||x||^2$ comme un trinôme en $t$, toujours positif ou nul. Par conséquent son discriminant est négatif ou nul, soit

$$4<x\,,\,y>^2-4||x||^2||y||^2\leq 0$$
i.e.

$$|<x\,,\,y>|\leq ||x||\,||y||$$
\noindent Le cas d'égalité signifie que ce discriminant est nul. Dans ce cas, il existe $t$ réel tel que $x=ty$, ce qui signifie exactement que $x$ et $y$ sont colinéaires.

$\square$

\noindent Dans le cadre de la théorie des probabilités, l'inégalité de Cauchy-Schwarz est souvent appliquée dans l'epace $L^2(\Omega, \mathcal{P}(\Omega), \mathbb{P})$.

### Théorème de Fubini pour les séries doubles

\noindent On rappelle le résultat d'analyse suivant (que l'on admet) :

:::: {.thmbox .thm data-latex="important"}
\noindent
**Théorème de Fubini pour les séries doubles.** On suppose que $(a_{mn})_{(m,n),\in\mathbb{N}^2}$ est une suite à double indice telle que :

- pour tout entier $m$, la série $\sum\limits_{n}a_{m,n}$ est absolument convergente ;
- la série double $\sum\limits_{m}\sum\limits_{n}a_{m,n}$ est convergente.

\noindent Alors :

$$\sum\limits_{m=0}^{\infty}\sum\limits_{n=0}^{\infty}a_{m,n}=\sum\limits_{n=0}^{\infty}\sum\limits_{m=0}^{\infty}a_{m,n}$$
\noindent autrement dit on peut interertir l'ordre des sommes sans modifier le résultat.
::::

