[["index.html", "Cours de probabilités-statistiques pour le concours interne d’administrateur Insee Chapitre 1 Présentation du cours 1.1 Généralités 1.2 Coquilles et erreurs", " Cours de probabilités-statistiques pour le concours interne d’administrateur Insee Olivier Guin 2024-03-06 Chapitre 1 Présentation du cours 1.1 Généralités Ce document est un cours de probabilités et statistiques à destination des candidats au concours interne d’administrateur de l’Insee. Il est encore en construction et pour le moment très incomplet. Seule la partie Statistique inférentielle est à ce jour disponible. A terme, il devrait contenir les parties suivantes : Dénombrement et probabilités Variables aléatoires discrètes Variables aléatoires à densité Convergence Statistique descriptive Statistique inférentielle Certaines des notions présentées ici, sans être explicitement au programme du concours, sont à la frontière de celui-ci. Concrètement, cela signifie que’on peut les retrouver dans un sujet d’écrit ou d’oral, mais qu’aucun prérequis les concernant n’est nécessaire pour traiter le sujet. Mais les avoir déjà rencontrées peut aider pour résoudre les questions… C’est le cas par exemple, dans la partie Statistique inférentielle, de l’information de Fisher, des statistiques exhaustives et de la borne de Cramer-Rao, qui sont présentes dans le sujet d’Administrateur interne de 2022 (sans être toutefois explicitement nommées). Même type de remarque pour les démonstrations. Celles qui sont présentées ici ne sont pas toutes indispensables pour aborder ce concours. Mais elles utilisent des méthodes de calcul ou de raisonnement qui reviennent souvent, et qui peuvent inspirer pour la résolution d’un exercice. Comme toujours en mathématiques, la seule façon de progresser est de faire. Ne pas hésiter donc, à passer un peu de temps sur un exercice, même si on sèche complètement. 1.2 Coquilles et erreurs La loi de Poisson est souvent utilisée pour modéliser le nombre d’erreurs ou de coquilles inévitablement présentes dans un document. Celui-ci n’échappe pas à la règle et j’espère juste que le \\(\\lambda\\) n’est pas trop grand… Pour m’aider à le réduire, n’hésitez pas à me les signaler. Plus généralement, vos commentaires permettent d’améliorer la qualité de ce document : ils sont donc les bienvenus. "],["dénombrement-et-probabilités.html", "Chapitre 2 Dénombrement et probabilités 2.1 Dénombrement 2.2 Evénements et probabilités", " Chapitre 2 Dénombrement et probabilités 2.1 Dénombrement On commence par quelques éléments d’analyse combinatoire. Ces résultats sont utilisés dans le cas où, lors d’une expérience aléatoire, tous les événements élémentaires (on parle aussi d’issues) sont de même probabilité. On parle dans ce cas d’équiprobabilité ou d’équirépartition des résultats. Des exemples classiques de tirages équirépartis : lancer d’un dé à 6 faces non truqué. Dans ce cas, chaque face a une probabilité d’apparition de \\(\\frac{1}{6}\\). dans une urne composée de 10 boules rouges, 10 boules blanches et 10 boules noires, tirage au hasard d’une boule. Les trois couleurs que l’on peut obtenir sont équiprobables, de probabilité commune \\(\\frac{1}{3}\\). L’utilité du dénombrement dans le cas équiprobable vient de la formule que l’on apprend au lycée : \\[\\mathbb{P}(A)=\\frac{\\text{Nombre de cas favorables à } A}{\\text{Nombre total de cas}}\\] Cette formule, qui n’est valable que dans le cas équiréparti, suppose de savoir compter le nombre de cas où l’événement \\(A\\) se réalise ainsi que de savoir compter le nombre total d’issues de l’expérience aléatoire que l’on étudie, autrement dit il s’agit bien de savoir dénombrer. Cette première partie présente les types de dénombrements les plus classiques. Si les concepts sont très simples (on reste vraiment sur du niveau lycée), on peut assez facilement mal s’y prendre (ce qui voudra dire essentiellement : oublier de compter des cas, ou au contraire compter plusieurs fois le même cas) et passer complètement à côté du résultat. Bref, malgré les apparences, les questions de dénombrement (assez peu courantes au concours ces dernières années cela dit) sont potentiellement piégeuses… C’est donc typiquement le genre de questions qu’il ne faut pas sous-estimer et qu’il faut traiter en prenant son temps, à plus forte raison si elle est posée en début de sujet, et qu’elle est donc potentiellement structurante pour la suite. 2.1.1 Produit cartésien et principe multiplicatif Produit cartésien Soient \\(k\\) un entier naturel non nul et \\(E_1,\\dots E_k\\) des ensembles finis de cardinaux respectifs \\(n_1,\\dots, n_k\\). Le produit cartésien de \\(E_1,\\dots, E_k\\) est l’ensemble noté \\(E_1\\times\\dots\\times E_k\\) de toutes les listes ordonnées \\((x_1,\\dots,x_k)\\) telles que, pour tout \\(i\\in\\{1,\\dots, k\\}\\) l’élément numéro \\(i\\) noté \\(x_i\\) appartient à l’ensemble \\(E_i\\). On dit aussi que \\((x_1,\\dots, x_k)\\) est un k-uplet. Cas particuliers : i. Les listes ordonnées à 2 éléments sont appelées des couples, celles à 3 élements sont appelées des triplets et les listes à 4 éléments sont les quadruplets. ii. Lorsque tous les ensembles \\(E_1,\\dots E_k\\) sont égaux, i.e. \\(E_1=\\dots=E_k=E\\), le produit cartésien \\(E\\times\\dots\\times E\\) est noté plus simplement \\(E^k\\). Remarques. Le mot important dans cette définition est ordonnée. L’ordre a en effet une importance ici, autrement dit \\((1, 2)\\in\\mathbb{R}^2\\) et \\((2, 1)\\in\\mathbb{R}^2\\) sont bien considérés comme deux couples distincts de réels. Le premier résultat de ce cours, qui est absolument fondamental lorsqu’on pratique le dénombrement, et donc lorsqu’on est en situation d’équiprobabilité, est le principe multiplicatif. Ce principe, à la fois très simple et très intuitif, répond à la question Combien existe-t-il de k-uplets ? Principe multiplicatif : Avec les notations de la définition précédente, le nombre d’élements du produit cartésien \\(E_1\\times \\dots\\times E_k\\) est égal à \\(n_1\\times\\dots\\times E_k\\). Formule que l’on peut aussi écrire (en notant \\(\\text{Card}\\,(E)\\) le cardinal d’un ensemble \\(E\\), i.e. le nombre d’éléments de \\(E\\)) : \\[\\text{Card }(E_1\\times\\dots\\times E_k)=\\text{Card }(E_1)\\times\\dots\\times\\text{Card }(E_k)\\] Si on veut faire chic, on peut dire aussi que \\[\\textit{Le cardinal d&#39;un produit est le produit des cardinaux}\\] Exemple 1 : expériences aléatoires successives. On réalise successivement les deux expériences aléatoires suivantes : lancer d’une pièce : 2 résultats possibles P ou F ; puis lancer d’un dé cubique : 6 résultats possibles notés de 1 à 6. L’ensemble des issues de cette double expérience aléatoire peut être modélisé par le produit cartésien \\(\\{P, F\\}\\times\\{1,2,3,4,5,6\\}\\). C’est un ensemble à 12 éléments : \\[(P,1), (P,2), (P,3), (P, 4), (P,5), (P, 6), (F,1), (F,2), (F,3), (F, 4), (F,5), (F, 6)\\] Cet ensemble peut facilement être représenté par un arbre de dénombrement : Exemple 2 : compter des poignées de mains. Soit \\(n\\geq 2\\) un entier. Compter le nombre de poignées de mains possibles dans un groupe de \\(n\\) personnes. Solution 2.a. On note \\(1,\\dots n\\) les personnes de ce groupe, et le couple \\((i, j)\\) modélise le fait que \\(i\\) sert la main de \\(j\\). On compte alors successivement : le nombre de couples : il y en a \\(n^2\\) d’après le principe multiplicatif ; le nombre de couples \\((i, i)\\) qui représenteraient le fait que \\(i\\) se sert la man à lui-même, situtation qu’on ne veut pas dénombrer et dont il faut donc soustraire le nombre d’occurences au nombre précédent. Il y en a \\(n\\), donc il y a \\(n^2-n=n(n-1)\\) façons qu’une personne \\(i\\) serre la main d’une autre personne \\(j\\) du goupe ; le nombre de couples correspondant à une poignée de mains : il s’agit de \\(2\\), puisque une poignée de mains entre deux personnes \\(i\\) et \\(j\\) correspond à exactement deux couples : \\((i,j)\\) et \\((j,i)\\). Il faut donc diviser par deux le nombre trouvé précédemment, ce qui fait un total de \\(\\frac{n(n-1)}{2}\\) poignées de mains. Solution 2.b.(plus directe) Une poignée de mains implique deux personnes différentes. On a \\(n\\) choix possibles pour la première personne, et \\(n-1\\) choix possibles pour la deuxième personne, soit \\(n(n-1)\\) choix de couples possibles. En l’état, on compte deux fois trop de poignées de mains (même raisonnement que dans l’exemple 2.a.), donc il y a en réalité \\(\\frac{n(n-1)}{2}\\) poignées de mans possibles.$ 2.1.2 Principe additif Un deuxième grand principe de dénombrement, tout aussi intuitif et tout aussi fondamental, est le principe additif : Principe additif : Si \\(E_1,\\dots E_k\\) sont \\(k\\) ensembles deux à deux disjoints (i.e. \\(i\\neq j\\Rightarrow E_i\\cap E_j=\\emptyset\\)) alors (en reprenant les mêmes notations que dans la définition précédente) leur union \\(E_1\\cup\\dots\\cup E_k\\) a pour cardinal \\(n_1+\\dots+n_k\\), ce que l’on peut aussi écrire : \\[\\text{Card }\\left(E_1\\cup\\dots\\cup E_k\\right)=\\text{Card }(E_1)+\\dots+\\text{Card }(E_k)\\] On pourra retenir que : \\[\\textit{Le cardinal d&#39;une union disjointe est la somme des cardinaux}\\] Remarque. Lorsqu’un ensemble \\(E\\) peut s’écrire sous la forme \\[E=E_1\\cup E_2\\cup\\dots\\cup E_k\\] avec \\(E_1, E_2, \\dots, E_k\\) deux à deux disjoints, on dit que \\(E_1, E_2,\\dots E_k\\) forment une partition de l’ensemble \\(E\\). Exemple 3 : compter des carrés. Combien la figure suivante compte-t-elle de carrés ? Solution. Tout carré de cette figure a pour côté 1, 2, 3 ou 4 (en supposant avoir fixé une unité de longueur, correspondant au côté d’un “petit” carré). L’ensemble \\(E\\) des carrés de cette figure peut donc s’écrire \\[E=E_1\\cup E_2\\cup E_3\\cup E_4\\] où, pour \\(k\\in\\{1,2,3,4\\}\\), \\(E_k\\) désigne l’ensemble des carrés de côté \\(k\\) de cette figure. Les \\(E_k\\) sont deux à deux disjoints (un carré de la figure ne peut pas avoir un côté de deux longueurs différentes) et donc pour compter le nombre de carrés possibles, il suffit de compter les carrés de côté 1, de côté 2, de côté 3, de côté 4 et d’ajouter tous ces nombres. On trouve : \\[\\begin{align} \\text{Card }(E_1) &amp;= 16 \\\\ \\text{Card }(E_2) &amp;= 9 \\\\ \\text{Card }(E_3) &amp;= 4 \\\\ \\text{Card }(E_4) &amp;= 1 \\\\ \\end{align}\\] d’où \\(\\text{Card }(E)=16+9+4+1=30\\). Exemple 4 (poignées de mains, à nouveau). On peut répondre à cette question en utilisant le principe additif. On note \\(E_1\\) l’ensemble des poignées de mains de la personne \\(1\\). Puis on note \\(E_2\\) l’ensemble des poignées de mains de la personne \\(2\\), hormis celle avec la personne \\(1\\) qui a déjà été comptée, \\(E_3\\) l’ensemble des poignées de mains de la personne \\(3\\) hormis celles avec les personnes \\(1\\) et \\(2\\) qui ont déjà été comptées, et ainsi de suite jusqu’à \\(E_{n}\\). Alors, \\(E_1,E_2,\\dots, E_n\\) forment une partition de l’ensemble \\(E\\) de toutes les poignées de mains du groupe, on va donc compter les cardinaux de \\(E_1,E_2,\\dots, E_n\\) et utiliser le principe additif : la personne \\(1\\) serre la main des \\(2\\) à \\(n\\), donc \\(E_1=n-1\\) ; les poignées de mains non encore comptées de la personne \\(2\\) sont celles avec les personnes \\(3\\) à \\(n\\) donc \\(E_2=n-2\\) ; les poignées de mains non encore comptées de la personne \\(3\\) sont celles avec les personnes \\(4\\) à \\(n\\) donc \\(E_2=n-3\\) ; … une seule poignée de mains n’a pas été comptée pour la personne \\(n-1\\), celle avec la personnes \\(n\\) donc \\(E_{n-1}=1\\) ; enfin, toutes les poignées de mains de la personne \\(n\\) ont été comptées, donc \\(E_n=0\\). En vertu du principe additif, le nombre de poignées de mains est donc égal à \\[0+1+2+\\dots+(n-1)=\\frac{n(n-1)}{2}\\] 2.1.3 Formule de Poincaré Il existe une formule lorsqu’on relâche l’hypothèse de non-djsjonction deux à deux, connue sous le nom de formule de Poincaré. C’est une formule que l’on utilise souvent dans le cas \\(k=2\\), de temps en temps dans le cas \\(k=3\\), plus rarement (mais ça peut arriver dans un sujet du concours) dans le cas \\(k\\geq 4\\) voire dans le cas général. Formule de Poincaré. Soit \\(E\\) un ensemble fini, qui peut s’écrire sous la forme \\[E=E_1\\cup E_2\\cup\\dots\\cup E_k\\] avec \\(E_1,E_2,\\dots E_k\\) des sous-ensembles de \\(E\\) non nécessairement disjoints deux à deux. Alors : \\[\\text{Card }(E)=\\sum\\limits_{i=1}^k (-1)^i \\sum\\limits_{1\\leq j_1 &lt; j_2 &lt;...&lt; j_i\\leq n} \\text{Card }\\left(E_{j_1}\\cap E_{j_2}\\cap\\dots\\cap E_{j_i}\\right)\\] Cas particulier \\(k=2\\) : \\[\\text{Card }(A\\cup B)=\\text{Card }(A)+\\text{Card }(B)-\\text{Card }(A\\cap B)\\] Cas particulier \\(k=3\\) : \\[\\begin{align} \\text{Card }(A\\cup B\\cup C)&amp;=\\text{Card }(A)+\\text{Card }(B)+\\text{Card }(C) \\\\ &amp;-\\text{Card }(A\\cap B)-\\text{Card }(A\\cap C)-\\text{Card }(B\\cap C) \\\\ &amp;+\\text{Card }(A\\cap B\\cap C) \\end{align}\\] Démonstration dans le cas \\(k=2\\). L’intutition de la démonstration est évidente : pour compter tout ce qu’il y a dans la réunion de \\(A\\) et \\(B\\), on compte tout ce qu’il y a dans \\(A\\), tout ce qu’il y a dans \\(B\\) et on ajoute le tout. Mais en faisant cela, on compte deux fois - c’est-à-dire une fois de trop - tout ce qui est à la fois dans \\(A\\) et dans \\(B\\), donc on doit ensuite soustraire l’excédent. Plus formellement, on écrit \\(A\\cup B\\) comme une union disjointe, puis on applique le principe additif. On a, en posant \\(A\\backslash B=A\\cap\\overline{B}\\) et \\(B\\backslash A=B\\cap\\overline{A}\\) : \\[A\\cup B = (A\\backslash B)\\cup(A\\cap B)\\cup (B\\backslash A)\\] Les trois ensembles du membre de droite de cette égalité dont deux à deux disjoints, donc on peut appliquer le principe additif : \\[\\text{Card }(A\\cup B)=\\text{Card }(A\\backslash B)+\\text{Card }(A\\cap B)+\\text{Card }(B\\backslash A)\\] Par ailleurs \\[A=(A\\backslash B)\\cup (A\\cap B)\\] \\[B=(B\\backslash A)\\cup (B\\cap A)\\] avec à nouveau des ensembles deux à disjoints dans les membres de droite. Donc, en appliquant deux fois le principe additif \\[\\text{Card }(A\\backslash B)=\\text{Card }(A)-\\text{Card }(A\\cap B)\\] \\[\\text{Card }(B\\backslash A)=\\text{Card }(B)-\\text{Card }(A\\cap B)\\] et donc finalement \\[\\begin{align} \\text{Card }(A\\cup B)&amp;=\\text{Card }(A\\backslash B)+\\text{Card }(A\\cap B)+\\text{Card }(B\\backslash A) \\\\ &amp;=\\text{Card }(A)-\\text{Card }(A\\cap B)+\\text{Card }(A\\cap B)+\\text{Card }(B)-\\text{Card }(A\\cap B) \\\\ &amp;=\\text{Card }(A)+\\text{Card }(B)-\\text{Card }(A\\cap B) \\end{align}\\] \\(\\square\\) 2.1.4 Dénombrement par bijection Une technique classique de dénombrement d’un ensemble fini \\(E\\) est l’utilisation d’un bijection entre \\(E\\) et un ensemble fini \\(F\\) dont on connaît le cardinal : Conservation du cardinal par bijection. Soient \\(E\\) un ensemble, \\(F\\) un ensemble fini. S’il existe une bijection \\(\\varphi : E\\longrightarrow F\\), alors \\(E\\) est un ensemble fini et il est de même cardinal que \\(F\\). Application classique : nombre de parties d’un ensemble fini. Soit \\(E\\) un ensemble de cardinal \\(n\\). Alors l’ensemble \\(\\mathcal{P}(E)\\) des parties de \\(E\\) (i.e. l’ensemble de tous les sous-ensembles de \\(E\\), y compris l’ensemble vide et \\(E\\) lui-même) est égal à \\(2^n\\) : \\[\\text{Card }(E)=n\\Rightarrow\\text{Card }(\\mathcal{P}(E))=2^n\\] En effet, notons \\(\\{0,1\\}^E\\) l’ensemble de toutes les fonctions possibles de \\(E\\) dans \\(\\{0,1\\}\\). Soit alors \\(\\varphi\\) l’application \\(\\varphi:\\{0,1\\}^E\\longrightarrow\\mathcal{P}(E)\\) définie, pour toute fonction \\(f\\in\\{0,1\\}^E\\) par \\[\\varphi(f)=\\{x\\in E, \\,f(x)=1\\}\\] L’application \\(\\varphi\\) est bien définie (si \\(f=g\\) on a clairement \\(\\varphi(f)=\\varphi(g)\\)). Elle est injective : si \\(\\varphi(f)=\\varphi(g)\\), alors \\(f(x)=1\\) si et seulement si \\(g(x)=1\\), et donc \\(f\\) et \\(g\\) ne pouvant prendre que \\(0\\) et \\(1\\) comme valeurs on en déduit que \\(f=g\\). Enfin, \\(\\varphi\\) est surjective. En effet, si \\(P\\in\\mathcal{P}(E)\\), alors en posant, pour tout \\(x\\) dans \\(E\\), \\(f(x)=1\\) si \\(x\\in P\\) et \\(f(x)=0\\) si \\(x\\not\\in P\\), on a \\(f\\in\\{0,1\\}^E\\) et \\(\\varphi(f)=P\\). Enfin, en vertu du principe multiplicatif on a \\(\\text{Card }(\\{0,1\\}^E)=2^n\\). On en déduit que \\(\\text{Card }(\\mathcal{P}(E))=2^n\\). \\(\\square\\) Intutivement, la démonstration précédente montre que toute partie \\(P\\) d’un ensemble fini \\(E\\) peut être codé de façon unique en une fonction sur \\(E\\) à valeurs dans \\(\\{0,1\\}\\), prenant la valeur \\(1\\) pour les éléments de \\(P\\) et \\(0\\) pour les élements qui ne sont pas dans \\(P\\). 2.1.5 Permutations Permutation d’un ensemble fini Soient \\(n\\) un entier naturel non nul et \\(E=\\{x_1,\\dots, x_n\\}\\)} un ensemble fini à \\(n\\) éléments. On appelle permutation de \\(E\\) tout réarragement ordonné et sans répétition des éléments de \\(E\\). De façon équivalente, une permutation est une bijection de \\(E\\) dans lui-même. Notation. L’ensemble des permutations d’un ensemble fini \\(E\\) est noté \\(\\mathfrak{S}(E)\\). Dans le cas particulier où \\(E=\\{1,2,\\dots, n\\}\\), on le note plus simplement \\(\\mathfrak{S}_n\\). Exemple. \\(E=\\{a,b,c\\}\\), les permutations de \\(E\\) sont \\[(a,b,c), (a,c,b), (b,a,c), (b,c,a), (c,a,b), (c,b,a)\\] Ces permutations peuvent aussi s’écrire comme des bijections \\(\\sigma_1,\\dots,\\sigma_6\\) de \\(E\\) dans lui-même : \\[\\sigma_1(a)=a,\\,\\sigma_1(b)=b,\\,\\sigma_1(c)=c\\] \\[\\sigma_2(a)=a,\\,\\sigma_2(b)=c,\\,\\sigma_2(c)=b\\] \\[\\sigma_3(a)=b,\\,\\sigma_3(b)=a,\\,\\sigma_3(c)=c\\] \\[\\sigma_4(a)=b,\\,\\sigma_4(b)=c,\\,\\sigma_4(c)=a\\] \\[\\sigma_5(a)=c,\\,\\sigma_5(b)=a,\\,\\sigma_5(c)=b\\] \\[\\sigma_6(a)=a,\\,\\sigma_6(b)=b,\\,\\sigma_6(c)=a\\] Le nombre de permutations d’un ensemble fini est facile à dénombrer : Théorème (nombre de permutations) : Soit \\(n\\) un entier naturel non nul. Le nombre de permutations d’un ensemble fini à \\(n\\) éléments est égal à \\(n!=1\\times 2\\times 3\\times\\dots\\times n\\). Démonstration. On note \\(x_1,\\dots,x_n\\) les éléments d’un ensemble de cardinal \\(n\\). Choisir une permutation \\(\\sigma\\) de \\(E\\), c’est choisir successivement : l’image \\(\\sigma(x_1)\\) parmi les \\(n\\) éléments \\(x_1,\\dots,x_n\\) : \\(n\\) choix possibles ; l’image \\(\\sigma(x_2)\\) parmi les \\(n-1\\) éléments restants : \\(n-1\\) choix possibles ; l’image \\(\\sigma(x_3)\\) parmi les \\(n-2\\) éléments restants : \\(n-2\\) choix possibles ; … l’image \\(\\sigma(x_n)\\) parmi le seul élément de \\(x_1,\\dots, x_n\\) qui n’a pas encore été choisi : \\(1\\) seul choix possible. D’après le principe multiplicatif, le nombre de permutations de \\(E\\) est donc égal à \\[n\\times(n-1)\\times(n-2)\\times\\dots\\times 1=n!\\] \\(\\square\\) Remarque. En filigrane, le théorème précédént dit aussi que le nombre de permutations d’un ensemble fini \\(E\\) ne dépend de \\(E\\) qu’à travers son cardinal. Autrement dit, peu importe l’ensemble \\(E\\) que l’on choisit, dès lors qu’il a \\(n\\) éléments le nombre de permutations de cet ensemble est \\(n!\\). Ce résultat est une simple conséquence du principe de dénombrement par bijection évoqué plus haut. Exemple : nombre d’anagrammes. Quel est le nombre d’anagrammes du mot MATHS ? Du mot ANAGRAMME ? Solution. i. Une anagramme du mot MATHS correspond à une permutation de l’ensemble \\(\\{M,A,T,H,S\\}\\). Il y en a donc \\(4!=24\\). ii. Pour le mot ANAGRAMME c’est un peu plus compliqué car certaines lettres apparaissent plusieurs fois. On commence par numéroter ces lettres-là, en les traitant comme des lettres différentes, autrement dit on commence par compter le nombre de permutations de l’ensemble \\(\\{A_1,N,A_2,G,R,A_3,M_1,M_2,E\\}\\) : il y en a \\(8!\\). Les lettres n’étant en réalité pas numérotées dans notre problème, il n’y a pas lieu de distinguer, par exemple, l’anagramme \\(A_1NA_2GRA_3M_1M_2E\\) de l’anagramme \\(A_2NA_1GRA_3M_1M_2E\\). Ainsi, la lettre \\(A\\) étant de multiplicité \\(3\\) dans le mot ANAGRAMME, chacune des \\(3!=6\\) permutations de cette lettre fournit exactement le même mot, de sorte que la numérotation de la lettre \\(A\\) conduit à compter \\(6\\) fois plus de permutations qu’il n’y en a en réalité. De même, la lettre \\(M\\) est de multiplicité \\(2\\), et donc en la numérotant on compte \\(2!=2\\) fois plus de permutations qu’il y en a réellement. Finalement, on en déduit que le nombre d’anagrammes du mot ANAGRAMME est égal à \\(\\frac{8!}{3!2!}=420\\). 2.1.6 Arrangements Arrangements Soient \\(n\\) et \\(0\\leq k\\leq n\\) deux entiers naturels, et \\(E\\) un ensemble à \\(n\\) éléments. On appelle arrangement de \\(k\\) éléments pris parmi les \\(n\\) éléments de \\(E\\), tout sous-ensemble ordonné à \\(k\\) éléments de \\(E\\). De la même façon qu’on peut définir les permutations par la notion de bijection, on peut définir les arrangements par la notion d’injection : Définition équivalente des arrangements Soient \\(n\\) et \\(0\\leq k\\leq n\\) deux entiers naturels, et \\(E\\) un ensemble à \\(n\\) éléments. Un arrangement de \\(k\\) éléments pris parmi les \\(n\\) éléments de \\(E\\) peut aussi être vu comme une injection de \\(\\{1,2,\\dots, k\\}\\) dans \\(E\\). Exemple. Si \\(E=\\{1,2,3\\}\\), les arrangements à \\(2\\) éléments de \\(E\\) sont les couples \\((1,2), (1,3), (2,1), (2,3), (3, 1), (3,2)\\). On utilise bien la notion de couple pour modéliser les arrangements car l’ordre a une importance : les arrangements \\((1,2)\\) et \\((2,1)\\) sont bien considérés comme différents. Il y a donc six arrangements de \\(2\\) éléments de \\(E\\). Plus généralement, on a une formule qui permet de calculer le nombre d’arrangements de \\(k\\) éléments pris parmi \\(n\\) éléments : Théorème (nombre d’arrangements). On note \\(A_n^k\\) le nombre d’arrangements à \\(k\\) éléments pris dans un ensemble à \\(n\\) éléments. Alors, on a la formule : \\[A_n^k=\\frac{n!}{(n-k)!}\\] Remarque. Ici aussi, le nombre d’arrangements à \\(k\\) éléments pris dans un ensemble à \\(n\\) éléments ne dépend que de \\(n\\) (et de \\(k\\)). Démonstration. C’est exactement la même démarche que pour le dénombrement des permutations : \\(n\\) façons de choisir le premier élément ; \\(n-1\\) façons de choisir le deuxième élément ; … \\(n-k+1\\) façons de choisir l’élément numéro \\(k\\). D’après le principe multiplicatif on a donc : \\[\\begin{align} A_n^k &amp;= n(n-1)\\dots(n-k+1) \\\\ &amp;= \\frac{n!}{(n-k)!} \\end{align}\\] \\(\\square\\) Remarque. Dans le cas où \\(k=n\\), on a \\(A_n^n=n!\\). Ce résultat était prévisible, puisqu’un arrangement de \\(n\\) éléments parmi \\(n\\) éléments est une injection de \\(\\{1,2,\\dots, n\\}\\) dans lui-même, autrement dit une bijection de \\(\\{1,2,\\dots,n\\}\\) dans lui-même. Il s’agit donc d’une permutation de \\(\\{1,2,\\dots,n\\}\\). 2.1.7 Combinaisons Les combinaisons sont l’équivalent non ordonné des arrangements : Combinaisons Soient \\(n\\) et \\(0\\leq k\\leq n\\) deux entiers naturels, et \\(E\\) un ensemble à \\(n\\) éléments. On appelle combinaison de \\(k\\) éléments pris parmi les \\(n\\) éléments de \\(E\\), tout sous-ensemble non ordonné à \\(k\\) éléments de \\(E\\). Exemples. Si \\(E=\\{1,2,3\\}\\), on a vu que les arrangements à \\(2\\) éléments de \\(E\\) sont les couples \\[(1,2), (1,3), (2,1), (2,3), (3, 1), (3,2)\\] Du point de vue des combinaisons, les couples \\((1,2)\\) et \\((2,1)\\) (resp. \\((1,3)\\) et \\((3,1)\\), \\((2,3)\\) et \\((3,2)\\)) sont considérés comme équivalents. Il y a donc trois combinaisons à \\(2\\) éléments de \\(E\\) : \\[\\{1,2\\}, \\{1,3\\} \\text{ et } \\{2,3\\}\\] Remarque. Bien faire attention à la différence de notation : la notation avec parenthèses \\((a_1, a_2,\\dots, a_n)\\) désigne un \\(n-\\)uplet, c’est-à-dire un objet ordonné. Alors que la notation ensembliste \\(\\{a_1,a_2,\\dots a_n\\}\\) désigne un objet non ordonné. On a donc, pour toute permutation \\(\\sigma\\in\\mathfrak{S}_n\\) différente de l’identité : \\[(a_{\\sigma(1)},a_{\\sigma(Z)},\\dots, a_{\\sigma_(n)})\\neq (a_1,a_2,\\dots, a_n)\\] mais \\[\\{a_{\\sigma(1)},a_{\\sigma(Z)},\\dots, a_{\\sigma_(n)}\\}=\\{a_1,a_2,\\dots, a_n\\}\\] Comme pour les permutations et les arrangements, on a une formule simple pour compter les combinaisons : Théorème (nombre de combinaisons). Soient \\(n\\) et \\(0\\leq k\\leq n\\) des entiers naturels. Le nombre de combinaisons de \\(k\\) éléments pris parmi les \\(n\\) éléments d’un ensemnble \\(E\\) quelconque est noté \\(C_n^k\\) ou \\(\\binom{n}{k}\\). Ce nombre, appelé coefficient binomial, est égal à : \\[\\binom{n}{k}=\\frac{n!}{k!\\,(n-k)!}\\] On peut aussi définir de façon cohérente le coefficient binomial pour \\(k\\) et \\(n\\) des entiers naturels avec \\(k&gt;n\\) en posant \\[\\binom{n}{k}=0\\] Démonstration. On commence par compter les arrangements de \\(k\\) éléments parmi \\(n\\) : il y en a \\(A_n^k=\\frac{n!}{(n-k)!}\\). Par ailleurs, toute combinaison \\((a_1,\\dots, a_k)\\) de \\(k\\) éléments parmi \\(n\\) génère \\(k!\\) arrangements distincts \\((a_{\\sigma(1)},\\dots, a_{\\sigma(k)})\\) distincts \\((\\sigma\\in\\mathfrak{S}_k)\\). Il y a donc \\(k!\\) fois plus d’arrangements que de combinaisons. D’où : \\[\\begin{align} \\binom{n}{k} &amp;= \\frac{A_n^k}{k!} \\\\ &amp;= \\frac{n!}{k!(n-k)!} \\end{align}\\] \\(\\square\\) Plusieurs formules impliquent les combinaisons : Formules usuelles sur les combinaisons. Soient \\(n\\) et \\(0\\leq k\\leq n\\) deux entiers naturels. Alors : i. (Cas particuliers) \\[\\binom{n}{0}=1\\] \\[\\binom{n}{n}=1\\] \\[\\binom{n}{1}=n\\] \\[\\binom{n}{2}=\\frac{n(n-1)}{2}\\] ii. (Complémentaire) \\[\\binom{n}{k}=\\binom{n}{n-k}\\] iii. (Triangle de Pascal) \\[\\binom{n}{k}+\\binom{n}{k+1}=\\binom{n+1}{k+1}\\] iv. (Formule du binôme de Newton) Sous la convention \\(0^0=1\\), pour \\(a\\) et \\(b\\) des réels quelconques et \\(n\\) un entier naturel : \\[(a+b)^n=\\sum\\limits_{k=0}^n \\binom{n}{k}a^k b^{n-k}\\] (si on rejette la convention \\(0^0=1\\), alors la formule est toujours vraie sauf dans le cas où \\(n=0\\) et \\(a=-b\\)). En particulier, pour \\(a=b=1\\) on obtient : \\[\\sum\\limits_{k=0}^n \\binom{n}{k}=2^n\\] Pour \\(a=-1\\) et \\(b=1\\) on obtient : \\[\\sum\\limits_{k=0}^n (-1)^k\\binom{n}{k}=0\\] Pour \\(a=x\\) et \\(b=1\\) on obtient : \\[\\sum\\limits_{k=0}^n \\binom{n}{k}x^k=(x+1)^n\\] Pour \\(a=-1\\) et \\(b=x\\) on obtient : \\[\\sum\\limits_{k=0}^n \\binom{n}{k}(-1)^kx^{n-k}=(x-1)^n\\] Démonstration. i. \\(\\binom{n}{0}=\\frac{n!}{0!(n-0)!}=\\frac{n!}{n!}=1\\) L’égalité \\(\\binom{n}{n}=1\\) est une conséquence de la formule précédente et de la formule ii. qui va être montrée après. \\(\\binom{n}{1}=\\frac{n!}{1!(n-1)!}=\\frac{n(n-1)!}{(n-1)!}=n\\) \\(\\binom{n}{2}=\\frac{n!}{2! (n-2)!}=\\frac{n(n-1)(n-2)!}{2(n-2)!}=\\frac{n(n-1)}{2}\\) Autre méthode. Soit \\(E=\\{1,2, \\dots, n\\}\\). Le seul sous-ensemble de \\(E\\) à zéro élément est \\(\\emptyset\\), donc \\(\\binom{n}{0}=1\\). Le seul sous-ensemble de \\(E\\) à \\(n\\) éléments est \\(E\\) lui-même, donc \\(\\binom{n}{n}=1\\). Les seuls sous-ensembles de \\(E\\) à un élément sont les \\(n\\) singletons \\(\\{1\\}, \\{2\\}, \\dots, \\{n\\}\\), donc \\(\\binom{n}{1}=n\\). Enfin, les sous-ensembles à deux éléments de \\(E\\) sont : \\[\\begin{align} &amp;\\{1,2\\}, \\{1,3\\}, \\dots, \\{1,n\\} \\\\ &amp;\\{2,3\\}, \\dots ,\\{2,n\\} \\\\ &amp;\\dots \\\\ &amp;\\{n-1, n\\} \\end{align}\\] Il y en a donc \\(n+(n-1)+\\dots+1=\\frac{n(n-1)}{2}\\) ii. \\[\\begin{align} \\binom{n}{k}&amp;=\\frac{n!}{k!(n-k)!} \\\\ &amp;=\\frac{n!}{(n-k)! k!} \\\\ &amp;=\\frac{n!}{(n-k)!(n-(n-k))!} \\\\ &amp;=\\binom{n}{n-k} \\end{align}\\] Autre méthode. Choisir un sous-ensemble \\(F\\subset E\\) à \\(k\\) éléments revient à choisir son complémentaire \\(\\overline{F}\\) dans \\(E\\), qui contient \\(n-k\\) éléments. Donc \\(\\binom{n}{k}=\\binom{n}{n-k}\\). iii. \\[\\begin{align} \\binom{n}{k}+\\binom{n}{k+1}&amp;=\\frac{n!}{k!(n-k)!}+\\frac{n!}{(k+1)!(n-k-1)!} \\\\ &amp;=\\frac{n!(k+1)}{(k+1)!(n-k)!}+\\frac{n!(n-k)}{(k+1)!(n-k)!} \\\\ &amp;=\\frac{n!(k+1+n-k)}{(k+1)!(n-k)!} \\\\ &amp;=\\frac{n!(n+1)}{(k+1)!(n-k)!} \\\\ &amp;=\\frac{(n+1)!}{(k+1)!((n+1)-(k+1))!} \\\\ &amp;=\\binom{n+1}{k+1} \\end{align}\\] Autre méthode. On sépare les sous-ensembles à \\(k+1\\) éléments de \\(E=\\{1,2,\\dots, n, n+1\\}\\) en deux parties disjointes : les sous-ensembles \\(F\\) qui contiennent \\(n+1\\). Ils sont de la forme \\(\\{x_1,\\dots, x_k\\}\\cup\\{n+1\\}\\), et il y en a donc autant que de façons de choisir un sous-ensemble à \\(k\\) éléments \\(\\{x_1,\\dots, x_k\\}\\) de l’ensemble \\(E&#39;=\\{1,2,\\dots, n\\}\\), i.e. il y en a exactement \\(\\binom{n}{k}\\). les sous-ensembles \\(F\\) qui ne contiennent pas \\(n+1\\). Ils s’écrivent donc sous la forme \\(F=\\{x_1,x_2,\\dots, x_{k+1}\\}\\), avec les \\(x_{k+1}\\) pris dans \\(E&#39;=\\{1,2,\\dots, n\\}\\). Il y en a donc exactement \\(\\binom{n}{k+1}\\). Commes ces deux parties sont disjointes, on peut appliquer le principe additif, pour affirmer que le nombre de sous-ensembles à \\(k+1\\) éléments d’un ensemble à \\(n+1\\) éléments est égal à \\(\\binom{n}{k}+\\binom{n}{k+1}\\). Par ailleurs, le nombre de sous-ensembles à \\(k+1\\) éléments d’un ensemble à \\(n+1\\) éléments est égal à \\(\\binom{n+1}{k+1}\\) (par défintion des coefficients binomiaux). D’où l’égalité \\(\\binom{n}{k}+\\binom{n}{k+1}=\\binom{n+1}{k+1}\\). iv. On montre la formule par récurrence sur \\(n\\). Pour \\(n=0\\), cette formule s’écrit \\((a+b)^0=\\binom{0}{0}a^0b^0\\), soit \\(1=1\\) (sous la convention \\(0^0=1\\), on a quel que soit \\(x\\) réel, \\(x^0=1\\)). Supposons la formule établie pour un entier naturel \\(n\\) donné. Alors : \\[\\begin{align} (a+b)^{n+1} &amp;= (a+b)(a+b)^n \\\\ &amp;= (a+b).\\sum\\limits_{k=0}^n \\binom{n}{k} a^k b^{n-k} \\\\ &amp;\\text{(d&#39;après l&#39;hypothèse de récurrence)} \\\\ &amp;= \\sum\\limits_{k=0}^n \\binom{n}{k} a^{k+1} b^{n-k}+\\sum\\limits_{k=0}^n \\binom{n}{k} a^{k} b^{n-k+1} \\\\ &amp;=\\sum\\limits_{k=1}^{n+1} \\binom{n}{k-1} a^{k} b^{n-k+1}+\\sum\\limits_{k=0}^n \\binom{n}{k} a^{k} b^{n-k+1} \\\\ &amp;=\\binom{n}{n} a^{n+1}+\\sum\\limits_{k=1}^n \\left(\\binom{n}{k-1}+\\binom{n}{k}\\right) a^kb^{n-k+1}+\\binom{n}{0}b^{n+1} \\\\ &amp;=a^{n+1}+\\sum\\limits_{k=1}^n \\binom{n+1}{k} a^k b^{n+1-k} +b^{n+1} \\\\ &amp;\\text{(d&#39;après la formule du triangle de Pascal)} \\\\ &amp;= \\sum\\limits_{k=0}^{n+1}\\binom{n+1}{k} a^k b^{n+1-k} \\\\ \\end{align}\\] qui est la formule attendue au rang \\(n+1\\). Autre méthode. En développant le produit \\[(a+b)^n=(a+b).(a+b)\\dots (a+b)\\] on obtient une somme de termes de la forme \\(a^kb^{n-k}\\). Pour obtenir un tel terme, on doit choisir \\(k\\) fois le terme \\(a\\) parmi les \\(n\\) facteurs \\((a+b)\\) (et donc, de façon complémentaire, \\(n-k\\) fois le terme \\(b\\) parmi ces mêmes facteurs). On en déduit, par définition des coefficients binomiaux, que le terme \\(a^kb^{n-k}\\) apparaît exactement \\(\\binom{n}{k}\\) fois dans la somme. Autrement dit on a bien \\((a+b)^n=\\sum\\limits_{k=0}^n \\binom{n}{k}a^k b^{n-k}\\). \\(\\square\\) Remarques. i. Comme souvent en analyse combinatoire, la démonstration d’une égalité peut se faire soit par le calcul, soit en utilisant une approche de dénombrement pur (qui en général est plus élégante mais peut-être un peu moins évidente à trouver). ii. La deuxième démonstration de la formule du triangle de Pascal repose sur une approche classique en dénombrement : compter la même chose de deux façons différentes. 2.2 Evénements et probabilités 2.2.1 Evénements Définition Opérations sur les événements : réunion, intersection, événement contraire 2.2.2 Probabilités Définition d’une probabilité Propriétés : probabilité d’un événement contraire, d’une union disjointe \\(0\\leq p(A)\\leq 1\\) propriété de croisssance crible de Poincaré Equiprobabilité 2.2.3 Probabilités conditionnelles Définition Propriétés : les mêmes que pour une probabilité “non conditionnelle” Formule des probabilités composées Formule des probabilités totales Formule de Bayes Indépendance (deux à deux, mutuelle) "],["variables-aléatoires-discrètes.html", "Chapitre 3 Variables aléatoires discrètes 3.1 Définition et premières propriétés 3.2 Transformation d’une variable aléatoire discrète 3.3 Vecteurs aléatoires", " Chapitre 3 Variables aléatoires discrètes 3.1 Définition et premières propriétés 3.1.1 Définition 3.1.2 Loi d’une variable aléatoire discrète 3.1.3 Définition de \\(p(X\\in A)\\) 3.1.4 Fonction de répartition, quantiles 3.1.5 Exemples classiques : loi uniforme sur un ensemble fini loi de Bernoulli loi binomiale loi de Poisson loi géométrique loi hypergéométrique 3.1.6 Moments d’une variable aléatoire Espérance, variance, moments d’ordres supérieurs inégalité de Markov, inégalité de Bieanymé-Tchébychev (exemples + intérêt) 3.2 Transformation d’une variable aléatoire discrète 3.2.1 Définition Définition Cas particuliers : bijection continue un unique extremum Déterminer la loi de \\(f(X)\\) en pratique (message = passer par la fonction de répartition) 3.2.2 Théorème de transfert (cas discret) Théorème Exemple 3.3 Vecteurs aléatoires 3.3.1 Définition 3.3.2 Loi jointe, loi marginales 3.3.3 Loi conditionnelle \\(\\mathcal{L}(Y|X)\\) 3.3.4 Loi d’un couple de VA indépendantes Définition Somme de deux VA indépendantes (produit de convolution discret) 3.3.5 Espérance conditionnelle, variance conditionnelle "],["variables-aléatoires-à-densité.html", "Chapitre 4 Variables aléatoires à densité 4.1 Définition et premières propriétés 4.2 Transformation d’une variable aléatoire à densité 4.3 Vecteurs aléatoires", " Chapitre 4 Variables aléatoires à densité 4.1 Définition et premières propriétés 4.1.1 Définition 4.1.2 Loi d’une variable aléatoire à densité 4.1.3 Définition de \\(p(X\\in A)\\) 4.1.4 Fonction de répartition, quantiles 4.1.5 Exemples classiques : loi uniforme sur un segment loi normale loi exponentielle loi gamma \\(\\gamma(p\\,;\\,\\theta)\\) loi log-normale loi du Chi-Deux loi de Student loi de Fisher 4.1.6 Moments d’une variable aléatoire Espérance, variance, espaces \\(L^1\\) et \\(L^2\\) moments d’ordres supérieurs inégalité de Markov, inégalité de Bieanymé-Tchébychev (exemples + intérêt) 4.2 Transformation d’une variable aléatoire à densité 4.2.1 Définition Définition Cas particuliers : bijection continue un unique extremum Déterminer la loi de \\(f(X)\\) en pratique (message = passer par la fonction de répartition) 4.2.2 Théorème de transfert (cas à densité) Théorème Exemple 4.3 Vecteurs aléatoires 4.3.1 Définition 4.3.2 Loi jointe, loi marginales 4.3.3 Loi conditionnelle \\(\\mathcal{L}(Y|X)\\) 4.3.4 Loi d’un couple de VA indépendantes Définition Somme de deux VA indépendantes (produit de convolution à densité) 4.3.5 Espérance, matrice de variance-covariance exemple : vecteurs gaussiens en dimension 2 4.3.6 Espérance conditionnelle, variance conditionnelle "],["convergence.html", "Chapitre 5 Convergence 5.1 Différents modes de convergence 5.2 Loi Faible des Grands Nombres, Loi Forte des Grands Nombres 5.3 Théorème Central Limite (TCL) 5.4 Variantes du TCL (hors-programme)", " Chapitre 5 Convergence 5.1 Différents modes de convergence 5.1.1 Convergence en probabilité 5.1.2 Convergence dans les espaces \\(L^p\\) focus sur les cas \\(p=1\\) et \\(p=2\\) 5.1.3 Convergence en loi 5.1.4 Convergence presque-sûre (hors-prgramme ?) 5.1.5 Liens entre les différents modes de convergence 5.1.6 Approximations approximation de la loi binomiale \\(\\mathcal{B}(n\\,;\\,p)\\approx\\mathcal{N}(np\\,;\\,np(1-p))\\) approximation de la loi de Poisson \\(\\mathcal{P}(\\lambda)\\approx\\mathcal{N}(\\lambda\\,;\\,\\lambda)\\) (bien préciser les hypothèses sous-jcantes à ces approximations) 5.2 Loi Faible des Grands Nombres, Loi Forte des Grands Nombres énoncé théorique exemples avec illustration en R 5.3 Théorème Central Limite (TCL) énoncé théorique exemples avec illustration en R 5.4 Variantes du TCL (hors-programme) "],["statistique-descriptive.html", "Chapitre 6 Statistique descriptive 6.1 Vocabulaire 6.2 Analyse statistique univariée 6.3 Analyse statistique bivariée", " Chapitre 6 Statistique descriptive 6.1 Vocabulaire 6.1.1 Population, individus, échantillon 6.2 Analyse statistique univariée 6.2.1 Notion de série statistique univariée série statistique à une variable valeurs variable statistique 6.2.2 Indicateurs d’une série statistique univariée modalités, effectif, fréquence effectifs cumulées croissants, fréquences cumulées croissantes indicateurs de position, indicateurs de dispersion indicateurs de concentration courbe de Lorenz indice de Gini quantiles 6.2.3 Représentations graphiques 6.3 Analyse statistique bivariée 6.3.1 Notion de série statistique bivariée série statistique à deux variables 6.3.2 Indicateurs propres à l’analyse statistique multivariée distribution marginale effectif marginal fréquence marginale covariance empirique distribution conditionnelle formule de Huygens-Koenig coefficient de corrélation linéaire empirique 6.3.3 Nuage de points 6.3.4 Ajustement des moindres carrés "],["statistique-inférentielle.html", "Chapitre 7 Statistique inférentielle 7.1 Estimation 7.2 Tests statistiques", " Chapitre 7 Statistique inférentielle 7.1 Estimation On s’intéresse à une loi probabiliste \\(\\mathcal{L}_{\\theta}\\), qui est entièrement décrite par la donnée d’un paramètre inconnu \\(\\theta\\). Pour mieux appréhender cette loi, il serait intéressant de connaître la valeur de \\(\\theta\\). Plutôt que de chercher à déterminer la valeur exacte de \\(\\theta\\), on peut essayer de l’approcher. Dans le cadre de la statistique inférentielle, on suppose qu’on dispose d’un échantillon i.i.d. de \\(\\mathcal{L}_{\\theta}\\), autrement dit d’un certain nombre de réalisations \\((Y_1,\\dots, Y_n)\\) indépendantes et identiquement distribuées de la loi \\(\\mathcal{L}_{\\theta}\\). La donnée d’un tel échantillon constitue un ensemble d’informations qui vont nous être utiles pour estimer le paramètre \\(\\theta\\). on fait donc bien ici de l’inférence - ou encore de l’induction - dans le sens où on part d’observations particulières (les réalisations \\(Y_1,\\dots, Y_n)\\) pour énoncer une règle générale (le fait que ces réalisations sont issues de la loi \\(\\mathcal{L}_{\\theta}\\)). 7.1.1 Premières définitions Estimateurs Soit \\(Y\\) une variable aléatoire de loi \\(\\mathcal{L}(Y)\\), paramétrée par un réel \\(\\theta\\) inconnu. Soit \\((Y_1,\\dots, Y_n)\\) un échantillon i.i.d. de loi \\(\\mathcal{L}(Y)\\). On appelle estimateur de \\(\\theta\\) toute fonction de \\(Y_1,\\dots, Y_n\\), i.e. \\[\\widehat{\\theta}_n=S(Y_1,\\dots, Y_n)\\] On veut estimer la moyenne d’une loi normale \\(\\mathcal{N}(\\mu\\,;\\,1)\\), à partir d’un échantillon d’observations i.i.d. \\((Y_1,\\dots, Y_n)\\) tirées sous cette loi. Une façon naturelle d’estimer \\(\\mu=\\mathbb{E}(Y_1)\\) est de poser \\(\\widehat{\\mu}_n=\\frac{Y_1+\\dots Y_n}{n}\\). Ici, on estime donc une moyenne théorique par sa contrepartie empirique. Biais, erreur quadratique Soit \\(\\widehat{\\theta}_n\\) un estimateur de \\(\\theta\\) admettant un moment d’ordre \\(1\\). On appelle biais de \\(\\widehat{\\theta}_n\\) la quantité \\(b_{\\theta}(\\widehat{\\theta}_n)=\\mathbb{E}(\\widehat{\\theta}_n)-\\theta\\). Un estimateur est dit sans biais lorsque son biais est nul, i.e. \\(\\mathbb{E}(\\widehat{\\theta}_n)=\\theta\\). Il est dit asymptotiquement sans biais lorsque son biais tend vers \\(0\\), i.e. \\(b_{\\theta}(\\widehat{\\theta}_n)\\underset{n\\to +\\infty}{\\longrightarrow}0\\). Pour un estimateur des moments d’ordre \\(1\\) et \\(2\\), on appelle erreur quadratique moyenne la quantité (positive) \\(\\text{EQM}_{\\theta}(\\widehat{\\theta}_n)=\\mathbb{E}\\left(\\left(\\widehat{\\theta}_n-\\theta\\right)^2\\right)\\) L’erreur quadratique moyenne s’écrit à l’aide de l’espérance et de la variance : Théorème : Soit \\(\\widehat{\\theta}_n\\) un estimateur de \\(\\theta\\) admettant des moments d’ordres \\(1\\) et \\(2\\). Son erreur quadratique moyenne peut se décomposer en biais au carré/variance : \\[\\text{EQM}_{\\theta}(\\widehat{\\theta}_n)=b_{\\theta}^2(\\widehat{\\theta}_n)+\\mathbb{V}(\\widehat{\\theta}_n)\\] Autrement dit, réduire l’erreur (quadratique moyenne) d’un estimateur revient à essayer de réduire son biais et/ou sa variance. En pratique, uune réduction du biais implique souvent une augmentation de la variance (et vice-versa) et il faut trouver un compromis entre les deux, i.e. un estimateur pour lequel la combinaison (biais, variance) implique une faible erreur quadratique moyenne. On parle alors de compromis biais-variance. 7.1.2 Convergence d’un estimateur Estimateurs convergents Un estimateur \\(\\widehat{\\theta}_n\\) de \\(\\theta\\) est dit convergent lorsqu’il converge en probabilité vers \\(\\theta\\) i.e. lorsque \\[\\forall\\varepsilon &gt;0, \\mathbb{P}\\left(|\\widehat{\\theta}_n-\\theta|&gt;\\varepsilon\\right)\\longrightarrow 0\\] La convergence d’un estimateur sans biais peut se montrer à l’aide du critère pratique suivant : Théorème (critère pratique de convergence) : Un estimateur \\(\\widehat{\\theta}_n\\) sans biais de \\(\\theta\\) est convergent dès que sa variance tend vers \\(0\\), i.e. \\[\\left(\\mathbb{E}_{\\theta}(\\widehat{\\theta}_n)=0 \\text{ et } \\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)\\longrightarrow 0\\right)\\Rightarrow \\left(\\widehat{\\theta}_n \\underset{n \\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}\\theta\\right)\\] Démonstration. Compte-tenu du fait que \\(\\widehat{\\theta}_n\\) est un estimateur sans biais pour \\(\\theta\\), l’inégalité de Bieanymé-Tchebychev s’écrit \\(\\mathbb{P}(|\\widehat{\\theta}_n-\\theta|&gt;\\varepsilon)\\leq\\frac{\\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)}{\\varepsilon^2}\\), ce qui permet de conclure. \\(\\square\\) On peut même affaiblir un peu l’hypothèse d’absence de biais par une hypothèse de biais asymptotiquement nul : Théorème (critère pratique de convergence (suite)) : Un estimateur \\(\\widehat{\\theta}_n\\) asymtotiquement sans biais de \\(\\theta\\) est convergent dès que sa variance tend vers \\(0\\), i.e. \\[\\left(\\mathbb{E}_{\\theta}(\\widehat{\\theta}_n)\\underset{n\\to +\\infty}{\\longrightarrow}\\theta \\text{ et } \\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)\\longrightarrow 0\\right)\\Rightarrow \\left(\\widehat{\\theta}_n \\underset{n \\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}\\theta\\right)\\] 7.1.3 Exemples classiques Quelques exemples très classiques d’estimateurs : Exemple 1 : moyenne empirique. Soit \\(X_1,\\dots X_n\\) une suite de \\(VAR\\) i.i.d. de même loi que \\(X\\), admettant une espérance \\(\\mu\\). La moyenne empirique est l’estimateur \\[\\overline{X_n}=\\frac{X_1+\\dots + X_n}{n}\\] Théorème : Quelle que soit la loi suivie par \\(X\\), la moyenne empirique \\(\\overline{X_n}\\) est un estimateur sans biais de l’espérance \\(\\mu=\\mathbb{E}(X)\\). Si, de plus, \\(X\\) admet une variance \\(\\sigma^2\\), alors \\(\\overline{X_n}\\) admet également une variance et celle-ci est donnée par \\(\\mathbb{V}(\\overline{X_n})=\\frac{\\sigma^2}{n}\\). Démonstration. Par linéarité de l’espérance : \\(\\mathbb{E}(\\overline{X_n})=\\frac{1}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i)=\\frac{1}{n}\\sum\\limits_{i=1}^n\\mu=\\mu\\). Si \\(X\\) admet une variance, alors \\(\\overline{X_n}\\) aussi et \\(\\mathbb{V}(\\overline{X_n})=\\frac{1}{n^2}\\sum\\limits_{i=1}^n\\mathbb{V}(X_i)=\\frac{\\sigma^2}{n}\\), par indépendance de \\(X_1,\\dots X_n\\). \\(\\square\\) Corollaire : La moyenne empirique est un estimateur convergent de l’espérance (lorsqu’elle existe). Démonstration. L’estimateur \\(\\overline{X_n}\\) est sans biais et \\(\\mathbb{V}(\\overline{X_n})=\\frac{\\sigma^2}{n}\\longrightarrow 0\\). C’est donc un estimateur convergent de l’espérance. \\(\\square\\). Exemple 2 : estimation d’une proportion. Au sein d’une population, une proportion \\(p\\) d’individus présente une caractéristique. On suppose que la présence de cette caractéristique est distribuée de façon identique et indépendante d’un individu à l’autre suivant la loi de Bernoulli de paramètre \\(p\\). On peut donc estimer la proportion \\(p\\) au niveau population par la proportion \\(\\widehat{p_n}\\) au niveau échantillon : cet estimateur est la moyenne empirique, il est sans biais et de variance (inconnue) \\(\\frac{p(1-p)}{n}\\). Exemple 3 : variance empirique. Si \\(X\\) admet une variance \\(\\sigma^2\\) et \\(X_1,\\dots, X_n\\) sont i.i.d. de même loi que \\(X\\), alors un estimateur de \\(\\sigma^2\\) est donné par la variance empirique \\(S_n^{&#39;2}=\\frac{1}{n}\\sum\\limits_{i=1}^n(X_i-\\overline{X_n})^2\\). Théorème : La variance empirique \\(S_n^{&#39;2}\\) est un estimateur biaisé de la variance \\(\\sigma^2\\). Plus précisément, on a \\[\\mathbb{E}(S_n^{&#39;2})=\\frac{n-1}{n}\\sigma^2\\] Démonstration. \\[\\begin{align} \\mathbb{E}(S_n^{&#39;2}) &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i^2)-\\frac{2\\overline{X_n}}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i)+\\frac{1}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(\\overline{X_n}^2) \\\\ &amp;= \\mathbb{E}(X^2)-\\mathbb{E}(\\overline{X_n}^2) \\end{align}\\] Par ailleurs : \\[\\begin{align} \\mathbb{E}(\\overline{X_n}^2)&amp;=\\frac{1}{n^2}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i^2)+\\frac{1}{n^2}\\sum\\limits_{i\\neq j}\\mathbb{E}(X_iX_j) \\\\ &amp;= \\frac{1}{n}^2\\sum\\limits_{i=1}^n\\mathbb{E}(X_i^2)+\\frac{1}{n^2}\\sum\\limits_{i\\neq j}\\mathbb{E}(X_i)\\mathbb{E}(X_j) \\\\ &amp;= \\frac{1}{n}\\mathbb{E}(X^2)+\\frac{n-1}{n}\\left(\\mathbb{E}(X)\\right)^2 \\end{align}\\] Avec la formule de Huygens \\(\\mathbb{V}(X)=\\mathbb{E}(X^2)-\\mathbb{E}(X)^2\\), on en déduit que \\[\\mathbb{E}(S_n^{&#39;2})=\\frac{n-1}{n}\\sigma^2\\] \\(\\square\\) Remarque. Le biais de l’estimateur \\(S_n^{&#39;2}\\) devient cependant très faible pour \\(n\\) suffisamment grand. Il s’agit d’un estimateur asymptotiquement sans biais de la variance \\(\\sigma^2\\) : \\(\\mathbb{E}(S_n^{&#39;2})\\longrightarrow \\sigma^2\\). Exemple 4 : variance empirique corrigée. En modifiant l’estimateur de la variance empirique par un petit facteur correctif, on obtient un estimateur sans biais de la variance. Il suffit de poser \\[S_n^2=\\frac{1}{n-1}\\sum\\limits_{i=1}^n(X_i-\\overline{X_n})^2\\] Cet estimateur s’appelle la variance empirique corrigée. Théorème : La variance empirique corrigée \\(S_n^2=\\frac{1}{n-1}\\sum\\limits_{i=1}^n (X_i-\\overline{X_n})^2\\) est un estimateur sans biais de la variance \\(\\sigma^2=\\mathbb{V}(X)\\) : \\[\\mathbb{E}(S_n^2)=\\sigma^2\\] 7.1.4 Méthodes de construction des estimateurs On présente ici deux méthodes classiques de construction des estimateurs ; la méthode des moments et la méthode du maximum de vraisemblance. 7.1.4.1 La méthode des moments La méthode des moments Soit \\(X\\) une variable aléatoire réelle de loi \\(\\mathcal{L}_{\\theta}\\), où \\(\\theta\\) est un paramètre inconnu. On considère une fonction \\(f\\) de \\(I\\subset\\mathbb{R}\\) dans \\(\\mathbb{R}\\) telle que \\(f(X)\\) admette une espérance. Comme la loi de \\(X\\) dépend de \\(\\theta\\), il en est de même de \\(\\mathbb{E}(f(X))\\). La méthode des moments suppose qu’on sait expliciter une telle dépendance, i.e. qu’on connaisse une fonction \\(g\\) telle que \\[\\mathbb{E}(f(X))=g(\\theta)\\] La contrepartie empirique du membre de gauche de cette égalité est \\(\\frac{1}{n}\\sum\\limits_{i=1}^n f(X_i)\\), et la méthode des moments consiste alors à résoudre l’équation en \\(\\widehat{\\theta}\\) : \\[g(\\widehat{\\theta})=\\frac{1}{n}\\sum\\limits_{i=1}^n f(X_i)\\] Exemple 5 : estimation du paramètre d’une loi exponentielle. Soit \\(X\\sim\\mathcal{E}(\\lambda)\\), où \\(\\lambda&gt;0\\) est un paramètre inconnu que l’on veut estimer. La variable aléatoire \\(X\\) admet une espérance, et celle-ci est donnée par \\(\\mathcal{E}(X)=\\frac{1}{\\lambda}\\). La méthode des moments consiste alors à résoudre l’équation \\[\\frac{1}{\\widehat{\\lambda_n}}=\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\] Cette équation est très simple, elle admet pour solution \\[\\widehat{\\lambda_n}=\\frac{1}{\\overline{X_n}}\\] C’est l’estimateur que l’on obtient par la méthode des moments. Remarque. En reprenant les notations explicitées ci-dessus, on peut identifier les fonctions \\(f\\) et \\(g\\) : \\[f(x)=x\\] \\[g(x)=\\frac{1}{x}\\] et ici évidemment \\(\\theta=\\lambda\\). En général, la méthode des moments s’utilise de façon complètement intuitive sans qu’on ait même à expliciter forcément les fonctions \\(f\\) et \\(g\\). 7.1.4.2 La méthode du maximum de vraisemblance Une autre méthode de construction d’estimateurs est celle du maximum de vraisemblance. L’idée générale de cette méthode est la suivante. On suppose qu’on dispose de réalisations \\(x_1,\\dots x_n\\) d’une même variable aléatoire, dont la loi appartient à une famille paramétrique \\(\\left\\{\\mathcal{L}_{\\theta}\\,;\\,\\theta\\in\\Theta\\right\\}\\) et on cherche à estimer \\(\\theta\\). Si par exemple on dispose d’une série de cinq obersations \\((0.12, -0.65, 1.35, 1.04, -1.19, 0.08)\\) et qu’on veut inférer sur \\(\\theta\\) à partir de ces observations, on est enclin à penser que la valeur \\(\\theta=0\\) est plus plausible que la valeur \\(\\theta=-10\\). La vraisemblance est une formalisation de l’idée intuitive de plausibilité d’un paramètre à partir d’une observation ou d’un ensemble d’observations. A nouveau, \\(X\\) désigne une variable aléatoire de loi dépendant d’un paramètre inconnu \\(\\theta\\), et \\(x\\) une réalisation de \\(X\\). La vraisemblance \\(L(x,.)\\) est une fonction de \\(\\theta\\) définie par \\[L(x;\\theta)=\\left\\{ \\begin{array}{lll} \\mathbb{P}_{\\theta}(X=x) &amp;\\text{; si } X \\text{ est discrète} \\\\ f(x;\\theta) &amp;\\text{; si } X \\text{ est une continue de densité } f(.;\\theta) \\\\ \\end{array} \\right.\\] Remarque : D’autres notations existent dans la littérature, comme \\(L(x|\\theta), \\mathbb{P}(X=x|\\theta), f(x|\\theta)\\). Ces notations viennent de la statistique bayésienne (hors programme du concours) qui envisage \\(\\theta\\) comme une variable aléatoire de distribution inconnue. Dans ce cas, la vraisemblance s’interprète comme une probabilité ou une densité de probabilité. La définition précédente s’étend au cas d’un échantillon \\((X_1,\\dots X_n)\\) de VA de même loi que \\(X\\). Dans ce cas, on note souvent \\(L_n(x;\\theta)\\) la vraisemblance, pour faire apparaître la dépendance en \\(n\\). Un cas particulier important est celui où ces VA sont i.i.d. Dans ce cas, la vraisemblance est définie par \\[L_n(x;\\theta)=L_n(x_1,\\dots,x_n ; \\theta)=\\left\\{ \\begin{array}{lll} \\prod\\limits_{i=1}^n\\mathbb{P}_{\\theta}(X_i=x_i) &amp;\\text{; si } X \\text{ est discrète} \\\\ \\prod\\limits_{i=1}^n f(x_i,\\theta) &amp;\\text{; si } X \\text{ est une continue de densité } f(.;\\theta) \\\\ \\end{array} \\right.\\] La méthode du maximum de vraisemblance consiste juste à dire que si toute l’information dont on dispose sur la variable aléatoire \\(X\\) est l’observation de l’échantillon \\((x_1, \\dots, x_n)\\), alors la meilleure estimation que l’on puisse faire de \\(\\theta\\) à partir de cette information est celle qui maximise la fonction de vraisemblance. Autrement dit, on cherche la valeur de \\(\\theta\\) qui rend l’observation \\((x_1,\\dots, x_n)\\) la plus plausible. Formellement : Méthode du maximum de vraisemblance Etant donné une collection de \\(n\\) réalisations \\(x=(x_1,\\dots, x_n)\\) des VA \\((X_1,\\dots X_n)\\) de même loi \\(\\mathcal{L}_{\\theta}\\) de paramètre inconnu \\(\\theta\\), on appelle estimation du maximum de vraisemblance toute estimation \\(\\widehat{\\theta}_n=\\widehat{\\theta}_n(x_1,\\dots,x_n)\\) vérifiant \\[\\widehat{\\theta}_n\\in \\arg\\max\\limits_{\\theta\\in\\Theta}L_n(x;\\theta)\\] Cas particulier : si la fonction \\(\\theta\\mapsto L_n(x;\\theta)\\) est deux fois dérivable sur \\(\\Theta\\), alors on peut chercher à résoudre (en \\(\\theta\\)) le système \\[\\left\\{ \\begin{array}{lll} \\frac{\\partial}{\\partial\\theta}L_n(x;\\theta)=0 \\\\ \\frac{\\partial^2}{\\partial\\theta^2}L_n(x;\\theta)&lt;0 \\\\ \\end{array} \\right.\\] Les solutions de ce système fournissent des estimations par maximum de vraisemblance. Log-vraisemblance. Il est souvent plus commode de considérer la log-vraisemblance \\(l_n(x;\\theta)=\\ln L_n(x;\\theta)=\\sum\\limits_{i=1}^n \\ln L_n(x_i;\\theta)\\). La fonction \\(\\ln\\) étant croissante sur \\(\\mathbb{R}_{+}^*\\), maximiser la vraisemblance équivaut à maximiser la log-vraisemblance. Maximisation de la log-vraisemblance En supposant que \\(L_n(x;\\theta)&gt;0\\) pour tout \\(\\theta\\in\\Theta\\), on note \\(l_n(x;\\theta)=\\ln L_n(x;\\theta)\\) la log-vraisemblance. Sous les mêmes hypothèses que ci-dessus, on cherche \\[\\widehat{\\theta}_n\\in\\arg\\max\\limits_{\\theta\\in\\Theta}\\left(l_n(x;\\theta)\\right)\\] Cas particulier : si la fonction \\(\\theta\\mapsto L_n(x;\\theta)\\) est deux fois dérivable sur \\(\\Theta\\), alors la fonction \\(\\theta\\mapsto l_n(x;\\theta)\\) l’est aussi et on peut chercher à résoudre (en \\(\\theta\\)) le système \\[\\left\\{ \\begin{array}{lll} \\frac{\\partial}{\\partial\\theta}l_n(x;\\theta)=0 \\\\ \\frac{\\partial^2}{\\partial\\theta^2}l_n(x;\\theta)&lt;0 \\\\ \\end{array} \\right.\\] Les solutions de ce système fournissent des estimations par maximum de vraisemblance. Exemple 6 : loi normale. \\(\\mathcal{N}(\\mu, 1)\\). On veut estimer le paramètre inconnu \\(\\mu\\) par maximum de vraisemblance. La vraisemblance est donnée par \\[\\begin{align} L_n(x;\\mu)&amp;=\\prod\\limits_{i=1}^n\\left(\\frac{e^{-\\frac{(x_i-\\mu)^2}{2}}}{\\sqrt{2\\pi}}\\right)\\\\ &amp;=\\frac{1}{(2\\pi)^{\\frac{n}{2}}}e^{-\\sum\\limits_{i=1}^n (x_i-\\mu)^2} \\end{align}\\] La log-vraisemblance est plus facile à manipuler : \\[\\begin{align} l_n(x;\\mu)&amp;=\\ln L_n(x;\\mu) \\\\ &amp;= -\\frac{n}{2}\\ln(2\\pi)-\\sum\\limits_{i=1}^n(x_i-\\mu)^2 \\end{align}\\] La fonction \\(\\mu\\mapsto l_n(x;\\mu)\\) est deux fois dérivable sur \\(\\mathbb{R}\\) et \\(\\frac{\\partial}{\\partial\\mu}l_n(x;\\mu)=2\\sum_{i=1}^n(\\mu-x_i)\\). Une seule valeur de \\(\\mu\\) l’annule : \\[\\widehat{\\mu}_n=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i=\\overline{x}_n\\] Par ailleurs \\(\\frac{\\partial^2}{\\partial\\mu^2}l_n(x;\\mu)=2n&gt;0\\), et donc \\(\\widehat{\\mu}_n\\in\\arg\\max\\limits_{\\mu\\in\\mathbb{R}}l(x;\\mu)\\). Finalement, un estimateur par maximum de vraisemblance est donné par \\[\\widehat{\\mu}_n=\\overline{X}_n=\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\] Remarque. Comme souvent en statistique, on commet un léger abus de notation en désignant par la même lettre l’estimateur \\(\\widehat{\\mu}_n=\\frac{X_1+\\dots+X_n}{n}=\\widehat{\\mu}_n(X_1,\\dots,X_n)\\) (qui est une statistique, i.e. une fonction de \\((X_1,\\dots,X_n\\)) et l’estimation \\(\\widehat{\\mu}_n=\\frac{x_1+\\dots+x_n}{n}=\\widehat{\\mu}_n(x_1,\\dots, X_n)\\) qui en est une réalisation. Conditionnellement à \\((X_1,\\dots,X_n)\\) (i.e. si l’on suppose que l’on observe \\((X_1,\\dots, X_n)\\)) ces deux objets sont bien les mêmes. Exemple 7 : loi exponentielle. Soit \\((X_1,\\dots,X_n)\\) un échantillon i.i.d. tiré selon une loi exponentielle \\(\\mathcal{E}(\\lambda)\\) de paramètre \\(\\lambda&gt;0\\) inconnu. La vraisemblance est donnée par \\[\\begin{align} L_n(x;\\lambda)&amp;=\\prod\\limits_{i=1}^n (\\lambda e^{-\\lambda x_i}\\mathbb{1}_{x_i\\geq 0}) \\\\ \\end{align}\\] Si l’un des \\(x_i\\) est négatif elle vaut \\(0\\). Sinon on calcule la log-vraisemblance \\[l_n(x;\\lambda)=n\\ln(\\lambda)-\\lambda\\sum_{i=1}^n x_i\\] La fonction \\(\\lambda\\in\\mathbb{R}_{+}^*\\mapsto l_n(x;\\lambda)\\) est deux fois dérivable et \\(\\frac{\\partial}{\\partial\\lambda}l_n(x;\\lambda)=\\frac{n}{\\lambda}-\\sum\\limits_{i=1}^n x_i\\), qui s’annule en \\(\\lambda=\\frac{n}{\\sum\\limits_{i=1}^n x_i}=\\frac{1}{\\overline{x}_n}\\). De plus, \\(\\frac{\\partial^2}{\\partial\\lambda^2}l_n(x;\\lambda)=-\\frac{n}{\\lambda^2}&lt;0\\) et donc à \\(x\\) fixé, \\(l_n(x;\\lambda)\\) atteint son maximum en \\(\\frac{1}{\\overline{x_n}}\\). L’estimateur du maximum de vraisemblance est donc \\(\\widehat{\\lambda}_n=\\frac{1}{\\overline{X}_n}\\). On remarque qu’on retrouve ici le même estimateur que celui obtenu par la méthode des moments. 7.1.5 Compléments (hors-programme) On présente dans cette partie les notions suivantes : information de Fisher borne de Cramer-Rao statistique exhaustive famille exponentielle amélioration d’un estimateur Ces notions ne sont pas au programme du concours, mais elles sont clairement dans sa périphérie immédiate. On les retrouve d’ailleurs dans le sujet d’interne 2022, mais leur connaissance n’est pas requise pour traiter le sujet. 7.1.5.1 Information de Fisher Soient \\(X\\) une variable aléatoire (discrète ou continue) à valeurs dans \\(\\mathcal{X}\\) de loi \\(L(x;\\theta)&gt;0\\), avec \\(\\theta\\in\\mathbb{R}\\). On fait les hypothèses suivantes : existence de \\(\\frac{\\partial L}{\\partial\\theta}(x;\\theta)\\) et de \\(\\frac{\\partial^2}{\\partial\\theta^2}L(x;\\theta)\\) on peut échanger tous les opérateurs de dérivation (à l’ordre \\(1\\) et \\(2\\)) et d’intégration On considère un échantillon i.i.d. \\((X_1,\\dots,X_n)\\) tel que chacun des \\(X_i\\) suit la même loi que \\(X\\). Pour \\(x=(x_1,\\dots,x_n)\\) une réalisation de l’échantillon aléatoire \\((X_1,\\dots, X_n)\\), On note \\(L_n(x;\\theta)\\) la vraisemblance de \\((x_1,\\dots, x_n)\\) : \\[L_n(x;\\theta)=\\prod\\limits_{i=1}^n L(x_i;\\theta)\\] On appelle alors score la quantité (aléatoire) \\(\\frac{\\partial}{\\partial\\theta}\\,\\ln L_n(X;\\theta)=\\frac{\\partial}{\\partial\\theta}\\, l_n(X;\\theta)\\), i.e. la dérivée de la log-vraisemblance par rapport à \\(\\theta\\). Théorème : On a \\[\\mathbb{E}_{\\theta}\\left(\\frac{\\partial }{\\partial\\theta}\\, l_n(X;\\theta)\\right)=0\\] i.e. le score est d’espérance nulle. Démonstration. On démontre cette égalité dans le cas à densité : \\[\\begin{align} \\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta}\\, l_n(X ; \\theta)\\right) &amp;= \\int_{\\mathbb{R}^n} \\frac{\\partial}{\\partial\\theta} \\,l_n(x;\\theta)\\,L_n(x;\\theta)\\,dx \\\\ &amp;=\\int_{\\mathbb{R}^n}\\frac{\\frac{\\partial L_n}{\\partial\\theta}(x;\\theta)}{L_n(x;\\theta)}\\,L_n(x;\\theta)\\,dx \\\\ &amp;= \\int_{\\mathbb{R}^n} \\frac{\\partial L_n}{\\partial\\theta}(x;\\theta)\\,dx \\\\ &amp;=\\frac{\\partial}{\\partial\\theta}\\int_{\\mathbb{R}^n} L_n(x;\\theta) \\, dx \\text{ (on permute intégrale et dérivée)} \\\\ &amp;= 0 \\text{ (car } \\int_{\\mathbb{R}^n} L_n(x;\\theta)\\,dx=1\\text{)} \\\\ \\end{align}\\] \\(\\square\\) L’information de Fisher est définie à partir du score de la façon suivante : Information de Fisher L’information de Fisher est la quantité définie par \\[I_n(\\theta)\\equiv\\mathbb{E}_{\\theta}\\left(\\left(\\frac{\\partial }{\\partial\\theta}\\, l_n(X;\\theta)\\right)^2\\right)=\\mathbb{V}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta}l_n(X;\\theta)\\right)\\] Lorsque le domaine de \\(X\\) ne dépend pas de \\(\\theta\\), l’information de Fisher est aussi égale à \\[I_n(\\theta)=-\\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2} l_n(X;\\theta)\\right)\\] Cette dernière expression est généralement plus facile à calculer. Interprétation de l’information de Fisher. On utilise généralement l’information de Fisher lorsqu’on veut inférer sur un paramètre inconnu \\(\\theta\\) par maximum de vraisemblance. Par construction, l’estimation \\(\\widehat{\\theta}\\) que l’on obtient par cette méthode est celle qui maximise la log-vraisemblance \\(\\ln L_n(X;\\theta)\\), pour une observation de \\(X\\) donnée. L’expression \\(I_n(\\theta)=-\\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2}\\ln L_n(X;\\theta)\\right)\\) montre que l’information de Fisher correspond (au signe près) à la courbure de la log-vraisemblance. Plus celle-ci est importante, plus la courbe présente un “pic” autour du maximum, et donc plus la valeur estimée de ce maximum est précise. Au contraire, si la courbure est faible, la courbe est aplatie autour du maximum, et donc l’estimation de \\(\\theta\\) sera moins précise. Dit autrement, l’information de Fisher quantifie le niveau d’information que nous apporte l’observation relativement au paramètre \\(\\theta\\). Démonstration. Etant donné que \\(\\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right)=0\\) on a \\(\\mathbb{V}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right)=\\mathbb{E}_\\theta\\left(\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta\\right)^2\\right)\\), ce qui démontre la première égalité. Pour démontrer la deuxième égalité, on dérive par rapport à \\(\\theta\\) l’égalité \\(\\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right)=0\\). Pour cela, on utilise la permutation \\(\\frac{\\partial}{\\partial\\theta}\\int=\\int\\frac{\\partial}{\\partial\\theta}\\) qui est possible car le domaine de \\(X\\) ne dépend pas de \\(\\theta\\). On obtient donc : \\[\\begin{align} 0 &amp;= \\frac{\\partial}{\\partial\\theta}\\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right) \\\\ &amp;= \\frac{\\partial}{\\partial\\theta}\\int_{\\mathbb{R}^n}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right) L_n(x;\\theta)\\,dx \\\\ &amp;=\\int_{\\mathbb{R}^n}\\frac{\\partial}{\\partial\\theta}\\left(\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right) L_n(x;\\theta)\\right)\\,dx \\\\ &amp;=\\int_{\\mathbb{R}^n}\\left(\\frac{\\partial^2}{\\partial\\theta^2}l_n(x;\\theta)\\right)L_n(x;\\theta)\\,dx+\\int_{\\mathbb{R}^n}\\frac{\\partial}{\\partial\\theta}l_n(x;\\theta)\\frac{\\partial}{\\partial\\theta}L_n(x;\\theta)\\,dx \\\\ &amp;= \\int_{\\mathbb{R}^n}\\left(\\frac{\\partial^2}{\\partial\\theta^2}l_n(x;\\theta)\\right)L_n(x;\\theta)\\,dx+\\int_{\\mathbb{R}^n}\\left(\\frac{\\partial}{\\partial\\theta}l_n(x;\\theta)\\right)^2 L_n(x;\\theta)\\,dx \\\\ &amp;= \\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2} l_n(X;\\theta)\\right)+\\mathbb{E}_{\\theta}\\left(\\left(\\frac{\\partial}{\\partial\\theta} l_n(X;\\theta)\\right)^2\\right) \\end{align}\\] d’où \\[\\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2} l_n(X;\\theta)\\right)=-\\mathbb{E}_{\\theta}\\left(\\left(\\frac{\\partial}{\\partial\\theta} l_n(X;\\theta)\\right)^2\\right)\\] ce qui achève la démonstration. \\(\\square\\) L’information de Fisher vérifie une propriété d’additivité : Théorème (additivité de l’information de Fisher) : Si l’ensemble \\(\\left\\{x\\in\\mathbb{R}^n, f(x;\\theta)&gt;0\\right\\}\\) ne dépend pas de \\(\\theta\\), alors l’information de Fisher est additive, i.e. \\[I_n(\\theta)=n\\,I_1(\\theta)\\] Si le domaine de \\(X\\) ne dépend pas de \\(\\theta\\), l’information de Fisher apportée par un échantillon \\((X_1,\\dots,X_n)\\) est donc égale à \\(n\\) fois l’information de Fisher apportée par chacune des observations \\(X_i\\). Cela signifie que chaque observation apporte la même information de Fisher. 7.1.5.2 Borne de Fréchet-Darmois-Cramer-Rao Sous certaines hypothèses, on peut montrer que la variance d’un estimateur sans biais ne peut être inférieure à une certaine borne, appelée borne de Fréchet-Darmois-Cramer-Rao, liée à l’information de Fisher : Théorème : On suppose que les hypothèses suivantes, appelées hypothèses de Cramer-Rao, sont vérifiées : (H1) : \\(\\Theta\\) est un ouvert sur lequel \\(f(x;\\theta)&gt;0\\) et \\(\\theta\\mapsto f(x;\\theta)\\) est dérivable pour tout \\(x\\) (H2) : on peut permuter \\(\\int\\) et \\(\\frac{\\partial}{\\partial\\theta}\\) (H3) : \\(\\forall\\theta\\in\\Theta, \\, I_n(\\theta)&gt;0\\) (H4) : \\(g:\\Theta\\longrightarrow\\mathbb{R}\\) est une fonction dérivable Alors, pour tout estimateur sans biais \\(T_n=T_n(X_1,\\dots, X_n)\\) de \\(g(\\theta)\\) on a l’inégalité \\[\\mathbb{V}_{\\theta}(T_n)\\geq\\frac{\\left(g&#39;(\\theta)\\right)^2}{I_n(\\theta)}\\] Le nombre \\(\\frac{\\left(g&#39;(\\theta)\\right)^2}{I_n(\\theta)}\\) s’appelle la borne de Fréchet-Darmois-Cramer-Rao (FDCR). Dans le cas particulier où \\(T_n=\\widehat{\\theta}_n\\) est un estimateur sans biais de \\(\\theta\\) (cas où \\(g(\\theta)=\\theta\\)) on a \\(\\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)\\geq\\frac{1}{I_n(\\theta)}\\). Ce théorème est admis. La borne FDCR n’est pas nécessairement atteinte. Quand elle l’est, l’estimateur qui l’atteint est dit efficace : Estimateurs efficaces Un estimateur \\(T_n\\) sans biais de \\(g(\\theta)\\) tel que \\(\\mathbb{V}_{\\theta}(T_n)=\\frac{\\left(g&#39;(\\theta)\\right)^2}{I_n(\\theta)}\\) est appelé un estimateur efficace. 7.1.5.3 Statistiques exhaustives Tout échantillon \\((X_1,\\dots, X_n)\\) tel que \\(X_i\\sim\\mathcal{L}_{\\theta}\\) apporte de l’information sur le paramètre inconnu \\(\\theta\\), et donc sur la loi inconnue \\(\\mathcal{L}_{\\theta}\\). Plutôt que de faire de l’inférence à partir de l’échantillon \\((X_1,\\dots, X_n)\\) on préfère en général utiliser une statistique \\(T_n=T(X_1,\\dots,X_n)\\), qui est une sorte de résumé de l’échantillon tout entier. La contrepartie est qu’en général, le passage de \\((X_1,\\dots,X_n)\\) à son résumé \\(T_n\\) génère une perte d’information sur \\(\\theta\\). Une statistique exhaustive est une statistique qui n’engendre pas de telle perte, autrement dit elle contient toute l’information sur \\(\\theta\\) contenue dans l’échantillon \\((X_1,\\dots, X_n)\\). On formalise cette idée de la façon suivante : Statistiques exhaustives Une statistique \\(T_n\\) est dite exhaustive si la loi conditionnelle \\(\\mathcal{L}(X|T_n=t)\\) est indépendante de \\(\\theta\\). Conditionnellement à l’observation \\(T=t\\), la loi de \\(X\\) ne dépend plus de \\(\\theta\\) : \\[\\mathbb{P}(X=x|T=t,\\theta)=\\mathbb{P}(X=x|T=t) \\text{ (pour une loi discrète)}\\] \\[f(x|T=t,\\theta)=f(x|T=t) \\text{ (pour une loi continue)}\\] Dit autrement, une fois que l’on sait que \\(T_n=t\\), ajouter la connaissance de \\(X\\) n’apporte plus aucune information supplémentaire sur \\(\\theta\\). Cette définition n’est pas très commode à manipuler, et en pratique pour démontrer qu’une statistique est (ou n’est pas) exhaustive on utilise plutôt le théorème de factorisation de Neyman-Fisher : Théorème (factorisation de Neyman-Fisher) : Une statistique \\(T_n\\) est exhaustive si, et seulement s’il existe deux fonctions mesurables positives \\(g\\) et \\(h\\) telles qu’on ait la factorisation suivante : \\[L_n(x;\\theta)=g(T_n(x);\\theta).h(x)\\] Remarques : i. La notion de mesurabilité n’est pas au programme du concours. Il s’agit d’une classe très générale de fonctions, qui englobe en particulier les fonctions continues, continues par morceaux etc. Il est même assez compliqué de construire une fonction non mesurable. En pratique : pour démontrer qu’une statistique est exhaustive, il suffit de montrer qu’une telle décomposition existe avec \\(g\\) et \\(h\\) continues (car continue implique mesurable) ; pour démontrer qu’une telle statistique n’est pas exhaustive, il suffit de démontrer qu’une telle décomposition avec \\(g\\) et \\(h\\) quelconques est impossible (elle sera en particulier impossible avec \\(g\\) et \\(h\\) mesurables). ii. Il n’y a pas unicité du couple \\((g,h)\\). Par exemple, si \\((g,h)\\) permet une factorisation, alors pour tout \\(\\lambda\\) strictement positif \\(\\left(\\lambda g, \\frac{h}{\\lambda}\\right)\\) aussi. 7.1.5.4 Famille exponentielle Les densités suivantes assurent l’existence d’une statistique exhaustive : Théorème de Darmois : Soit \\(\\theta\\in\\Theta\\subset\\mathbb{R}\\). Soit \\(f(x;\\theta)\\) une densité telle que l’ensemble \\(\\{x\\in\\mathbb{R}^n, \\, f(x;\\theta)&gt;0\\}\\) ne dépend pas de \\(\\theta\\). Alors, l’échantillon \\((X_1,\\dots,X_n)\\) admet une statistique exhaustive si et seulement si \\(f(x;\\theta)\\) est de la forme \\[f(x;\\theta)=\\exp\\left(a(x)\\alpha(\\theta)+b(x)+\\beta(\\theta)\\right)\\] Par ailleurs, si l’application \\(a\\) est de classe \\(\\mathcal{C}^1\\), alors \\(T_n\\equiv\\sum\\limits_{i=1}^n a(X_i)\\) est une statistique exhaustive. La famille des densités \\(f(x;\\theta)\\) vérifiant ces propriétés s’appelle la famille exponentielle. Remarque. Ici, on convient de parler de densité aussi bien pour une variable discrète que pour une variable continue. Pour une variable discrète, la densité est par définition \\(f(x;\\theta)\\equiv\\mathbb{P}_{\\theta}(X=x)\\). Exemple (loi de Poisson). La densité d’une loi de Poisson de paramètre \\(\\lambda\\) est \\(f(x;\\lambda)=e^{-\\lambda}\\frac{\\lambda^x}{x!}\\mathbb{1}_{x\\in\\mathbb{N}}\\). L’ensemble \\(\\left\\{x\\in\\mathbb{R},\\,f(x;\\theta)&gt;0\\right\\}\\) est \\(\\mathbb{N}\\), qui ne dépend pas de \\(\\lambda\\). Par ailleurs : \\[f(x;\\lambda)=\\exp\\left(-\\lambda+x\\,\\ln(\\lambda)-\\sum\\limits_{i=1}^x \\ln i\\right)\\] On reconnait bien la forme générale d’une densité de la famille exponentielle, avec \\(a(x)=x\\), \\(\\alpha(\\lambda)=\\ln(\\lambda)\\), \\(b(x)=\\sum\\limits_{i=1}^x \\ln i\\), \\(\\beta(\\lambda)=-\\lambda\\). L’application \\(a\\) est par ailleurs de classe \\(\\mathcal{C}^1\\). On en déduit avec le théorème de Darmois que la statistique \\(T_n=\\sum\\limits_{i=1}^n X_i\\) est une statistique exhaustive pour \\(\\theta\\). La famille exponentielle permet de construire des estimateurs efficaces. Théorème : On suppose les hypothèses de Cramer-Rao vérifiées. On suppose également que \\(\\theta\\mapsto \\frac{\\partial}{\\partial\\theta}f(x;\\theta)\\) est continue en \\(\\theta\\). Soit \\(T_n\\) un estimateur sans biais de \\(g(\\theta)\\). Alors, \\(T_n\\) est un estimateur efficace si et seulement si la densité \\(f(x;\\theta)\\) appartient à la famille exponentielle. 7.1.5.5 Rao-Blackwellisation d’un estimateur Le théorème de Rao-Blackwell montre comment améliorer un estimateur. Théorème de Rao-Blackwell : Soient \\(T_n\\) une statistique exhaustive et \\(S\\) un estimateur sans biais de \\(g(\\theta)\\). Alors, l’estimateur \\(\\mathbb{E}_{\\theta}(S|T_n)\\) est sans biais et \\(\\mathbb{V}_{\\theta}(\\mathbb{E}_{\\theta}(S|T_n))\\leq\\mathbb{V}_{\\theta}(S)\\). L’estimateur \\(\\mathbb{E}_{\\theta}(S|T_n)\\) est dit préférable à l’estimateur \\(S\\). 7.1.6 Estimation des coefficients d’une régression linéaire 7.1.6.1 Présentation du modèle \\(X\\) et \\(Y\\) sont deux variables aléatoires pour lesquelles on dispose d’observations \\(x_1,\\dots, x_n\\) et \\(y_1,\\dots y_n\\). On considère le modèle \\[Y_i=aX_i+b+u_i\\] où \\((a,b)\\) est un couple de réels inconnus et \\(u_i\\) est un terme d’erreur (inconnu lui aussi). Le but est d’estimer des coefficients \\((a,b)\\) à partir de l’échantillons d’observations \\((x_i, y_i)\\) et de donner des propriétés des estimateurs obtenus sous certaines hypothèses. Hypothèses du modèle. On fait les hypothèses suivantes : (H1) : Les couples \\((X_i, Y_i)\\) sont i.i.d. (H2) : Les termes d’erreur \\(u_i\\) sont indépendants des \\(X_i\\) (H3) : \\(\\mathbb{E}(u_i|X_i)=0\\) (hypothèse d’exogénéité) (H4) : \\(\\mathbb{V}(u_i|X_i)=\\sigma_u^2\\) ne dépend pas de \\(X_i\\) (hypothèse d’homoscédasticité) (H5) : \\(u_i|X_i\\sim\\mathcal{N}(0, \\sigma_u^2)\\) (hypothèse de normalité des termes d’erreur) On présente deux approches différentes pour estimer \\(a\\) et \\(b\\) : par la méthode des moindres carrés et par maximum de vraisemblance. Bien que différentes, ces méthodes vont fournir les mêmes estimateurs. Avant cela, on rappelle quelques résultats classiques de statistique descriptive. 7.1.6.2 Rappels utiles Avant de présenter cette méthode, on rappelle des égalités qui àa la fois très utiles et très classiques. Il faut les connaître pour le concours et savoir les redémontrer. Moyenne, covariance, variance Pour \\(x=(x_1,\\dots, x_n)\\in\\mathbb{R}^n\\) on note \\(\\overline{x}_n=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i\\) la moyenne de \\(x\\) \\(\\sigma_x^2=\\frac{1}{n}\\sum\\limits_{i=1}^n(x_i-\\overline{x}_n)^2\\) la variance de \\(x\\) si de plus \\(y=(y_1,\\dots, y_n)\\), \\(\\sigma_{xy}=\\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n)\\) est la covariance de \\(x\\) et \\(y\\). On a alors les égalités suivantes : 1. \\(\\sigma_{xx}=\\sigma_x^2\\) 2. \\(\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)=0\\) 3. Différentes formules de la covariance : \\[\\begin{align} \\sigma_{xy} &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n) \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n(x_i-\\overline{x}_n)y_i \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_i(y_i-\\overline{y}_n) \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_iy_i-\\overline{x}_n\\overline{y}_n \\end{align}\\] 4. Différentes formules de la variance : \\[\\begin{align} \\sigma_x^2 &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)^2 \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_i^2-(\\overline{x}_n)^2 \\end{align}\\] Démonstration. 1. Evidente 2. \\[\\begin{align} \\sum\\limits_{i=1}^n (x_i-\\overline{x}_n) &amp;= \\sum\\limits_{i=1}^n x_i -n\\overline{x}_n \\\\ &amp;= n\\overline{x}_n-n\\overline{x}_n \\\\ &amp; =0 \\end{align}\\] 3. \\[\\begin{align} \\sigma_{xy} &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n) \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)y_i-\\frac{\\overline{y}_n}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n) \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)y_i \\end{align}\\] d’après l’égalité 2. Par symétrie des rôles joués par \\(x\\) et \\(y\\) on a donc aussi \\(\\sigma_{xy}=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i(y_i-\\overline{y}_n)\\). On montre la dernière égalité : \\[\\begin{align} \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n) &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)y_i \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_iy_i-\\overline{x}_n\\frac{1}{n}\\sum\\limits_{i=1}^n y_i \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n x_iy_i-\\overline{x}_n\\overline{y}_n \\end{align}\\] 4. On applique la dernière égalité de 4 dans le cas particulier où \\(x=y\\). On obtient alors \\[\\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)^2=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i^2-\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n x_i\\right)^2\\] \\(\\square\\) 7.1.6.3 Estimation de \\(a\\) et \\(b\\) par la méthode des moindres carrés On montre maintenant les formules des estimateurs de \\(a\\) et \\(b\\) par application de la méthode des moindres carrés : Estimation de \\(a\\) et \\(b\\) par la méthode des moindres carrés La méthode des moindres carrés consiste à minimiser l’erreur quadratique globale \\[E(\\alpha,\\beta)\\equiv\\sum\\limits_{i=1}^n (Y_i-\\alpha X_i-\\beta)^2\\] qui représente l’erreur globale faite en approchant \\(Y_i\\) par \\(\\alpha X_i+\\beta\\). Cette méthode fournit les estimateurs suivants de \\(a\\) et \\(b\\) : \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\widehat{a} &amp;= \\frac{\\overline{\\sigma_{XY}}}{\\overline{\\sigma^2_X}} \\\\ \\widehat{b} &amp;= \\overline{Y}_n-\\widehat{a}\\overline{X}_n \\end{array} \\right. \\end{align}\\] où on note \\(\\overline{\\sigma_{XY}}=\\frac{1}{n}\\sum\\limits_{i=1}^n(X_i-\\overline{X}_n)(Y_i-\\overline{Y}_n)\\) et \\(\\overline{\\sigma^2_X}=\\overline{\\sigma_{XX}}=\\frac{1}{n}\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\). Démonstration. La fonction \\((\\alpha, \\beta)\\mapsto E(\\alpha, \\beta)\\) est deux fois dérivable par rapport à chacune de ses variables. Conditions de premier ordre (CPO) : Les conditions du premier ordre s’écrivent \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\frac{\\partial}{\\partial\\alpha} E(\\alpha, \\beta) &amp;=0 \\\\ \\frac{\\partial}{\\partial\\beta} E(\\alpha, \\beta) &amp;=0 \\\\ \\end{array} \\right. \\end{align}\\] i.e. \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\sum\\limits_{i=1}^n X_i Y_i-\\alpha\\sum\\limits_{i=1}^n X_i^2-\\beta\\sum\\limits_{i=1}^n X_i&amp;=0 \\\\ \\sum\\limits_{i=1}^n Y_i-\\alpha\\sum\\limits_{i=1}^n X_i-n\\beta &amp;= 0 \\\\ \\end{array} \\right. \\end{align}\\] Il s’agit d’un système de deux équations à deux inconnues \\((\\alpha, \\beta)\\). Sa résolution donne \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\alpha &amp;= \\frac{\\frac{1}{n}\\sum\\limits_{i=1}^n X_iY_i-\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\right)\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n Y_i\\right)}{\\frac{1}{n}\\sum\\limits_{i=1}^n X_i^2-\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\right)^2} \\\\ \\beta &amp;= \\overline{Y}_n-\\alpha\\overline{X}_n \\end{array} \\right. \\end{align}\\] soit encore \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\alpha &amp;= \\frac{\\overline{\\sigma_{XY}}}{\\overline{\\sigma^2_X}} \\\\ \\beta &amp;= \\overline{Y}_n-\\alpha\\overline{X}_n \\end{array} \\right. \\end{align}\\] Par ailleurs, pour tout couple \\((x, y)\\) de réels, la fonction \\((\\alpha, \\beta)\\mapsto (y-\\alpha x-\\beta)^2\\) est convexe. Le point critique trouvé ci-dessus est donc un minimum. On en déduit le résultat. \\(\\square\\) 7.1.6.4 Estimation de \\(a\\) et \\(b\\) par la méthode du maximum de vraisemblance La méthode par maximum de vraisemblance requiert une information supplémentaire : celle de la distribution de la variable de terme d’erreur \\(u\\). Or, une telle information est justement donnée ici par l’hypothèse (H5) de distribution normale du terme d’erreur. Estimation de \\(a\\) et \\(b\\) par la méthode du maximum de vraisemblance. Sous l’hypothèse \\((H5)\\) de distribution normale des termes d’erreur, la méthode par maximum de vraisemblance fournit les mêmes estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) que la méthode des moindres carrés. Démonstration. La vraisemblance est donnée par \\[L_n((\\alpha,\\beta);u)=\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi}\\sigma_u}e^{-\\frac{(Y_i-\\alpha X_i-\\beta)^2}{2\\sigma_u^2}}\\] On passe à la log-vraisemblance, qui est plus simple à dériver \\[l_n((\\alpha,\\beta);u)=-n\\ln(\\sqrt{2\\pi}\\sigma_u^2)-\\frac{(Y_i-\\alpha X_i-\\beta)^2}{2\\sigma_u^2}\\] On résout alors en \\((\\alpha, \\beta)\\) le système d’équations \\[\\begin{align} \\frac{\\partial l_n}{\\partial\\alpha}l((\\alpha,\\beta);u) &amp;= 0 \\\\ \\frac{\\partial l_n}{\\partial\\beta}l((\\alpha,\\beta);u) &amp;= 0 \\\\ \\end{align}\\] soit \\[\\begin{align} \\frac{X_i(Y_i-\\alpha X_i-\\beta)}{2\\sigma_u^2} &amp;= 0 \\\\ \\frac{Y_i-\\alpha X_i-\\beta}{2\\sigma_u^2} &amp;= 0 \\\\ \\end{align}\\] On vérifie facilement qu’on obtient le même couple de solution qu’avec la méthode des moindres carrés, et que ce couple constitue bien un maximum de la log-vraisemblance. \\(\\square\\) Remarque : Dans des approches plus générales que celle présentée ici, aucune hypothèse n’est faite sur la distribution des termes d’erreur. Dans ce cas, la méthode par maximum de vraisemblance n’est plus applicable. On peut cependant toujours utiliser la méthode des moindres carrés. 7.1.6.5 Absence de biais des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) Théorème : (absence de biais des estimateurs MCO) Les estimateurs \\[\\widehat{a}=\\frac{\\overline{\\sigma_{XY}}}{\\overline{\\sigma_X^2}}\\] et \\[\\widehat{b}=\\overline{Y}_n-\\widehat{a}\\overline{X}_n\\] sont des estimateurs sans biais de \\(a\\) et \\(b\\). Démonstration. On remarque d’abord qu’avec l’hypothèse d’exogénéité (H3) \\(\\mathbb{E}(u_i|X_i)=0\\) on a \\(\\mathbb{E}(Y_i|X_i)=aX_i+b\\) et donc \\(\\mathbb{E}(Y_i-\\overline{Y}_n|X_1,\\dots, X_n)=a(X_i-\\overline{X}_n)\\). D’où \\[\\begin{align} \\mathbb{E}(\\widehat{a}|X_1,\\dots, X_n) &amp;= \\mathbb{E}\\left(\\left.\\frac{\\frac{1}{n}\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)(Y_i-\\overline{Y}_n)}{\\overline{\\sigma_X^2}}\\right|X_1,\\dots, X_n\\right) \\\\ &amp;=\\frac{1}{\\overline{\\sigma_X^2}}\\frac{1}{n}\\sum\\limits_{i=1}^n(X_i-\\overline{X}_n)\\mathbb{E}(\\left. Y_i-\\overline{Y}_n\\right|X_1\\,\\dots,X_n) \\\\ &amp;= a\\frac{1}{\\overline{\\sigma_X^2}}\\frac{1}{n}\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2 \\\\ &amp; =a\\frac{\\overline{\\sigma_X^2}}{\\overline{\\sigma_X^2}} \\\\ &amp; =a \\end{align}\\] Par ailleurs \\[\\begin{align} \\mathbb{E}(\\widehat{b}|X_1,\\dots,X_n)&amp;=\\mathbb{E}(\\overline{Y}_n-\\widehat{a}\\overline{X}_n|X_1,\\dots,X_n) \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n \\mathbb{E}(Y_i|X_1,\\dots,X_n)-\\overline{X}_n\\mathbb{E}(\\widehat{a}|X_1,\\dots,X_n) \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n (aX_i+b)-a\\overline{X}_n \\\\ &amp;= a\\overline{X}_n+b-a\\overline{X}_n \\\\ &amp;= b \\end{align}\\] \\(\\square\\) 7.1.6.6 Variance des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) Théorème (variance des estimateurs MCO) Les estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) ont pour variances \\[\\begin{align} \\mathbb{V}(\\widehat{a}|X_1,\\dots, X_n) &amp;= \\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2} \\\\ \\mathbb{V}(\\widehat{b}|X_1,\\dots,X_n) &amp;=\\sigma_u^2\\left(\\frac{1}{n}+ \\frac{\\overline{X}_n^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}\\right) \\end{align}\\] Démonstration. On remarque tout d’abord que \\[\\mathbb{V}(Y_i|X_1,\\dots,X_n)=\\sigma_u^2\\] En effet \\[\\begin{align} \\mathbb{V}(Y_i|X_1,\\dots,X_n) &amp;= \\mathbb{V}(aX_i+b+u_i|X_1,\\dots, X_n) \\\\ &amp;= \\mathbb{V}(u_i|X_1,\\dots,X_n) \\\\ &amp;= \\sigma_u^2 \\end{align}\\] Le passage de la première à la deuxième ligne vient du fait qu’à \\(X_1,\\dots, X_n\\) fixées, \\(aX_i+b\\) est considérée comme une constante, et donc ce terme a une contribution à la variance conditionnellement à \\(X_1,\\dots X_n\\). On a donc \\[\\begin{align} \\mathbb{V}(\\widehat{a}|X_1,\\dots X_n) &amp;= \\mathbb{V}\\left(\\left.\\frac{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)Y_i}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}\\right|X_1,\\dots, X_n\\right) \\\\ &amp;= \\frac{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\mathbb{V}(Y_i|X_1,\\dots,X_n)}{\\left(\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\right)^2} \\\\ &amp; \\text{ (somme de VA i.i.d.)} \\\\ &amp;= \\frac{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\sigma_u^2}{\\left(\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\right)^2} \\\\ &amp;= \\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2} \\end{align}\\] et \\[\\begin{align} \\mathbb{V}(\\widehat{b}|X_1,\\dots,X_n) &amp;= \\mathbb{V}(\\overline{Y}_n-\\widehat{a}\\overline{X}_n|X_1,\\dots,X_n) \\\\ &amp;= \\mathbb{V}(a\\overline{X}_n+b+\\overline{u}_n-\\widehat{a}\\overline{X}_n|X_1,\\dots,X_n) \\\\ &amp;= \\mathbb{V}((a-\\widehat{a}\\overline{X}_n)+b+\\overline{u}_n|X_1,\\dots, X_n) \\\\ &amp;= \\overline{X}_n^2\\underbrace{\\mathbb{V}(\\widehat{a}|X_1,\\dots,X_n)}_{=\\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}}+\\underbrace{\\mathbb{V}(\\overline{u}_n|X_1,\\dots,X_n)}_{=\\frac{\\sigma_u^2}{n} \\text{ car } u_i \\text{ i.i.d. de variance } \\sigma_u^2} \\\\ &amp;= \\overline{X}_n^2\\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}+\\frac{\\sigma_u^2}{n} \\\\ &amp;= \\sigma_u^2\\left(\\frac{1}{n}+\\frac{\\overline{X}_n^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}\\right) \\end{align}\\] \\(\\square\\) 7.1.6.7 Résidus La variance \\(\\sigma_u^2\\) des termes d’erreur \\(u_i\\) n’est pas connue. Cependant, elle peut être estimée. Pour cela, on introduit la notion de résidu. Le résidu \\(\\widehat{u}_i\\) est défini comme l’écart entre la vraie valeur \\(Y_i\\) et sa prédiction \\(\\widehat{Y}_i=\\widehat{a}X_i+\\widehat{b}\\) : \\[\\widehat{u}_i\\equiv Y_i-\\widehat{Y}_i\\] On a donc \\[\\widehat{u}_i=Y_i-\\widehat{a}X_i-\\widehat{b}\\] Il s’agit d’une estimation (sans biais) de la vraie erreur \\[u_i=Y_i-aX_i-b\\] Théorème (estimation de la variance) : \\(\\sigma_u^2\\) La variance \\(\\sigma_u^2\\) est estimée par \\[s^2=\\frac{1}{n-2}\\sum\\limits_{i=1}^n \\widehat{u}_i^2\\] 7.1.6.8 Distributions des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) On admet alors le résultat suivant Théorème : Sous l’hypothèse de normalité des termes d’erreur \\(u_i\\), on a \\[\\frac{(n-2)s^2}{\\sigma_u^2}\\sim\\chi^2_{(n-2)}\\] et les statistiques \\[\\frac{\\widehat{a}-a}{s\\sqrt{\\frac{1}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}}}\\] et \\[\\frac{\\widehat{b}-b}{s\\sqrt{\\frac{1}{n}+\\frac{\\overline{X}_n^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}}}\\] suivent une loi de Student à \\(n-2\\) degrés de liberté. 7.1.6.9 Convergence des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) Si on suppose que les \\(X_i\\) admettent des moments d’ordre \\(1\\) et \\(2\\), alors on peut montrer que les estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) sont des estimateurs convergents. On sait déjà qu’ils sont sans biais, il suffit donc de démontrer que leurs variances tendent vers \\(0\\). Or, comme \\(X_i\\) admet des moments d’ordres \\(1\\) et \\(2\\) on a, conditionnellement à \\(X_1,\\dots,X_n\\) : \\[\\overline{X}_n\\approx\\mathbb{E}(X)\\] et \\[\\sum\\limits_{i=1}^n(X_i-\\overline{X}_n)^2\\approx n\\mathbb{V}(X_1)\\] On en déduit que \\[\\mathbb{V}(\\widehat{a}|X_1,\\dots, X_n)\\approx\\frac{\\sigma_u^2}{n\\mathbb{V}(X_1)}\\longrightarrow 0\\] et \\[\\mathbb{V}(\\widehat{b}|X_1,\\dots,X_n)\\approx\\sigma_u^2\\left(\\frac{1}{n}+\\frac{\\overline{X}_n^2}{n\\mathbb{V}(X_1)}\\right)\\longrightarrow 0\\] \\(\\widehat{a}\\) et \\(\\widehat{b}\\) sont des estimateurs sans biais de \\(a\\) et \\(b\\) de variances asymptotiquement nulles. Ce sont donc des estimateurs convergents de \\(a\\) et \\(b\\). 7.1.7 Intervalles de confiance Jusqu’à présent, l’estimation était uniquement envisagée du point de vue de l’estimation ponctuelle : il s’agissait, à partir de l’observation d’un échantillon \\((X_1,\\dots,X_n)\\) de fournir une valeur ponctuelle \\(\\widehat{\\theta}_n\\) approchant la vraie valeur inconnue d’un paramètre \\(\\theta\\). Cependant, la valeur estimée dépend de l’échantillon tiré. En effet, si l’on tire \\(1,000\\) échantillons différents, on va obtenir \\(1\\,000\\) estimations \\(\\widehat{\\theta}^{(1)}_n,\\dots,\\widehat{\\theta}^{(1\\,000)}_n\\) a priori différentes également. Certaines de ces estimations peuvent être des valeurs atypiques. Se pose donc la question de la confiance que l’on peut accorder à l’estimation obtenue à partir d’une seule réalisation particulière \\((x_1,\\dots,x_n)\\) de l’échantillon, puisqu’en pratique c’est tout ce dont on dispose pour inférer sur \\(\\theta\\). L’approche présentée jusqu’ici ne répond pas à cette question. Le bon outil pour aborder ce problème est la notion d’intervalle de confiance. Intervalles de confiance Soit \\(\\theta\\) un paramètre inconnu et \\(\\alpha\\) un réel compris entre \\(0\\) et \\(1\\). On appelle intervalle de confiance de niveau \\(1-\\alpha\\) du paramètre \\(\\theta\\) tout intervalle \\([a;b]\\) tel que \\[\\mathbb{P}\\left(\\theta\\in [a;b]\\, \\right)=1-\\alpha\\] Remarques : i. Les réels \\(a\\) et \\(b\\) dépendent de \\(\\theta\\), du niveau de confiance \\(1-\\alpha\\). En pratique, pour les déterminer on utilise l’échantillon \\((X_1,\\dots, X_n)\\), ou plus précisément un résumé \\(T_n\\) de cet échantillon, i.e. une statistique \\(T_n=T_n(X_1,\\dots,X_n)\\). On a donc \\[\\begin{align} a &amp;= a_n(T_n\\,;\\,\\theta\\,;\\,\\alpha) \\\\ b &amp;= b_n(T_n\\,;\\,\\theta\\,;\\,\\alpha) \\\\ \\end{align}\\] Ce sont donc des variables aléatoires, que l’on notera désormais plus simplement \\(a_n\\) et \\(b_n\\). L’intervalle de confiance est donc lui-même un objet aléatoire. ii. Idéalement, on aimerait savoir avec certitude que \\(\\theta\\in [a,b]\\). Comme les réels \\(a\\) et \\(b\\) dépendent de l’échantillon tiré, on ne peut espérer mieux qu’une probabilité d’appartenance de \\(\\theta\\) à \\([a,b]\\). A défaut qu’elle soit égale à 1, on la veut proche de \\(1\\), autrement dit on veut \\(\\alpha\\) proche de \\(0\\). En pratique, on prendra souvent \\(\\alpha=0,05\\), parfois \\(\\alpha=0,01\\). iii. Le réel \\(\\alpha\\) représente un risque : celui de donner un intervalle de confiance qui ne contienne pas la vraie valeur de \\(\\theta\\). iv. Réduire la valeur de \\(\\alpha\\) n’est pas gratuit. Le prix à payer est un élargissement de l’intervalle de confiance \\([a,b]\\), ce qui signifie des intervalles de confiance moins fins et donc moins informatifs sur la vraie valeur de \\(\\theta\\). Inversement, si on veut des intervalles de confiance plus fins, il faut assumer un risque plus grand d’avoir un intervalle de confiance laissant échapper le vrai \\(\\theta\\). On voit maintenant une méthode générale de construction de \\([a_n\\,;\\,b_n]\\). Construction d’un intervalle de confiance On cherche un couple de réels \\((a_n,b_n)\\) tel que \\[\\mathbb{P}\\left(a_n\\leq \\theta\\leq b_n\\right)=1-\\alpha\\] On suppose qu’on dispose d’une statistique \\(T_n\\) à partir de laquelle on calcule ces réels : \\[\\begin{align} a_n &amp;= a_n(T_n) \\\\ b_n &amp;= b_n(T_n) \\end{align}\\] On cherche alors à transformer l’écriture \\(\\theta\\in[a_n(T_n)\\,;\\,b_n(T_n)]\\) en une écriture équivalente du type \\(T_n\\in[\\alpha_n(\\theta)\\,;\\,\\beta_n(\\theta)]\\), autrement dit on veut \\[\\theta\\in[a_n(T_n)\\,;\\,b_n(T_n)]\\Leftrightarrow T_n\\in[\\alpha_n(\\theta)\\,;\\,\\beta_n(\\theta)]\\] Dans ce cas, on doit avoir \\[\\mathbb{P}\\left(T_n\\in[\\alpha_n(\\theta)\\,;\\,\\beta_n(\\theta)]\\right)=1-\\alpha\\] Il s’agit donc de trouver un couple de réels \\((\\alpha_n,\\beta_n)=(\\alpha_n(\\theta),\\beta_n(\\theta))\\) tel que \\[F_{T_n}(\\beta_n)-F_{T_n}(\\alpha_n)=1-\\alpha\\] ou, de façon équivalente \\[\\mathbb{P}(T_n&lt;\\alpha_n)+\\mathbb{P}(T_n&gt;\\beta_n)=\\alpha\\] Remarque. La dernière égalité s’interprète comme un risque à répartir entre \\(\\mathbb{P}(T_n&lt;\\alpha_n)\\) et \\(\\mathbb{P}(T_n&gt;\\alpha_n)\\). Une première approche pour construire des intervalles de confiance consiste à utiliser, lorsque cela est possible, l’inégalité de Bienaymé-Tchebychev : Construction d’intervalles de confiance par application de l’inégalité de Bienaymé-Tchebychev Soit \\(\\widehat{\\theta}_n\\) un estimateur sans biais de \\(\\theta\\) et admettant une variance \\(\\sigma^2\\) que l’on suppose connue. On peut donc appliquer l’inégalité de Bienaymé-Tchebychev : \\[\\mathbb{P}\\left(|\\widehat{\\theta}_n-\\theta|\\geq\\varepsilon\\right)\\leq\\frac{\\sigma^2}{\\varepsilon^2}\\] soit \\[\\mathbb{P}\\left(|\\widehat{\\theta}_n-\\theta|&lt;\\varepsilon \\right)&gt;1-\\frac{\\sigma^2}{\\varepsilon^2}\\] On choisit \\(\\varepsilon\\) de façon à avoir \\(\\alpha=\\frac{\\sigma^2}{\\varepsilon^2}\\), i.e. on pose \\[\\varepsilon=\\frac{\\sigma}{\\sqrt{\\alpha}}\\] Par inversion des inégalités on a \\(|\\widehat{\\theta}_n-\\theta|&lt;\\varepsilon\\Leftrightarrow\\widehat{\\theta}_n-\\varepsilon&lt;\\theta&lt;\\widehat{\\theta}_n+\\varepsilon\\). On en déduit un intervalle de confiance de \\(\\theta\\) au niveau de confiance \\(1-\\alpha\\) : \\[IC^{1-\\alpha}_m=\\left[\\widehat{\\theta}_n-\\frac{\\sigma}{\\sqrt{\\alpha}}\\,;\\,\\widehat{\\theta}_n+\\frac{\\sigma}{\\sqrt{\\alpha}}\\right]\\] Cet intervalle de confiance est bien calculable en pratique puisqu’on a supposé \\(\\sigma^2\\) connue. Exemple (moyenne empirique). Soient \\(X\\) une VA admettant une espérance \\(m\\) et une variance \\(\\sigma^2\\), et \\((X_1,\\dots, X_n)\\) des VA i.i.d. de même loi que \\(X\\). La moyenne empirique \\(\\widehat{\\theta}_n\\equiv\\overline{X}_n\\) est un estimateur sans biais de \\(\\theta\\equiv m\\) et admettant comme variance \\(\\frac{\\sigma^2}{n}\\), on peut donc appliquer ce qui précède et obtenir un intervalle de confiance de \\(m\\) au niveau de confiance \\(1-\\alpha\\) : \\[IC^{1-\\alpha}_m=\\left[\\overline{X}_n-\\frac{\\sigma}{\\sqrt{n\\alpha}}\\,;\\,\\overline{X}_n+\\frac{\\sigma}{\\sqrt{n\\alpha}}\\right]\\] Pour le concours d’administrateur, il est précisé que la construction d’intervalle de confiances est abordée dans un contexte d’application du théorème central limite (Construction d’un intervalle de confiance dans le cadre des modèles d’échantillonnage, dans le cas où le théorème central limite s’applique.). En d’autres termes, il s’agit de se ramener - si l’on n’y est pas déjà - au cas d’une loi normale et d’en déduire un intervalle de confiance (asymptotique). On commence par considérer le cas où la statistique \\(T_n\\) est gaussienne. Construction d’intervalles de confiance dans le cas gaussien Supposons que \\(X\\) suive une loi normale : \\[X\\sim\\mathcal{N}(m,\\sigma^2)\\] Exemple : estimation de \\(m\\) lorsque \\(\\sigma\\) est connu. \\(m\\) est l’espérance de \\(X\\), on peut l’estimer par la moyenne empirique \\[\\overline{X}_n\\sim\\mathcal{N}\\left(m\\,;\\,\\frac{\\sigma^2}{n}\\right)\\] on commence par centrer et réduire \\(\\overline{X}_n\\) pour se ramener à une loi normale standard \\(\\mathcal{N}(0,1)\\). On pose donc \\[Z_n\\equiv\\frac{\\overline{X}_n-m}{\\frac{\\sigma}{\\sqrt{n}}}\\] on cherche ensuite un intervalle \\([-v,v]\\) de niveau de confiance \\(1-\\alpha\\) pour \\(Z_n\\). Comme \\(Z_n\\) est symétrique par rapport à \\(0\\), il est plus simple de le chercher sous la forme \\([-v,v]\\). On résout donc, en notant \\(\\Phi\\) la fonction de répartition d’un loi normale standard et en remarquant que \\(\\Phi(-x)=1-\\Phi(x)\\) : \\[\\begin{align} \\Phi(v)-\\Phi(-v) &amp;= 1-\\alpha \\\\ 2\\Phi(v)-1 &amp;= 1-\\alpha \\\\ \\Phi(v) &amp;= 1-\\frac{\\alpha}{2} \\\\ v &amp;= \\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right) \\end{align}\\] on en déduit un intervalle de confiance de niveau \\(1-\\alpha\\) pour \\(m\\) : \\[\\begin{align} &amp; -v\\leq Z_n \\leq v \\\\ \\text{ssi } &amp; -v\\leq\\frac{\\overline{X}_n-m}{\\frac{\\sigma}{\\sqrt{n}}}\\leq n \\\\ \\text{ssi } &amp; \\overline{X}_n-\\frac{\\sigma}{\\sqrt{n}}v\\leq m\\leq \\overline{X}_n+\\frac{\\sigma}{\\sqrt{n}}v &amp; \\\\ \\end{align}\\] Un intervalle de confiance de \\(m\\) au niveau \\(1-\\alpha\\) est donc \\[\\text{IC}^m_{1-\\alpha}\\equiv\\left[\\overline{X}_n-\\frac{\\sigma}{\\sqrt{n}}\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right) \\, , \\, \\overline{X}_n+\\frac{\\sigma}{\\sqrt{n}}\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right]\\] On peut calculer cet intervalle de confiance à partir de l’échantillon pusiqu’on a supposé \\(\\sigma\\) connu. On considère maintenant un cas où la stastistique n’est plus gaussienne, mais où il est possible d’appliquer le théorème central-limite, et donc se ramener à une loi approximativement gaussienne. Dans ce cas, peut obtenir des intervalles de confiance asymptotiques : Construction d’intervalles de confiance asymptotiques dans un cas d’application du TCL On suppose que \\(X\\) suit une loi normale centrée : \\[X_n\\sim\\mathcal{N}(0,\\sigma^2)\\] Exemple : estimation de \\(\\sigma\\). On considère la statistique \\[D_n\\equiv\\frac{1}{n}\\sum\\limits_{i=1}^n |X_i|\\] On vérifie facilement que l’intégrale \\(\\int_{\\mathbb{R}} |x|\\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{x^2}{2\\sigma^2}}\\,dx\\) est convergente et vaut \\(\\sqrt{\\frac{2}{\\pi}}\\sigma\\). Ainsi, la variable aléatoire \\(|X|\\) admet une espérance et \\[\\mathbb{E}(|X|)=\\sqrt{\\frac{2}{\\pi}}\\,\\sigma\\] On en déduit un estimateur sans biais de \\(\\sigma\\) : \\[T_n\\equiv\\sqrt{\\frac{\\pi}{2}}\\,D_n\\] Avec la loi faible des grands nombres, \\(T_n\\) est un estimateur convergent de \\(\\sigma\\). Par ailleurs, \\(|X|\\) admet un moment d’ordre \\(2\\) (\\(\\mathbb{E}(|X|^2)=\\mathbb{E}(X^2)=\\sigma^2\\)) et \\[\\begin{align} \\mathbb{V}(|X|) &amp;= \\mathbb{E}(X^2)-(\\mathbb{E}(|X|))^2 \\\\ &amp;= \\left(1-\\frac{2}{\\pi}\\right)\\sigma^2 \\end{align}\\] On en déduit que \\(T_n\\) admet une variance et que \\[\\mathbb{V}(T_n)=\\left(\\frac{\\pi}{2}-1\\right)\\frac{\\sigma^2}{n}\\] Avec le théorème central limite on a l’approximation en loi \\[\\frac{T_n-\\sigma}{\\frac{\\sigma}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\approx\\mathcal{N}(0,1)\\] En posant \\(u_{\\alpha}=\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\), avec toujours \\(\\Phi\\) la fonction de répartition de la loi normale standard, on a donc \\[\\mathbb{P}\\left(-u_{\\alpha}\\leq\\sqrt{n}\\frac{T_n-\\sigma}{\\sigma\\sqrt{\\frac{\\pi}{2}-1}}\\leq u_{\\alpha}\\right)\\approx 1-\\alpha\\] Or \\[-u_{\\alpha}\\leq\\sqrt{n}\\frac{T_n-\\sigma}{\\sigma\\sqrt{\\frac{\\pi}{2}-1}}\\leq u_{\\alpha}\\Leftrightarrow \\frac{T_n}{1+\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\leq\\sigma\\leq\\frac{T_n}{1-\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\] On en déduit un intervalle de confiance asymptotique de \\(\\sigma\\) au niveau de confiance \\(1-\\alpha\\) : \\[\\text{IC}^{1-\\alpha}_{\\sigma}\\equiv\\left[\\frac{T_n}{1+\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\, ;\\, \\frac{T_n}{1-\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\right]\\] 7.2 Tests statistiques 7.2.1 Définition et principes On s’intéresse à un phénomène réel que l’on modélise par une variable aléatoire \\(X\\) dont la loi est modélisée statistiquement par une famille paramétrique de distributions \\(\\{P_{\\theta}, \\theta\\in\\Theta\\}\\). On suppose que l’espace \\(\\Theta\\) de tous les paramètres possibles est partitionné en deux sous-ensembles \\(\\Theta_0\\) et \\(\\Theta_1\\). On note \\(\\theta\\) la vraie valeur associée à la loi de \\(X\\). On considère alors les deux hypothèses suivantes : \\[(H_0):\\,\\theta\\in\\Theta_0\\] \\[(H_1):\\,\\theta\\in\\Theta_1\\] L’hypothèse \\((H_0)\\) s’appelle l’hypothèse nulle alors que l’hypothèse \\((H_1)\\) s’appelle l’hypothèse alternative. Construire un test revient à construire une partition de \\(\\mathbb{R}^n\\) : \\[\\mathbb{R}^n=W\\cup\\overline{W}\\] tel que, pour toute réalisation \\((x_1,\\dots,x_n)\\) d’un échantillon aléatoire \\((X_1,\\dots,X_n)\\) de variables aléatoires i.i.d. \\(X_i\\) de loi \\(P_{\\theta}\\), on suive la règle de décision suivante : \\[\\hbox{Si } (x_1,\\dots, x_n)\\in W \\hbox{ alors on rejette l&#39;hypothèse nulle } (H_0)\\] \\[\\hbox{Si } (x_1,\\dots, x_n)\\in \\overline{W} \\hbox{ alors on ne rejette pas l&#39;hypothèse nulle } (H_0)\\] La partie \\(W\\) s’appelle la région de rejet de \\((H_0)\\), ou encore la région critique. La partie \\(\\overline{W}\\) s’appelle la région d’acceptation de l’hypothèse nulle \\((H_0)\\). Construire un test, c’est donc décider d’une partition particulière \\((W, \\overline{W})\\) de \\(\\mathbb{R}^n\\). Les tests constituent un outil d’aide à la décision. On en présente ici une méthodlogie générale : Méthodologie des tests d’hypothèse On suit généralement les étapes suivantes : on définit l’hypothèse nulle \\((H_0)\\) et l’hypothèse alternative \\((H_1)\\) ; on choisit une statistique de test \\(T=T(X_1,\\dots, X_n)\\) ; on détermine la distribution de \\(T\\) sous l’hypothèse nulle \\((H_0)\\) ; on choisit un niveau de significativité \\(\\alpha\\) du test, et on calcule, à partir de la distibution de \\(T\\) obtenue à l’étape précédente, la région de rejet de \\((H_0)\\) ; on calcule, à partir des données observées \\((x_1,\\dots x_n)\\) (qui constituent une réalisation de l’échantillon aléatoire \\((X_1,\\dots, X_n)\\)) la valeur \\(T(x_1,\\dots, x_n)\\) prise par \\(T\\) ; à partir de cette dernière valeur et de la région de rejet, on prend une décision. Cette méthodologie correspond en gros à un raisonnement par l’absurde probabiliste. En effet, dans un raisonnement par l’absurde classique : on veut démontrer une certaine affirmation \\(A\\) ; sous l’hypothèse contraire \\(\\overline{A}\\), on en déduit quelque chose que l’on sait faux ; on conclut que notre hypothèse de départ \\(\\overline{A}\\) est fausse, i.e. on rejette \\(\\overline{A}\\), ou, de façon équivalente, on conclut que \\(A\\) est vraie. Lorsqu’on fait un test : on définit une hypothèse nulle \\((H_0)\\), qui est l’hypothèse que l’on aimerait pouvoir rejeter ; on calcule la distribution de \\(T\\) et on calcule par ailleurs la valeur \\(T(x_1,\\dots, x_n)\\) ; si la probabilité sous l’hypothèse nulle que \\(T\\) prenne cette valeur est très faible, i.e. en dessous d’un certain seuil (le seuil standard étant 5 %), on rejette l’hypothèse nulle. Si en revanche cette probabilité est au-dessus de ce seuil, on ne rejette pas l’hypothèse nulle. Remarques. i En résumé, on suit donc le principe suivant : je suppose \\((H_0)\\) vraie, j’arrive à un résultat très improbable, je conclus que \\((H_0)\\) est fausse. ii. A la différence d’un raisonnement par l’absurde classique, cette conclusion peut toutefois être erronée. Autrement dit, il est possible de rejeter à tort \\((H_0)\\). Toutefois, ce risque de rejet à tort est maitrisable : il s’agit du seuil de significativité \\(\\alpha=\\mathbb{P}(\\hbox{on rejette } H_0\\,|\\, H_0)\\). Donc, si on choisit \\(\\alpha\\) petit, ce risque -appelé risque de première espèce- sera très limité. iii. Lorsqu’on tente de faire un raisonnement par l’absurde, mais qu’on ne parvient pas à aboutir à une contradiction, il est incorrect de conclure que l’hypothèse initiale est vraie. Notre raisonnement ne nous a juste pas permis de conclure qu’elle était fausse… ce qui ne signifie pas qu’elle est vraie. Dans un tel cas, on ne peut tout simplement rien conclure. De manière analogue, si la probabilité calculée dans un test est au-dessus du seuil de significativité, il serait incorrect d’accepter l’hypothèse nulle. Même si on trouve parfois l’expression accepter \\((H_0)\\) dans la littérature, il s’agit d’un abus de langage et on lui préfèrera l’expression ne pas rejeter \\((H_0)\\). Cela ne signifie pas que \\((H_1)\\) est probablement vraie, mais plutôt que notre test ne nous a pas permis de conclure que \\((H_0)\\) était probablement fausse, ce qui est assez différent. iv. De la même façon que l’on peut rejeter à tort l’hypothèse nulle \\((H_0)\\), il est possible de ne pas rejeter à tort \\((H_0)\\). La probabilité d’un tel événement est \\(\\mathbb{P}(\\hbox{ne pas rejeter } H_0\\,|\\, H_1)\\). Cette probabilité s’appelle le risque de deuxième espèce. v. Tout test présente une dyssymétrie dans sa façon de traiter \\((H_0)\\) et \\((H_1)\\). Parmi les deux types d’erreurs que l’on peut commettre dans la conclusion d’un test, il y en a généralement l’une des deux que l’on veut éviter en priorité. Par exemple, un test médical peut amener deux types d’erreurs : les faux positifs et les faux négatifs. On préfère en général avoir des tests pour lesquels la probabilité de faux négatif est faible, car conclure que le patient n’est pas malade (et donc ne pas le traiter) alors qu’il l’est est en général plus ennuyeux que conclure qu’il est malade (et donc le traiter) alors qu’il ne l’est pas. On retient le plus souvent la convention suivante : l’erreur de première espèce est celle que l’on veut éviter, on veut donc maitriser le risque de première espèce \\(\\alpha=\\mathbb{P}(\\hbox{rejeter } H_0\\,|\\,H_0)\\). On choisit un \\(\\alpha\\) petit et on en déduit une région de rejet \\(W=W_{\\alpha}\\). La valeur \\(\\beta=\\mathbb{P}(\\hbox{ne pas rejeter } H_0\\,|\\, H_1)\\) dépend alors du choix de \\(\\alpha\\), on ne la contrôle pas. 7.2.2 Tests unilatéraux, tests bilatéraux On note \\(\\theta\\) le paramètre inconnu associé à la loi de \\(X\\). Test bilatéral Un test bilatéral est un test dont les hypothèses nulle \\((H_0)\\) et alternative \\((H_1)\\) sont de la forme \\[(H_0):\\,\\theta=\\theta_0\\] \\[(H_1):\\,\\theta\\neq\\theta_0\\] Exemple : tester si une pièce est équilibrée. On veut s’assurer qu’une pièce est équilibrée en utilisant un test statistique. On note \\(p\\) sa probabilité de tomber sur pile. La pièce est équilibrée si et seulement si \\(p=\\frac{1}{2}\\). On définit alors le test suivant : \\[(H_0):\\,p=\\frac{1}{2}\\] \\[(H_1):\\, p\\neq\\frac{1}{2}\\] Il s’agit d’un test bilatéral. De même, il existe des tests unilatéraux : Test unilatéral Un test unilatéral est un test dont les hypothèses nulle \\((H_0)\\) et alternative \\((H_1)\\) sont soit de la forme \\[(H_0):\\,\\theta=\\theta_0\\] \\[(H_1):\\,\\theta&gt;\\theta_0\\] soit de la forme \\[(H_0):\\,\\theta=\\theta_0\\] \\[(H_1):\\,\\theta&lt;\\theta_0\\] Un test unilatéral suppose donc connu le signe de la différence \\(\\theta-\\theta_0\\), contrairement à un test bilatéral. Exemple : tester l’efficacité d’un médicament. Le fabricant d’un médicament annonce une efficacité à \\(90/,/%\\) pour l’un de ses produits. Sur un échantillon de 200 personnes, ce médicament a fonctionné pour 160 personnes. On souhaite déterminer si l’afformation du fabrication est exacte au seuil de significativité \\(\\alpha=1\\,\\%\\). On va ici prendre pour hypothèses \\[(H_0):\\,p=0,9\\] \\[(H_1):\\,p&lt;0,9\\] où \\(p\\) est la probabilité que le médicament soit efficace. Il s’agit d’un test unilatéral gauche. 7.2.3 Exemples On reprend les deux exemples précédents. Exemple 1 : tester si une pièce est équilibrée. On effectue \\(n=1\\,000\\) lancers de cette pièce. Sur ces \\(10\\,000\\) lancers, la pièce est tombée \\(4\\,880\\) fois sur pile. On veut déterminer si cette pièce est équilirée au seuil de significativité \\(\\alpha = 5\\,\\%\\). Pour \\(1\\leq i\\leq n\\), on note \\(X_i\\in\\{0,1\\}\\) la variable aléatoire qui prend la valeur \\(1\\) si la pièce est tombée sur pile au lancer numéro \\(i\\), qui prend la valeur \\(0\\) si elle est tombée sur face. Les variables aléatoires \\(X_1,\\dots,X_n\\) sont i.i.d. de loi de Bernoulli \\(\\mathcal{B}(p)\\) où \\(p\\) est la probabilité que la pièce tombe sur pile : \\(p=\\mathbb{P}(X_i=1)\\). La variable aléatoire \\(S_n\\equiv\\sum\\limits_{i=1}^n X_i\\) suit une loi binomiale \\(\\mathcal{B}(n, p)\\). On rappelle l’énoncé du théorème de Moivre-Laplace, qui n’est qu’un cas particulier du théorème central limite : Théorème de Moivre-Laplace. Si la variable aléatoire \\(X_n\\) suit une loi binomiale \\[X_n\\sim\\mathcal{B}(n, \\,p)\\] alors la variable aléatoire \\[Z_n\\equiv\\frac{X_n-np}{\\sqrt{np(1-p)}}\\] converge en loi vers la loi normale standard \\(\\mathcal{N}(0,1)\\). En pratique, dès lors que les conditions suivantes sont vérifiées : \\(n\\geq 30\\) \\(np\\geq 5\\) \\(n(1-p)\\geq 5\\)$ on peut écrire l’approximation en loi \\[Z_n\\equiv\\frac{X_n-np}{\\sqrt{np(1-p)}}\\approx\\mathcal{N}(0,1)\\] Sous l’hypothèse nulle \\((H_0):\\,p=\\frac{1}{2}\\), on a \\[S_n\\sim\\mathcal{B}\\left(n, \\frac{1}{2}\\right)\\] Les trois conditions à vérifier sont bien satisfaites : \\(n=10\\,000\\geq 30\\) \\(np=5\\,000\\geq 5\\) \\(n(1-p)=5\\,000\\geq 5\\) si bien que \\[Z_n\\equiv\\frac{S_n-np}{\\sqrt{np(1-p)}}\\approx\\mathcal{N}(0,1)\\] i.e. \\[Z_n\\equiv\\frac{S_n-5\\,000}{50}\\approx\\mathcal{N}(0,1)\\] La variable aléatoire \\(Z_n\\) est notre statistique de test. On vient de déterminer sa loi, on peut donc en déduire la zone de rejet de notre test. Pour une loi normale standard \\(Z_n\\), on a \\[\\mathbb{P}\\left(-1,96\\leq Z_n\\leq 1,96\\right)\\approx 0,95\\] La région d’acceptation du test au seuil de significativité \\(\\alpha=5\\,\\%\\) est donc \\(\\overline{W}=[-1,96\\,;\\,1,96]\\) et son complémentaire \\(W=]-\\infty\\;\\,-1,96[\\cup]1,96\\,;\\,+\\infty[\\) est donc la région de rejet. On applique donc la règle de décision suivante : \\[\\hbox{Si } z_n\\not\\in \\overline{W}=[-1,96\\,;\\,1,96] \\hbox{ on rejette l&#39;hypothèse nulle} (H_0)\\] \\[\\hbox{Si } z_n\\in\\overline{W}=[-1,96\\,;\\,1,96] \\hbox{ on ne rejette pas l&#39;hypothèse nulle} (H_0)\\] Or, la valeur observée de \\(Z_n\\) sur l’échantillon tiré est \\(z_n=\\frac{4\\,880-5\\,000}{50}=-2,4\\). Elle appartient à la région de rejet. Conclusion. Au seuil de significativité \\(5\\,\\%\\) on rejette donc l’hypothèse nulle, ce qui revient à dire qu’on conclut que la pièce est désiquilibrée. Remarque. Si on avait obtenu \\(4\\,920\\) fois pile sur nos \\(5\\,000\\) tirages, on aurait calculé \\(z_n=-1,6\\) qui est dans la zone d’acceptation. On n’aurait donc pas rejeté l’hypothèse nulle, autrement dit on n’aurait pas rejeté l’hypothèse d’une pièce équilibrée. Exemple 2 : tester l’efficacité d’un médicament. Pour \\(i\\) compris entre \\(1\\) et \\(200\\), on pose \\(X_i=1\\) si le médicament a été efficace pour l’individu numéro \\(i\\), et \\(X_i=0\\) dans le cas contraire. Comme dans l’exemple 1, sous l’hypothèse nulle \\((H_0):\\,p=0,9\\) les \\(X_i\\) sont i.i.d. et suivent une loi de Benoulli, de paramètre \\(p\\). On en déduit que leur somme \\(S_n=\\sum\\limits_{i=1}^{200}X_i\\) suit une loi binomiale de paramètre \\(np=180\\). On a \\(n=200\\geq 30\\) \\(np=180\\geq 5\\) \\(n(1-p)=20\\geq 5\\) On a donc \\[Z_n\\equiv\\frac{S_n-180}{\\sqrt{18}}\\approx\\mathcal{N}(0,1)\\] Il s’agit de notre statistique de test. Sur l’échantillon observé, elle prend comme valeur \\[z_n=\\frac{160-180}{\\sqrt{0.5}}\\approx -4,71\\] La région de rejet est \\(W=]-\\infty, t]\\) avec \\(t\\) l’unique réel tel que \\(\\mathbb{P}(Z_n\\leq t)=0,01\\). Grâce à la table de la loi normale standard, on obtient \\(t\\approx -2,33\\), donc \\(W=]-\\infty\\,;\\,-2,33]\\). Ainsi, \\(z_n\\) est dans la région de rejet. On rejette donc l’hypothèse nulle : l’affirmation du fabricant est fausse au seuil de significativité \\(1\\,\\%\\). "],["méthodologie.html", "Chapitre 8 Méthodologie 8.1 Convergence", " Chapitre 8 Méthodologie Le but de cette partie est de recenser des méthodes qui reviennent fréquemment dans les sujets de concours. La liste n’est pas exhaustive, mais l’idée est surtout de construire (progressivement) une boite à outils qui devrait être utile autant pour les écrits que les oraux. 8.1 Convergence Les sujets du concours d’administrateur regorgent de questions sur la convergence en loi et la convergence en probabilité. Les techniques qui reviennent souvent sont les suivantes : Comment démontrer la convergence en loi d’une suite de variables aléatoires ? Méthode 1 : revenir à la définition Si on montre que pour toute fonction \\(\\phi\\) continue et bornée \\[\\lim\\limits_{n\\to +\\infty}\\mathbb{E}(\\phi(X_n))\\underset{n\\to +\\infty}\\longrightarrow\\mathbb{E}(\\phi(X))\\] on peut alors conclure que \\[X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}\\longrightarrow} X\\] Méthode 2 : utiliser la fonction de répartition On considère la fonction de répartition \\(F_n\\) de \\(X_n\\). Si on peut montrer que \\(\\lim\\limits_{n\\to +\\infty}F_n(x) = F(x)\\) en tout point où \\(F\\) est continue, et que \\(F\\) est une fonction de répartition (éventuellement la fonction de répartition d’une loi usuelle), alors on peut conclure que \\((X_n)_n\\) converge en loi vers la loi associée à cette fonction de répartition. Exemple. On suppose que \\(X_n\\) suit une loi uniforme sur \\(\\left\\{\\frac{1}{n},\\dots,\\frac{n-1}{n}, 1\\right\\}\\) et on veut montrer que \\((X_n)_n\\) converge en loi vers la loi uniforme \\(\\mathcal{U}([0\\,,\\,1])\\). Soit \\(x\\in [0\\,;\\,1]\\). Il existe un unique entier naturel \\(k\\in [0\\,;\\,n]\\) tel que \\(\\frac{k}{n}\\leq x &lt;\\frac{k+1}{n}\\). Cet encadrement s’écrit aussi \\(nx-1 &lt;k\\leq nx\\), i.e. \\(nx\\leq k &lt;nx+1\\). On en déduit que \\(k=\\lfloor nx\\rfloor\\). Comme \\(X_n\\) est entier, on a donc \\[X_n\\leq x \\Leftrightarrow X_n\\leq\\frac{\\lfloor nx \\rfloor}{n}\\] et donc \\(F_{X_n}(x)=F_{X_n}\\left(\\frac{\\lfloor nx \\rfloor}{n}\\right)=\\frac{\\lfloor nx\\rfloor}{n}\\). On en déduit que \\[x\\leq F_{X_n}(x)&lt;x+\\frac{1}{n}\\] et donc \\[\\lim\\limits_{n\\to +\\infty} F_{X_n}(x)=x\\] Or, la fonction \\(F\\) définie par \\(F(x)=x\\) est la fonction de répartition de la loi uniforme sur \\(\\mathcal{U}([0\\,;\\,1])\\). On a donc finalement \\[X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}\\longrightarrow}\\mathcal{U}([0\\,;\\,1])\\] Méthode 3 : utiliser le théorème central limite C’est le résultat auquel il faut penser lorsqu’on voit une somme \\(S_n\\equiv\\sum\\limits_{i=1}^n X_i\\) de variables aléatoires i.i.d. Pour pouvoir l’appliquer, les \\(X_i\\) doivent admettre une espérance \\(\\mu\\) et une variance \\(\\sigma^2&gt;0\\). La version centrée-réduite de \\(S_n\\) converge alors en loi vers la loi normale standard \\(\\mathcal{N}(0,1)\\) : \\[\\frac{S_n-n\\mu}{n\\,\\sigma}\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\mathcal{N}(0\\,;1)\\] De façon équivalente, on a aussi \\[\\sqrt{n}\\,\\frac{\\overline{X_n}-\\mu}{\\sigma}\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\mathcal{N}(0\\,;1)\\] ou encore \\[\\sqrt{n}\\left(\\overline{X_n}-\\mu\\right)\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\mathcal{N}(0\\,;\\sigma^2)\\] Exemple. Soit \\((X_n)_n\\) une suite de variables aléatoires i.i.d. de loi \\(\\mathcal{E}(b)\\). On pose \\[Z_n\\equiv\\sqrt{n}\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n X_i-\\frac{1}{b}\\right)\\] et on nous demande de démontrer que \\((Z_n)_n\\) converge en loi, et de déterminer sa limite. On reconnaît une expression du type \\(\\sqrt{n}(\\overline{X}_n-\\mu)\\), qui doit activer l’automatisme utilisation du TCL… On a en effet \\(\\mathbb{E}(X_n)=\\frac{1}{b}\\) et \\(\\mathbb{V}(X_n)=\\frac{1}{b^2}\\) avec des variables \\(X_i\\) i.i.d., et donc le théorème central limite permet d’écrire \\[Z_n=\\sqrt{n}\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n X_i-\\frac{1}{b}\\right)\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\mathcal{N}\\left(0\\,;\\,\\frac{1}{b^2} \\right)\\] Méthode 4 : Montrer la convergence en probabilité Si \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}X\\) alors \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}X\\). Méthode 5 : Utiliser le continuous mapping theorem Si on a déjà montré que \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}X\\) et qu’on veut montrer que \\(Y_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}Y\\) (la recherche de \\(Y\\) pouvant éventuellement être laissée à la charge du candidat…), on peut regarder si on peut écrire \\(X_n\\) sous la forme \\(X_n=f(Y_n)\\). Si c’est le cas et si \\(f\\) est une fonction continue, alors le continuous mapping theorem permet de conclure que \\(X_n=f(Y_n)\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}f(Y)=:X\\). Ce théorème peut s’utiliser en invoquant simplement la stabilité de la convergence en loi par les applications continues. Exemples. Si \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}X\\), alors \\(X_n^2\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}X^2\\), \\(\\sqrt{X_n}\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\sqrt{X}\\) (sous réserve d’existence), \\(\\frac{1}{X_n}\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\frac{1}{X}\\) (sous réserve d’existence), etc. Méthode 6 : Utiliser le lemme de Slutsky Pour rappel, ce lemme affirme que si \\((X_n)\\) converge en loi vers \\(X\\) et \\(Y_n\\) converge en probabilité vers \\(Y\\), alors le couple aléatoire \\((X_n, \\, Y_n)\\) converge en loi vers le couple \\((X,\\, Y)\\). On utilise en général plutôt une conséquence de ce lemme : pour toute fonction continue \\(f:\\mathcal{U}\\subset\\mathbb{R}^2\\longrightarrow\\mathbb{R}\\) (en fait mesurable suffit, mais c’est hors-programme…) la variable aléatoire \\(Z_n=f(X_n\\,Y_n)\\) converge en loi vers \\(Z=f(X,\\,Y)\\). Exemples. Typiquement, on a donc \\(X_n+Y_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}X+Y\\), \\(X_nY_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}XY\\), \\(\\frac{X_n}{Y_n}\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\frac{X}{Y}\\), etc. Comment montrer la convergence en probabilité d’une suite de variables aléatoires ? Méthode 1 : revenir à la défintion Autrement dit si on parvient à montrer que pour tout réel \\(\\varepsilon &gt;0\\) quelconque \\[\\mathbb{P}(|X_n-X|\\geq\\varepsilon)\\underset{n\\to +\\infty}\\longrightarrow 0\\] alors on peut conclure que \\((X_n)_n\\) converge en probabilité vers \\(X\\). Exemple. \\((X_n)_n\\) est une suite de variables aléatoires telles que \\[\\begin{align} \\mathbb{P}(X_n=0) &amp;= 1-\\frac{1}{n} \\\\ \\mathbb{P}(X_n=n) &amp;= \\frac{1}{n} \\end{align}\\] et on veut montrer que \\((X_n)_n\\) converge en probabilité. On fixe donc un \\(\\varepsilon &gt;0\\) quelconque. \\((X_n)_n\\) est à valeurs dans \\(\\{0, n\\}\\) car \\(\\mathbb{P}(X_n=0)+\\mathbb{P}(X_n=n)=1\\), donc \\[\\begin{align} \\mathbb{P}(|X_n|&gt;\\varepsilon) &amp;= \\mathbb{P}(X_n=n) \\\\ &amp;= \\frac{1}{n} \\end{align}\\] Ainsi, \\(\\mathbb{P}(|X_n|\\geq\\varepsilon)\\underset{n\\to +\\infty}\\longrightarrow 0\\), et donc la suite \\((X_n)\\) converge en probabilité vers \\(0\\). Méthode 2 : utiliser la loi faible des grands nombres Pour rappel, la loi faible des grands nombres affirme que si les \\(X_i\\) sont des variables aléatoires i.i.d. admettant une espérance \\(\\mu\\), alors la suite des moyennes empiriques \\(\\overline{X}_n\\) converge en probabilité vers \\(\\mu\\) : \\[\\overline{X}_n\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}\\mu=\\mathbb{E}(X)\\] C’est un outil auquel il faut donc penser dès que l’on nous demande de montrer la convergence en probabilité d’une moyenne empirique vers une constante. Exemple. Si les \\(X_i\\) sont i.i.d. de loi \\(\\mathcal{E}(2)\\), alors \\[\\frac{X_1+\\dots +X_n}{n}\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}\\frac{1}{2}\\] Méthode 3 : utiliser une inégalité de concentration Intuitivement, une inégalité de concentration nous dit qu’une variable aléatoire a peu de chance de prendre une valeur trop éloignée de la moyenne, ou une valeur trop grande (en valeur absolue). Le programme du concours suppose connues deux inégalités de concentration : l’inégalité de Markov : si \\(X\\) est positive et admet une espérance, alors pour tout \\(\\varepsilon &gt;0\\), on a \\[\\mathbb{P}(X&gt;\\varepsilon)\\leq\\frac{\\mathbb{E}(X)}{\\varepsilon}\\] l’inégalité de Bieanymé-Tchebychev qui est une conséquence de l’inégalité de Markov (appliquée à \\(Y\\equiv (X-\\mathbb{E}(X))^2\\)) : si \\(X\\) admet une espérance et une variance, alors pour tout \\(\\varepsilon &gt;0\\) : \\[\\mathbb{P}(|X-\\mathbb{E}(X)|\\geq\\varepsilon)\\leq\\frac{\\mathbb{V}(X)}{\\varepsilon^2}\\] Exemple. On sait que \\(X_n\\) (de signe quelconque) est telle que \\(\\mathbb{E}(|X_n|)\\underset{n\\to +\\infty}\\longrightarrow 0\\) et on veut montrer que la suite \\((X_n)_n\\) converge en probabilité et déterminer sa limite. D’après l’inégalité de Markov appliquée à \\(Y_n\\equiv|X_n|\\), pour tout \\(\\varepsilon &gt;0\\) on a \\[0\\leq \\mathbb{P}(|X_n|\\geq\\varepsilon)\\leq\\frac{\\mathbb{E}(|X_n|)}{\\varepsilon}\\] et le théorème des gendarmes nous permet de conclure que, pour tout \\(\\varepsilon &gt;0\\) on a \\(\\lim\\limits_{n\\to +\\infty}\\mathbb{P}(|X_n|\\geq\\varepsilon)=0\\), et donc \\((X_n)\\) converge en probabilité vers \\(0\\). Méthode 4 : montrer la convergence en loi vers une constante Pour rappel : la convergence en probabilité implique toujours la convergence en loi la réciproque est fausse dans le cas général. Toutefois, elle est vraie si la limite est constante. D’après le deuxième point, pour montrer que \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}a\\) avec \\(a\\in\\mathbb{R}\\) une constante, il suffit de démontrer que \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}a\\) Exemple. On sait que \\(X_n\\) admet pour fonction de répartition la fonction \\(F_n\\) telle que \\(F_n(x)=0\\) si \\(x\\leq 1-\\frac{1}{n}\\), \\(F_n(x)=1\\) si \\(x\\geq 1\\) et \\(F_n\\) est affine sur \\(\\left[1-\\frac{1}{n}\\,;\\,1\\right]\\). On veut montrer que \\((X_n)_n\\) converge en probabilité vers \\(1\\). Pour cela, il suffit donc de démontrer que \\((X_n)_n\\) converge en loi vers \\(1\\). Or, pour tout réel \\(x\\), \\(F_n(x)\\underset{n\\to +\\infty}\\longrightarrow F(x)=\\mathbb{1}_{x\\leq 1}\\). On reconnait la fonction de répartition de la variable aléatoire constante égale à \\(1\\) : la suite \\((X_n)_n\\) converge donc en loi vers la constante 1, et donc elle converge en probabilité vers \\(1\\). Méthode 5 : utiliser le continuous mapping theorem Ce théorème fonctionne aussi pour la convergence en probabilité Autrement dit, la convergence en probabilité est stable par les applications continues: si \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}X\\), alors pour toute fonction continue \\(f\\) on a aussi \\(f(X_n)\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}f(X)\\). Exemple. On sait que \\(X_n\\) est telle que \\(\\mathbb{E}(|X_n|)\\underset{n\\to +\\infty}\\longrightarrow 0\\) et on veut montrer que la suite \\((Y_n)_n\\) définie par \\(Y_n=e^{X_n}\\) converge en probabilité et déterminer sa limite. On a déjà démontré dans l’exemple de la méthode 3 que \\((X_n)_n\\) converge en probabilité vers \\(0\\) via l’inégalité de Markov. Par application de la fonction exponentielle, qui est continue, la suite \\((Y_n)_n\\) converge donc en probabilité vers \\(1\\). Un autre exemple. Supposons que l’on ait une suite de variables aléatoires i.i.d. \\(X_1,\\dots, X_n,\\dots\\), avec \\(\\mathbb{E}(X_i)=0\\) et que l’on veuille montrer que la suite \\((Y_n)_n\\) définie par \\(Y_n\\equiv e^{\\frac{1}{n}\\sum\\limits_{i=1}^n X_i}\\) converge en probabilité. Alors on peut procéder ainsi : les \\(X_i\\) étant i.i.d. et admettant une espérance, on peut appliquer la loi faible des grands nombres : \\[\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}\\longrightarrow}0\\] l’application \\(\\exp\\) étant continue en \\(0\\), on a d’après le continuous mapping theorem \\(e^{\\frac{1}{n}\\sum\\limits_{i=1}^n X_i}\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}\\longrightarrow}e^0=1\\). \\(\\fbox{Concours}\\) L’exercice 1 du sujet du concours externe de 2022 est un bon exemple d’exercice mobilisant ces techniques, parfois de façon combinée. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
