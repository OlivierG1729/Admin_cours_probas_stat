[["index.html", "Cours de probabilités-statistiques pour le concours interne d’administrateur Insee Chapitre 1 Présentation du cours 1.1 Généralités 1.2 Coquilles et erreurs", " Cours de probabilités-statistiques pour le concours interne d’administrateur Insee Olivier Guin 2023-11-09 Chapitre 1 Présentation du cours 1.1 Généralités Ce document est un cours de probabilités et statistiques à destination des candidats au concours interne d’administrateur de l’Insee. Il est encore en construction et pour le moment très incomplet. Seule la partie Statistique inférentielle est à ce jour disponible. A terme, il devrait contenir les parties suivantes : Dénombrement et probabilités Variables aléatoires discrètes Variables aléatoires à densité Convergence Statistique descriptive Statistique inférentielle Certaines des notions présentées ici, sans être explicitement au programme du concours, sont à la frontière de celui-ci. Concrètement, cela signifie que’on peut les retrouver dans un sujet d’écrit ou d’oral, mais qu’aucun prérequis les concernant n’est nécessaire pour traiter le sujet. Mais les avoir déjà rencontrées peut aider pour résoudre les questions… C’est le cas par exemple, dans la partie Statistique inférentielle, de l’information de Fisher, des statistiques exhaustives et de la borne de Cramer-Rao, qui sont présentes dans le sujet d’Administrateur interne de 2022 (sans être toutefois explicitement nommées). Même type de remarque pour les démonstrations. Celles qui sont présentées ici ne sont pas toutes indispensables pour aborder ce concours. Mais elles utilisent des méthodes de calcul ou de raisonnement qui reviennent souvent, et qui peuvent inspirer pour la résolution d’un exercice. Comme toujours en mathématiques, la seule façon de progresser est de faire. Ne pas hésiter donc, à passer un peu de temps sur un exercice, même si on sèche complètement. 1.2 Coquilles et erreurs La loi de Poisson est souvent utilisée pour modéliser le nombre d’erreurs ou de coquilles inévitablement présentes dans un document. Celui-ci n’échappe pas à la règle et j’espère juste que le \\(\\lambda\\) n’est pas trop grand… Pour m’aider à le réduire, n’hésitez pas à me les signaler. Plus généralement, vos commentaires permettent d’améliorer la qualité de ce document : ils sont donc les bienvenus. "],["dénombrement-et-probabilités.html", "Chapitre 2 Dénombrement et probabilités 2.1 Dénombrement 2.2 Evénements et probabilités", " Chapitre 2 Dénombrement et probabilités 2.1 Dénombrement 2.1.1 Permutations 2.1.2 Arrangements 2.1.3 Combinaisons 2.1.4 Formule du binôme de Newton 2.1.5 Triangle de Pascal 2.2 Evénements et probabilités 2.2.1 Evénements Définition Opérations sur les événements : réunion, intersection, événement contraire 2.2.2 Probabilités Définition d’une probabilité Propriétés : probabilité d’un événement contraire, d’une union disjointe \\(0\\leq p(A)\\leq 1\\) propriété de croisssance crible de Poincaré Equiprobabilité 2.2.3 Probabilités conditionnelles Définition Propriétés : les mêmes que pour une probabilité “non conditionnelle” Formule des probabilités composées Formule des probabilités totales Formule de Bayes Indépendance (deux à deux, mutuelle) "],["variables-aléatoires-discrètes.html", "Chapitre 3 Variables aléatoires discrètes 3.1 Définition et premières propriétés 3.2 Transformation d’une variable aléatoire discrète 3.3 Vecteurs aléatoires", " Chapitre 3 Variables aléatoires discrètes 3.1 Définition et premières propriétés 3.1.1 Définition 3.1.2 Loi d’une variable aléatoire discrète 3.1.3 Définition de \\(p(X\\in A)\\) 3.1.4 Fonction de répartition, quantiles 3.1.5 Exemples classiques : loi uniforme sur un ensemble fini loi de Bernoulli loi binomiale loi de Poisson loi géométrique loi hypergéométrique 3.1.6 Moments d’une variable aléatoire Espérance, variance, moments d’ordres supérieurs inégalité de Markov, inégalité de Bieanymé-Tchébychev (exemples + intérêt) 3.2 Transformation d’une variable aléatoire discrète 3.2.1 Définition Définition Cas particuliers : bijection continue un unique extremum Déterminer la loi de \\(f(X)\\) en pratique (message = passer par la fonction de répartition) 3.2.2 Théorème de transfert (cas discret) Théorème Exemple 3.3 Vecteurs aléatoires 3.3.1 Définition 3.3.2 Loi jointe, loi marginales 3.3.3 Loi conditionnelle \\(\\mathcal{L}(Y|X)\\) 3.3.4 Loi d’un couple de VA indépendantes Définition Somme de deux VA indépendantes (produit de convolution discret) 3.3.5 Espérance conditionnelle, variance conditionnelle "],["variables-aléatoires-à-densité.html", "Chapitre 4 Variables aléatoires à densité 4.1 Définition et premières propriétés 4.2 Transformation d’une variable aléatoire à densité 4.3 Vecteurs aléatoires", " Chapitre 4 Variables aléatoires à densité 4.1 Définition et premières propriétés 4.1.1 Définition 4.1.2 Loi d’une variable aléatoire à densité 4.1.3 Définition de \\(p(X\\in A)\\) 4.1.4 Fonction de répartition, quantiles 4.1.5 Exemples classiques : loi uniforme sur un segment loi normale loi exponentielle loi gamma \\(\\gamma(p\\,;\\,\\theta)\\) loi log-normale loi du Chi-Deux loi de Student loi de Fisher 4.1.6 Moments d’une variable aléatoire Espérance, variance, espaces \\(L^1\\) et \\(L^2\\) moments d’ordres supérieurs inégalité de Markov, inégalité de Bieanymé-Tchébychev (exemples + intérêt) 4.2 Transformation d’une variable aléatoire à densité 4.2.1 Définition Définition Cas particuliers : bijection continue un unique extremum Déterminer la loi de \\(f(X)\\) en pratique (message = passer par la fonction de répartition) 4.2.2 Théorème de transfert (cas à densité) Théorème Exemple 4.3 Vecteurs aléatoires 4.3.1 Définition 4.3.2 Loi jointe, loi marginales 4.3.3 Loi conditionnelle \\(\\mathcal{L}(Y|X)\\) 4.3.4 Loi d’un couple de VA indépendantes Définition Somme de deux VA indépendantes (produit de convolution à densité) 4.3.5 Espérance, matrice de variance-covariance exemple : vecteurs gaussiens en dimension 2 4.3.6 Espérance conditionnelle, variance conditionnelle "],["convergence.html", "Chapitre 5 Convergence 5.1 Différents modes de convergence 5.2 Loi Faible des Grands Nombres, Loi Forte des Grands Nombres 5.3 Théorème Central Limite (TCL) 5.4 Variantes du TCL (hors-programme)", " Chapitre 5 Convergence 5.1 Différents modes de convergence 5.1.1 Convergence en probabilité 5.1.2 Convergence dans les espaces \\(L^p\\) focus sur les cas \\(p=1\\) et \\(p=2\\) 5.1.3 Convergence en loi 5.1.4 Convergence presque-sûre (hors-prgramme ?) 5.1.5 Liens entre les différents modes de convergence 5.1.6 Approximations approximation de la loi binomiale \\(\\mathcal{B}(n\\,;\\,p)\\approx\\mathcal{N}(np\\,;\\,np(1-p))\\) approximation de la loi de Poisson \\(\\mathcal{P}(\\lambda)\\approx\\mathcal{N}(\\lambda\\,;\\,\\lambda)\\) (bien préciser les hypothèses sous-jcantes à ces approximations) 5.2 Loi Faible des Grands Nombres, Loi Forte des Grands Nombres énoncé théorique exemples avec illustration en R 5.3 Théorème Central Limite (TCL) énoncé théorique exemples avec illustration en R 5.4 Variantes du TCL (hors-programme) "],["statistique-descriptive.html", "Chapitre 6 Statistique descriptive 6.1 Vocabulaire 6.2 Analyse statistique univariée 6.3 Analyse statistique bivariée", " Chapitre 6 Statistique descriptive 6.1 Vocabulaire 6.1.1 Population, individus, échantillon 6.2 Analyse statistique univariée 6.2.1 Notion de série statistique univariée série statistique à une variable valeurs variable statistique 6.2.2 Indicateurs d’une série statistique univariée modalités, effectif, fréquence effectifs cumulées croissants, fréquences cumulées croissantes indicateurs de position, indicateurs de dispersion indicateurs de concentration courbe de Lorenz indice de Gini quantiles 6.2.3 Représentations graphiques 6.3 Analyse statistique bivariée 6.3.1 Notion de série statistique bivariée série statistique à deux variables 6.3.2 Indicateurs propres à l’analyse statistique multivariée distribution marginale effectif marginal fréquence marginale covariance empirique distribution conditionnelle formule de Huygens-Koenig coefficient de corrélation linéaire empirique 6.3.3 Nuage de points 6.3.4 Ajustement des moindres carrés "],["statistique-inférentielle.html", "Chapitre 7 Statistique inférentielle 7.1 Estimation 7.2 Tests statistiques", " Chapitre 7 Statistique inférentielle 7.1 Estimation On s’intéresse à une loi probabiliste \\(\\mathcal{L}_{\\theta}\\), qui est entièrement décrite par la donnée d’un paramètre inconnu \\(\\theta\\). Pour mieux appréhender cette loi, il serait intéressant de connaître la valeur de \\(\\theta\\). Plutôt que de chercher à déterminer la valeur exacte de \\(\\theta\\), on peut essayer de l’approcher. Dans le cadre de la statistique inférentielle, on suppose qu’on dispose d’un échantillon i.i.d. de \\(\\mathcal{L}_{\\theta}\\), autrement dit d’un certain nombre de réalisations \\((Y_1,\\dots, Y_n)\\) indépendantes et identiquement distribuées de la loi \\(\\mathcal{L}_{\\theta}\\). La donnée d’un tel échantillon constitue un ensemble d’informations qui vont nous être utiles pour estimer le paramètre \\(\\theta\\). on fait donc bien ici de l’inférence - ou encore de l’induction - dans le sens où on part d’observations particulières (les réalisations \\(Y_1,\\dots, Y_n)\\) pour énoncer une règle générale (le fait que ces réalisations sont issues de la loi \\(\\mathcal{L}_{\\theta}\\)). 7.1.1 Premières définitions Estimateurs Soit \\(Y\\) une variable aléatoire de loi \\(\\mathcal{L}(Y)\\), paramétrée par un réel \\(\\theta\\) inconnu. Soit \\((Y_1,\\dots, Y_n)\\) un échantillon i.i.d. de loi \\(\\mathcal{L}(Y)\\). On appelle estimateur de \\(\\theta\\) toute fonction de \\(Y_1,\\dots, Y_n\\), i.e. \\[\\widehat{\\theta}_n=S(Y_1,\\dots, Y_n)\\] On veut estimer la moyenne d’une loi normale \\(\\mathcal{N}(\\mu\\,;\\,1)\\), à partir d’un échantillon d’observations i.i.d. \\((Y_1,\\dots, Y_n)\\) tirées sous cette loi. Une façon naturelle d’estimer \\(\\mu=\\mathbb{E}(Y_1)\\) est de poser \\(\\widehat{\\mu}_n=\\frac{Y_1+\\dots Y_n}{n}\\). Ici, on estime donc une moyenne théorique par sa contrepartie empirique. Biais, erreur quadratique Soit \\(\\widehat{\\theta}_n\\) un estimateur de \\(\\theta\\) admettant un moment d’ordre \\(1\\). On appelle biais de \\(\\widehat{\\theta}_n\\) la quantité \\(b_{\\theta}(\\widehat{\\theta}_n)=\\mathbb{E}(\\widehat{\\theta}_n)-\\theta\\). Un estimateur est dit sans biais lorsque son biais est nul, i.e. \\(\\mathbb{E}(\\widehat{\\theta}_n)=\\theta\\). Il est dit asymptotiquement sans biais lorsque son biais tend vers \\(0\\), i.e. \\(b_{\\theta}(\\widehat{\\theta}_n)\\underset{n\\to +\\infty}{\\longrightarrow}0\\). Pour un estimateur des moments d’ordre \\(1\\) et \\(2\\), on appelle erreur quadratique moyenne la quantité (positive) \\(\\text{EQM}_{\\theta}(\\widehat{\\theta}_n)=\\mathbb{E}\\left(\\left(\\widehat{\\theta}_n-\\theta\\right)^2\\right)\\) L’erreur quadratique moyenne s’écrit à l’aide de l’espérance et de la variance : Théorème : Soit \\(\\widehat{\\theta}_n\\) un estimateur de \\(\\theta\\) admettant des moments d’ordres \\(1\\) et \\(2\\). Son erreur quadratique moyenne peut se décomposer en biais au carré/variance : \\[\\text{EQM}_{\\theta}(\\widehat{\\theta}_n)=b_{\\theta}^2(\\widehat{\\theta}_n)+\\mathbb{V}(\\widehat{\\theta}_n)\\] Autrement dit, réduire l’erreur (quadratique moyenne) d’un estimateur revient à essayer de réduire son biais et/ou sa variance. En pratique, uune réduction du biais implique souvent une augmentation de la variance (et vice-versa) et il faut trouver un compromis entre les deux, i.e. un estimateur pour lequel la combinaison (biais, variance) implique une faible erreur quadratique moyenne. On parle alors de compromis biais-variance. 7.1.2 Convergence d’un estimateur Estimateurs convergents Un estimateur \\(\\widehat{\\theta}_n\\) de \\(\\theta\\) est dit convergent lorsqu’il converge en probabilité vers \\(\\theta\\) i.e. lorsque \\[\\forall\\varepsilon &gt;0, \\mathbb{P}\\left(|\\widehat{\\theta}_n-\\theta|&gt;\\varepsilon\\right)\\longrightarrow 0\\] La convergence d’un estimateur sans biais peut se montrer à l’aide du critère pratique suivant : Théorème (critère pratique de convergence) : Un estimateur \\(\\widehat{\\theta}_n\\) sans biais de \\(\\theta\\) est convergent dès que sa variance tend vers \\(0\\), i.e. \\[\\left(\\mathbb{E}_{\\theta}(\\widehat{\\theta}_n)=0 \\text{ et } \\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)\\longrightarrow 0\\right)\\Rightarrow \\left(\\widehat{\\theta}_n \\underset{n \\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}\\theta\\right)\\] Démonstration. Compte-tenu du fait que \\(\\widehat{\\theta}_n\\) est un estimateur sans biais pour \\(\\theta\\), l’inégalité de Bieanymé-Tchebychev s’écrit \\(\\mathbb{P}(|\\widehat{\\theta}_n-\\theta|&gt;\\varepsilon)\\leq\\frac{\\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)}{\\varepsilon^2}\\), ce qui permet de conclure. \\(\\square\\) On peut même affaiblir un peu l’hypothèse d’absence de biais par une hypothèse de biais asymptotiquement nul : Théorème (critère pratique de convergence (suite)) : Un estimateur \\(\\widehat{\\theta}_n\\) asymtotiquement sans biais de \\(\\theta\\) est convergent dès que sa variance tend vers \\(0\\), i.e. \\[\\left(\\mathbb{E}_{\\theta}(\\widehat{\\theta}_n)\\underset{n\\to +\\infty}{\\longrightarrow}\\theta \\text{ et } \\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)\\longrightarrow 0\\right)\\Rightarrow \\left(\\widehat{\\theta}_n \\underset{n \\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}\\theta\\right)\\] 7.1.3 Exemples classiques Quelques exemples très classiques d’estimateurs : Exemple 1 : moyenne empirique. Soit \\(X_1,\\dots X_n\\) une suite de \\(VAR\\) i.i.d. de même loi que \\(X\\), admettant une espérance \\(\\mu\\). La moyenne empirique est l’estimateur \\[\\overline{X_n}=\\frac{X_1+\\dots + X_n}{n}\\] Théorème : Quelle que soit la loi suivie par \\(X\\), la moyenne empirique \\(\\overline{X_n}\\) est un estimateur sans biais de l’espérance \\(\\mu=\\mathbb{E}(X)\\). Si, de plus, \\(X\\) admet une variance \\(\\sigma^2\\), alors \\(\\overline{X_n}\\) admet également une variance et celle-ci est donnée par \\(\\mathbb{V}(\\overline{X_n})=\\frac{\\sigma^2}{n}\\). Démonstration. Par linéarité de l’espérance : \\(\\mathbb{E}(\\overline{X_n})=\\frac{1}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i)=\\frac{1}{n}\\sum\\limits_{i=1}^n\\mu=\\mu\\). Si \\(X\\) admet une variance, alors \\(\\overline{X_n}\\) aussi et \\(\\mathbb{V}(\\overline{X_n})=\\frac{1}{n^2}\\sum\\limits_{i=1}^n\\mathbb{V}(X_i)=\\frac{\\sigma^2}{n}\\), par indépendance de \\(X_1,\\dots X_n\\). \\(\\square\\) Corollaire : La moyenne empirique est un estimateur convergent de l’espérance (lorsqu’elle existe). Démonstration. L’estimateur \\(\\overline{X_n}\\) est sans biais et \\(\\mathbb{V}(\\overline{X_n})=\\frac{\\sigma^2}{n}\\longrightarrow 0\\). C’est donc un estimateur convergent de l’espérance. \\(\\square\\). Exemple 2 : estimation d’une proportion. Au sein d’une population, une proportion \\(p\\) d’individus présente une caractéristique. On suppose que la présence de cette caractéristique est distribuée de façon identique et indépendante d’un individu à l’autre suivant la loi de Bernoulli de paramètre \\(p\\). On peut donc estimer la proportion \\(p\\) au niveau population par la proportion \\(\\widehat{p_n}\\) au niveau échantillon : cet estimateur est la moyenne empirique, il est sans biais et de variance (inconnue) \\(\\frac{p(1-p)}{n}\\). Exemple 3 : variance empirique. Si \\(X\\) admet une variance \\(\\sigma^2\\) et \\(X_1,\\dots, X_n\\) sont i.i.d. de même loi que \\(X\\), alors un estimateur de \\(\\sigma^2\\) est donné par la variance empirique \\(S_n^{&#39;2}=\\frac{1}{n}\\sum\\limits_{i=1}^n(X_i-\\overline{X_n})^2\\). Théorème : La variance empirique \\(S_n^{&#39;2}\\) est un estimateur biaisé de la variance \\(\\sigma^2\\). Plus précisément, on a \\[\\mathbb{E}(S_n^{&#39;2})=\\frac{n-1}{n}\\sigma^2\\] Démonstration. \\[\\begin{align} \\mathbb{E}(S_n^{&#39;2}) &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i^2)-\\frac{2\\overline{X_n}}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i)+\\frac{1}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(\\overline{X_n}^2) \\\\ &amp;= \\mathbb{E}(X^2)-\\mathbb{E}(\\overline{X_n}^2) \\end{align}\\] Par ailleurs : \\[\\begin{align} \\mathbb{E}(\\overline{X_n}^2)&amp;=\\frac{1}{n^2}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i^2)+\\frac{1}{n^2}\\sum\\limits_{i\\neq j}\\mathbb{E}(X_iX_j) \\\\ &amp;= \\frac{1}{n}^2\\sum\\limits_{i=1}^n\\mathbb{E}(X_i^2)+\\frac{1}{n^2}\\sum\\limits_{i\\neq j}\\mathbb{E}(X_i)\\mathbb{E}(X_j) \\\\ &amp;= \\frac{1}{n}\\mathbb{E}(X^2)+\\frac{n-1}{n}\\left(\\mathbb{E}(X)\\right)^2 \\end{align}\\] Avec la formule de Huygens \\(\\mathbb{V}(X)=\\mathbb{E}(X^2)-\\mathbb{E}(X)^2\\), on en déduit que \\[\\mathbb{E}(S_n^{&#39;2})=\\frac{n-1}{n}\\sigma^2\\] \\(\\square\\) Remarque. Le biais de l’estimateur \\(S_n^{&#39;2}\\) devient cependant très faible pour \\(n\\) suffisamment grand. Il s’agit d’un estimateur asymptotiquement sans biais de la variance \\(\\sigma^2\\) : \\(\\mathbb{E}(S_n^{&#39;2})\\longrightarrow \\sigma^2\\). Exemple 4 : variance empirique corrigée. En modifiant l’estimateur de la variance empirique par un petit facteur correctif, on obtient un estimateur sans biais de la variance. Il suffit de poser \\[S_n^2=\\frac{1}{n-1}\\sum\\limits_{i=1}^n(X_i-\\overline{X_n})^2\\] Cet estimateur s’appelle la variance empirique corrigée. Théorème : La variance empirique corrigée \\(S_n^2=\\frac{1}{n-1}\\sum\\limits_{i=1}^n (X_i-\\overline{X_n})^2\\) est un estimateur sans biais de la variance \\(\\sigma^2=\\mathbb{V}(X)\\) : \\[\\mathbb{E}(S_n^2)=\\sigma^2\\] 7.1.4 Méthodes de construction des estimateurs On présente ici deux méthodes classiques de construction des estimateurs ; la méthode des moments et la méthode du maximum de vraisemblance. 7.1.4.1 La méthode des moments La méthode des moments Soit \\(X\\) une variable aléatoire réelle de loi \\(\\mathcal{L}_{\\theta}\\), où \\(\\theta\\) est un paramètre inconnu. On considère une fonction \\(f\\) de \\(I\\subset\\mathbb{R}\\) dans \\(\\mathbb{R}\\) telle que \\(f(X)\\) admette une espérance. Comme la loi de \\(X\\) dépend de \\(\\theta\\), il en est de même de \\(\\mathbb{E}(f(X))\\). La méthode des moments suppose qu’on sait expliciter une telle dépendance, i.e. qu’on connaisse une fonction \\(g\\) telle que \\[\\mathbb{E}(f(X))=g(\\theta)\\] La contrepartie empirique du membre de gauche de cette égalité est \\(\\frac{1}{n}\\sum\\limits_{i=1}^n f(X_i)\\), et la méthode des moments consiste alors à résoudre l’équation en \\(\\widehat{\\theta}\\) : \\[g(\\widehat{\\theta})=\\frac{1}{n}\\sum\\limits_{i=1}^n f(X_i)\\] Exemple 5 : estimation du paramètre d’une loi exponentielle. Soit \\(X\\sim\\mathcal{E}(\\lambda)\\), où \\(\\lambda&gt;0\\) est un paramètre inconnu que l’on veut estimer. La variable aléatoire \\(X\\) admet une espérance, et celle-ci est donnée par \\(\\mathcal{E}(X)=\\frac{1}{\\lambda}\\). La méthode des moments consiste alors à résoudre l’équation \\[\\frac{1}{\\widehat{\\lambda_n}}=\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\] Cette équation est très simple, elle admet pour solution \\[\\widehat{\\lambda_n}=\\frac{1}{\\overline{X_n}}\\] C’est l’estimateur que l’on obtient par la méthode des moments. Remarque. En reprenant les notations explicitées ci-dessus, on peut identifier les fonctions \\(f\\) et \\(g\\) : \\[f(x)=x\\] \\[g(x)=\\frac{1}{x}\\] et ici évidemment \\(\\theta=\\lambda\\). En général, la méthode des moments s’utilise de façon complètement intuitive sans qu’on ait même à expliciter forcément les fonctions \\(f\\) et \\(g\\). 7.1.4.2 La méthode du maximum de vraisemblance Une autre méthode de construction d’estimateurs est celle du maximum de vraisemblance. L’idée générale de cette méthode est la suivante. On suppose qu’on dispose de réalisations \\(x_1,\\dots x_n\\) d’une même variable aléatoire, dont la loi appartient à une famille paramétrique \\(\\left\\{\\mathcal{L}_{\\theta}\\,;\\,\\theta\\in\\Theta\\right\\}\\) et on cherche à estimer \\(\\theta\\). Si par exemple on dispose d’une série de cinq obersations \\((0.12, -0.65, 1.35, 1.04, -1.19, 0.08)\\) et qu’on veut inférer sur \\(\\theta\\) à partir de ces observations, on est enclin à penser que la valeur \\(\\theta=0\\) est plus plausible que la valeur \\(\\theta=-10\\). La vraisemblance est une formalisation de l’idée intuitive de plausibilité d’un paramètre à partir d’une observation ou d’un ensemble d’observations. A nouveau, \\(X\\) désigne une variable aléatoire de loi dépendant d’un paramètre inconnu \\(\\theta\\), et \\(x\\) une réalisation de \\(X\\). La vraisemblance \\(L(x,.)\\) est une fonction de \\(\\theta\\) définie par \\[L(x;\\theta)=\\left\\{ \\begin{array}{lll} \\mathbb{P}_{\\theta}(X=x) &amp;\\text{; si } X \\text{ est discrète} \\\\ f(x;\\theta) &amp;\\text{; si } X \\text{ est une continue de densité } f(.;\\theta) \\\\ \\end{array} \\right.\\] Remarque : D’autres notations existent dans la littérature, comme \\(L(x|\\theta), \\mathbb{P}(X=x|\\theta), f(x|\\theta)\\). Ces notations viennent de la statistique bayésienne (hors programme du concours) qui envisage \\(\\theta\\) comme une variable aléatoire de distribution inconnue. Dans ce cas, la vraisemblance s’interprète comme une probabilité ou une densité de probabilité. La définition précédente s’étend au cas d’un échantillon \\((X_1,\\dots X_n)\\) de VA de même loi que \\(X\\). Dans ce cas, on note souvent \\(L_n(x;\\theta)\\) la vraisemblance, pour faire apparaître la dépendance en \\(n\\). Un cas particulier important est celui où ces VA sont i.i.d. Dans ce cas, la vraisemblance est définie par \\[L_n(x;\\theta)=L_n(x_1,\\dots,x_n ; \\theta)=\\left\\{ \\begin{array}{lll} \\prod\\limits_{i=1}^n\\mathbb{P}_{\\theta}(X_i=x_i) &amp;\\text{; si } X \\text{ est discrète} \\\\ \\prod\\limits_{i=1}^n f(x_i,\\theta) &amp;\\text{; si } X \\text{ est une continue de densité } f(.;\\theta) \\\\ \\end{array} \\right.\\] La méthode du maximum de vraisemblance consiste juste à dire que si toute l’information dont on dispose sur la variable aléatoire \\(X\\) est l’observation de l’échantillon \\((x_1, \\dots, x_n)\\), alors la meilleure estimation que l’on puisse faire de \\(\\theta\\) à partir de cette information est celle qui maximise la fonction de vraisemblance. Autrement dit, on cherche la valeur de \\(\\theta\\) qui rend l’observation \\((x_1,\\dots, x_n)\\) la plus plausible. Formellement : Méthode du maximum de vraisemblance Etant donné une collection de \\(n\\) réalisations \\(x=(x_1,\\dots, x_n)\\) des VA \\((X_1,\\dots X_n)\\) de même loi \\(\\mathcal{L}_{\\theta}\\) de paramètre inconnu \\(\\theta\\), on appelle estimation du maximum de vraisemblance toute estimation \\(\\widehat{\\theta}_n=\\widehat{\\theta}_n(x_1,\\dots,x_n)\\) vérifiant \\[\\widehat{\\theta}_n\\in \\arg\\max\\limits_{\\theta\\in\\Theta}L_n(x;\\theta)\\] Cas particulier : si la fonction \\(\\theta\\mapsto L_n(x;\\theta)\\) est deux fois dérivable sur \\(\\Theta\\), alors on peut chercher à résoudre (en \\(\\theta\\)) le système \\[\\left\\{ \\begin{array}{lll} \\frac{\\partial}{\\partial\\theta}L_n(x;\\theta)=0 \\\\ \\frac{\\partial^2}{\\partial\\theta^2}L_n(x;\\theta)&lt;0 \\\\ \\end{array} \\right.\\] Les solutions de ce système fournissent des estimations par maximum de vraisemblance. Log-vraisemblance. Il est souvent plus commode de considérer la log-vraisemblance \\(l_n(x;\\theta)=\\ln L_n(x;\\theta)=\\sum\\limits_{i=1}^n \\ln L_n(x_i;\\theta)\\). La fonction \\(\\ln\\) étant croissante sur \\(\\mathbb{R}_{+}^*\\), maximiser la vraisemblance équivaut à maximiser la log-vraisemblance. Maximisation de la log-vraisemblance En supposant que \\(L_n(x;\\theta)&gt;0\\) pour tout \\(\\theta\\in\\Theta\\), on note \\(l_n(x;\\theta)=\\ln L_n(x;\\theta)\\) la log-vraisemblance. Sous les mêmes hypothèses que ci-dessus, on cherche \\[\\widehat{\\theta}_n\\in\\arg\\max\\limits_{\\theta\\in\\Theta}\\left(l_n(x;\\theta)\\right)\\] Cas particulier : si la fonction \\(\\theta\\mapsto L_n(x;\\theta)\\) est deux fois dérivable sur \\(\\Theta\\), alors la fonction \\(\\theta\\mapsto l_n(x;\\theta)\\) l’est aussi et on peut chercher à résoudre (en \\(\\theta\\)) le système \\[\\left\\{ \\begin{array}{lll} \\frac{\\partial}{\\partial\\theta}l_n(x;\\theta)=0 \\\\ \\frac{\\partial^2}{\\partial\\theta^2}l_n(x;\\theta)&lt;0 \\\\ \\end{array} \\right.\\] Les solutions de ce système fournissent des estimations par maximum de vraisemblance. Exemple 6 : loi normale. \\(\\mathcal{N}(\\mu, 1)\\). On veut estimer le paramètre inconnu \\(\\mu\\) par maximum de vraisemblance. La vraisemblance est donnée par \\[\\begin{align} L_n(x;\\mu)&amp;=\\prod\\limits_{i=1}^n\\left(\\frac{e^{-\\frac{(x_i-\\mu)^2}{2}}}{\\sqrt{2\\pi}}\\right)\\\\ &amp;=\\frac{1}{(2\\pi)^{\\frac{n}{2}}}e^{-\\sum\\limits_{i=1}^n (x_i-\\mu)^2} \\end{align}\\] La log-vraisemblance est plus facile à manipuler : \\[\\begin{align} l_n(x;\\mu)&amp;=\\ln L_n(x;\\mu) \\\\ &amp;= -\\frac{n}{2}\\ln(2\\pi)-\\sum\\limits_{i=1}^n(x_i-\\mu)^2 \\end{align}\\] La fonction \\(\\mu\\mapsto l_n(x;\\mu)\\) est deux fois dérivable sur \\(\\mathbb{R}\\) et \\(\\frac{\\partial}{\\partial\\mu}l_n(x;\\mu)=2\\sum_{i=1}^n(\\mu-x_i)\\). Une seule valeur de \\(\\mu\\) l’annule : \\[\\widehat{\\mu}_n=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i=\\overline{x}_n\\] Par ailleurs \\(\\frac{\\partial^2}{\\partial\\mu^2}l_n(x;\\mu)=2n&gt;0\\), et donc \\(\\widehat{\\mu}_n\\in\\arg\\max\\limits_{\\mu\\in\\mathbb{R}}l(x;\\mu)\\). Finalement, un estimateur par maximum de vraisemblance est donné par \\[\\widehat{\\mu}_n=\\overline{X}_n=\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\] Remarque. Comme souvent en statistique, on commet un léger abus de notation en désignant par la même lettre l’estimateur \\(\\widehat{\\mu}_n=\\frac{X_1+\\dots+X_n}{n}=\\widehat{\\mu}_n(X_1,\\dots,X_n)\\) (qui est une statistique, i.e. une fonction de \\((X_1,\\dots,X_n\\)) et l’estimation \\(\\widehat{\\mu}_n=\\frac{x_1+\\dots+x_n}{n}=\\widehat{\\mu}_n(x_1,\\dots, X_n)\\) qui en est une réalisation. Conditionnellement à \\((X_1,\\dots,X_n)\\) (i.e. si l’on suppose que l’on observe \\((X_1,\\dots, X_n)\\)) ces deux objets sont bien les mêmes. Exemple 7 : loi exponentielle. Soit \\((X_1,\\dots,X_n)\\) un échantillon i.i.d. tiré selon une loi exponentielle \\(\\mathcal{E}(\\lambda)\\) de paramètre \\(\\lambda&gt;0\\) inconnu. La vraisemblance est donnée par \\[\\begin{align} L_n(x;\\lambda)&amp;=\\prod\\limits_{i=1}^n (\\lambda e^{-\\lambda x_i}\\mathbb{1}_{x_i\\geq 0}) \\\\ \\end{align}\\] Si l’un des \\(x_i\\) est négatif elle vaut \\(0\\). Sinon on calcule la log-vraisemblance \\[l_n(x;\\lambda)=n\\ln(\\lambda)-\\lambda\\sum_{i=1}^n x_i\\] La fonction \\(\\lambda\\in\\mathbb{R}_{+}^*\\mapsto l_n(x;\\lambda)\\) est deux fois dérivable et \\(\\frac{\\partial}{\\partial\\lambda}l_n(x;\\lambda)=\\frac{n}{\\lambda}-\\sum\\limits_{i=1}^n x_i\\), qui s’annule en \\(\\lambda=\\frac{n}{\\sum\\limits_{i=1}^n x_i}=\\frac{1}{\\overline{x}_n}\\). De plus, \\(\\frac{\\partial^2}{\\partial\\lambda^2}l_n(x;\\lambda)=-\\frac{n}{\\lambda^2}&lt;0\\) et donc à \\(x\\) fixé, \\(l_n(x;\\lambda)\\) atteint son maximum en \\(\\frac{1}{\\overline{x_n}}\\). L’estimateur du maximum de vraisemblance est donc \\(\\widehat{\\lambda}_n=\\frac{1}{\\overline{X}_n}\\). On remarque qu’on retrouve ici le même estimateur que celui obtenu par la méthode des moments. 7.1.5 Compléments (hors-programme) On présente dans cette partie les notions suivantes : information de Fisher borne de Cramer-Rao statistique exhaustive famille exponentielle amélioration d’un estimateur Ces notions ne sont pas au programme du concours, mais elles sont clairement dans sa périphérie immédiate. On les retrouve d’ailleurs dans le sujet d’interne 2022, mais leur connaissance n’est pas requise pour traiter le sujet. 7.1.5.1 Information de Fisher Soient \\(X\\) une variable aléatoire (discrète ou continue) à valeurs dans \\(\\mathcal{X}\\) de loi \\(L(x;\\theta)&gt;0\\), avec \\(\\theta\\in\\mathbb{R}\\). On fait les hypothèses suivantes : existence de \\(\\frac{\\partial L}{\\partial\\theta}(x;\\theta)\\) et de \\(\\frac{\\partial^2}{\\partial\\theta^2}L(x;\\theta)\\) on peut échanger tous les opérateurs de dérivation (à l’ordre \\(1\\) et \\(2\\)) et d’intégration On considère un échantillon i.i.d. \\((X_1,\\dots,X_n)\\) tel que chacun des \\(X_i\\) suit la même loi que \\(X\\). Pour \\(x=(x_1,\\dots,x_n)\\) une réalisation de l’échantillon aléatoire \\((X_1,\\dots, X_n)\\), On note \\(L_n(x;\\theta)\\) la vraisemblance de \\((x_1,\\dots, x_n)\\) : \\[L_n(x;\\theta)=\\prod\\limits_{i=1}^n L(x_i;\\theta)\\] On appelle alors score la quantité (aléatoire) \\(\\frac{\\partial}{\\partial\\theta}\\,\\ln L_n(X;\\theta)=\\frac{\\partial}{\\partial\\theta}\\, l_n(X;\\theta)\\), i.e. la dérivée de la log-vraisemblance par rapport à \\(\\theta\\). Théorème : On a \\[\\mathbb{E}_{\\theta}\\left(\\frac{\\partial }{\\partial\\theta}\\, l_n(X;\\theta)\\right)=0\\] i.e. le score est d’espérance nulle. Démonstration. On démontre cette égalité dans le cas à densité : \\[\\begin{align} \\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta}\\, l_n(X ; \\theta)\\right) &amp;= \\int_{\\mathbb{R}^n} \\frac{\\partial}{\\partial\\theta} \\,l_n(x;\\theta)\\,L_n(x;\\theta)\\,dx \\\\ &amp;=\\int_{\\mathbb{R}^n}\\frac{\\frac{\\partial L_n}{\\partial\\theta}(x;\\theta)}{L_n(x;\\theta)}\\,L_n(x;\\theta)\\,dx \\\\ &amp;= \\int_{\\mathbb{R}^n} \\frac{\\partial L_n}{\\partial\\theta}(x;\\theta)\\,dx \\\\ &amp;=\\frac{\\partial}{\\partial\\theta}\\int_{\\mathbb{R}^n} L_n(x;\\theta) \\, dx \\text{ (on permute intégrale et dérivée)} \\\\ &amp;= 0 \\text{ (car } \\int_{\\mathbb{R}^n} L_n(x;\\theta)\\,dx=1\\text{)} \\\\ \\end{align}\\] \\(\\square\\) L’information de Fisher est définie à partir du score de la façon suivante : Information de Fisher L’information de Fisher est la quantité définie par \\[I_n(\\theta)\\equiv\\mathbb{E}_{\\theta}\\left(\\left(\\frac{\\partial }{\\partial\\theta}\\, l_n(X;\\theta)\\right)^2\\right)=\\mathbb{V}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta}l_n(X;\\theta)\\right)\\] Lorsque le domaine de \\(X\\) ne dépend pas de \\(\\theta\\), l’information de Fisher est aussi égale à \\[I_n(\\theta)=-\\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2} l_n(X;\\theta)\\right)\\] Cette dernière expression est généralement plus facile à calculer. Interprétation de l’information de Fisher. On utilise généralement l’information de Fisher lorsqu’on veut inférer sur un paramètre inconnu \\(\\theta\\) par maximum de vraisemblance. Par construction, l’estimation \\(\\widehat{\\theta}\\) que l’on obtient par cette méthode est celle qui maximise la log-vraisemblance \\(\\ln L_n(X;\\theta)\\), pour une observation de \\(X\\) donnée. L’expression \\(I_n(\\theta)=-\\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2}\\ln L_n(X;\\theta)\\right)\\) montre que l’information de Fisher correspond (au signe près) à la courbure de la log-vraisemblance. Plus celle-ci est importante, plus la courbe présente un “pic” autour du maximum, et donc plus la valeur estimée de ce maximum est précise. Au contraire, si la courbure est faible, la courbe est aplatie autour du maximum, et donc l’estimation de \\(\\theta\\) sera moins précise. Dit autrement, l’information de Fisher quantifie le niveau d’information que nous apporte l’observation relativement au paramètre \\(\\theta\\). Démonstration. Etant donné que \\(\\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right)=0\\) on a \\(\\mathbb{V}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right)=\\mathbb{E}_\\theta\\left(\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta\\right)^2\\right)\\), ce qui démontre la première égalité. Pour démontrer la deuxième égalité, on dérive par rapport à \\(\\theta\\) l’égalité \\(\\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right)=0\\). Pour cela, on utilise la permutation \\(\\frac{\\partial}{\\partial\\theta}\\int=\\int\\frac{\\partial}{\\partial\\theta}\\) qui est possible car le domaine de \\(X\\) ne dépend pas de \\(\\theta\\). On obtient donc : \\[\\begin{align} 0 &amp;= \\frac{\\partial}{\\partial\\theta}\\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right) \\\\ &amp;= \\frac{\\partial}{\\partial\\theta}\\int_{\\mathbb{R}^n}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right) L_n(x;\\theta)\\,dx \\\\ &amp;=\\int_{\\mathbb{R}^n}\\frac{\\partial}{\\partial\\theta}\\left(\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right) L_n(x;\\theta)\\right)\\,dx \\\\ &amp;=\\int_{\\mathbb{R}^n}\\left(\\frac{\\partial^2}{\\partial\\theta^2}l_n(x;\\theta)\\right)L_n(x;\\theta)\\,dx+\\int_{\\mathbb{R}^n}\\frac{\\partial}{\\partial\\theta}l_n(x;\\theta)\\frac{\\partial}{\\partial\\theta}L_n(x;\\theta)\\,dx \\\\ &amp;= \\int_{\\mathbb{R}^n}\\left(\\frac{\\partial^2}{\\partial\\theta^2}l_n(x;\\theta)\\right)L_n(x;\\theta)\\,dx+\\int_{\\mathbb{R}^n}\\left(\\frac{\\partial}{\\partial\\theta}l_n(x;\\theta)\\right)^2 L_n(x;\\theta)\\,dx \\\\ &amp;= \\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2} l_n(X;\\theta)\\right)+\\mathbb{E}_{\\theta}\\left(\\left(\\frac{\\partial}{\\partial\\theta} l_n(X;\\theta)\\right)^2\\right) \\end{align}\\] d’où \\[\\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2} l_n(X;\\theta)\\right)=-\\mathbb{E}_{\\theta}\\left(\\left(\\frac{\\partial}{\\partial\\theta} l_n(X;\\theta)\\right)^2\\right)\\] ce qui achève la démonstration. \\(\\square\\) L’information de Fisher vérifie une propriété d’additivité : Théorème (additivité de l’information de Fisher) : Si l’ensemble \\(\\left\\{x\\in\\mathbb{R}^n, f(x;\\theta)&gt;0\\right\\}\\) ne dépend pas de \\(\\theta\\), alors l’information de Fisher est additive, i.e. \\[I_n(\\theta)=n\\,I_1(\\theta)\\] Si le domaine de \\(X\\) ne dépend pas de \\(\\theta\\), l’information de Fisher apportée par un échantillon \\((X_1,\\dots,X_n)\\) est donc égale à \\(n\\) fois l’information de Fisher apportée par chacune des observations \\(X_i\\). Cela signifie que chaque observation apporte la même information de Fisher. 7.1.5.2 Borne de Fréchet-Darmois-Cramer-Rao Sous certaines hypothèses, on peut montrer que la variance d’un estimateur sans biais ne peut être inférieure à une certaine borne, appelée borne de Fréchet-Darmois-Cramer-Rao, liée à l’information de Fisher : Théorème : On suppose que les hypothèses suivantes, appelées hypothèses de Cramer-Rao, sont vérifiées : (H1) : \\(\\Theta\\) est un ouvert sur lequel \\(f(x;\\theta)&gt;0\\) et \\(\\theta\\mapsto f(x;\\theta)\\) est dérivable pour tout \\(x\\) (H2) : on peut permuter \\(\\int\\) et \\(\\frac{\\partial}{\\partial\\theta}\\) (H3) : \\(\\forall\\theta\\in\\Theta, \\, I_n(\\theta)&gt;0\\) (H4) : \\(g:\\Theta\\longrightarrow\\mathbb{R}\\) est une fonction dérivable Alors, pour tout estimateur sans biais \\(T_n=T_n(X_1,\\dots, X_n)\\) de \\(g(\\theta)\\) on a l’inégalité \\[\\mathbb{V}_{\\theta}(T_n)\\geq\\frac{\\left(g&#39;(\\theta)\\right)^2}{I_n(\\theta)}\\] Le nombre \\(\\frac{\\left(g&#39;(\\theta)\\right)^2}{I_n(\\theta)}\\) s’appelle la borne de Fréchet-Darmois-Cramer-Rao (FDCR). Dans le cas particulier où \\(T_n=\\widehat{\\theta}_n\\) est un estimateur sans biais de \\(\\theta\\) (cas où \\(g(\\theta)=\\theta\\)) on a \\(\\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)\\geq\\frac{1}{I_n(\\theta)}\\). Ce théorème est admis. La borne FDCR n’est pas nécessairement atteinte. Quand elle l’est, l’estimateur qui l’atteint est dit efficace : Estimateurs efficaces Un estimateur \\(T_n\\) sans biais de \\(g(\\theta)\\) tel que \\(\\mathbb{V}_{\\theta}(T_n)=\\frac{\\left(g&#39;(\\theta)\\right)^2}{I_n(\\theta)}\\) est appelé un estimateur efficace. 7.1.5.3 Statistiques exhaustives Tout échantillon \\((X_1,\\dots, X_n)\\) tel que \\(X_i\\sim\\mathcal{L}_{\\theta}\\) apporte de l’information sur le paramètre inconnu \\(\\theta\\), et donc sur la loi inconnue \\(\\mathcal{L}_{\\theta}\\). Plutôt que de faire de l’inférence à partir de l’échantillon \\((X_1,\\dots, X_n)\\) on préfère en général utiliser une statistique \\(T_n=T(X_1,\\dots,X_n)\\), qui est une sorte de résumé de l’échantillon tout entier. La contrepartie est qu’en général, le passage de \\((X_1,\\dots,X_n)\\) à son résumé \\(T_n\\) génère une perte d’information sur \\(\\theta\\). Une statistique exhaustive est une statistique qui n’engendre pas de telle perte, autrement dit elle contient toute l’information sur \\(\\theta\\) contenue dans l’échantillon \\((X_1,\\dots, X_n)\\). On formalise cette idée de la façon suivante : Statistiques exhaustives Une statistique \\(T_n\\) est dite exhaustive si la loi conditionnelle \\(\\mathcal{L}(X|T_n=t)\\) est indépendante de \\(\\theta\\). Conditionnellement à l’observation \\(T=t\\), la loi de \\(X\\) ne dépend plus de \\(\\theta\\) : \\[\\mathbb{P}(X=x|T=t,\\theta)=\\mathbb{P}(X=x|T=t) \\text{ (pour une loi discrète)}\\] \\[f(x|T=t,\\theta)=f(x|T=t) \\text{ (pour une loi continue)}\\] Dit autrement, une fois que l’on sait que \\(T_n=t\\), ajouter la connaissance de \\(X\\) n’apporte plus aucune information supplémentaire sur \\(\\theta\\). Cette définition n’est pas très commode à manipuler, et en pratique pour démontrer qu’une statistique est (ou n’est pas) exhaustive on utilise plutôt le théorème de factorisation de Neyman-Fisher : Théorème (factorisation de Neyman-Fisher) : Une statistique \\(T_n\\) est exhaustive si, et seulement s’il existe deux fonctions mesurables positives \\(g\\) et \\(h\\) telles qu’on ait la factorisation suivante : \\[L_n(x;\\theta)=g(T_n(x);\\theta).h(x)\\] Remarques : i. La notion de mesurabilité n’est pas au programme du concours. Il s’agit d’une classe très générale de fonctions, qui englobe en particulier les fonctions continues, continues par morceaux etc. Il est même assez compliqué de construire une fonction non mesurable. En pratique : pour démontrer qu’une statistique est exhaustive, il suffit de montrer qu’une telle décomposition existe avec \\(g\\) et \\(h\\) continues (car continue implique mesurable) ; pour démontrer qu’une telle statistique n’est pas exhaustive, il suffit de démontrer qu’une telle décomposition avec \\(g\\) et \\(h\\) quelconques est impossible (elle sera en particulier impossible avec \\(g\\) et \\(h\\) mesurables). ii. Il n’y a pas unicité du couple \\((g,h)\\). Par exemple, si \\((g,h)\\) permet une factorisation, alors pour tout \\(\\lambda\\) strictement positif \\(\\left(\\lambda g, \\frac{h}{\\lambda}\\right)\\) aussi. 7.1.5.4 Famille exponentielle Les densités suivantes assurent l’existence d’une statistique exhaustive : Théorème de Darmois : Soit \\(\\theta\\in\\Theta\\subset\\mathbb{R}\\). Soit \\(f(x;\\theta)\\) une densité telle que l’ensemble \\(\\{x\\in\\mathbb{R}^n, \\, f(x;\\theta)&gt;0\\}\\) ne dépend pas de \\(\\theta\\). Alors, l’échantillon \\((X_1,\\dots,X_n)\\) admet une statistique exhaustive si et seulement si \\(f(x;\\theta)\\) est de la forme \\[f(x;\\theta)=\\exp\\left(a(x)\\alpha(\\theta)+b(x)+\\beta(\\theta)\\right)\\] Par ailleurs, si l’application \\(a\\) est de classe \\(\\mathcal{C}^1\\), alors \\(T_n\\equiv\\sum\\limits_{i=1}^n a(X_i)\\) est une statistique exhaustive. La famille des densités \\(f(x;\\theta)\\) vérifiant ces propriétés s’appelle la famille exponentielle. Remarque. Ici, on convient de parler de densité aussi bien pour une variable discrète que pour une variable continue. Pour une variable discrète, la densité est par définition \\(f(x;\\theta)\\equiv\\mathbb{P}_{\\theta}(X=x)\\). Exemple (loi de Poisson). La densité d’une loi de Poisson de paramètre \\(\\lambda\\) est \\(f(x;\\lambda)=e^{-\\lambda}\\frac{\\lambda^x}{x!}\\mathbb{1}_{x\\in\\mathbb{N}}\\). L’ensemble \\(\\left\\{x\\in\\mathbb{R},\\,f(x;\\theta)&gt;0\\right\\}\\) est \\(\\mathbb{N}\\), qui ne dépend pas de \\(\\lambda\\). Par ailleurs : \\[f(x;\\lambda)=\\exp\\left(-\\lambda+x\\,\\ln(\\lambda)-\\sum\\limits_{i=1}^x \\ln i\\right)\\] On reconnait bien la forme générale d’une densité de la famille exponentielle, avec \\(a(x)=x\\), \\(\\alpha(\\lambda)=\\ln(\\lambda)\\), \\(b(x)=\\sum\\limits_{i=1}^x \\ln i\\), \\(\\beta(\\lambda)=-\\lambda\\). L’application \\(a\\) est par ailleurs de classe \\(\\mathcal{C}^1\\). On en déduit avec le théorème de Darmois que la statistique \\(T_n=\\sum\\limits_{i=1}^n X_i\\) est une statistique exhaustive pour \\(\\theta\\). La famille exponentielle permet de construire des estimateurs efficaces. Théorème : On suppose les hypothèses de Cramer-Rao vérifiées. On suppose également que \\(\\theta\\mapsto \\frac{\\partial}{\\partial\\theta}f(x;\\theta)\\) est continue en \\(\\theta\\). Soit \\(T_n\\) un estimateur sans biais de \\(g(\\theta)\\). Alors, \\(T_n\\) est un estimateur efficace si et seulement si la densité \\(f(x;\\theta)\\) appartient à la famille exponentielle. 7.1.5.5 Rao-Blackwellisation d’un estimateur Le théorème de Rao-Blacwell montre comment améliorer un estimateur. Théorème de Rao-Blackwell : Soient \\(T_n\\) une statistique exhaustive et \\(S\\) un estimateur sans biais de \\(g(\\theta)\\). Alors, l’estimateur \\(\\mathbb{E}_{\\theta}(S|T_n)\\) est sans biais et \\(\\mathbb{V}_{\\theta}(\\mathbb{E}_{\\theta}(S|T_n))\\leq\\mathbb{V}_{\\theta}(S)\\). L’estimateur \\(\\mathbb{E}_{\\theta}(S|T_n)\\) est dit préférable à l’estimateur \\(S\\). 7.1.6 Estimation des coefficients d’une régression linéaire 7.1.6.1 Présentation du modèle \\(X\\) et \\(Y\\) sont deux variables aléatoires pour lesquelles on dispose d’observations \\(x_1,\\dots, x_n\\) et \\(y_1,\\dots y_n\\). On considère le modèle \\[Y_i=aX_i+b+u_i\\] où \\((a,b)\\) est un couple de réels inconnus et \\(u_i\\) est un terme d’erreur (inconnu lui aussi). Le but est d’estimer des coefficients \\((a,b)\\) à partir de l’échantillons d’observations \\((x_i, y_i)\\) et de donner des propriétés des estimateurs obtenus sous certaines hypothèses. Hypothèses du modèle. On fait les hypothèses suivantes : (H1) : Les couples \\((X_i, Y_i)\\) sont i.i.d. (H2) : Les termes d’erreur \\(u_i\\) sont indépendants des \\(X_i\\) (H3) : \\(\\mathbb{E}(u_i|X_i)=0\\) (hypothèse d’exogénéité) (H4) : \\(\\mathbb{V}(u_i|X_i)=\\sigma_u^2\\) ne dépend pas de \\(X_i\\) (hypothèse d’homoscédasticité) (H5) : \\(u_i|X_i\\sim\\mathcal{N}(0, \\sigma_u^2)\\) (hypothèse de normalité des termes d’erreur) On présente deux approches différentes pour estimer \\(a\\) et \\(b\\) : par la méthode des moindres carrés et par maximum de vraisemblance. Bien que différentes, ces méthodes vont fournir les mêmes estimateurs. Avant cela, on rappelle quelques résultats classiques de statistique descriptive. 7.1.6.2 Rappels utiles Avant de présenter cette méthode, on rappelle des égalités qui àa la fois très utiles et très classiques. Il faut les connaître pour le concours et savoir les redémontrer. Moyenne, covariance, variance Pour \\(x=(x_1,\\dots, x_n)\\in\\mathbb{R}^n\\) on note \\(\\overline{x}_n=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i\\) la moyenne de \\(x\\) \\(\\sigma_x^2=\\frac{1}{n}\\sum\\limits_{i=1}^n(x_i-\\overline{x}_n)^2\\) la variance de \\(x\\) si de plus \\(y=(y_1,\\dots, y_n)\\), \\(\\sigma_{xy}=\\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n)\\) est la covariance de \\(x\\) et \\(y\\). On a alors les égalités suivantes : 1. \\(\\sigma_{xx}=\\sigma_x^2\\) 2. \\(\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)=0\\) 3. Différentes formules de la covariance : \\[\\begin{align} \\sigma_{xy} &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n) \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n(x_i-\\overline{x}_n)y_i \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_i(y_i-\\overline{y}_n) \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_iy_i-\\overline{x}_n\\overline{y}_n \\end{align}\\] 4. Différentes formules de la variance : \\[\\begin{align} \\sigma_x^2 &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)^2 \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_i^2-(\\overline{x}_n)^2 \\end{align}\\] Démonstration. 1. Evidente 2. \\[\\begin{align} \\sum\\limits_{i=1}^n (x_i-\\overline{x}_n) &amp;= \\sum\\limits_{i=1}^n x_i -n\\overline{x}_n \\\\ &amp;= n\\overline{x}_n-n\\overline{x}_n \\\\ &amp; =0 \\end{align}\\] 3. \\[\\begin{align} \\sigma_{xy} &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n) \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)y_i-\\frac{\\overline{y}_n}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n) \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)y_i \\end{align}\\] d’après l’égalité 2. Par symétrie des rôles joués par \\(x\\) et \\(y\\) on a donc aussi \\(\\sigma_{xy}=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i(y_i-\\overline{y}_n)\\). On montre la dernière égalité : \\[\\begin{align} \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n) &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)y_i \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_iy_i-\\overline{x}_n\\frac{1}{n}\\sum\\limits_{i=1}^n y_i \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n x_iy_i-\\overline{x}_n\\overline{y}_n \\end{align}\\] 4. On applique la dernière égalité de 4 dans le cas particulier où \\(x=y\\). On obtient alors \\[\\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)^2=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i^2-\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n x_i\\right)^2\\] \\(\\square\\) 7.1.6.3 Estimation de \\(a\\) et \\(b\\) par la méthode des moindres carrés On montre maintenant les formules des estimateurs de \\(a\\) et \\(b\\) par application de la méthode des moindres carrés : Estimation de \\(a\\) et \\(b\\) par la méthode des moindres carrés La méthode des moindres carrés consiste à minimiser l’erreur quadratique globale \\[E(\\alpha,\\beta)\\equiv\\sum\\limits_{i=1}^n (Y_i-\\alpha X_i-\\beta)^2\\] qui représente l’erreur globale faite en approchant \\(Y_i\\) par \\(\\alpha X_i+\\beta\\). Cette méthode fournit les estimateurs suivants de \\(a\\) et \\(b\\) : \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\widehat{a} &amp;= \\frac{\\overline{\\sigma_{XY}}}{\\overline{\\sigma^2_X}} \\\\ \\widehat{b} &amp;= \\overline{Y}_n-\\widehat{a}\\overline{X}_n \\end{array} \\right. \\end{align}\\] où on note \\(\\overline{\\sigma_{XY}}=\\frac{1}{n}\\sum\\limits_{i=1}^n(X_i-\\overline{X}_n)(Y_i-\\overline{Y}_n)\\) et \\(\\overline{\\sigma^2_X}=\\overline{\\sigma_{XX}}=\\frac{1}{n}\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\). Démonstration. La fonction \\((\\alpha, \\beta)\\mapsto E(\\alpha, \\beta)\\) est deux fois dérivable par rapport à chacune de ses variables. Conditions de premier ordre (CPO) : Les conditions du premier ordre s’écrivent \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\frac{\\partial}{\\partial\\alpha} E(\\alpha, \\beta) &amp;=0 \\\\ \\frac{\\partial}{\\partial\\beta} E(\\alpha, \\beta) &amp;=0 \\\\ \\end{array} \\right. \\end{align}\\] i.e. \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\sum\\limits_{i=1}^n X_i Y_i-\\alpha\\sum\\limits_{i=1}^n X_i^2-\\beta\\sum\\limits_{i=1}^n X_i&amp;=0 \\\\ \\sum\\limits_{i=1}^n Y_i-\\alpha\\sum\\limits_{i=1}^n X_i-n\\beta &amp;= 0 \\\\ \\end{array} \\right. \\end{align}\\] Il s’agit d’un système de deux équations à deux inconnues \\((\\alpha, \\beta)\\). Sa résolution donne \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\alpha &amp;= \\frac{\\frac{1}{n}\\sum\\limits_{i=1}^n X_iY_i-\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\right)\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n Y_i\\right)}{\\frac{1}{n}\\sum\\limits_{i=1}^n X_i^2-\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\right)^2} \\\\ \\beta &amp;= \\overline{Y}_n-\\alpha\\overline{X}_n \\end{array} \\right. \\end{align}\\] soit encore \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\alpha &amp;= \\frac{\\overline{\\sigma_{XY}}}{\\overline{\\sigma^2_X}} \\\\ \\beta &amp;= \\overline{Y}_n-\\alpha\\overline{X}_n \\end{array} \\right. \\end{align}\\] Par ailleurs, pour tout couple \\((x, y)\\) de réels, la fonction \\((\\alpha, \\beta)\\mapsto (y-\\alpha x-\\beta)^2\\) est convexe. Le point critique trouvé ci-dessus est donc un minimum. On en déduit le résultat. \\(\\square\\) 7.1.6.4 Estimation de \\(a\\) et \\(b\\) par la méthode du maximum de vraisemblance La méthode par maximum de vraisemblance requiert une information supplémentaire : celle de la distribution de la variable de terme d’erreur \\(u\\). Or, une telle information est justement donnée ici par l’hypothèse (H5) de distribution normale du terme d’erreur. Estimation de \\(a\\) et \\(b\\) par la méthode du maximum de vraisemblance. Sous l’hypothèse \\((H5)\\) de distribution normale des termes d’erreur, la méthode par maximum de vraisemblance fournit les mêmes estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) que la méthode des moindres carrés. Démonstration. La vraisemblance est donnée par \\[L_n((\\alpha,\\beta);u)=\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi}\\sigma_u}e^{-\\frac{(Y_i-\\alpha X_i-\\beta)^2}{2\\sigma_u^2}}\\] On passe à la log-vraisemblance, qui est plus simple à dériver \\[l_n((\\alpha,\\beta);u)=-n\\ln(\\sqrt{2\\pi}\\sigma_u^2)-\\frac{(Y_i-\\alpha X_i-\\beta)^2}{2\\sigma_u^2}\\] On résout alors en \\((\\alpha, \\beta)\\) le système d’équations \\[\\begin{align} \\frac{\\partial l_n}{\\partial\\alpha}l((\\alpha,\\beta);u) &amp;= 0 \\\\ \\frac{\\partial l_n}{\\partial\\beta}l((\\alpha,\\beta);u) &amp;= 0 \\\\ \\end{align}\\] soit \\[\\begin{align} \\frac{X_i(Y_i-\\alpha X_i-\\beta)}{2\\sigma_u^2} &amp;= 0 \\\\ \\frac{Y_i-\\alpha X_i-\\beta}{2\\sigma_u^2} &amp;= 0 \\\\ \\end{align}\\] On vérifie facilement qu’on obtient le même couple de solution qu’avec la méthode des moindres carrés, et que ce couple constitue bien un maximum de la log-vraisemblance. \\(\\square\\) Remarque : Dans des approches plus générales que celle présentée ici, aucune hypothèse n’est faite sur la distribution des termes d’erreur. Dans ce cas, la méthode par maximum de vraisemblance n’est plus applicable. On peut cependant toujours utiliser la méthode des moindres carrés. 7.1.6.5 Absence de biais des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) Théorème : (absence de biais des estimateurs MCO) Les estimateurs \\[\\widehat{a}=\\frac{\\overline{\\sigma_{XY}}}{\\overline{\\sigma_X^2}}\\] et \\[\\widehat{b}=\\overline{Y}_n-\\widehat{a}\\overline{X}_n\\] sont des estimateurs sans biais de \\(a\\) et \\(b\\). Démonstration. On remarque d’abord qu’avec l’hypothèse d’exogénéité (H3) \\(\\mathbb{E}(u_i|X_i)=0\\) on a \\(\\mathbb{E}(Y_i|X_i)=aX_i+b\\) et donc \\(\\mathbb{E}(Y_i-\\overline{Y}_n|X_1,\\dots, X_n)=a(X_i-\\overline{X}_n)\\). D’où \\[\\begin{align} \\mathbb{E}(\\widehat{a}|X_1,\\dots, X_n) &amp;= \\mathbb{E}\\left(\\left.\\frac{\\frac{1}{n}\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)(Y_i-\\overline{Y}_n)}{\\overline{\\sigma_X^2}}\\right|X_1,\\dots, X_n\\right) \\\\ &amp;=\\frac{1}{\\overline{\\sigma_X^2}}\\frac{1}{n}\\sum\\limits_{i=1}^n(X_i-\\overline{X}_n)\\mathbb{E}(\\left. Y_i-\\overline{Y}_n\\right|X_1\\,\\dots,X_n) \\\\ &amp;= a\\frac{1}{\\overline{\\sigma_X^2}}\\frac{1}{n}\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2 \\\\ &amp; =a\\frac{\\overline{\\sigma_X^2}}{\\overline{\\sigma_X^2}} \\\\ &amp; =a \\end{align}\\] Par ailleurs \\[\\begin{align} \\mathbb{E}(\\widehat{b}|X_1,\\dots,X_n)&amp;=\\mathbb{E}(\\overline{Y}_n-\\widehat{a}\\overline{X}_n|X_1,\\dots,X_n) \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n \\mathbb{E}(Y_i|X_1,\\dots,X_n)-\\overline{X}_n\\mathbb{E}(\\widehat{a}|X_1,\\dots,X_n) \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n (aX_i+b)-a\\overline{X}_n \\\\ &amp;= a\\overline{X}_n+b-a\\overline{X}_n \\\\ &amp;= b \\end{align}\\] \\(\\square\\) 7.1.6.6 Variance des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) Théorème (variance des estimateurs MCO) Les estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) ont pour variances \\[\\begin{align} \\mathbb{V}(\\widehat{a}|X_1,\\dots, X_n) &amp;= \\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2} \\\\ \\mathbb{V}(\\widehat{b}|X_1,\\dots,X_n) &amp;=\\sigma_u^2\\left(\\frac{1}{n}+ \\frac{\\overline{X}_n^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}\\right) \\end{align}\\] Démonstration. On remarque tout d’abord que \\[\\mathbb{V}(Y_i|X_1,\\dots,X_n)=\\sigma_u^2\\] En effet \\[\\begin{align} \\mathbb{V}(Y_i|X_1,\\dots,X_n) &amp;= \\mathbb{V}(aX_i+b+u_i|X_1,\\dots, X_n) \\\\ &amp;= \\mathbb{V}(u_i|X_1,\\dots,X_n) \\\\ &amp;= \\sigma_u^2 \\end{align}\\] Le passage de la première à la deuxième ligne vient du fait qu’à \\(X_1,\\dots, X_n\\) fixées, \\(aX_i+b\\) est considérée comme une constante, et donc ce terme a une contribution à la variance conditionnellement à \\(X_1,\\dots X_n\\). On a donc \\[\\begin{align} \\mathbb{V}(\\widehat{a}|X_1,\\dots X_n) &amp;= \\mathbb{V}\\left(\\left.\\frac{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)Y_i}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}\\right|X_1,\\dots, X_n\\right) \\\\ &amp;= \\frac{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\mathbb{V}(Y_i|X_1,\\dots,X_n)}{\\left(\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\right)^2} \\\\ &amp; \\text{ (somme de VA i.i.d.)} \\\\ &amp;= \\frac{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\sigma_u^2}{\\left(\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\right)^2} \\\\ &amp;= \\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2} \\end{align}\\] et \\[\\begin{align} \\mathbb{V}(\\widehat{b}|X_1,\\dots,X_n) &amp;= \\mathbb{V}(\\overline{Y}_n-\\widehat{a}\\overline{X}_n|X_1,\\dots,X_n) \\\\ &amp;= \\mathbb{V}(a\\overline{X}_n+b+\\overline{u}_n-\\widehat{a}\\overline{X}_n|X_1,\\dots,X_n) \\\\ &amp;= \\mathbb{V}((a-\\widehat{a}\\overline{X}_n)+b+\\overline{u}_n|X_1,\\dots, X_n) \\\\ &amp;= \\overline{X}_n^2\\underbrace{\\mathbb{V}(\\widehat{a}|X_1,\\dots,X_n)}_{=\\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}}+\\underbrace{\\mathbb{V}(\\overline{u}_n|X_1,\\dots,X_n)}_{=\\frac{\\sigma_u^2}{n} \\text{ car } u_i \\text{ i.i.d. de variance } \\sigma_u^2} \\\\ &amp;= \\overline{X}_n^2\\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}+\\frac{\\sigma_u^2}{n} \\\\ &amp;= \\sigma_u^2\\left(\\frac{1}{n}+\\frac{\\overline{X}_n^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}\\right) \\end{align}\\] \\(\\square\\) 7.1.6.7 Résidus La variance \\(\\sigma_u^2\\) des termes d’erreur \\(u_i\\) n’est pas connue. Cependant, elle peut être estimée. Pour cela, on introduit la notion de résidu. Le résidu \\(\\widehat{u}_i\\) est défini comme l’écart entre la vraie valeur \\(Y_i\\) et sa prédiction \\(\\widehat{Y}_i=\\widehat{a}X_i+\\widehat{b}\\) : \\[\\widehat{u}_i\\equiv Y_i-\\widehat{Y}_i\\] On a donc \\[\\widehat{u}_i=Y_i-\\widehat{a}X_i-\\widehat{b}\\] Il s’agit d’une estimation (sans biais) de la vraie erreur \\[u_i=Y_i-aX_i-b\\] Théorème (estimation de la variance) : \\(\\sigma_u^2\\) La variance \\(\\sigma_u^2\\) est estimée par \\[s^2=\\frac{1}{n-2}\\sum\\limits_{i=1}^n \\widehat{u}_i^2\\] 7.1.6.8 Distributions des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) On admet alors le résultat suivant Théorème : Sous l’hypothèse de normalité des termes d’erreur \\(u_i\\), on a \\[\\frac{(n-2)s^2}{\\sigma_u^2}\\sim\\chi^2_{(n-2)}\\] et les statistiques \\[\\frac{\\widehat{a}-a}{s\\sqrt{\\frac{1}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}}}\\] et \\[\\frac{\\widehat{b}-b}{s\\sqrt{\\frac{1}{n}+\\frac{\\overline{X}_n^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}}}\\] suivent une loi de Student à \\(n-2\\) degrés de liberté. 7.1.6.9 Convergence des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) Si on suppose que les \\(X_i\\) admettent des moments d’ordre \\(1\\) et \\(2\\), alors on peut montrer que les estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) sont des estimateurs convergents. On sait déjà qu’ils sont sans biais, il suffit donc de démontrer que leurs variances tendent vers \\(0\\). Or, comme \\(X_i\\) admet des moments d’ordres \\(1\\) et \\(2\\) on a, conditionnellement à \\(X_1,\\dots,X_n\\) : \\[\\overline{X}_n\\approx\\mathbb{E}(X)\\] et \\[\\sum\\limits_{i=1}^n(X_i-\\overline{X}_n)^2\\approx n\\mathbb{V}(X_1)\\] On en déduit que \\[\\mathbb{V}(\\widehat{a}|X_1,\\dots, X_n)\\approx\\frac{\\sigma_u^2}{n\\mathbb{V}(X_1)}\\longrightarrow 0\\] et \\[\\mathbb{V}(\\widehat{b}|X_1,\\dots,X_n)\\approx\\sigma_u^2\\left(\\frac{1}{n}+\\frac{\\overline{X}_n^2}{n\\mathbb{V}(X_1)}\\right)\\longrightarrow 0\\] \\(\\widehat{a}\\) et \\(\\widehat{b}\\) sont des estimateurs sans biais de \\(a\\) et \\(b\\) de variances asymptotiquement nulles. Ce sont donc des estimateurs convergents de \\(a\\) et \\(b\\). 7.1.7 Intervalles de confiance Jusqu’à présent, l’estimation était uniquement envisagée du point de vue de l’estimation ponctuelle : il s’agissait, à partir de l’observation d’un échantillon \\((X_1,\\dots,X_n)\\) de fournir une valeur ponctuelle \\(\\widehat{\\theta}_n\\) approchant la vraie valeur inconnue d’un paramètre \\(\\theta\\). Cependant, la valeur estimée dépend de l’échantillon tiré. En effet, si l’on tire \\(1,000\\) échantillons différents, on va obtenir \\(1\\,000\\) estimations \\(\\widehat{\\theta}^{(1)}_n,\\dots,\\widehat{\\theta}^{(1\\,000)}_n\\) a priori différentes également. Certaines de ces estimations peuvent être des valeurs atypiques. Se pose donc la question de la confiance que l’on peut accorder à l’estimation obtenue à partir d’une seule réalisation particulière \\((x_1,\\dots,x_n)\\) de l’échantillon, puisqu’en pratique c’est tout ce dont on dispose pour inférer sur \\(\\theta\\). L’approche présentée jusqu’ici ne répond pas à cette question. Le bon outil pour aborder ce problème est la notion d’intervalle de confiance. Intervalles de confiance Soit \\(\\theta\\) un paramètre inconnu et \\(\\alpha\\) un réel compris entre \\(0\\) et \\(1\\). On appelle intervalle de confiance de niveau \\(1-\\alpha\\) du paramètre \\(\\theta\\) tout intervalle \\([a;b]\\) tel que \\[\\mathbb{P}\\left(\\theta\\in [a;b]\\, \\right)=1-\\alpha\\] Remarques : i. Les réels \\(a\\) et \\(b\\) dépendent de \\(\\theta\\), du niveau de confiance \\(1-\\alpha\\). En pratique, pour les déterminer on utilise l’échantillon \\((X_1,\\dots, X_n)\\), ou plus précisément un résumé \\(T_n\\) de cet échantillon, i.e. une statistique \\(T_n=T_n(X_1,\\dots,X_n)\\). On a donc \\[\\begin{align} a &amp;= a_n(T_n\\,;\\,\\theta\\,;\\,\\alpha) \\\\ b &amp;= b_n(T_n\\,;\\,\\theta\\,;\\,\\alpha) \\\\ \\end{align}\\] Ce sont donc des variables aléatoires, que l’on notera désormais plus simplement \\(a_n\\) et \\(b_n\\). L’intervalle de confiance est donc lui-même un objet aléatoire. ii. Idéalement, on aimerait savoir avec certitude que \\(\\theta\\in [a,b]\\). Comme les réels \\(a\\) et \\(b\\) dépendent de l’échantillon tiré, on ne peut espérer mieux qu’une probabilité d’appartenance de \\(\\theta\\) à \\([a,b]\\). A défaut qu’elle soit égale à 1, on la veut proche de \\(1\\), autrement dit on veut \\(\\alpha\\) proche de \\(0\\). En pratique, on prendra souvent \\(\\alpha=0,05\\), parfois \\(\\alpha=0,01\\). iii. Le réel \\(\\alpha\\) représente un risque : celui de donner un intervalle de confiance qui ne contienne pas la vraie valeur de \\(\\theta\\). iv. Réduire la valeur de \\(\\alpha\\) n’est pas gratuit. Le prix à payer est un élargissement de l’intervalle de confiance \\([a,b]\\), ce qui signifie des intervalles de confiance moins fins et donc moins informatifs sur la vraie valeur de \\(\\theta\\). Inversement, si on veut des intervalles de confiance plus fins, il faut assumer un risque plus grand d’avoir un intervalle de confiance laissant échapper le vrai \\(\\theta\\). On voit maintenant une méthode générale de construction de \\([a_n\\,;\\,b_n]\\). Construction d’un intervalle de confiance On cherche un couple de réels \\((a_n,b_n)\\) tel que \\[\\mathbb{P}\\left(a_n\\leq \\theta\\leq b_n\\right)=1-\\alpha\\] On suppose qu’on dispose d’une statistique \\(T_n\\) à partir de laquelle on calcule ces réels : \\[\\begin{align} a_n &amp;= a_n(T_n) \\\\ b_n &amp;= b_n(T_n) \\end{align}\\] On cherche alors à transformer l’écriture \\(\\theta\\in[a_n(T_n)\\,;\\,b_n(T_n)]\\) en une écriture équivalente du type \\(T_n\\in[\\alpha_n(\\theta)\\,;\\,\\beta_n(\\theta)]\\), autrement dit on veut \\[\\theta\\in[a_n(T_n)\\,;\\,b_n(T_n)]\\Leftrightarrow T_n\\in[\\alpha_n(\\theta)\\,;\\,\\beta_n(\\theta)]\\] Dans ce cas, on doit avoir \\[\\mathbb{P}\\left(T_n\\in[\\alpha_n(\\theta)\\,;\\,\\beta_n(\\theta)]\\right)=1-\\alpha\\] Il s’agit donc de trouver un couple de réels \\((\\alpha_n,\\beta_n)=(\\alpha_n(\\theta),\\beta_n(\\theta))\\) tel que \\[F_{T_n}(\\beta_n)-F_{T_n}(\\alpha_n)=1-\\alpha\\] ou, de façon équivalente \\[\\mathbb{P}(T_n&lt;\\alpha_n)+\\mathbb{P}(T_n&gt;\\beta_n)=\\alpha\\] Remarque. La dernière égalité s’interprète comme un risque à répartir entre \\(\\mathbb{P}(T_n&lt;\\alpha_n)\\) et \\(\\mathbb{P}(T_n&gt;\\alpha_n)\\). Une première approche pour construire des intervalles de confiance consiste à utiliser, lorsque cela est possible, l’inégalité de Bienaymé-Tchebychev : Construction d’intervalles de confiance par application de l’inégalité de Bienaymé-Tchebychev Soit \\(\\widehat{\\theta}_n\\) un estimateur sans biais de \\(\\theta\\) et admettant une variance \\(\\sigma^2\\). On peut donc appliquer l’inégalité de Bienaymé-Tchebychev : \\[\\mathbb{P}\\left(|\\widehat{\\theta}_n-\\theta|\\geq\\varepsilon\\right)\\leq\\frac{\\sigma^2}{\\varepsilon^2}\\] soit \\[\\mathbb{P}\\left(|\\widehat{\\theta}_n-\\theta|&lt;\\varepsilon \\right)&gt;1-\\frac{\\sigma^2}{\\varepsilon^2}\\] On choisit \\(\\varepsilon\\) de façon à avoir \\(\\alpha=\\frac{\\sigma^2}{\\varepsilon^2}\\), i.e. on pose \\[\\varepsilon=\\frac{\\sigma}{\\sqrt{\\alpha}}\\] Par inversion des inégalités on a \\(|\\widehat{\\theta}_n-\\theta|&lt;\\varepsilon\\Leftrightarrow\\widehat{\\theta}_n-\\varepsilon&lt;\\theta&lt;\\widehat{\\theta}_n+\\varepsilon\\). On en déduit un intervalle de confiance de \\(\\theta\\) au niveau de confiance \\(1-\\alpha\\) : \\[IC^{1-\\alpha}_m=\\left[\\widehat{\\theta}_n-\\frac{\\sigma}{\\sqrt{\\alpha}}\\,;\\,\\widehat{\\theta}_n+\\frac{\\sigma}{\\sqrt{\\alpha}}\\right]\\] Exemple (moyenne empirique). Soient \\(X\\) une VA admettant une espérance \\(m\\) et une variance \\(\\sigma^2\\), et \\((X_1,\\dots, X_n)\\) des VA i.i.d. de même loi que \\(X\\). La moyenne empirique \\(\\widehat{\\theta}_n\\equiv\\overline{X}_n\\) est un estimateur sans biais de \\(\\theta\\equiv m\\) et admettant comme variance \\(\\frac{\\sigma^2}{n}\\), on peut donc appliquer ce qui précède et obtenir un intervalle de confiance de \\(m\\) au niveau de confiance \\(1-\\alpha\\) : \\[IC^{1-\\alpha}_m=\\left[\\overline{X}_n-\\frac{\\sigma}{\\sqrt{n\\alpha}}\\,;\\,\\overline{X}_n+\\frac{\\sigma}{\\sqrt{n\\alpha}}\\right]\\] Pour le concours d’administrateur, il est précisé que la construction d’intervalle de confiances est abordée dans un contexte d’application du théorème central limite (Construction d’un intervalle de confiance dans le cadre des modèles d’échantillonnage, dans le cas où le théorème central limite s’applique.). En d’autres termes, il s’agit de se ramener - si l’on n’y est pas déjà - au cas d’une loi normale et d’en déduire un intervalle de confiance (asymptotique). On commence par considérer le cas où la statistique \\(T_n\\) est gaussienne. Construction d’intervalles de confiance dans le cas gaussien Supposons que \\(X\\) suive une loi normale : \\[X\\sim\\mathcal{N}(m,\\sigma^2)\\] Exemple : estimation de \\(m\\) lorsque \\(\\sigma\\) est connu. \\(m\\) est l’espérance de \\(X\\), on peut l’estimer par la moyenne empirique \\[\\overline{X}_n\\sim\\mathcal{N}\\left(m\\,;\\,\\frac{\\sigma^2}{n}\\right)\\] on commence par centrer et réduire \\(\\overline{X}_n\\) pour se ramener à une loi normale standard \\(\\mathcal{N}(0,1)\\). On pose donc \\[Z_n\\equiv\\frac{\\overline{X}_n-m}{\\frac{\\sigma}{\\sqrt{n}}}\\] on cherche ensuite un intervalle \\([-v,v]\\) de niveau de confiance \\(1-\\alpha\\) pour \\(Z_n\\). Comme \\(Z_n\\) est symétrique par rapport à \\(0\\), il est plus simple de le chercher sous la forme \\([-v,v]\\). On résout donc, en notant \\(\\Phi\\) la fonction de répartition d’un loi normale standard et en remarquant que \\(\\Phi(-x)=1-\\Phi(x)\\) : \\[\\begin{align} \\Phi(v)-\\Phi(-v) &amp;= 1-\\alpha \\\\ 2\\Phi(v)-1 &amp;= 1-\\alpha \\\\ \\Phi(v) &amp;= 1-\\frac{\\alpha}{2} \\\\ v &amp;= \\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right) \\end{align}\\] on en déduit un intervalle de confiance de niveau \\(1-\\alpha\\) pour \\(m\\) : \\[\\begin{align} &amp; -v\\leq Z_n \\leq v \\\\ \\text{ssi } &amp; -v\\leq\\frac{\\overline{X}_n-m}{\\frac{\\sigma}{\\sqrt{n}}}\\leq n \\\\ \\text{ssi } &amp; \\overline{X}_n-\\frac{\\sigma}{\\sqrt{n}}v\\leq m\\leq \\overline{X}_n+\\frac{\\sigma}{\\sqrt{n}}v &amp; \\\\ \\end{align}\\] Un intervalle de confiance de \\(m\\) au niveau \\(1-\\alpha\\) est donc \\[\\text{IC}^m_{1-\\alpha}\\equiv\\left[\\overline{X}_n-\\frac{\\sigma}{\\sqrt{n}}\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right) \\, , \\, \\overline{X}_n+\\frac{\\sigma}{\\sqrt{n}}\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right]\\] On considère maintenant un cas où la stastistique n’est plus gaussienne, mais où il est possible d’appliquer le théorème central-limite, et donc se ramener à une loi approximativement gaussienne. Dans ce cas, peut obtenir des intervalles de confiance asymptotiques : Construction d’intervalles de confiance asymptotiques dans un cas d’application du TCL On suppose que \\(X\\) suit une loi normale centrée : \\[X_n\\sim\\mathcal{N}(0,\\sigma^2)\\] Exemple : estimation de \\(\\sigma\\). On considère la statistique \\[D_n\\equiv\\frac{1}{n}\\sum\\limits_{i=1}^n |X_i|\\] On vérifie facilement que l’intégrale \\(\\int_{\\mathbb{R}} |x|\\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{x^2}{2\\sigma^2}}\\,dx\\) est convergente et vaut \\(\\sqrt{\\frac{2}{\\pi}}\\sigma\\). Ainsi, la variable aléatoire \\(|X|\\) admet une espérance et \\[\\mathbb{E}(|X|)=\\sqrt{\\frac{2}{\\pi}}\\,\\sigma\\] On en déduit un estimateur sans biais de \\(\\sigma\\) : \\[T_n\\equiv\\sqrt{\\frac{\\pi}{2}}\\,D_n\\] Avec la loi faible des grands nombres, \\(T_n\\) est un estimateur convergent de \\(\\sigma\\). Par ailleurs, \\(|X|\\) admet un moment d’ordre \\(2\\) (\\(\\mathbb{E}(|X|^2)=\\mathbb{E}(X^2)=\\sigma^2\\)) et \\[\\begin{align} \\mathbb{V}(|X|) &amp;= \\mathbb{E}(X^2)-(\\mathbb{E}(|X|))^2 \\\\ &amp;= \\left(1-\\frac{2}{\\pi}\\right)\\sigma^2 \\end{align}\\] On en déduit que \\(T_n\\) admet une variance et que \\[\\mathbb{V}(T_n)=\\left(\\frac{\\pi}{2}-1\\right)\\frac{\\sigma^2}{n}\\] Avec le théorème central limite on a l’approximation en loi \\[\\frac{T_n-\\sigma}{\\frac{\\sigma}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\approx\\mathcal{N}(0,1)\\] En posant \\(u_{\\alpha}=\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\), avec toujours \\(\\Phi\\) la fonction de répartition de la loi normale standard, on a donc \\[\\mathbb{P}\\left(-u_{\\alpha}\\leq\\sqrt{n}\\frac{T_n-\\sigma}{\\sigma\\sqrt{\\frac{\\pi}{2}-1}}\\leq u_{\\alpha}\\right)\\approx 1-\\alpha\\] Or \\[-u_{\\alpha}\\leq\\sqrt{n}\\frac{T_n-\\sigma}{\\sigma\\sqrt{\\frac{\\pi}{2}-1}}\\leq u_{\\alpha}\\Leftrightarrow \\frac{T_n}{1+\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\leq\\sigma\\leq\\frac{T_n}{1-\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\] On en déduit un intervalle de confiance asymptotique de \\(\\sigma\\) au niveau de confiance \\(1-\\alpha\\) : \\[\\text{IC}^{1-\\alpha}_{\\sigma}\\equiv\\left[\\frac{T_n}{1+\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\, ;\\, \\frac{T_n}{1-\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\right]\\] 7.2 Tests statistiques 7.2.1 Définition et principes approche très intuitive (d’après le programme du concours) 7.2.2 Exemples de test le but est avant tout de montrer la démarche générale d’un test statistique à travers quelques exemples simples "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
