[["variables-aléatoires-discrètes.html", "Chapitre 3 Variables aléatoires discrètes 3.1 Définition et premières propriétés 3.2 Transformation d’une variable aléatoire discrète 3.3 Vecteurs aléatoires", " Chapitre 3 Variables aléatoires discrètes Supposons que vous jouiez avec un ami au jeu suivant. Votre ami lance un dé équilibré et vous convenez des règles suivantes : si le dé tombe sur \\(1\\) ou \\(2\\), vous donnez \\(3\\) euros à votre ami ; si le dé tombe sur \\(2\\) ou \\(3\\), votre ami vous donne \\(3\\) euros ; si le dé tombe sur \\(5\\) ou \\(6\\), aucun de vous deux ne gagne ni ne perd d’argent. On note \\(X\\) votre gain algébrique. Alors, \\(X\\) est un nombre aléatoire dont les valeurs possibles sont \\(-3, 3\\) et \\(0\\). L’expérience aléatoire qui consiste à lancer ce dé et à relever son numéro peut être modélisée par l’univers probabilisé \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\), où \\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\(\\mathcal{A}=\\mathcal{P}(\\Omega)\\) et \\(\\mathbb{P}\\) est la mesure équirépartie : \\(\\forall\\omega\\in\\Omega, \\,\\mathbb{P}(\\{\\omega\\})=\\frac{1}{6}\\). Dans ce cas, votre gain \\(X\\) peut être vu comme une application \\[X:\\Omega=\\{1,2,3,4,5,6\\}\\longrightarrow\\{-3, 0, 3\\}\\] définie par \\[X(1)=X(2)=-3\\] \\[X(3)=X(4)=3\\] \\[X(5)=X(6)=0\\] Imaginons maintenant qu’un ami commun prenne connaissance de votre gain à ce jeu, mais sans prendre connaissance du jeu lui-même (ni les issues possibles, ni les règles définissant le gain), et encore moins du numéro du dé que vous avez obtenu. De son point de vue, l’expérience qui aboutira à l’observation de votre gain sera également une expérience aléatoire, cependant l’espace probabilisé la modélisant ne sera plus \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) mais plutôt \\((\\Omega_X, \\mathcal{A}_X, \\mathbb{P}_X)\\), où \\[\\Omega_X=X(\\Omega)=\\{-3, 0, 3\\}\\] \\[\\mathcal{A}_X=\\mathcal{P}(\\{-3,0,3\\})\\] \\[\\mathbb{P}_X \\text{ donnée par } \\mathbb{P}_X(\\{-3\\})=\\mathbb{P}_X(\\{0\\})=\\mathbb{P}_X(\\{0\\})=\\frac{1}{3}\\] Dans ce genre de situation, on dit que \\(X\\) est une variable aléatoire, et on appelle loi de \\(X\\) la mesure de probabilité \\(\\mathbb{P}_X\\). D’une certaine façon, la variable aléatoire \\(X\\) a donc transformé l’espace probabilisé de départ \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) en un nouvel espace probabilisé \\((\\Omega_X, \\mathcal{A}_X,\\mathbb{P}_X)\\). Dans la plupart des expériences aléatoires, on cherchera à mesurer une grandeur (un gain à un jeu de hasard, la durée d’attente à un feu rouge, le nombre de coquilles dans un texte, le nombre buts marqués dans un match de foot, etc.), si bien que ce qui nous intéressera ne sera pas tant l’espace de départ \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) mais plutôt son image \\((\\Omega_X, \\mathcal{A}_X, \\mathbb{P}_X)\\) par cette grandeur. Cela a une conséquence pratique lorsqu’on résout un exercice de probabilités mettant en scène une variable aléatoire \\(X\\) : sauf dans des cas très simples, on n’explicitera pas \\(\\Omega\\) qu’on supposera donné (un peu à la façon de votre ami commun qui est aveugle aux numéros du dé) mais on cherchera plutôt à déterminer \\(X(\\Omega)\\). La tribu \\(\\mathcal{A}_X\\) sera, elle, généralement passée sous silence (en pratique, on aura souvent \\(\\mathcal{A}_X=\\mathcal{P}(X(\\Omega)\\)). Enfin, on accordera toute l’attention sur la loi de \\(X\\), autrement dit sur la mesure de probabilité \\(\\mathbb{P}_X\\), à partir de laquelle on pourra calculer différents indicateurs (espérance, variance, quantiles etc.). Ce chapitre s’intéresse aux variables alétoires discrètes, autrement dit les variables aléatoires dont les images forment un ensemble discret, soit parce que cet ensemble est fini, soit parce-qu’il est infini mais dénombrable (comme l’ensemble des entiers naturels ou des nombres rationnels). Le chapitre suivant traitera des variables aléatoires continues : ce sont les variables aléatoires dont l’ensemble des valeurs est continu, comme par exemple l’ensemble des nombres réels. 3.1 Définition et premières propriétés 3.1.1 Définition Variables aléatoires discrètes Soit \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) un espace probabilisé. On appelle variable aléatoire discrète (réelle) sur \\(\\Omega\\) toute application \\[X:\\Omega\\longrightarrow F=X(\\Omega)\\subset\\mathbb{R}\\] où \\(F=X(\\Omega)\\) est : soit un ensemble fini : \\(F=\\{x_1,\\dots, x_n\\}\\) soit un ensemble infini dénombrable : \\(F=\\{x_n,\\,n\\in\\mathbb{N}\\}\\) On dira alors que \\(F\\) est au plus dénombrable, et on utilisera souvent la notation unifiée \\[F=X(\\Omega)=\\{x_i, \\, i\\in I\\}, \\, I\\subset\\mathbb{N}\\] De plus, pour tout \\(\\omega\\in\\Omega\\), on dira que \\(X(\\omega)\\) est une réalisation de \\(X\\). Exemples. i. On reprend l’exemple des deux dés équilibrés présenté dans le chapitre précédent : L’expérience aléatoire associée à cette expérience aléatoire est modélisée par l’espace probabilisé \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\), avec \\(\\Omega=\\{1,2,3,4,5,6\\}^2\\), \\(\\mathcal{A}=\\mathcal{P}(\\Omega)\\) et \\(\\mathbb{P}\\) la mesure de probabilité équirépartie. La somme \\(S\\) des deux numéros obtenus est une variable aléatoire \\[X:\\Omega \\longrightarrow X(\\Omega)\\] définie, pour \\(\\omega=(\\omega_1, \\omega_2)\\in\\Omega\\), par \\(S(\\omega)=\\omega_1+\\omega_2\\). On a \\[X(\\Omega)=[\\![2;12]\\!]\\] où pour tout couple d’entiers \\((a,b)\\) tel que \\(a\\leq b\\), \\([\\![a;b]\\!]\\) désigne l’ensemble de tous les entiiers entre \\(a\\) et \\(b\\) (notation que nous réutiliserons régulièrement dans ce cours). Ainsi, \\(X(\\Omega)\\) est fini, et donc \\(X\\) est une variable aléatoire discrète. ii. Une urne contient \\(4\\) boules blanches et \\(6\\) boules noires. On tire une boule au hasard. Si elle est noire on s’arrête là, sinon on remet la boule dans l’urne, et on recommence jusqu’à obtenir une boule noire. On note \\(N\\) le nombre de boules tirées. \\(N\\) est une variable aléatoire, prenant des valeurs entières et non majorée. Ainsi \\(N(\\Omega)=\\mathbb{N}^*\\) et \\(N\\) est discrète. iii. Dans une file d’attente, on note \\(T\\) le temps de passage entre deux clients. \\(T\\) est une variable aléatoire à valeurs dans \\(\\mathbb{R}_+\\). Elle n’est donc pas discrète, mais continue. 3.1.2 Loi d’une variable aléatoire discrète Pour une variable aléatoire discrète (réelle) définie sur un espace probabilisé \\(\\left(\\Omega, \\, \\mathcal{P}(\\Omega), \\, \\mathbb{P}\\right)\\), on peut définir la loi de \\(X\\). Théorème (Loi d’une variable aléatoire discrète). Soit \\(X\\) une variable aléatoire discrète définie sur un espace probabilisé \\((\\Omega,\\, \\mathcal{P}(\\Omega),\\, \\mathbb{P})\\), à valeurs dans \\(F=X(\\Omega)\\). Sur l’espace probabilisable \\((F,\\, \\mathcal{P}(F))\\) on peut alors définir une probabilité \\(\\mathbb{P}_X\\) en posant, pour tout \\(x_i\\) dans \\(F\\) : \\[\\mathbb{P}_X(\\{x_i\\})=\\mathbb{P}(X^{-1}(\\{x_i\\}))\\] On notera plus simplement \\((X=x_i)\\) l’événement \\(X^{-1}(\\{x_i\\})\\). La loi de \\(X\\) est donc définie par : la donnée de \\(F=X(\\Omega)\\), i.e. l’ensemble de toutes les valeurs prises par \\(X\\). Cet ensemble s’appelle le support de la loi de \\(X\\) ; la donnée, pour tout \\(x_i\\) dans \\(X(\\Omega)\\), de la probabilité \\(\\mathbb{P}(X=x_i)\\). Cette loi est unique à des événements de probabilité nulle près. Démonstration. Admis. Remarques. i. On définit \\(\\mathbb{P}_X\\) à partir des \\(\\mathbb{P}_X(\\{x_i\\})\\) : les \\(\\{x_i\\}\\) sont des éléments de (la tribu) \\(\\mathcal{P}(F)\\), donc \\(\\mathbb{P}_X\\) est bien une mesure de probabilité sur l’espace probabilisable \\((F,\\,\\mathcal{P}(F))\\) ; par ailleurs, \\(\\mathbb{P}_X(\\{x_i\\})\\) est définie par \\(\\mathbb{P}(X^{-1}(\\{x_i\\}))\\) et \\(X^{-1}(\\{x_i\\})\\) est un élément de la tribu \\(\\mathcal{P}(\\Omega)\\) sur laquelle est définie la probabilité \\(\\mathbb{P}\\), donc cette définition a bien un sens. ii. La loi de \\(X\\) est définie par la donnée des couples \\((x_i, p_i)\\) tels que \\(x_i\\in X(\\Omega)\\) et \\(p_i=\\mathbb{P}(X=x_i)\\). Dans cette définition, on peut se restreindre aux couples \\((x_i, p_i)\\) pour lesquels \\(p_i&gt;0\\). La loi de \\(X\\) n’est donc pas unique au sens strict du terme, mais elle l’est bien à des événements élémentaires de probabilité nulle près. Par exemple, dans l’exercice 2 du sujet du concours interne de 2012 (exercice 2.7. de ce cours) la variable aléatoire \\(X\\) prend a priori les valeurs \\(0,1,2,3\\), mais a posteriori on a \\(\\mathbb{P}(X=0)=0\\), donc on peut enlever \\(0\\) de \\(X(\\Omega)\\). Exemple. i. On reprend l’exemple sur la somme des deux dés. On a vu que \\(X(\\Omega)=[\\![2;12]\\!]\\). On calcule maintenant toutes les probablités \\(\\mathbb{P}(X=i)\\) pour \\(i\\in [\\![2;12]\\!]\\). On montre en fait facilement que \\[\\forall i\\in [\\![2;6]\\!],\\, \\mathbb{P}(X=i)=\\frac{i-1}{36}\\] \\[\\forall i\\in [\\![7;12]\\!], \\, \\mathbb{P}(X=i)=\\frac{13-i}{36}\\] On peut vérifier la cohérence de ce résultat : \\[\\begin{align} \\sum\\limits_{i=2}^{6}\\frac{i-1}{36}+\\sum\\limits_{i=7}^{12}\\frac{13-i}{36} &amp;= \\sum\\limits_{i=1}^{5}\\frac{i}{36}+\\sum\\limits_{i=1}^{6}\\frac{i}{36} \\\\ &amp;= \\frac{2\\sum\\limits_{i=1}^5 i +6}{36} \\\\ &amp;= \\frac{6\\times 5+6}{36} \\\\ &amp;= 1 \\\\ \\end{align}\\] ii. On reprend l’exemple de l’urne contenant \\(4\\) boules blanches et \\(6\\) boules noires. On répète des tirages successifs avec remise jusqu’à obtenir une boule noire, et \\(N\\geq 1\\) désigne le nombre de tirages. Pour \\(n\\in\\mathbb{N}^*\\), l’événement \\((N=n)\\) est réalisé lorsque les \\(n-1\\) premiers tirages amènent une boule blanche et le tirage numéro \\(n\\) amène une boule noire. Les tirages étant effectués avec remise ils sont indépendants, donc \\[\\mathbb{P}(N=n)=\\left(\\frac{2}{5}\\right)^{n-1}\\frac{3}{5}\\] ce qui définit complètement la loi de \\(N\\). Remarques. i. On peut vérifier de façon immédiate que la série \\(\\sum\\limits_{n}\\mathbb{P}(N=n)\\) est convergente de somme \\(1\\) : c’est, au facteur \\(\\frac{3}{5}\\) près, une série géométrique de raison \\(\\frac{2}{5}\\in]-1;1[\\), donc elle converge vers \\(\\frac{3}{5}\\frac{1}{1-\\frac{2}{5}}=1\\). ii. \\(N\\) suit une loi géométrique de paramètre \\(p=\\frac{3}{5}\\) (voir un peu plus loin la définition des lois géométriques). 3.1.3 Calcul de \\(\\mathbb{P}(X\\in B)\\) Théorème (calcul de \\(\\mathbb{P}(X\\in B)\\)). Soit \\(X:\\Omega\\longrightarrow X(\\Omega)\\) une variable aléatoire discrète (réelle), avec \\[X(\\Omega)=\\{x_i,\\,\\,i\\in I\\} \\text{, où } I\\subset\\mathbb{N}\\] Pour \\(B\\in\\mathcal{P}(X(\\Omega))\\), on note \\((X\\in B)\\) l’événement \\[(X\\in B)=X^{-1}(B)=\\left\\{\\omega\\in\\Omega, X(\\omega)\\in B\\right\\}\\] La probabilité d’un tel événement se calcule ainsi : \\[\\begin{align} \\mathbb{P}(X\\in B)&amp;=\\mathbb{P}\\left(\\bigsqcup\\limits_{i\\in I/ x_i\\in B} (X=x_i)\\right) \\\\ &amp;=\\sum\\limits_{i\\in I/ x_i\\in B}\\mathbb{P}(X=x_i) \\end{align}\\] Démonstration. Les événements \\((X=x_i)\\) tels que \\(i\\in I, x_i\\in B\\) forment une partition de l’événement \\((X\\in B)\\). On conclut en utilisant le fait qu’une probabilité d’une réunion disjointe d’événements \\(A_i\\) est la somme des probablités \\(\\mathbb{P}(A_i)\\). \\(\\square\\) Exemple. Dans l’exemple précédent de l’urne, on cherche maintenant la probabilité que \\(X\\) soit impaire. On a \\[\\begin{align} \\mathbb{P}(X\\in 2\\mathbb{N}+1) &amp;= \\sum\\limits_{n=0}^{\\infty}\\mathbb{P}(X=2n+1) \\\\ &amp;=\\sum\\limits_{n=0}^{\\infty}\\left(\\frac{2}{5}\\right)^{2n}\\frac{3}{5} \\\\ &amp;=\\frac{3}{5}\\sum\\limits_{n=0}^{\\infty}\\left(\\frac{4}{25}\\right)^{n} \\\\ &amp;=\\frac{3}{5}\\frac{1}{1-\\frac{4}{25}} \\\\ &amp;=\\frac{5}{7} \\\\ \\end{align}\\] 3.1.4 Fonction de répartition La fonction de répartition d’une variable aléatoire discrète (ou même continue comme on le verra dans le prochain chapitre) réelle est définie par la donnée des probabilités \\(\\mathbb{P}(X\\leq x)=\\mathbb{P}(X\\in ]-\\infty\\,;\\,x])\\) : Fonction de répartition Soit \\(X\\) une variable aléatoire discrète (réelle). On appelle fonction de répartition de \\(X\\) la fonction \\(F_X\\) définie sur \\(\\mathbb{R}\\) par \\[\\forall x\\in\\mathbb{R},\\,F_X(x)=\\mathbb{P}(X\\leq x)\\] Quand le contexte le permet, on la note plus simplement \\(F\\). Note : cette définition de la fonction de répartition est valable pour toutes les variables aléatoires, qu’elles suivent ou non une loi discrète. Calcul pratique. On note \\(x_1,\\dots x_n\\) (resp. \\(x_1,\\dots, x_n, \\dots\\)) les éléments de \\(X(\\Omega)\\) rangés dans l’ordre croissant si \\(X(\\Omega)\\) est fini (resp. infini dénombrable). Soient \\(x\\in\\mathbb{R}\\) et \\(i_0\\) le plus grand entier tel que \\(x_{i_0}\\leq x\\). Alors, d’après le théorème précédent : \\[F(x)=\\sum\\limits_{i=1}^{i_0}\\mathbb{P}(X=x_i)\\] Exemple. On considère une variable aléatoire \\(X\\) telle que \\(X(\\Omega)=\\{1,2,3,4\\}\\) et \\(\\mathbb{P}(X=i)\\) est proportionnel à \\(i\\). On souhaite déterminer sa fonction de répartition. On note \\(\\alpha=\\mathbb{P}(X=1)\\). On a donc \\[\\mathbb{P}(X=i)=\\alpha\\, i\\] On a donc \\(\\alpha\\sum\\limits_{i=1}^4 i=1\\), soit \\(\\alpha=\\frac{1}{10}\\) et donc \\[\\forall i\\in [\\![1;4]\\!],\\, \\mathbb{P}(X=i)=\\frac{i}{10}\\] La fonction de répartition \\(F\\) de \\(X\\) est alors donnée par \\[F(x)=\\left \\{ \\begin{array}{lcl} 0&amp;\\text{ si }&amp; x&lt;1 \\\\ \\frac{1}{10}&amp;\\text{ si }&amp; 1\\leq x&lt;2 \\\\ \\frac{3}{10}&amp;\\text{ si }&amp; 2\\leq x&lt;3 \\\\ \\frac{3}{5}&amp;\\text{ si }&amp; 3\\leq x&lt;4 \\\\ 1&amp;\\text{ si }&amp; x\\geq 4 \\\\ \\end{array} \\right.\\] Propriétés des fonctions de répartition Soit \\(F\\) la fonction de répartition d’une variable aléatoire réelle (discrète ou non). Alors : i. \\(F\\) est une fonction croissante sur \\(\\mathbb{R}\\) ii. \\(F\\) est continue à droite iii. \\(\\lim\\limits_{x\\to -\\infty}F(x)=0\\) iv. \\(\\lim\\limits_{x\\to +\\infty}F(x)=1\\) Note : ces propriétés résultent directement de la défintion précédente, et sont donc vraies pour toutes les variables aléatoires, qu’elles soient discrètes ou non. Démonstration. On note \\(X\\) une variable aléatoire réelle discrète ayant \\(F\\) pour fonction de répartition. i. Soient \\(x,y\\) deux réels tels que \\(x\\leq y\\). Alors l’événement \\(\\{X\\leq x\\}\\) est inclus dans l’événement \\(\\{X\\leq y\\}\\). Par croissance des probabilités on a donc \\(\\mathbb{P}(X\\leq x)\\leq\\mathbb{P}(X\\leq y)\\), i.e. \\(F(x)\\leq F(y)\\). On en déduit que \\(F\\) est croissante. ii. Soit \\(x\\) un réel. Les événements \\(\\left\\{X\\in\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]\\right\\}\\) forment une suite décroissante (par rapport à \\(n\\)) pour l’inclusion, donc d’après la propriété de continuité décroissante des probabilités, on a \\[\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty}\\left\\{X\\in\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]\\right\\}\\right)=\\lim\\limits_{n\\to\\infty}\\mathbb{P}\\left(X\\in\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]\\right)\\] i.e. \\[\\mathbb{P}\\left(X\\in \\bigcap_{n=1}^{\\infty}\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]\\right)=\\lim\\limits_{n\\to\\infty}\\mathbb{P}\\left(X\\in\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]\\right)\\] Or, \\(\\bigcap\\limits_{n=1}^{\\infty}\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]=]-\\infty ; x]\\), donc le terme de gauche est égal à \\(\\mathbb{P}(X\\leq x)=F(x)\\). Par ailleurs le terme de droite est égal à \\(\\lim\\limits_{n\\to\\infty}F\\left(x+\\frac{1}{n}\\right)\\), et donc : \\[F(x)=\\lim\\limits_{n\\to\\infty}F\\left(x+\\frac{1}{n}\\right)\\] ce qui traduit exactement la continuité à droite de \\(F\\). iii. La suite d’événements \\(\\left\\{X\\leq -n\\right\\}_n\\) est décroissante, donc d’après la propriété de continuité décroissante \\[\\begin{align} \\lim\\limits_{n\\to\\infty}F(-n)&amp;=\\mathbb{P}\\left(\\bigcap\\limits_{n=0}^{\\infty}\\{X\\leq -n\\}\\right) \\\\ &amp;=\\mathbb{P}(\\emptyset) \\\\ &amp;=0 \\\\ \\end{align}\\] Par croissance de \\(F\\), on en déduit que \\(\\lim\\limits_{x\\to -\\infty}F(x)=0\\). iv. On utilise exactement le même raisonnement avec la suite croissante \\(\\left\\{X\\geq n\\right\\}_n\\). \\(\\square\\) Remarque. L’hypothèse d’une loi discrète n’étant utilisée nulle part dans cette démonstration, ces propriétés sont donc effectivement vraies pour toutes les lois de probabilités, discrètes ou non. Nous avons montré que les fonctions de répartition (de lois discrètes ou non) étaient toujours continues à droite. Pour avoir une propriété de continuité, il faudrait donc qu’elles soient également continues à gauche (rappel d’analyse : \\(f\\) est continue en \\(a\\) si et seulement si elle est continue à droite et à gauche en \\(a\\)). Mais cette propriété n’est pas vraie en toute généralité : Théorème (discontinuités d’une fonction de répartition). Soit \\(X\\) une variable aléatoire réelle (discrète ou non) définie sur un espace probabilisé \\((\\Omega, \\, \\mathcal{P}(\\Omega), \\, \\mathbb{P})\\). Pour tout réel \\(x\\) on a : \\[F(x)=F(x^{-})+\\mathbb{P}(X=x)\\] où \\(F(x^{-})=\\lim\\limits_{t\\to x^{-}}F(t)\\). Autrement dit, la fonction de répartition de \\(F\\) est continue partout, sauf aux points \\(x\\) tels que \\(p_x:=\\mathbb{P}(X=x)&gt;0\\) en lesquels elle présente un saut d’amplitude \\(p_x\\). En particulier, si \\(X\\) est discrète sa fonction de répartition présente en chaque point \\(x\\) de son support un saut d’amplitude \\(p_x\\). Démonstration. Pour tout réel \\(x\\) on a \\[F(x)=\\mathbb{P}(X&lt;x)+\\mathbb{P}(X=x)\\] Or, \\((X&lt;x)=\\bigcup\\limits_{n=1}^{\\infty} \\left(X\\in\\left]-\\infty\\,;\\, x-\\frac{1}{n}\\right]\\right)\\), et les événements \\(\\left(X\\in\\left]-\\infty\\,;\\, x-\\frac{1}{n}\\right]\\right)_{n\\geq 1}\\) forment une suite croissante pour l’inclusion, donc par continuité croissante de \\(\\mathbb{P}\\) on a : \\[\\begin{align} \\mathbb{P}(X&lt;x)&amp;=\\mathbb{P}\\left(\\bigcup_{n=1}^{\\infty}\\left(X\\in\\left]-\\infty\\,;\\,x-\\frac{1}{n}\\right]\\right)\\right) \\\\ &amp;=\\lim\\limits_{n\\to\\infty}\\mathbb{P}\\left(X\\in\\left]-\\infty\\,;\\,x-\\frac{1}{n}\\right]\\right) \\\\ &amp;=\\lim\\limits_{n\\to\\infty}F\\left(x-\\frac{1}{n}\\right) \\\\ &amp;=F(x^{-}) \\end{align}\\] ce qui montre l’égalité annoncée et permet de conclure. \\(\\square\\) Remarque. Les variables aléatoires ayant une fonction de répartition continue sont appelées des lois continues. Elles font l’objet du chapitre suivant (on se restreindra au cas où l’espace d’arrivée est l’ensemble des réels). D’après le résultat précédent, si \\(X\\) est une variable aléatoire de loi continue on a donc \\(\\mathbb{P}(X=x)=0\\) pour tout réel \\(x\\). Théorème (fonction de répartition et loi). Soit \\(X\\) une variable aléatoire réelle discrète définie sur un espace probabilisé \\((\\Omega, \\,\\mathcal{P}(\\Omega), \\mathbb{P})\\) et de fonction de répartition \\(F\\). Alors : si \\(a\\) et \\(b\\) sont des nombres réels tels que \\(a\\leq b\\) on a \\[\\mathbb{P}(X\\in]a\\,;\\,b])=F(b)-F(a)\\] supposons que \\(X(\\Omega)=\\{x_i,\\,i\\in I\\}\\) avec les \\(x_i\\) rangés dans l’ordre croissant. Alors \\[\\mathbb{P}(X=x_0)=F(x_0)\\] et \\[\\forall i\\geq 1,\\, \\mathbb{P}(X=x_i)=F(x_i)-F(x_{i-1})\\] Démonstration. On a \\[]-\\infty\\,;\\,b]=]-\\infty\\,;\\,a]\\,\\sqcup\\,]a\\,;\\,b]\\] donc \\[F(b)=F(a)+\\mathbb{P}(X\\in ]a\\,;\\,b])\\] ce qui montre la première égalité. Comme \\(x_0=\\inf X(\\Omega)\\), on a \\((X=x_0)=(X\\leq x_0)\\) et donc ces deux événements ont la même probabilité, i.e. \\(\\mathbb{P}(X=x_0)=F(x_0)\\). Soit \\(i\\geq 1\\). D’après le théorème précédent, on a \\[\\begin{align} \\mathbb{P}(X=x_i)&amp;=F(x_i)-F(x_i^{-}) \\\\ &amp;=F(x_i)-\\mathbb{P}(X&lt;x_i) \\\\ &amp;=F(x_i)-\\mathbb{P}(X\\leq x_{i-1}) \\\\ &amp;=F(x_i)-F(x_{i-1}) \\\\ \\end{align}\\] \\(\\square\\) On déduit du résultat précédent : Théorème. La fonction de répartition d’une variable aléatoire réelle discrète caractérise sa loi. Autrement dit, si \\(X\\) et \\(Y\\) sont deux variables aléatoires réelles discrètes, on a \\[F_X=F_Y \\text{ ssi } \\mathbb{P}_X=\\mathbb{P}_Y\\] Démonstration. La loi d’une variable aléatoire réelle discrète \\(X\\) est complètement définie par la donnée des probabilités \\(\\mathbb{P}(X=x_i)\\), qui elles-mêmes sont complètement définies par la fonction \\(F\\) d’après le théorème précédent, d’où le résultat. \\(\\square\\) Remarque. Le résultat précédent autorise donc à parler de fonction de répartition associée à une loi, ou même réciproquement de loi associée à une fonction de répartition. 3.1.5 Quantiles Pour définir la notion de quantile, on a besoin de définir la notion d’inverse généralisé à gauche. Inverse généralisé à gauche Soit \\(F\\) une fonction définie sur \\(\\mathbb{R}\\) et à valeurs dans \\([0,1]\\), croissante et continue à droite. On adopte les conventions suivantes : \\[F(-\\infty)=\\lim\\limits_{x\\to -\\infty}F(x)\\] \\[F(+\\infty)=1\\] \\[\\inf\\,\\emptyset=+\\infty\\] On appelle alors fonction inverse généralisée à gauche de \\(F\\), et on note \\(F^{-1}\\), la fonction définie sur \\([0,1]\\) par \\[\\forall p\\in [0,1],\\, F^{-1}(p)=\\inf\\{x\\in\\mathbb{R},\\,F(x)\\geq p\\}\\] Il s’agit d’une fonction croissante sur \\(\\mathbb{R}\\). Démonstration. Soient \\(p\\) et \\(q\\) deux réels tels que \\(p\\leq q\\). si \\(\\{x\\in\\mathbb{R},\\,F(x)\\geq p\\}=\\emptyset\\), alors \\(\\{x\\in\\mathbb{R}, \\, F(x)\\geq q\\}=\\emptyset\\) et donc \\(F^{-1}(p)=F^{-1}(q)=+\\infty\\). supposons maintenant que \\(\\{x\\in\\mathbb{R},\\,F(x)\\geq p\\}\\neq\\emptyset\\) : il existe donc un réel \\(x\\) tel que \\(F^{-1}(p)=x\\). On diistingue deux cas : si \\(\\{x\\in\\mathbb{R}, \\, F(x)\\geq q\\}=\\emptyset\\), alors \\(F^{-1}(q)=+\\infty\\), et donc \\(F^{-1}(p)=x&lt;+\\infty=F^{-1}(q)\\). si \\(\\{x\\in\\mathbb{R},\\,F(x)\\geq q\\}\\neq\\emptyset\\), alors il existe un réel \\(y\\) tel que \\(y=F^{-1}(q)\\). Par définition de \\(y\\), on a \\(F(y)\\geq q\\). Mais comme \\(q\\geq p\\), on en déduit que \\(F(y)\\geq p\\). Par définition de \\(x\\), on en déduit que \\(y\\geq x\\), i.e. que \\(F^{-1}(q)\\geq F^{-1}(p)\\). Ainsi, dans tous les cas, si \\(p\\leq q\\) alors \\(F^{-1}(p)\\leq F^{-1}(q)\\), ce qui montre que \\(F^{-1}\\) est croissante. \\(\\square\\) Remarque. Cette notion d’inverse généralisé à gauche permet de définir un pseudo-inverse pour des fonctions qui ne sont pas inversibles (on en verra un exemple un peu plus bas en application de la définition de la fonction quantile). Dans le cas où la fonction \\(F\\) est strictement croissante et continue, elle est inversible, et son inverse et son inverse généralisé à gauche coïncident. Il s’agit donc bien d’une généralisation de l’inverse d’une fonction croissante et continue à droite. La fonction quantile d’une variable aléatoire réelle \\(X\\) se définit alors ainsi : Fonction quantile, quantiles Soient \\(X\\) une variable aléatoire réelle (discrète ou non) et \\(F\\) sa fonction de répartition. On appelle fonction quantile de \\(X\\) la fonction inverse généralisée à gauche \\(F^{-1}\\) de \\(F\\). De plus, pour tout réel \\(p\\) dans \\([0,1]\\), on appelle quantile d’ordre \\(p\\) le réel \\(F^{-1}(p)\\). Exemples usuels de quantiles : \\(m_e=F^{-1}\\left(\\frac{1}{2}\\right)\\) est la médiane de \\(X\\) ; \\(Q_1=F^{-1}\\left(\\frac{1}{4}\\right)\\) et \\(Q_3=F^{-1}\\left(\\frac{3}{4}\\right)\\) sont les quartiles de \\(X\\) ; pour \\(i=1,\\dots,9\\), les \\(D_i=F^{-1}\\left(\\frac{i}{10}\\right)\\) sont les déciles de \\(X\\). Exemple. Dans un exemple précédent, on a introduit une variable aléatoire discrète \\(X\\) de fonction de répartition \\(F\\) donnée par \\[F(x)=\\left \\{ \\begin{array}{lcl} 0&amp;\\text{ si }&amp; x&lt;1 \\\\ \\frac{1}{10}&amp;\\text{ si }&amp; 1\\leq x&lt;2 \\\\ \\frac{3}{10}&amp;\\text{ si }&amp; 2\\leq x&lt;3 \\\\ \\frac{3}{5}&amp;\\text{ si }&amp; 3\\leq x&lt;4 \\\\ 1&amp;\\text{ si }&amp; x\\geq 4 \\\\ \\end{array} \\right.\\] Déterminons sa médiane et ses quartiles : \\(F(x)\\geq\\frac{1}{2}\\Leftrightarrow x\\geq 3\\), donc \\(m_e=3\\) ; \\(F(x)\\geq\\frac{1}{4}\\Leftrightarrow x\\geq 2\\), donc \\(Q_1=2\\) ; \\(F(x)\\geq\\frac{3}{4}\\Leftrightarrow x\\geq 4\\), donc \\(Q_3=4\\). Un intérêt des quantiles. Il est fréquent de vouloir résumer une distribution statistique à l’aide d’indicateurs. Un indicateur couramment utilisé est la moyenne. Il présente toutefois pour inconvénient majeur d’être fortement sensible aux valeurs extrêmes. Ainsi, une seule valeur atypique d’une distribution suffit à perturber considérablement la moyenne. Une alternative est alors de recourir à un quantile, comme par exemple la médiane, qui est plus robuste aux valeurs atypiques. 3.1.6 Exemples classiques de lois discrètes Pour \\(X\\) une variable aléatoire réelle discrète et \\(\\mathcal{L}\\) une loi de probabilité, la notation \\(X\\sim\\mathcal{L}\\) signfiera que \\(X\\) suit la loi \\(\\mathcal{L}\\). Exemple 1 : loi uniforme sur un ensemble fini. La loi uniforme affecte les mêmes probabilités à tous les éléments d’un ensemble fini \\(X(\\Omega)=\\{x_1,\\dots, x_n\\}\\) : \\[\\forall 1\\leq i\\leq n,\\, \\mathbb{P}(X=x_i)=\\frac{1}{n}\\] C’est cette loi à laquelle on doit penser lorsqu’on parle de tirer au hasard parmi un ensemble fini. C’est aussi cette loi qu’on utilise si on veut modéliser un phénomène aléatoire sur un ensemble fini en l’absence de toute information sur le tirage. On suppose les \\(x_i\\) rangés dans l’ordre croissant. Alors, la fonction de répartition de cette loi est la fonction \\(F\\) donnée par \\[F(x)=\\left \\{ \\begin{array}{lcl} 0&amp;\\text{ si }&amp; x&lt;x_1 \\\\ \\frac{i}{n}&amp;\\text{ si }&amp; x_i\\leq x&lt;x_{i+1}\\, \\text{, avec } 1\\leq i\\leq n-1 \\\\ 1&amp;\\text{ si }&amp; x\\geq x_n \\\\ \\end{array} \\right.\\] Exemple 2 : loi de Bernoulli \\(\\mathcal{B}(p)\\). Ici, \\(p\\in[0,1]\\). Cette loi est généralement mobilisée lorsque l’on souhaite modéliser l’issue d’une expérience de Bernoulli, autrement dit une expérience ayant deux issues nommées réussite et échec. Il s’agit donc d’une loi à deux issues, généralement notées \\(0\\) (représentant généralement l’échec) et \\(1\\) (représentant généralement la réussite) : \\[X(\\Omega)=\\{0,1\\}\\] Une telle loi est définie de façon unique à partir du paramètre \\(p=\\mathbb{P}(X=1)\\). De façon immédiate, on a \\(\\mathbb{P}(X=0)=1-p\\). On note souvent \\(q=1-p\\). La fonction de répartition de la loi de Benoulli \\(\\mathcal{B}(p)\\) est donnée par \\[F(x)=\\left \\{ \\begin{array}{lcl} 0&amp;\\text{ si }&amp; x&lt;0 \\\\ p&amp;\\text{ si }&amp; 0\\leq x&lt;1 \\\\ 1&amp;\\text{ si }&amp; x\\geq 1 \\\\ \\end{array} \\right.\\] Exemple 3 : loi binomiale \\(\\mathcal{B}(n,p)\\). \\(n\\) est un entier naturel non nul et \\(p\\in [0,1]\\). La loi binomiale sert à modéliser le nombre de succès lors de la répétition de \\(n\\) expériences de Bernoulli identiques et indépendantes. On a donc \\[X(\\Omega)=\\{0,1,\\dots, n\\}\\] Les probabilités de la loi binomiale \\(\\mathcal{B}(n,p)\\) font intervenir les coefficients binomiaux \\(\\binom{n}{k}\\) : Probabilités d’une loi binomiale. Soit \\(X\\) une variable aléatoire telle que \\(X\\sim\\mathcal{B}(n,p)\\). Alors, pour tout entier \\(0\\leq k\\leq n\\), on a \\[\\mathbb{P}(X=k)=\\binom{n}{k}\\,p^k\\,(1-p)^{n-k}\\] Démonstration. Cette formule est une conséquence de la définition de la loi \\(\\mathcal{B}(n,p)\\). On peut écrire \\[X=\\sum\\limits_{i=1}^n X_i\\] où les \\(X_i\\) sont des variables aléatoires de Bernoulli de paramètre \\(\\mathcal{B}(p)\\), représentant l’issue de l’expérience de Bernoulli numéro \\(i\\). Soit \\(k\\) un entier tel que \\(0\\leq k\\leq n\\). Notons \\[E_k=\\left\\{(x_1,\\dots, x_n)\\in\\{0,1\\}^n,\\, \\sum\\limits_{i=1}^n x_i=k\\right\\}\\] Pour \\((x_1,\\dots, x_n)\\in E_k\\), les événements \\((X_1=x_1),\\dots,(X_n=x_n)\\) sont indépendants, puisque les expériences de Bernoulli associées aux \\(X_i\\) sont indépendantes. Par conséquent, on a \\[\\begin{align} \\mathbb{P}(X_1=x_1,\\dots, X_n=x_n)&amp;=\\prod\\limits_{i=1}^n\\mathbb{P}(X=x_i) \\\\ &amp;=p^k\\,(1-p)^{n-k} \\\\ \\end{align}\\] puisque le vecteur \\((x_1,\\dots, x_n)\\) est constitué de \\(k\\) composantes égales à \\(1\\) et \\(n-k\\) composantes égales à \\(0\\). Par ailleurs, \\(\\text{Card }(E_k)=\\binom{n}{k}\\) donc : \\[\\begin{align} \\mathbb{P}(X=k)&amp;=\\mathbb{P}\\left(\\sum\\limits_{i=1}^n X_i=k\\right) \\\\ &amp;=\\mathbb{P}\\left(\\bigsqcup\\limits_{(x_1,\\dots, x_n)\\in E_k} (X_1=x_1,\\dots, X_n=x_n)\\right) \\\\ &amp;=\\sum\\limits_{(x_1,\\dots,x_n)\\in E_k}\\mathbb{P}\\left(X_1=x_1,\\dots, X_n=x_n\\right) \\\\ &amp;=\\sum\\limits_{(x_1,\\dots, x_n)\\in E_k} p^k\\,(1-p)^{n-k} \\\\ &amp;=\\text{Card }(E_k)\\,p^k\\,(1-p)^{n-k} \\\\ &amp;=\\binom{n}{k}\\,p^k\\,(1-p)^{n-k} \\\\ \\end{align}\\] \\(\\square\\) Remarque. On déduit de l’expression des \\(\\mathbb{P}(X=k)\\) l’identité \\[\\sum\\limits_{k=0}^n\\binom{n}{k}\\,p^k\\,(1-p)^{n-k}=1\\] qui n’est autre qu’un cas particulier de la formule du binôme de Newton : \\[(p+(1-p))^n=\\sum\\limits_{k=0}^n\\binom{n}{k}\\,p^k\\,(1-p)^{n-k}\\] La fonction de répartition de la loi binomiale \\(\\mathcal{B}(n,p)\\) est donnée par \\[F(x)=\\left \\{ \\begin{array}{lcl} 0&amp;\\text{ si }&amp; x&lt;0 \\\\ \\sum\\limits_{k=0}^l \\binom{n}{k}\\,p^k\\,(1-p)^{n-k} &amp;\\text{ si }&amp; l\\leq x&lt;l+1, \\,0\\leq l&lt;n \\\\ 1&amp;\\text{ si }&amp; x\\geq n \\\\ \\end{array} \\right.\\] Exemple 4 : loi de Poisson \\(\\mathcal{P}(\\lambda)\\). \\(\\lambda\\) est un réel strictement positif. La loi de Poisson \\(\\mathcal{P}(\\lambda)\\) permet de modéliser le nombre (aléatoire) \\(X\\) d’événements se produisant sur une période \\(T\\), lorsqu’on sait qu’en moyenne \\(\\lambda\\) événements se produisent sur une telle période. Elle est généralement appliquée pour des événements rares (accidents, fautes dans un texte, etc.). On peut aussi l’utiliser pour des domaines spatiaux plutôt que des intervalles temporels. On a \\[X(\\Omega)=\\mathbb{N}\\] et les probabilités \\(\\mathbb{P}(X=n)\\) pour \\(n\\in\\mathbb{N}\\) sont données par la formule suivante : Probabilités d’une loi de Poisson \\(\\mathcal{P}(\\lambda)\\). Soit \\(X\\) une variable aléatoire telle que \\(X\\sim\\mathcal{P}(\\lambda)\\). Alors : \\[\\forall k\\in\\mathbb{N}, \\, \\mathbb{P}(X=k)=e^{-\\lambda}\\frac{\\lambda^k}{k!}\\] Justification de cette formule. On considère un événement qui se produit aléatoirement et de façon répétée dans le temps, selon les règles suivantes : sur tout intervalle de temps de longueur (petite) \\(\\Delta t\\) : cet événement se produit une fois avec une probabilité \\(p\\) très petite ; pour tout \\(k\\geq 2\\), la probabilité qu’il se produise \\(k\\) fois est négligeable ; sur deux intervalles de temps disjoints de longueur \\(\\Delta t\\), les survenues (ou non) de cet événement sont indépendantes. On compte alors le nombre d’occurences \\(X\\) de cet événement sur un intervalle de temps \\([a\\,;\\,a+n\\Delta t]\\), avec \\(a&gt;0\\) et \\(n\\) un entier très grand. Pour tout entier \\(k\\), on note \\(X_k\\) la variable aléatoire prenant la valeur \\(1\\) si l’événement s’est produit sur l’intervalle de temps \\([a+k\\Delta t \\, ; \\, a+(k+1)\\Delta t[\\) et \\(0\\) sinon, de sorte que \\[X=\\sum\\limits_{k=0}^{n-1}X_k\\] D’après les hypothèses faites plus haut, les variables \\(X_k\\) suivent toutes la loi de Bernoulli \\(\\mathcal{B}(p)\\) et les événements \\((X_1=\\varepsilon_1),\\dots,(X_n=\\varepsilon_n)\\) sont indépendantes pour tout \\((\\varepsilon_1,\\dots,\\varepsilon_n)\\in\\{0,1\\}^n\\), donc \\(X\\) suit une loi binomiale \\(\\mathcal{B}(n,p)\\). Ainsi \\[\\forall k\\in\\{0,1,\\dots, n\\}, \\,\\mathbb{P}(X=k)=\\binom{n}{k}\\,p^k\\,(1-p)^{n-k}\\] La loi de Poisson découle alors d’une approximation de la formule précédente pour de très grandes valeurs de \\(n\\) et une très petite valeur de \\(p\\). En posant \\(\\lambda = np\\), on a en effet : \\[\\begin{align} \\mathbb{P}(X=k)&amp;=\\binom{n}{k}\\,\\left(\\frac{\\lambda}{n}\\right)^k\\,\\left(1-\\frac{\\lambda}{n}\\right)^{n-k} \\\\ &amp;=\\frac{n(n-1)\\dots(n-k+1)}{n^k} \\frac{\\lambda^k}{k!}\\left(1-\\frac{\\lambda}{n}\\right)^{n-k} \\\\ &amp;=\\left(1-\\frac{1}{n}\\right)\\dots \\left(1-\\frac{k-1}{n}\\right) \\frac{\\lambda^k}{k!}e^{(n-k)\\,\\log\\left(1-\\frac{\\lambda}{n}\\right)} \\\\ &amp;\\approx \\left(1-\\frac{1}{n}\\right)\\dots \\left(1-\\frac{k-1}{n}\\right) \\frac{\\lambda^k}{k!}e^{-(n-k)\\,\\left(\\frac{\\lambda}{n}+o\\left(\\frac{1}{n} \\right)\\right)} \\\\ &amp;\\approx \\left(1-\\frac{1}{n}\\right)\\dots \\left(1-\\frac{k-1}{n}\\right) \\frac{\\lambda^k}{k!}e^{-\\lambda+O\\left(\\frac{1}{n}\\right)} \\\\ &amp;\\to \\frac{\\lambda^k}{k!}e^{-\\lambda}\\, \\text{ lorsque } n\\to\\infty \\end{align}\\] Remarque. Comme \\(X\\) suit une loi binomiale \\(\\mathcal{B}(n,p)\\), on a \\(\\mathbb{E}(X)=np\\). Le paramètre \\(\\lambda\\) d’une loi de Poisson \\(\\mathcal{P}(\\lambda)\\) s’interprète donc comme le nombre moyen d’événements ayant lieu pendant une période de référence. Exemple 5 : loi géométrique \\(\\mathcal{G}(p)\\). \\(p\\) est un réel appartenant à \\(]0\\,;\\,1[\\) et on considère une succession d’épreuves de Bernoulli indépendantes (donc se soldant par un succès ou un échec). On dit que \\(X\\) suit la loi géométrique de paramètre \\(p\\) si \\(X\\in\\mathbb{N}^{*}\\) est le numéro du premier succès. Probabilités d’une loi géométrique. Soit \\(X\\) une variable aléatoire telle que \\(X\\sim\\mathcal{G}(p)\\). Alors, pour tout entier \\(k\\geq 1\\) on a \\[\\mathbb{P}(X=k)=(1-p)^{k-1}p\\] Démonstration. Soit \\(k\\) un entier supérieur ou égal à \\(1\\). Dire que \\(X=k\\) revient à dire que les \\(k-1\\) premières expériences se sont soldées par des échecs et que l’expérience numéro \\(k\\) a été un succès. En notant \\(S_k\\) l’événement L’expérience numéro \\(k\\) s’est soldée par un succès et \\(E_k\\) l’événement L’expérience numéro \\(k\\) s’est soldée par un échec, on a donc \\[\\begin{align} \\mathbb{P}(X=k)&amp;=\\mathbb{P}(S_1\\cap S_2\\cap\\dots\\cap S_{k-1}\\cap E_k) \\\\ &amp;=\\mathbb{P}(S_1)\\mathbb{P}(S_2)\\dots\\mathbb{P}(S_{k-1})\\mathbb{P}(E_k) \\, \\text{ par indépendance} \\\\ &amp;=(1-p)^{k-1}p \\\\ \\end{align}\\] \\(\\square\\) Exemple 6 : loi hypergéométrique. La loi hypergéométrique est, comme la loi binomiale, utilisée dans un contexte où l’on souhaite compter le nombre de succès dans une succession d’épreuves de Bernoulli. La différence avec la loi binomiale étant que maintenant, ces épreuves de Bernoulli ne sont plus identiques ni indépendantes. On suppose qu’une population de taille \\(N\\), exactement \\(D\\) individus possèdent une certaine caractéristique \\(\\mathcal{C}\\) (donc \\(0\\leq D\\leq N\\)). On tire un échantillon de taille \\(n\\) dans cette population, sans remise (donc \\(0\\leq n\\leq N\\)) et de façon équiprobable. On compte le nombre \\(X\\) d’individus de l’échantillon possédant la caractéristique \\(\\mathcal{C}\\). On dit alors que \\(X\\) suit la loi hypergéométrique \\(\\mathcal{H}(N,D,n)\\). On a alors : Support et probabilités d’une loi hypergéométrique. Pour \\(X\\sim\\mathcal{H}(N,D,n)\\), on a : i. Support de X. \\[\\max(0 \\,; \\,n-N+D)\\leq X\\leq \\min(n\\,;\\,D)\\] ii. Probabilités. Pour tout entier \\(\\max(0 \\,; \\,n-N+D)\\leq k\\leq \\min(n\\,;\\,D)\\) : \\[\\mathbb{P}(X=k)=\\frac{\\binom{D}{k}\\binom{N-D}{n-k}}{\\binom{N}{n}}\\] Démonstration. i. On a nécessairement : \\(0\\leq X\\leq n\\) : l’échantillon étant de taille \\(n\\), on tire au plus \\(n\\) individus ayant la propriété \\(\\mathcal{C}\\) ; \\(0\\leq X\\leq D\\) : le tirage de l’échantillon étant sans remise, on ne peut pas tirer plus d’unités ayant la propriété \\(\\mathcal{C}\\) qu’il n’y en a dans la population. De façon symétrique, on fait exactement le même raisonnement pour le tirage des individus n’ayant pas la propriété \\(\\mathcal{C}\\) : \\(0\\leq n-X\\leq n\\) : l’échantillon étant de taille \\(n\\), on tire au plus \\(n\\) individus n’ayant pas la propriété \\(\\mathcal{C}\\). On remarque que cet encadrement est automatiquement vérifié dès que le premier encadrement (sa version symétrique) l’est ; \\(0\\leq n-X \\leq N-D\\) : on ne peut pas tirer plus d’individus n’ayant pas la propriété \\(\\mathcal{C}\\) qu’il n’y en a dans la population. Les deux premiers encadrements s’écrivent plus simplement \\[0\\leq X\\leq \\min(n,D)\\] et le dernier encadrement s’écrit \\[\\max(0,n-N+D)\\leq X\\leq n\\] Enfin, ces deux encadrements s’écrivent \\[\\max(0,n-N+D)\\leq X\\leq\\min(n,D)\\] ii. Soit \\(k\\in R_X\\). Dénombrons le nombre d’échantillons de taille \\(n\\) satisfaisant la condition \\(X=k\\). La donnée d’un tel échantillon repose sur : le choix de \\(k\\) individus parmi les \\(D\\) ayant la caractéristique \\(\\mathcal{C}\\), soit \\(\\binom{D}{k}\\) choix possibles ; le choix de \\(n-k\\) individus parmi les \\(N-D\\) n’ayant pas la caractéristique \\(\\mathcal{C}\\), soit \\(\\binom{N-D}{n-k}\\) choix possibles. Pour \\(k\\) fixé, ces deux choix sont complètement indépendants, donc le nomnre \\(N_k\\) de choix d’un tel échantillon s’obtient par produit : \\(N_k=\\binom{D}{k}\\binom{N-D}{n-k}\\). Enfin, tous ces échantillons sont équiprobables, donc \\[\\mathbb{P}(X=k)=\\frac{\\binom{D}{k}\\binom{N-D}{n-k}}{\\binom{N}{n}}\\] \\(\\square\\) Exemple. Une urne contient \\(20\\) boules, parmi lesquelles \\(14\\) exactement sont rouges. On tire \\(12\\) boules dans l’urne, sans remise, et on compte le nombre \\(X\\) de boules rouges obtenues. Alors, \\(X\\sim\\mathcal{H}(20, 8, 5)\\). Le support de \\(X\\) est \\(R_X= [\\![6;12]\\!]\\) et \\[\\forall k\\in R_X, \\, \\mathbb{P}(X=k)=\\frac{\\binom{14}{k}\\binom{6}{12-k}}{\\binom{20}{12}}\\] 3.1.7 Simulation d’une variable aléatoire réelle 3.1.8 Moments d’une variable aléatoire Espérance d’une variable aléatoire réelle discrète Soit \\(X\\) une variable aléatoire réelle de support fini \\(X(\\Omega)=\\{x_1,\\dots,x_n\\}\\). On appelle espérance de \\(X\\) le nombre réel \\[\\mathbb{E}(X)=\\sum\\limits_{k=1}^n \\mathbb{P}(X=x_k)\\,x_k\\] Pour une variable aléatoire réelle discrète de support infini dénombrable \\(X(\\Omega)=\\{x_1,\\dots, x_n\\dots\\}\\), l’existence d’une espérance n’est pas systématique. On dit qu’une telle variable \\(X\\) admet une espérance finie si la série \\(\\sum\\limits_{n}\\mathbb{P}(X=x_n)\\,x_n\\) est asbolument convergente. Dans ce cas, l’espérance \\(\\mathbb{E}(X)\\) de \\(X\\) est la somme de cette série : \\[\\mathbb{E}(X)=\\sum\\limits_{n=0}^{\\infty}\\mathbb{P}(X=x_n)\\,x_n\\] Notation unifiée. Pour ne pas avoir à distinguer le cas fini / infini dénombrable, on peut aussi utiliser une notation englobant les deux cas : \\[\\mathbb{E}(X)=\\sum\\limits_{x\\in X(\\Omega)}\\mathbb{P}(X=x)\\,x\\] Remarque. L’espérance d’une variable est donc une moyenne de ses valeurs, pondérée par les probabilités qui leur sont associées. Cette expression de l’espérance s’écrit à partir des valeurs \\(x\\) prises par \\(X:\\Omega\\longrightarrow\\mathbb{R}\\), c’est-à-dire les éléments de l’espace d’arrivée de \\(X\\). On peut aussi exprimer l’espérance à partir des éléments de l’espace de départ de \\(X\\) : Espérance d’une variable aléatoire réelle discrète (variante) Soit \\(X:\\Omega\\longrightarrow\\mathbb{R}\\) une variable aléatoire réelle discrète d’espérance finie. Alors : \\[\\mathbb{E}(X)=\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})X(\\omega)\\] Démonstration. L’univers \\(\\Omega\\) peut se décomposer en \\[\\Omega=\\bigsqcup\\limits_{x\\in X(\\Omega)}\\bigsqcup\\limits_{\\omega\\in X^{-1}(\\{x\\})}\\{\\omega\\}\\] On a donc, sous réserve d’existence : \\[\\begin{align} \\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})X(\\omega)&amp;=\\sum\\limits_{x\\in X(\\Omega)}\\sum\\limits_{\\omega\\in X^{-1}(\\{x\\})}\\mathbb{P}(\\{\\omega\\})X(\\omega) \\\\ &amp;=\\sum\\limits_{x\\in X(\\Omega)}\\left(\\sum\\limits_{\\omega\\in X^{-1}(\\{x\\})}\\mathbb{P}(\\{\\omega\\})\\right)x \\\\ &amp;=\\sum\\limits_{x\\in X(\\Omega)}\\mathbb{P}(X=x)\\,x \\\\ &amp;=\\mathbb{E}(X) \\\\ \\end{align}\\] \\(\\square\\) Exemple. Le résultat précédent énonce l’égalité suivante : \\[\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})\\,X(\\omega)=\\sum\\limits_{x\\in X(\\Omega)}\\mathbb{P}(X=x)\\,x\\] Il nous dit que l’espérance de \\(X\\) peut être vue comme une moyenne sur l’espace de départ de \\(X\\), ou comme une moyenne sur l’espace d’arrivée de \\(X\\). L’équivalence entre ces deux points de vue est facile à saisir sur un exemple. Soient \\((\\Omega, \\mathcal{P}(\\Omega), \\mathbb{P})\\) un espace probabilisé tel que \\(\\Omega=\\{a,b,c,d\\}\\) et \\(X\\) une variable aléatoire réelle discrète sur cet espace. On donne le tableau suivant : Pour calculer \\(\\mathbb{E}(X)\\), on peut utiliser l’expression de l’espérance utilisant les éléments de l’univers \\(\\Omega\\) : \\[\\begin{align} \\mathbb{E}(X)&amp;=\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})\\,X(\\omega) \\\\ &amp;=0,3\\times 1+0,1\\times 1+0,4\\times 2+0,2\\times 2 \\\\ &amp;=1,6 \\\\ \\end{align}\\] Mais on peut aussi regrouper les valeurs de \\(\\omega\\) ayant des images communes par \\(X\\), et raisonner directement sur ces images (et leurs probabilités associées) : Dans ce cas, on fait plutôt le calcul : \\[\\begin{align} \\mathbb{E}(X)&amp;=0,4\\times 1+0,6\\times 2 \\\\ &amp;=1,6 \\\\ \\end{align}\\] On obtient alors bien le même résultat. Une application de ce résultat est le théorème de transfert : Théorème de transfert. Soient \\(X:\\Omega\\longrightarrow\\mathbb{R}\\) une variable aléatoire réelle discrète et \\(\\phi:X(\\Omega)\\longrightarrow\\mathbb{R}\\). On suppose que \\(\\phi(X)\\) admet une espérance finie. Alors, on a \\[\\mathbb{E}(\\phi(X))=\\sum\\limits_{x\\in X(\\Omega)}\\mathbb{P}(X=x)\\,\\phi(x)\\] En particulier, pour \\(\\phi(x)=x^m\\), avec \\(m\\) entier naturel, on a donc (sous réserve d’existence) : \\[\\mathbb{E}(X^m)=\\sum\\limits_{x\\in X(\\Omega)}\\mathbb{P}(X=x)\\,x^m\\] Démonstration. Avec les mêmes notations que pour le résultat précédent, on a \\[\\begin{align} \\mathbb{E}(\\phi(X))&amp;=\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})\\phi(X(\\omega)) \\\\ &amp;=\\sum\\limits_{x\\in X(\\Omega)}\\phi(x)\\sum\\limits_{\\omega\\in X^{-1}(\\{x\\})}\\mathbb{P}(\\{\\omega\\}) \\\\ &amp;=\\sum\\limits_{x\\in X(\\Omega)}\\mathbb{P}(X=x)\\phi(x) \\\\ \\end{align}\\] \\(\\square\\) Inteprétation du théorème de transfert. Ce résultat nous dit que pour calculer l’espérance de \\(\\phi(X)\\), la connaissance de la loi de \\(\\phi(X)\\) - qui dans certains cas peut être couteuse à acquérir - est inutile : la loi de \\(X\\) suffit. Exemple. Soit \\(X\\) une variable aléatoire de support \\(X(\\Omega)=\\mathbb{N}^*\\) et telle que \\[\\forall n\\in\\mathbb{N}^*,\\,\\mathbb{P}(X=n)=\\frac{1}{n(n+1)}\\] Nous allons montrer : qu’on définit ainsi bien la loi de probabilité d’une variable aléatoire ; que \\(X\\) n’admet pas d’espérance finie ; que \\(\\frac{X+1}{X}\\) admet une espérance finie, et que celle-ci est donnée par \\[\\mathbb{E}(X)=\\frac{\\pi^2}{6}\\] Soit \\(n\\) un entier naturel non nul. On a \\[\\begin{align} \\sum\\limits_{k=1}^n\\frac{1}{k(k+1)}&amp;=\\sum\\limits_{k=1}^n\\left(\\frac{1}{k}-\\frac{1}{k+1}\\right) \\\\ &amp;= 1-\\frac{1}{n+1} \\\\ &amp; \\text{(somme télescopique)} \\\\ \\end{align}\\] La série de terme général \\(\\frac{1}{n(n+1)}\\) est donc convergente, et sa somme vaut \\(1\\) : \\[\\sum\\limits_{n=1}^{\\infty}\\frac{1}{n(n+1)}=1\\] On a donc bien défini la loi d’une variable aléatoire. Par ailleurs, la série de terme général \\(n\\,\\mathbb{P}(X=n)=\\frac{1}{n+1}\\) n’est pas (absolument) convergente, donc \\(X\\) n’admet pas d’espérance finie. Enfin, pour démontrer que \\(\\frac{X+1}{X}\\) admet une espérance finie, il suffit d’après le théorème de transfert de montrer que la série de terme \\(\\sum\\limits_{n}\\mathbb{P}(X=n)\\,\\frac{n+1}{n}\\) est convergente. Si c’est bien le cas, son espérance sera égale à la somme de cette série. Or, on a : \\[\\begin{align} \\mathbb{P}(X=n)\\,\\frac{n+1}{n}&amp;=\\frac{1}{n(n+1)}\\frac{n+1}{n} \\\\ &amp;=\\frac{1}{n^2} \\\\ \\end{align}\\] La série \\(\\sum\\limits_{n}\\frac{1}{n^2}\\) est convergente, de somme \\[\\sum\\limits_{n=1}^{\\infty}\\frac{1}{n^2}=\\frac{\\pi^2}{6}\\] On en déduit le résultat. L’espérance, vue comme un opérateur, possède les propriétés suivantes : Propriétés de l’espérance. \\(X\\) et \\(Y\\) désignent des variables aléatoires réelles discrètes admettant une espérance, \\(\\lambda\\) est un réel. On a : i. Espérance d’une constante. Si \\(X=a\\) est constante, alors \\(\\mathbb{E}(X)=a\\). ii. Linéarité de l’espérance. \\(\\mathbb{E}(X+\\lambda Y)=\\mathbb{E}(X)+\\lambda\\,\\mathbb{E}(Y)\\) iii. Positivité de l’espérance. Si \\(X\\geq 0\\), alors \\(\\mathbb{E}(X)\\geq 0\\). iv. Croissance de l’espérance. Si \\(X\\leq Y\\), alors \\(\\mathbb{E}(X)\\leq\\mathbb{E}(Y)\\). Démonstration. i. Si \\(X=a\\) est constante, alors elle a pour support \\(R_x=\\{a\\}\\) et donc \\(\\mathbb{E}(X)=\\mathbb{P}(X=a).a=1.a=a\\). ii. Ici, il est plus simple d’utiliser la variante de la définition de l’espérance puisque dans ce cas la linéarité de l’espérance n’est rien d’autre qu’une traduction de la linéarité de l’opérateur \\(\\Sigma\\) : \\[\\begin{align} \\mathbb{E}(X+\\lambda Y)&amp;=\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})\\left(X(\\omega)+\\lambda\\,Y(\\omega)\\right) \\\\ &amp;=\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})X(\\omega)+\\lambda\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})Y(\\omega) \\\\ &amp;=\\mathbb{E}(X)+\\lambda\\,\\mathbb{E}(Y) \\\\ \\end{align}\\] iii. \\(X\\) étant positive, on a \\(\\mathbb{E}(X)=\\sum\\limits_{\\omega}\\mathbb{P}(\\{\\omega\\})X(\\omega)\\geq 0\\). iv. \\(Y-X\\geq 0\\) donc par positivité de l’espérance on a \\(\\mathbb{E}(Y-X)\\geq 0\\), et par linéarité on en déduit que \\(\\mathbb{E}(X)\\leq\\mathbb{E}(Y)\\). \\(\\square\\) Exemples. i. Espérance d’une loi uniforme finie. Sot \\(X\\) une loi uniforme sur \\(R_X=\\{x_1,\\dots,x_n\\}\\). On a donc \\(\\mathbb{P}(X=x_k)=\\frac{1}{n}\\), pour tout entier \\(1\\leq k\\leq n\\). D’où \\[\\mathbb{E}(X)=\\frac{1}{n}\\sum\\limits_{k=1}^n x_k=\\overline{x_n}\\] autrement dit, \\(\\mathbb{E}(X)\\) est la moyenne arithmétique des réels \\(x_1,\\dots, x_n\\). ii. Espérance d’une loi de Bernoulli \\(\\mathcal{B}(p)\\). On a \\[\\begin{align} \\mathbb{E}(X)&amp;=0\\times (1-p)+1\\times p \\\\ &amp;= p \\end{align}\\] On en profite pour signaler une égalité extrêment simple mais souvent utile en pratique : Espérance d’une indicatrice. Pour tout événement \\(A\\), on note \\(\\mathbb{1}_A\\) la variable aléatoire appelée indicatrice de \\(A\\), définie par \\[\\mathbb{1}_A= \\left \\{ \\begin{array}{c @{=} c} 1 &amp; \\text{ si } A \\text{ est réalisé } \\\\ 0 &amp; \\text{ sinon} \\end{array} \\right. \\] autrement dit, pour tout \\(\\omega\\in\\Omega\\) : \\[\\mathbb{1}_A(\\omega)= \\left \\{ \\begin{array}{c @{=} c} 1 &amp; \\text{ si } \\omega\\in A \\\\ 0 &amp; \\text{ sinon} \\end{array} \\right. \\] \\(\\mathbb{1}_A\\) suit une loi de Bernoulli de paramètre \\(p=\\mathbb{P}(A)\\), donc en particulier on a \\[\\mathbb{E}(\\mathbb{1}_A)=\\mathbb{P}(A)\\] Un exemple classique d’application de cette égalité est l’inégalité de Markov, qui est démontrée un peu plus bas. iii. Espérance d’une loi binomiale \\(\\mathcal{B}(n,p)\\). Pour \\(X\\sim\\mathcal{B}(n,p)\\), on peut écrire \\(X=\\sum\\limits_{i=1}^n X_i\\) avec \\(X_i\\sim\\mathcal{B}(p)\\). On a donc \\[\\begin{align} \\mathbb{E}\\left(\\sum\\limits_{i=1}^n X_i\\right) &amp;= \\sum\\limits_{i=1}^n \\mathbb{E}(X_i) \\\\ &amp;=np \\\\ \\end{align}\\] d’après ii. iv. Espérance d’une loi de Poisson \\(\\mathcal{P}(\\lambda)\\). Soit \\(X\\sim\\mathcal{P}(\\lambda)\\) avec \\(\\lambda&gt;0\\). La série \\(\\sum\\limits_{k}\\frac{\\lambda^k}{k!}k\\) est convergente, de somme \\[\\begin{align} \\sum\\limits_{k=0}^{\\infty}\\frac{\\lambda^k}{k!}k &amp;= \\sum\\limits_{k=1}^{\\infty}\\frac{\\lambda^k}{(k-1)!} \\\\ &amp;= \\lambda \\sum\\limits_{k=1}^{\\infty}\\frac{\\lambda^{k-1}}{(k-1)!} \\\\ &amp;= \\lambda\\sum\\limits_{k=0}^{\\infty}\\frac{\\lambda^k}{k!} \\\\ &amp;= \\lambda e^{\\lambda} \\\\ \\end{align}\\] Par conséquent, \\(X\\) admet une espérance et \\(\\mathbb{E}(X)=\\lambda\\). v. Espérance d’une loi géométrique \\(\\mathcal{G}(p)\\). On montre que si \\(X\\sim\\mathcal{G}(p)\\), avec \\(p\\in ]0;1[\\) alors \\(X\\) admet une espérance et \\[\\mathbb{E}(X)=\\frac{1}{p}\\] Pour cela on utilise le résultat suivant (seule l’égalité ii. est utile pour le calcul de l’espérance) : Série géométrique, séries géométriques dérivées Soit \\(x\\) un réel tel que \\(|x|&lt;1\\). Alors : i. \\(\\sum\\limits_{n=0}^{\\infty}x^n=\\frac{1}{1-x}\\) ii. \\(\\sum\\limits_{n=1}^{\\infty}nx^{n-1}=\\frac{1}{(1-x)^2}\\) iii. \\(\\sum\\limits_{n=2}^{\\infty}n(n-1)x^{n-2}=\\frac{2}{(1-x)^3}\\) Démonstration. i. Il s’agit de la somme d’une série géométrique de raison \\(x\\) tel que \\(|x|&lt;1\\). Pour \\(n\\) un entier tel que \\(n\\geq 1\\), on a \\(\\sum\\limits_{k=0}^n x^k=\\frac{1-x^{n+1}}{1-x}\\). Comme \\(|x|&lt;1\\) on a \\(x^{n+1}\\to 0\\) lorsque \\(n\\to\\infty\\). Donc la série \\(\\sum\\limits_{n}x^n\\) est convergente, de somme \\(\\frac{1}{1-x}\\). ii. Pour \\(n\\) entier supérieur ou égal à \\(1\\), on pose \\(S_n(x)=\\sum\\limits_{k=1}^n kx^{k-1}\\). On a \\(S_n=T_n^{&#39;}\\), avec \\(T_n(x)=\\sum\\limits_{k=0}^n x^k=\\frac{1-x^{n+1}}{1-x}\\). On a donc, pour \\(x\\) réel tel que \\(|x|&lt;1\\) : \\[\\begin{align} S_n(x)&amp;=T_n^{&#39;}(x) \\\\ &amp;=\\frac{-(n+1)x^n+(n+1)x^{n+1}+1-x^{n+1}}{(1-x)^2} \\\\ &amp;=\\frac{1-(n+1)x^n+nx^{n+1}}{(1-x)^2} \\\\ &amp;\\to\\frac{1}{(1-x)^2}\\, \\text{ lorsque } n\\to\\infty \\\\ \\end{align}\\] par croissances comparées. La série \\(\\sum\\limits_{n}nx^{n-1}\\) est donc convergente de somme \\(\\frac{1}{(1-x)^2}\\), ce qui permet de conclure. iii. L’égalité se montre exactement de la même façon que l’égalité ii. \\(\\square\\) Avec ce qui précède, la série \\(\\sum\\limits_{n}\\mathbb{P}(X=n)n=\\sum\\limits_{n}p\\,n\\,(1-p)^{n-1}\\) est convergente, de somme \\(\\frac{p}{(1-(1-p))^2}=\\frac{1}{p}\\). Autrement dit, \\(X\\) admet une espérance et \\(\\mathbb{E}(X)=\\frac{1}{p}\\). vi. Espérance d’une loi hypergéométrique \\(\\mathcal{H}(N,D,n)\\). On note \\(X\\) le nombre de boules blanches tirées lors de \\(n\\) tirages successifs sans remise dans une urne contenant \\(D\\) boules blanches et \\(N-D\\) boules rouges. On a \\[X=\\sum\\limits_{i=1}^n X_i\\] avec \\(X_i=1\\) si lors du tirage numéro \\(i\\) la boule est blanche, et \\(X_i=0\\) si elle est rouge. On a \\(X_i\\sim\\mathcal{B}(p_i)\\), avec \\(p_i=\\mathbb{P}(X=i)\\), et donc \\[\\mathbb{E}(X)=\\sum\\limits_{k=1}^n\\mathbb{E}(X_i)=\\sum\\limits_{i=1}^n p_i\\] Montrons que \\(p_i\\) est constant : \\(p_i=p\\). Pour cela, on note \\(a_i\\) (resp. \\(b_i\\)) le nombre de boules blanches (resp. rouges) restantes dans l’urne au moment du tirage numéro \\(i\\). Alors \\(p_i=\\frac{a_i}{b_i}\\) et : si \\(X_i=1\\), on a \\((a_{i+1},b_{i+1})=(a_i-1,b_i)\\) si \\(X_i=0\\), on a \\((a_{i+1},b_{i+1})=(a_i,b_i-1)\\) D’où \\[\\begin{align} p_{i+1}&amp;=\\mathbb{P}(X_{i+1}=1|X_i=1)\\,p_i+\\mathbb{P}(X_{i+1}=1|X_i=0)\\frac{b_i}{a_i+b_i}(1-p_i) \\\\ &amp;=\\frac{a_i-1}{a_i+b_i-1}\\frac{a_i}{a_i+b_i}+\\frac{a_i}{a_i+b_i-1}\\frac{b_i}{a_i+b_i} \\\\ &amp;=\\frac{a_i(a_i+b_i-1)}{(a_i+b_i-1)(a_i+b_i)} \\\\ &amp;=\\frac{a_i}{a_i+b_i} \\\\ &amp;=p_i \\end{align}\\] Ainsi, \\(p_i\\) ne dépend pas de \\(i\\) : \\(p_i=p=p_1=\\frac{N}{D}\\), et donc \\[\\mathbb{E}(X)=np\\] Plus généralement, on peut définir la notion de moment : Moments d’une variable aléatoire Soient \\(X\\) une variable aléatoire et \\(r\\in\\mathbb{N}\\). Si \\(X^r\\) admet une espérance finie, alors \\[m_r=\\mathbb{E}(X^r)\\] s’appelle moment d’ordre \\(r\\) de \\(X\\). De même, en notant \\(\\mu=\\mathbb{E}(X)\\), si \\((X-\\mu)^r\\) admet une espérance finie alors on appelle moment centré d’ordre \\(r\\) le réel \\[\\mu_r=\\mathbb{E}\\left((X-\\mu)^r\\right)\\] Cas \\(r=1\\) et \\(r=2\\) (toujours sous réserve d’existence) : \\(\\mu_1=0\\) \\(\\mu_2\\) s’appelle la variance de \\(X\\), notée \\(\\mathbb{V}(X)\\) : \\[\\mathbb{V}(X)=\\mathbb{E}\\left((X-\\mu)^2\\right)\\] Si \\(X\\) admet une variance, on appelle écart-type de \\(X\\) le réel positif \\[\\sigma_X=\\sqrt{\\mathbb{V}(X)}\\] Remarques. i. La formule \\(\\mu_1=0\\) est une conséquence directe de la linéarité de l’espérance : \\(\\mu_1=\\mathbb{E}(X-\\mu)=\\mathbb{E}(X)-\\mu=0\\). ii. L’espérance est un indicateur de position d’une variable aléatoire, alors que la variance et l’écart-type sont des indicateurs de dispersion. L’écart-type présente l’avantage sur la variance d’être de même dimension que la variable (tout comme l’espérance). La formule de König-Huygens permet d’exprimer la variance à partir des moments d’ordre 1 et 2 : Formule de König-Huygens Soit \\(X\\) une variable aléatoire réelle discrète admettant une variance. Alors \\[\\mathbb{V}(X)=\\mathbb{E}(X^2)-\\mathbb{E}(X)^2\\] Démonstration. En posant \\(\\mu=\\mathbb{E}(X)\\), on a \\[(x-\\mu)^2=X^2-2\\mu X+\\mu^2\\] En passant à l’espérance : \\[\\begin{align} \\mathbb{V}(X)&amp;=\\mathbb{E}(X^2)-2\\mu^2+\\mu^2 \\\\ &amp;=\\mathbb{E}(X^2)-\\mu^2 \\\\ \\end{align}\\] d’où le résultat. \\(\\square\\) Remarque. En pratique, c’est souvent cette formule que l’on utilise pour calculer une variance, qui est plus simple que celle de la définition. Propriétés de la variance Soient \\(X\\) une variable aléatoire réelle discrète admettant une variance, et \\(a\\) et \\(b\\) deux réels. Alors : i. \\(\\mathbb{V}(X)\\geq 0\\) avec égalité si et seulement si \\(X\\) est constante. ii. \\(\\mathbb{V}(aX+b)=a^2\\mathbb{V}(X)\\). Démonstration. i. On note \\(\\{x_k\\,;\\,k\\in K\\subset\\mathbb{N}\\}\\) les valeurs prises par \\(X\\) et \\(p_k=\\mathbb{P}(X=x_k)&gt;0\\). \\(\\mathbb{V}(X)=\\sum\\limits_{k\\in K}p_k\\,(x_k-\\mu)^2=0\\) si et seulement si \\(x_k=\\mu\\) pour tout \\(k\\) dans \\(K\\), autrement dit si et seulement si \\(X\\) est constante, égale à son espérance \\(\\mu\\). ii. \\(\\mathbb{E}(aX+b)=a\\mu+b\\), donc \\(\\left(aX+b-\\mathbb{E}(aX+b)\\right)^2=a^2(X-\\mu)^2\\), et en passant à l’espérance on en déduit que \\(\\mathbb{V}(aX+b)=a^2\\,\\mathbb{V}(X)\\). \\(\\square\\) Exemples. i. Variance d’une loi uniforme. Soit \\(X\\) uniforme sur l’ensemble fini \\(\\{x_1,\\dots,x_n\\}\\). Alors \\[\\mathbb{E}(X^2)=\\frac{1}{n}\\sum\\limits_{k=1}^n x_k^2\\] et donc \\[\\mathbb{V}(X)=\\frac{1}{n}\\sum\\limits_{k=1}^n x_k^2-\\left(\\frac{1}{n}\\sum\\limits_{k=1}^n x_k\\right)^2\\] ii. Variance d’une loi de Bernoulli \\(\\mathcal{B}(p)\\). Si \\(X\\sim\\mathcal{B}(p)\\), alors \\(X^2=X\\) (car \\(X\\in\\{0,1\\}\\)) donc \\(\\mathbb{E}(X^2)=\\mathbb{E}(X)=p\\), d’où \\[\\mathbb{V}(X)=p\\,(1-p)\\] iii. Variance d’une loi binomiale \\(\\mathcal{B}(n,p)\\). On démontrera un peu plus loin que, si \\(X\\sim\\mathcal{B}(n,p)\\), alors \\[\\mathbb{V}(X)=n\\,p\\,(1-p)\\] iv. Variance d’une loi de Poisson \\(\\mathcal{P}(\\lambda)\\). Soit \\(X\\sim\\mathcal{P}(\\lambda)\\). Soit \\(n\\geq 1\\) un entier. On a \\[\\begin{align} \\sum\\limits_{k=0}^n\\frac{\\lambda^k}{k!}k^2&amp;=\\sum\\limits_{k=2}^n\\frac{\\lambda^k}{k!}k(k-1)+\\sum\\limits_{k=2}^n\\frac{\\lambda^k}{k!}k \\\\ &amp;=\\lambda^2\\sum\\limits_{k=2}^n\\frac{\\lambda^{k-2}}{(k-2)!}+\\lambda\\sum\\limits_{k=1}^n\\frac{\\lambda^{k-1}}{(k-1)!} \\\\ &amp;=\\lambda^2\\sum\\limits_{k=0}^{n-2}\\frac{\\lambda^k}{k!}+\\lambda^k\\sum\\limits_{k=0}^{n-1}\\frac{\\lambda^k}{k!} \\\\ &amp;\\to (\\lambda^2+\\lambda)e^{\\lambda} \\\\ \\end{align}\\] La série \\(\\sum\\limits_{n}\\frac{\\lambda^n}{n!}n^2\\) est donc convergente de somme \\((\\lambda^2+\\lambda)e^{\\lambda}\\). On en déduit que \\(X^2\\) admet une espérance, et que \\[\\mathbb{E}(X^2)=\\lambda^2+\\lambda\\] Comme \\(\\mathbb{E}(X)=\\lambda\\), on en déduit que \\[\\mathbb{V}(X)=\\lambda\\] v. Variance d’une loi géométrique \\(\\mathcal{G}(p)\\). Pour \\(p\\in ]0\\,;\\,1[\\), on a \\[\\sum\\limits_{n=2}^{\\infty}n(n-1)(1-p)^{n-2}=\\frac{2}{p^3}\\] soit \\[\\sum\\limits_{n=1}^{\\infty}n(n+1)(1-p)^{n-1}=\\frac{2}{p^3}\\] et donc \\[\\begin{align} \\mathbb{E}(X^2)&amp;=p\\sum\\limits_{n=1}^{\\infty}n^2(1-p)^{n-1} \\\\ &amp;=\\frac{2}{p^2}-p\\sum\\limits_{n=1}^{\\infty}n(1-p)^{n-1} \\\\ &amp;=\\frac{2}{p^2}-\\mathbb{E}(X) \\\\ &amp;=\\frac{2}{p^2}-\\frac{1}{p} \\\\ &amp;=\\frac{2-p}{p^2} \\end{align}\\] d’où \\[\\begin{align} \\mathbb{V}(X)&amp;=\\mathbb{E}(X^2)-\\mathbb{E}(X)^2 \\\\ &amp;=\\frac{2-p}{p^2}-\\frac{1}{p^2}\\\\ &amp;=\\frac{1-p}{p^2} \\end{align}\\] vi. Variance d’une loi hypergéométrique \\(\\mathcal{H}(N,D,n)\\). Si \\(X\\sim\\mathcal{H}(N,D,n)\\) alors \\(X\\) admet une variance et \\[\\mathbb{V}(X)=\\frac{N-n}{N-1}\\times\\frac{nD}{N}\\left(1-\\frac{D}{N}\\right)\\] (formule admise pour le moment) 3.1.9 Quelques inégalités classiques Les inégalités qui suivent reviennent souvent dans les exercices et problèmes du concours. Inégalité triangulaire. Soit \\(X\\) une variable aléatoire réelle discrète telle que \\(|X|\\) est d’espérance finie. Alors \\(X\\) est d’espérance finie et \\[|\\mathbb{E}(X)|\\leq\\mathbb{E}(|X|)\\] Démonstration. Par définition, \\(X\\) est d’espérance finie si et seulement si \\(|X|\\) est d’espérance finie. On a alors : \\[\\begin{align} |\\mathbb{E}(X)|&amp;=\\left|\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})X(\\omega)\\right| \\\\ &amp;\\leq\\sum\\limits_{\\omega\\in\\Omega}|\\mathbb{P}(\\{\\omega\\})X(\\omega)| \\\\ &amp;=\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})|X(\\omega)| \\\\ &amp;=\\mathbb{E}(|X|) \\end{align}\\] \\(\\square\\) L’inégalité triangulaire est un cas particulier d’une inégalité beaucoup plus générale, appelée inégalité de Jensen. Rappel (fonction convexe) : Soit \\(I\\subset\\mathbb{R}\\) un intervalle. Une fonction \\(\\varphi:I\\longrightarrow\\mathbb{R}\\) est dite convexe si pour tout couple \\((x,y)\\in I^2\\) et pour tout réel \\(t\\in [0,1]\\) on a \\[\\varphi(tx+(1-t)y)\\leq t\\,\\varphi(x)+(1-t)\\,\\varphi(y)\\] Cette définition admet une interprétation graphique simple : \\(\\varphi\\) est convexe si et seulement si sa courbe représentative est située en-dessous de chacune de ses cordes. On peut montrer que cette définition de la convexité est équivalente à la définition suivante : \\(\\varphi:I\\longrightarrow\\mathbb{R}\\) est convexe si et seulement si pour tout \\(n-\\)uplet \\((t_1,\\dots t_n)\\) de réels positifs tels que \\(t_1+\\dots t_n=1\\), pour tout \\(n-\\)uplet \\((x_1,\\dots, x_n)\\) de réels, on a \\[\\varphi(t_1x_1+\\dots t_n x_n)\\leq t_1\\,\\varphi(x_1)+\\dots t_n\\,\\varphi(x_n)\\] Dans le cas où \\(\\varphi\\) est dérivable sur \\(I\\), elle est convexe si et seulement si sa dérivée \\(\\varphi^{&#39;}\\) est croissante sur \\(I\\), autrement dit si la pente de sa courbe représentative est croissante. On peut montrer que cela revient encore à dire que la courbe représentative de \\(\\varphi\\) est située au-dessus de chacune de ses tangentes. Dans le cas où \\(\\varphi\\) est deux fois dérivable sur \\(I\\), avec ce qui précède on obtient immédiatement que \\(\\varphi\\) est convexe si et seulement si \\(\\varphi^{&#39;&#39;}\\geq 0\\) sur \\(I\\). Enfin, on dit que \\(\\varphi:I\\longrightarrow\\mathbb{R}\\) est concave sur \\(I\\) si et seulement si \\(-\\varphi\\) est convexe sur \\(I\\). Inégalité de Jensen. Soient \\(I\\) un intervalle réel, \\(\\varphi:I\\longrightarrow\\mathbb{R}\\) une fonction convexe et \\(X:\\Omega\\longrightarrow I\\) une variable aléatoire discrète à valeurs dans \\(I\\), admettant une espérance et telle que \\(\\varphi(X)\\) admet une espérance. Alors \\[\\varphi\\left(\\mathbb{E}(X)\\right)\\leq\\mathbb{E}\\left(\\varphi(X)\\right)\\] Démonstration. On démontre l’inégalité dans le cas où \\(\\varphi\\) est dérivable. Dans ce cas, la convexité de \\(\\varphi\\) signifie que la courbe représentative de \\(f\\) est située au-dessus de chacune de ses tangentes. Pour tout réel \\(a\\) dans \\(I\\), on a donc \\[\\forall x\\in I,\\, \\varphi(x)\\geq \\varphi(a)+(x-a)\\,\\varphi&#39;(a)\\] et donc en particulier pour \\(a=\\mathbb{E}(X)\\) et \\(x=X\\) on obtient \\[\\varphi(X)\\geq\\varphi\\left(\\mathbb{E}(X)\\right)+\\left(X-\\mathbb{E}(X)\\right)\\,\\varphi&#39;\\left(\\mathbb{E}(X)\\right)\\] En passant à l’espérance, on obtient \\[\\begin{align} \\mathbb{E}(\\varphi(X))&amp;\\geq\\mathbb{E}\\left(\\varphi(\\mathbb{E}(X))+\\left(X-\\mathbb{E}(X)\\right)\\,\\varphi&#39;(\\mathbb{E}(X))\\right) \\\\ &amp;=\\varphi(\\mathbb{E}(X))+(\\mathbb{E}(X)-\\mathbb{E}(X))\\,\\varphi&#39;(\\mathbb{E}(X)) \\\\ &amp;=\\varphi(\\mathbb{E}(X)) \\end{align}\\] par croissance et linéarité de l’espérance. \\(\\square\\) Remarque. Dans le cas où \\(X\\) est à support fini \\(\\{x_1,\\dots, x_n\\}\\) on a \\[\\begin{align} \\varphi(\\mathbb{E}(X))&amp;=\\varphi\\left(\\sum\\limits_{k=1}^n\\mathbb{P}(X=x_k)\\,x_k\\right) \\\\ &amp;\\leq\\sum\\limits_{k=1}^n\\mathbb{P}(X=x_k)\\,\\varphi(x_k) \\,\\text{ ; par convexité} \\\\ &amp;=\\mathbb{E}\\left(\\varphi(X)\\right) \\\\ \\end{align}\\] Le cas discret infini revient à étendre cette inégalité à des sommes infinies (sous réserve d’existence), autrement dit à écrire que \\[\\varphi\\left(\\sum\\limits_{k=1}^{\\infty}\\mathbb{P}(X=x_k)\\,x_k\\right)\\leq\\sum\\limits_{k=1}^{\\infty}\\mathbb{P}(X=x_k)\\,\\varphi(x_k)\\] Exemples. i. L’inégalité triangulaire est un cas particulier d’application de l’inégalité de Jensen à la fonction valeur absolue, qui est bien convexe sur \\(\\mathbb{R}\\). ii. La fonction \\(x\\mapsto x^2\\) est convexe sur \\(\\mathbb{R}\\), donc, sous réserve d’existence des espérances, on a \\[\\mathbb{E}(X)^2\\leq\\mathbb{E}(X^2)\\] Les deux inégalités qui suivent sont des inégalités de concentration. Une inégalité de concentration donne un majorant à la probabilité qu’une variable aléatoire positive s’écarte d’une certaine valeur. L’inégalité de Markov est à la fois très utile et très facile à démontrer. Il faut retenir qu’elle permet de montrer l’inégalité de Bieanymé-Tchébychev. Inégalité de Markov. Soit \\(X\\) une variable aléatoire positive admettant une espérance. Alors, pour tout réel \\(a\\) positif : \\[\\mathbb{P}(X\\geq a)\\leq\\frac{\\mathbb{E}(X)}{a}\\] Démonstration. Soit \\(a\\) un réel positif. Toute réalisation \\(X(\\omega)\\) est soit supérieure ou égale à \\(a\\), soit strictement inférieure à \\(a\\). On a donc l’égalité \\[X=X.\\mathbb{1}_{X\\geq a}+X.\\mathbb{1}_{X&lt;a}\\] d’où \\[\\begin{align} \\mathbb{E}(X)&amp;=\\mathbb{E}(X.\\mathbb{1}_{X\\geq a}+X.\\mathbb{1}_{X&lt;a}) \\\\ &amp;=\\mathbb{E}(X.\\mathbb{1}_{X\\geq a})+\\mathbb{E}(X.\\mathbb{1}_{X&lt;a}) \\\\ &amp;\\geq a\\mathbb{E}(\\mathbb{1}_{X\\geq a}) \\\\ &amp;=a\\mathbb{P}(X\\geq a) \\end{align}\\] d’où (puisque \\(a&gt;0\\)) : \\[\\mathbb{P}(X\\geq a)\\leq\\frac{\\mathbb{E}(X)}{a}\\] \\(\\square\\) Exemples. i. Démontrer que pour toute variable aléatoire \\(X\\) et pour tout réel \\(a\\), on a \\(\\mathbb{P}(X\\geq a)\\leq\\mathbb{E}(e^{X-a})\\). Solution. Posons \\(Y=e^{X-a}\\) : il s’agit d’une variable aléatoire positive. Par ailleurs, l’événement \\((X\\geq a)\\) peut aussi s’écrire \\((Y\\geq 1)\\). Donc, par application de l’inégalité de Markov : \\[\\begin{align} \\mathbb{P}(X\\geq a)&amp;=\\mathbb{P}(Y\\geq 1) \\\\ &amp;\\leq\\frac{\\mathbb{E}(Y)}{1} \\\\ &amp;=\\mathbb{E}(e^{X-a}) \\end{align}\\] ii. Soient \\(X\\) une variable aléatoire et \\(f:\\mathbb{R}_+\\longrightarrow\\mathbb{R}_+\\) une fonction strictement croissante. Démontrer : \\[\\forall a&gt;0,\\,\\mathbb{P}(|X|\\geq a)\\leq\\frac{\\mathbb{E}(f(|X|))}{f(a)}\\] Solution. On pose \\(Y=f(|X|)\\) : on a \\(Y\\geq 0\\), puisque \\(f\\) est une fonction de \\(\\mathbb{R}_+\\) dans lui-même. Comme \\(f\\) est croissante, les événements \\((|X|\\geq a)\\) et \\((Y\\geq f(a))\\) sont égaux. D’où, par l’inégalité de Markov : \\[\\begin{align} \\mathbb{P}(|X|\\geq a)&amp;=\\mathbb{P}(Y\\geq f(a)) \\\\ &amp;\\leq\\frac{\\mathbb{E}(Y)}{f(a)} \\\\ &amp;=\\frac{\\mathbb{E}(f(|X|))}{f(a)} \\end{align}\\] \\(\\square\\) Lorsque \\(X\\) admet des moments d’ordres \\(1\\) et \\(2\\), on peut appliquer l’inégalité de Bienaymé-Tchebychev, qui se déduit de façon immédiate de l’inégalité de Markov : Inégalité de Bienaymé-Tchebychev. Soit \\(X\\) une variable aléatoire admettant une espérance et une variance. Alors, pour tout réel \\(a\\) strictement positif : \\[\\mathbb{P}\\left(|X-\\mathbb{E}(X)|\\geq a\\right)\\leq\\frac{\\mathbb{V}(X)}{a^2}\\] Démonstration. On pose \\(Y=\\left(X-\\mathbb{E}(X)\\right)^2\\geq 0\\). On a \\(|X-\\mathbb{E}(X)|\\geq a\\Leftrightarrow Y\\geq a^2\\). D’après l’inégalité de Markov : \\[\\begin{align} \\mathbb{P}(|X-\\mathbb{E}(X)|\\geq a)&amp;=\\mathbb{P}(Y\\geq a^2) \\\\ &amp;\\leq\\frac{\\mathbb{E}(Y)}{a^2} \\\\ &amp;=\\frac{\\mathbb{V}(X)}{a^2} \\\\ \\end{align}\\] \\(\\square\\) Interprétation. L’inégalité de Bienaymé-Tchebychev nous dit qu’une variable aléatoire ne peut s’éloigner de son espérance qu’avec une faible probabilité : \\(\\mathbb{P}(|X-\\mathbb{E}(X)|\\geq a)\\) est coincé entre \\(0\\) et \\(\\frac{\\mathbb{V}(X)}{a^2}\\), qui devient de plus en plus proche de \\(0\\) au fur et à mesure que \\(a\\) augmente. Application de l’inégalité de Bienaymé-Tchebychev : la loi faible des grands nombres, qui sera abordée plus tard. Exemple. On joue \\(1\\,000\\) fois à pile ou face avec une pièce équilibrée. Montrer que la probabilité d’obtenir entre \\(480\\) et \\(520\\) faces est supérieure ou égale à \\(0,375\\). Solution. On note \\(X\\) le nombre de faces obtenues. \\(X\\) est une variable aléatoire suivant la loi de Benoulli \\(\\mathcal{B}\\left(1\\,000\\,;\\,\\frac{1}{2}\\right)\\). On a \\(\\mathbb{E}(X)=500\\) et \\(\\mathbb{V}(X)=250\\). Donc, d’après l’inégalité de Bienaymé-Tchebcychev : \\[\\begin{align} \\mathbb{P}\\left(X\\in[480\\,;\\,520]\\right)&amp;=\\mathbb{P}(|X-\\mathbb{E}(X)|\\leq 20) \\\\ &amp;=1-\\mathbb{P}(|X-\\mathbb{E}(X)|&gt;20) \\\\ &amp;\\geq 1-\\mathbb{P}(|X-\\mathbb{E}(X)|\\geq 20) \\\\ &amp;\\geq 1-\\frac{\\mathbb{V}(X)}{20^2} \\\\ &amp;=1-\\frac{250}{400} \\\\ &amp;=0,375 \\end{align}\\] d’où le résultat. Une autre inégalité classique est l’inégalité de Cauchy-Schwarz. Elle sera présentée un peu plus bas, dans la section consacrée aux vecteurs aléatoires. 3.2 Transformation d’une variable aléatoire discrète Il arrive souvent dans les exercices qu’on étudie des variables aléatoires s’écrivant comme fonctions de variables aléatoires plus simples, ou dont la loi est connue. Soient \\(D\\) un sous-ensemble au plus dénombrable de \\(\\mathbb{R}\\), \\(X:\\Omega\\longrightarrow D\\) une variable aléatoire réelle discrète de support \\(D\\), et \\(\\varphi:D\\longrightarrow\\mathbb{R}\\) une fonction injective. Elle réalise donc une bijection de \\(D\\) sur \\(\\varphi(D)=\\{\\varphi(x),\\,x\\in D\\}\\). On pose \\(Y=\\varphi(X)\\) : il s’agit d’une variable aléatoire réelle discrète, définie sur \\(\\Omega\\) et de support \\(\\varphi(D)\\). La loi de \\(Y\\) se déduit facilement de celle de \\(X\\). Pour tout \\(y\\in\\varphi(D)\\) : \\[\\begin{align} \\mathbb{P}(Y=y)&amp;=\\mathbb{P}(\\varphi(X)=y)\\\\ &amp;=\\mathbb{P}(X=\\varphi^{-1}(y)) \\end{align}\\] Exemple. Soit \\(X\\sim\\mathcal{P}(\\lambda)\\), où \\(\\lambda&gt;0\\). Déterminer la loi de \\(\\ln(X+1)\\). Solution. \\(X\\) est à support dans \\(\\mathbb{N}\\), donc \\(Y=\\ln(X+1)\\) est à support dans \\(\\{\\ln(k),\\,k\\in\\mathbb{N}^*\\}\\subset\\mathbb{R}_+\\) et, pour tout \\(k\\in\\mathbb{N}^*\\) : \\[\\begin{align} \\mathbb{P}(\\ln(X+1)=\\ln k)&amp;=\\mathbb{P}(X=k-1) \\\\ &amp;=e^{-\\lambda}\\frac{\\lambda^{k-1}}{(k-1)!} \\end{align}\\] 3.3 Vecteurs aléatoires 3.3.1 Couple aléatoire : loi conjointe, lois marginales Couple de variables aléatoires, loi conjointe, lois marginales Soient \\(X\\) et \\(Y\\) deux variables aléatoires réelles discrètes définies sur le même espace probabilisé \\((\\Omega,\\mathcal{P}(\\Omega),\\mathbb{P})\\). La variable aléatoire \\[(X,Y):\\omega\\in\\Omega\\longrightarrow (X(\\omega), Y(\\omega))\\in\\mathbb{R}^2\\] est également une variable aléatoire discrète. Sa loi, appelée loi conjointe de \\(X\\) et \\(Y\\), est définie par la donnée des probabilités \\(\\mathbb{P}(\\{X=x\\}\\cap\\{Y=y\\})\\) pour tous les couples \\((x,y)\\in X(\\Omega)\\times Y(\\Omega)\\). Ces probabilités seront notées par la suite plus simplement \\(\\mathbb{P}(X=x,Y=y)\\). Par ailleurs, les lois de \\(X\\) et de \\(Y\\) sont appelées les lois marginales du couple \\((X,Y)\\). Les lois marginales se déduisent de la loi conjointe : \\[\\forall x\\in X(\\Omega),\\, \\mathbb{P}(X=x)=\\sum\\limits_{y\\in Y(\\Omega)}\\mathbb{P}(X=x, Y=y)\\] \\[\\forall y\\in Y(\\Omega),\\, \\mathbb{P}(Y=y)=\\sum\\limits_{x\\in X(\\Omega)}\\mathbb{P}(X=x, Y=y)\\] Démonstration. Soit \\(x\\in X(\\Omega)\\). Les événements \\((Y=y), \\, y\\in Y(\\Omega)\\) forment un système complet d’événements, donc les événements \\((X=x, Y=y),\\, y\\in Y(\\Omega)\\) constituent une partition de l’événement \\((X=x)\\). D’après la formule des probabilités totales, on a donc \\[\\mathbb{P}(X=x)=\\sum\\limits_{y\\in Y(\\Omega)}\\mathbb{P}(X=x,Y=y)\\] En échangeant les rôles de \\(X\\) et \\(Y\\), on obtient la deuxième formule. \\(\\square\\) Notation. Soient \\(x_i, \\, i\\in I\\) et \\(y_j,\\,j\\in J\\) les valeurs prises par \\(X\\) et \\(Y\\) (avec \\(I,J\\subset\\mathbb{N}\\) puisque \\(X\\) et \\(Y\\) sont discrètes). Dans la suite, on notera souvent, pour \\((i,j)\\in I\\times J\\) : \\[\\begin{align} p_{ij}&amp;=\\mathbb{P}(X=x_i, Y=y_j) \\\\ p_{i.}&amp;=\\mathbb{P}(X=x_i) \\\\ p_{.j}&amp;=\\mathbb{P}(Y=y_j) \\end{align}\\] Avec ces notations, a donc, pour tout couple \\((i,j)\\in I\\times J\\) : \\[p_{i.}=\\sum\\limits_{j\\in J}p_{ij}\\] \\[p_{.j}=\\sum\\limits_{i\\in I}p_{ij}\\] Tableau de contingence. Un tableau de contingence d’un couple de variables aléatoires contient toutes les informations sur la loi de ce couple : On y trouve : la loi du couple \\((X,Y)\\), donnée par les cellules du tableau, en nombre \\(\\text{Card}(X(\\Omega))\\times\\text{Card}(Y(\\Omega))\\) (éventuellement infini). La probabilité \\(p_{ij}=\\mathbb{P}(X=i, Y=j)\\) se trouve dans la cellule située à la ligne \\(i\\) et la colonne \\(j\\) ; la loi marginale \\(\\mathbb{P}_Y\\) de \\(Y\\) sur la ligne des totaux (en bleu) ; la loi marginale \\(\\mathbb{P}_X\\) de \\(X\\) sur la colonne des totaux (en rouge). Ce tableau doit aussi servir de mise en garde sur le fait que, sauf cas trivial (variable(s) aléatoire(s) constante(s)) : La connaissance des lois marginales ne suffit pas à caractériser la loi du couple En effet, les lois marginales correspondent à la ligne des totaux (en bleu) et la colonne des totaux (en rouge). Or, il n’y a pas unicité des nombres \\(p_{ij}\\) permettant de générer cette ligne et cette colonne. La connaissance des \\(p_{i.}\\) et des \\(p_{.j}\\) ne suffit donc pas à reconstruire les \\(p_{ij}\\). Le premier (contre-)exemple ci-dessous permet de s’en convaincre. Exemples.i. On considère les couples de variables aléatoires \\((X_1, Y_1)\\) et \\((X_2, Y_2)\\) dont les lois sont données par les tableaux ci-dessous : \\((X_1, Y_1)\\) et \\((X_2, Y_2)\\) ont les même lois marginales : \\(X_1\\) et \\(X_2\\) ont pour support commun \\(\\{x_1, x_2\\}\\) et : \\[\\mathbb{P}(X_1=x_1)=\\mathbb{P}(X_2=x_1)=0,6\\] \\[\\mathbb{P}(X_1=x_2)=\\mathbb{P}(X_2=x_2)=0,4\\] \\(Y_1\\) et \\(Y_2\\) ont pour support commun \\(\\{y_1, y_2\\}\\) et : \\[\\mathbb{P}(Y_1=y_1)=\\mathbb{P}(Y_2=y_1)=0,3\\] \\[\\mathbb{P}(X_1=x_2)=\\mathbb{P}(X_2=x_2)=0,7\\] Pourtant, \\((X_1, Y_1)\\) et \\((X_2, Y_2)\\) n’ont pas les mêmes lois conjointes. Par exemple : \\[\\mathbb{P}(X_1=x_1, Y_1=y_1)=0,2\\] \\[\\mathbb{P}(X_2=x_1, Y_2=y_1)=0,25\\] ii. On suppose que le couple \\((X,Y)\\) est à valeurs dans \\(E=\\{x_1\\dots x_n\\}\\times\\{y_1\\dots y_p\\}\\) et que \\[\\forall 1\\leq i\\leq n, \\, \\forall 1\\leq j\\leq p,\\,\\mathbb{P}(X=x_i, Y=y_j)=\\frac{1}{np}\\] autrement dit \\((X,Y)\\) consiste en un tirage uniforme dans \\(E\\). Intuitivement, on devine que \\(X\\) (resp. \\(Y\\)) correspond à un tirage uniforme dans \\(\\{x_1,\\dots,x_n\\}\\) (resp. dans \\(\\{y_1,\\dots y_p\\}\\)). La démonstration est évidente : \\[\\begin{align} \\mathbb{P}(X=x_i)&amp;=\\sum\\limits_{j=1}^p\\mathbb{P}(X=x_i, Y=y_j) \\\\ &amp;=\\sum\\limits_{j=1}^p\\frac{1}{np} \\\\ &amp;=\\frac{1}{n} \\end{align}\\] et symétriquement on a évidemment \\[\\mathbb{P}(Y=y_j)=\\frac{1}{p}\\] iii. Soient \\(X\\) et \\(Y\\) deux variables aléatoires à valeurs dans \\(\\mathbb{N}\\). On suppose que la loi conjointe de \\((X,Y)\\) est donnée par \\[\\mathbb{P}(X=i, Y=j)=\\frac{a}{i!\\,j!}\\] avec \\(a\\) un réel. Nous allons déterminer les lois marginales de \\(X\\) et \\(Y\\). Pour cela, on constate d’abord que la valeur de \\(a\\) est contrainte par l’égalité \\[\\sum\\limits_{i=0}^{\\infty}\\sum\\limits_{j=0}^{\\infty}\\mathbb{P}(X=i, Y=j)=1\\] qui s’écrit \\[a\\sum\\limits_{i=0}^{\\infty}\\frac{1}{i!}.\\sum\\limits_{j=0}^{\\infty}\\frac{1}{j!}=1\\] et qui permet de trouver que \\[a=\\frac{1}{e^2}\\] On en déduit que, pour tout entier naturel \\(i\\), on a : \\[\\begin{align} \\mathbb{P}(X=i&amp;)=\\sum\\limits_{j=0}^{\\infty}\\mathbb{P}(X=i, Y=j) \\\\ &amp;= \\frac{1}{e^2}\\sum\\limits_{j=0}^{\\infty}\\frac{1}{i!\\,j!} \\\\ &amp;=\\frac{1}{e.i!} \\end{align}\\] On reconnaît la loi de Poisson \\(\\mathcal{P}(1)\\). \\(X\\) et \\(Y\\) jouant des rôles symétriques, on a donc \\[X\\sim\\mathcal{P}(1)\\] \\[Y\\sim\\mathcal{P}(1)\\] 3.3.2 \\(n-\\)uplets aléatoires Ce qui précède se généralise sans difficulté aux vecteurs aléatoires de taille quelconque, i.e. aux \\(n-\\)uplets \\((X_1,\\dots,X_n)\\) de variables aléatoires discrètes réelles définies sur un même espace probabilisé \\((\\Omega, \\mathcal{P}(\\Omega), \\mathbb{P})\\). La loi conjointe d’un tel vecteur est définie par la donnée de son support \\(X_1(\\Omega)\\times\\dots\\times X_n(\\Omega)\\) et des probabilités \\[\\mathbb{P}(X_1=x_1,\\dots,X_n=x_n)\\] pour tous les \\(n-\\)uplets \\((x_1,\\dots,x_n)\\in X_1(\\Omega)\\times\\dots\\times X_n(\\Omega)\\). Le vecteur \\((X_1,\\dots,X_n)\\) possède \\(n\\) lois marginales, qui sont les lois \\(\\mathbb{P}_{X_1},\\dots,\\mathbb{P}_{X_n}\\) des variables \\(X_1,\\dots,X_n\\). La loi conjointe d’un vecteur de taille quelconque définit complètement les lois marginales, mais à nouveau les lois marginales ne suffisent pas à définir la loi conjointe. 3.3.3 Loi conditionnelle \\(\\mathbb{P}_{X|Y=y_j}\\) Soit \\((X,Y)\\) un couple aléatoire dont la loi est donnée par le tableau de contingence suivant : La colonne numéro \\(j\\) fixe la valeur de \\(Y\\) à \\(Y=y_j\\). Considérons la liste des probabilités apparaissant dans cette colonne : \\[p_{1j},\\dots,p_{nj}\\] Cette série de valeurs somme à \\(p_{.j}\\) : \\[\\sum\\limits_{i\\in I}p_{ij}=p_{.j}\\] Donc, en divisant toutes ces probabilités par \\(p_{.j}\\), on obtient des nombres compris entre \\(0\\) et \\(1\\) et qui somment à \\(1\\) : \\[\\sum\\limits_{i\\in I}\\frac{p_{ij}}{p_{.j}}=1\\] de sorte que le vecteur \\(\\left(\\frac{p_{1j}}{p_{.j}},\\dots,\\frac{p_{nj}}{p_{.j}},\\dots\\right)\\) peut s’interpréter comme une loi de probabilité. Mais ces valeurs caractérisent la distribution de \\(X\\) lorsqu’on se place dans la colonne numéro \\(j\\), autrement dit lorsqu’on fait l’hypothèse \\(Y=j\\). Il est donc naturel d’appeler cette distribution la loi de \\(X\\) conditionnellement à \\((Y=y_j)\\). L’ensemble des lois conditionnelles \\(\\mathbb{P}(X|Y=y_j)\\) sont données par le tableau suivant (lecture en colonnes) : Loi conditionnelle de \\(X\\) sachant \\(Y=y_j\\). Avec les notations précédentes, et sous réserve que \\(\\mathbb{P}(Y=y_j)&gt;0\\), on pose, pour tout \\(x_i\\in X(\\Omega)\\) : \\[\\mathbb{P}(X=x_i|Y=y_j)=\\frac{\\mathbb{P}(X=x_i, Y=y_j)}{\\mathbb{P}(Y=y_j)}\\] On définit ainsi une loi de probabilité, appelée loi conditionnelle de \\(X\\) sachant que \\(Y=y_j\\), et notée \\(\\mathbb{P}_{X|Y=y_j}\\). Remarques. i. De façon symétrique, on définit des lois conditionnelles \\(\\mathbb{P}_{Y|X=x_i}\\) pour toutes les valeurs de \\(i\\) telles que \\(\\mathbb{P}(X=x_i)&gt;0\\). Cette loi est définie par la donnée des probabilités \\[\\mathbb{P}(Y=y_j|X=x_i)=\\frac{\\mathbb{P}(X=x_i, Y=y_j)}{\\mathbb{P}(X=x_i)}\\] pour tous les \\(y_j\\in Y(\\Omega)\\). L’ensemble de ces lois conditionnelles \\(\\mathbb{P}_{Y|X=x_i}\\) sont représentées dans le tableau suivant (lecture en lignes) : ii. On peut aussi introduire la notion de loi conditionnelle en utilisant directement la définion de probabilité conditionnelle faite au chapitre précédent. Pour deux événements \\(A\\) et \\(B\\) tels que \\(\\mathbb{P}(B)&gt;0\\), on définit la probabilité de \\(A\\) sachant \\(B\\) en posant \\[\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\] En posant \\(A=(X=x_i)\\) et \\(B=(Y=y_j)\\), on a donc \\[\\mathbb{P}(X=x_i|Y=y_j)=\\frac{\\mathbb{P}(X=x_i, Y=y_j)}{\\mathbb{P}(Y=y_j)}\\] L’approche par tableau de contingence présente toutefois l’avantage d’être un peu plus intuitive. Exemples. i. On tire aléatoirement deux nombres \\(X\\) et \\(Y\\) selon la règle suivante : tirage de \\(X\\) selon une loi de Bernoulli de paramètre \\(p\\in ]0,1[\\) ; puis tirage de \\(Y\\) : si \\(X=0\\), on tire \\(Y\\) selon une loi de Poisson \\(\\mathcal{P}(\\lambda)\\), avec \\(\\lambda&gt;0\\) ; si \\(X=1\\), on tire \\(Y\\) selon une loi uniforme sur \\(\\{0,1,2,3\\}\\). On connait donc la loi de \\(X\\) : \\[X\\sim\\mathcal{B}(p)\\] et on connait les lois de \\(Y\\) sachant \\(X=0\\) et de \\(Y\\) sachant \\(X=1\\) : \\[Y|X=0\\sim\\mathcal{P}(\\lambda)\\] \\[Y|X=1\\sim\\mathcal{U}\\left(\\{0,1,2,3\\}\\right)\\] On peut en déduire facilement les lois \\(\\mathbb{P}_Y\\) et \\(\\mathbb{P}_{(X,Y)}\\). Commençons par la loi de \\(Y\\). Support de \\(Y\\) : \\(Y(\\Omega)=\\mathbb{N}\\) Probabilités \\(\\mathbb{P}(Y=j)\\) : pour tout entier naturel \\(j\\), on a \\[\\begin{align} \\mathbb{P}(Y=j)&amp;=\\mathbb{P}(Y=j|X=0)\\mathbb{P}(X=0)+\\mathbb{P}(Y=j|X=1)\\mathbb{P}(X=1) \\\\ &amp;=(1-p).\\mathbb{P}(Y=j|X=0)+p.\\mathbb{P}(Y=j|X=1) \\end{align}\\] On en déduit que : si \\(0\\leq j\\leq 3\\), alors \\[\\mathbb{P}(Y=j)=(1-p)\\,e^{-\\lambda}\\frac{\\lambda^j}{j!}+\\frac{p}{4}\\] si \\(j\\geq 4\\), alors \\[\\mathbb{P}(Y=j)=(1-p)\\,e^{-\\lambda}\\frac{\\lambda^j}{j!}\\] *On détermine maintenant la loi conjointe de \\((X,Y)\\)** Support de \\((X,Y)\\) : \\((X,Y)(\\Omega)=\\{0,1\\}\\times\\mathbb{N}\\) Probabilités \\(\\mathbb{P}(X=i, Y=j)\\) : pour \\((i,j)\\in\\{0,1\\}\\times\\mathbb{N}\\), on a pour \\(i=0\\) : \\[\\begin{align} \\mathbb{P}(X=0,Y=j)&amp;=\\mathbb{P}(Y=j|X=0)\\mathbb{P}(X=0) \\\\ &amp;= (1-p)e^{-\\lambda}\\frac{\\lambda^j}{j!} \\\\ \\end{align}\\] pour \\(i=1\\), on a \\[\\begin{align} \\mathbb{P}(X=1,Y=j)&amp;=\\mathbb{P}(Y=j|X=1)\\mathbb{P}(X=1) \\\\ &amp;=\\left \\{ \\begin{array}{c @{=} c} \\frac{p}{4} &amp; \\text{ si } 0\\leq j\\leq 3 \\\\ 0 &amp; \\text{ si } j\\geq 4 \\end{array} \\right. \\end{align}\\] On peut donner l’expression générale de \\(\\mathbb{P}(X=i, Y=j)\\) : \\[\\mathbb{P}(X=i, Y=j)=i\\,\\frac{p}{4}.\\mathbb{1}_{0\\leq j\\leq 3}+(1-i)(1-p)e^{-\\lambda}\\frac{\\lambda^j}{j!}\\] On en déduit alors la loi de \\(Y\\). Support de \\(Y\\) : \\(Y(\\Omega)=\\mathbb{N}\\) Probabilités \\(\\mathbb{P}(Y=j)\\) : pour tout entier naturel \\(j\\), on a, d’après la formule des probabilités totales : \\[\\begin{align} \\mathbb{P}(Y=j)&amp;=\\mathbb{P}(Y=j,X=0)+\\mathbb{P}(Y=j,X=1) \\\\ &amp;=(1-p)e^{-\\lambda}\\frac{\\lambda^j}{j!}+\\frac{p}{4}\\mathbb{1}_{0\\leq j\\leq 3} \\end{align}\\] ii. Dans un exemple précédent, on a défini la loi d’un couple aléatoire \\((X,Y)\\) par \\[\\forall (i,j)\\in\\mathbb{N}^2,\\,\\mathbb{P}(X=i, Y=j)=\\frac{1}{e^2\\,i!\\,j!}\\] et on a montré que les lois marginales sont toutes les deux égales à la loi de Poisson \\(\\mathcal{P}(1)\\) : \\[\\forall i\\in\\mathbb{N},\\,\\mathbb{P}(X=i)=\\mathbb{P}(Y=i)=\\frac{1}{e.i!}\\] On en déduit que \\[\\begin{align} \\mathbb{P}(X=i|Y=j)&amp;=\\frac{\\mathbb{P}(X=i, Y=j)}{\\mathbb{P}(Y=j)}\\\\ &amp;=\\frac{\\frac{1}{e^2\\,i!\\,j!}}{\\frac{1}{e\\,j!}} \\\\ &amp;=\\frac{1}{e\\,i!} \\\\ &amp;=\\mathbb{P}(X=i) \\end{align}\\] De façon analogue : \\[\\mathbb{P}(Y=j|X=i)=\\mathbb{P}(Y=j)\\] Ces deux égalités signifient : pour la première, que l’information de la valeur prise par \\(Y\\) n’a aucun impact sur la loi de \\(X\\) ; pour la deuxième, que l’information de la valeur prise par \\(X\\) n’a aucun impact sur la loi de \\(Y\\). Dans une telle situation, on dit que les variables aléatoires \\(X\\) et \\(Y\\) sont indépendantes. De façon générale, l’indépendance de deux variables aléatoires est définie de façon simple par une égalité (ou plutôt une série d’égalités) : Indépendance de deux variables aléatoires Deux variables aléatoires réelles discrètes \\(X\\) et \\(Y\\) définies sur un même espace probabilisé \\((\\Omega, \\mathcal{P}(\\Omega),\\mathbb{P})\\) sont dites indépendantes lorsque \\[\\forall (x,y)\\in X(\\Omega)\\times Y(\\Omega),\\, \\mathbb{P}(X=x, Y=y)=\\mathbb{P}(X=x)\\,\\mathbb{P}(Y=y)\\] Notation : \\(X\\perp\\!\\!\\!\\perp Y\\) Remarques. i. Tout variable aléatoire constante est donc, selon cette définition, indépendante de n’importe quelle variable aléatoire (y compris elle-même !). En effet, soient \\(X=a\\) (\\(a\\in\\mathbb{R}\\)) une variable aléatoire constante et \\(Y\\) une variable aléatoire quelconque. On a, pour \\(x\\in\\mathbb{R}\\) : \\[(X=x)=\\left \\{ \\begin{array}{c @{=} c} \\Omega &amp; \\text{ si } x=a \\\\ \\emptyset &amp; \\text{ si } x\\neq a \\end{array} \\right.\\] donc \\[\\begin{align} \\mathbb{P}(X=x)\\,\\mathbb{P}(Y=y)&amp;=\\left \\{ \\begin{array}{c @{=} c} \\mathbb{P}(Y=y) &amp; \\text{ si } x=a \\\\ 0 &amp; \\text{ si } x\\neq a \\end{array} \\right. \\\\ &amp;=\\mathbb{P}(X=x, Y=y) \\\\ \\end{align}\\] ii. Si deux variables aléatoires sont indépendantes, leur loi conjointe peut donc être reconstruite à partir des lois marginales. Toutefois, à l’exception du cas trivial ou l’une au moins des deux variables est constante, la connaissance du caractère indépendant ou non de ces variables ne peut être acquise à l’aide de la seule information des lois marginales : la propriété d’indépendance est bien une propriété du couple, et non une propriété des lois marginales. Exemples. i. On considère deux variables aléatoires sont la loi conjointe est donnée par le tableau de contingence suivant : Pour déterminer si \\(X\\) et \\(Y\\) sont ou non indépendantes, on peut ajouter à ce tableau les probabilités marginales : On constate par exemple que \\(\\mathbb{P}(X=1,Y=1)=0\\), mais \\(\\mathbb{P}(X=1)\\,\\mathbb{P}(Y=1)\\neq 0\\) : donc \\(X\\) et \\(Y\\) ne sont donc pas indépendantes. ii. Cette fois, le couple \\((X,Y)\\) a pour tableau de contingence : Comme dans l’exemple précédent, on le complète des probabilités marginales : Cette fois, on constate que chaque probabilité conjointe est égale au produit des probabilités marginales correspondantes, donc \\(X\\) et \\(Y\\) sont indépendantes. Par définition de l’indépendance de deux variables, l’expression de chaque probabilité conjointe \\(\\mathbb{P}(X=x,Y=y)\\) peut s’écrire comme un produit de deux termes : un premier terme qui est une fonction de \\(x\\) uniquement, et un deuxième terme qui est une fonction de \\(y\\) uniquement. Cette possibilité de séparer en un terme en \\(x\\) et en un terme en \\(y\\) a pour conséquence que l’espérance d’un produit de deux variables indépendantes est le produit de leurs espérances : Théorème. Soient \\(X\\) et \\(Y\\) deux variables aléatoires définies sur un espace probabilisé \\((\\Omega, \\mathcal{P}(\\Omega), \\mathbb{P})\\). Si \\(X\\) et \\(Y\\) sont indépendantes, alors, sous réserve d’existence de ces espérances : \\[\\mathbb{E}(XY)=\\mathbb{E}(X)\\,\\mathbb{E}(Y)\\] Démonstration. \\[\\begin{align} \\mathbb{E}(XY)&amp;=\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})\\,X(\\omega)\\,Y(\\omega) \\\\ &amp;=\\sum\\limits_{x\\in X(\\Omega)}\\sum\\limits_{y\\in Y(\\omega)}\\mathbb{P}(X=x, Y=y)\\,x\\,y \\\\ &amp;\\text{(théorème de transfert)} \\\\ &amp; \\\\ &amp;=\\sum\\limits_{x\\in X(\\Omega)}\\sum\\limits_{y\\in Y(\\omega)}\\mathbb{P}(X=x)\\,\\mathbb{P}(Y=y)\\,x\\,y \\\\ &amp;\\text{(indépendance de } X \\text{ et } Y \\text{)} \\\\ &amp;\\\\ &amp;=\\left(\\sum\\limits_{x\\in X(\\Omega)}\\mathbb{P}(X=x)\\, x\\right).\\left(\\sum\\limits_{y\\in Y(\\omega)}\\mathbb{P}(Y=y)\\,y\\right) \\\\ &amp;=\\mathbb{E}(X)\\,\\mathbb{E}(Y) \\\\ \\end{align}\\] \\(\\square\\) Exemple. On reprend l’exemple précédent, dans lequel nous avons montré l’indépendance entre \\(X\\) et \\(Y\\). On a : \\[\\begin{align} \\mathbb{E}(X)&amp;=0,4\\times 1+0,2\\times 2+0,4\\times 3 \\\\ &amp;=2 \\\\ \\end{align}\\] et \\[\\begin{align} \\mathbb{E}(Y)&amp;=0,2\\times 1+0,1\\times 2+0,4\\times 3+0,3\\times 4 \\\\ &amp;=2,8 \\\\ \\end{align}\\] Par indépendance de \\(X\\) et \\(Y\\), on en déduit que \\[\\mathbb{E}(XY)=\\mathbb{E}(X)\\,\\mathbb{E}(Y)=5,6\\] 3.3.4 Espérance conditionnelle \\(\\mathbb{E}(Y|X=x)\\) 3.3.5 Loi conditionnelle \\(\\mathcal{L}(Y|X)\\) 3.3.6 Somme de deux VA indépendantes (produit de convolution discret) 3.3.7 Inégalité de Cauchy-Schwarz L’inégalité de Cauchy-Schwarz est un résultat important d’algèbre. On rappelle d’abord la notion de produit scalaire sur un espace vectoriel. Rappel : produit scalaire. Dans un espace-vectoriel \\(E\\), on appelle produit scalaire toute application \\(\\phi:E\\times E\\longrightarrow\\mathbb{R}\\) vérifiant les propriétés suivantes : Bilinéarité : \\(\\phi\\) est linéaire à gauche et linéaire à droite : Linéarité à gauche : \\(\\forall x,y,z\\in E,\\, \\forall\\lambda\\in\\mathbb{R}, \\, \\phi(x+\\lambda y, z)=\\phi(x,z)+\\lambda\\phi(y,z)\\) linéarité à droite : \\(\\forall x,y,z\\in E,\\, \\forall\\lambda\\in\\mathbb{R}, \\, \\phi(x, y+\\lambda z)=\\phi(x,y)+\\lambda\\phi(x,z)\\) Symétrie : \\(\\forall x,y\\in E,\\, \\phi(x,y)=\\phi(y,x)\\) Définie positive : \\(\\forall x\\in E, \\phi(x,x)\\geq 0\\), avec égalité si et seulement si \\(x=0\\). Une notation courante pour un produit scalaire est \\(&lt;.\\,,\\,.&gt;\\). De plus, pour \\(x\\in E\\), on note \\(||x||=\\sqrt{&lt;x\\,,\\,x&gt;}\\). Il s’agit d’une norme sur \\(E\\), i.e. une application de \\(E\\) dans \\(\\mathbb{R}\\) vérifiant les propriétés suivantes : pour tout \\(x\\) dans \\(E\\), \\(||x||=0\\) si et seulement si \\(x=0\\) ; pour tout \\(x\\) dans \\(E\\) et pour tout réel \\(\\lambda\\) : \\(||\\lambda x||=|\\lambda|.||x||\\) ; pour tous \\(x,y\\) dans \\(E\\), \\(||x+y||\\leq ||x||+||y||\\). L’inégalité de Cauchy-Schwarz établit une majoration du produit scalaire (et même de sa valeur absolue) par le produit des normes : Inégalité de Cauchy-Schwarz. Soient \\((E\\,,\\,&lt;\\,,\\,&gt;)\\) un espace préhilbertien réel et \\(||.||\\) la norme associée au produit scalaire \\(&lt;\\,,\\,&gt;\\). Alors, on a \\[\\forall x,y\\in E,\\,|&lt;x\\,,y&gt;|\\leq ||x||\\,||y||\\] avec égalité si et seulement si \\(x\\) et \\(y\\) sont colinéaires. Démonstration. Soient \\(x,y\\in E\\). Pour tout réel \\(t\\), on a \\[\\begin{align} 0&amp;\\leq||x-ty||^2 \\\\ &amp;=||y||^2t^2-2&lt;x\\,,\\,y&gt;t+||x||^2 \\\\ \\end{align}\\] On peut voir \\(||y||^2t^2-2&lt;x\\,,\\,y&gt;t+||x||^2\\) comme un trinôme en \\(t\\), toujours positif ou nul. Par conséquent son discriminant est négatif ou nul, soit \\[4&lt;x\\,,\\,y&gt;^2-4||x||^2||y||^2\\leq 0\\] i.e. \\[|&lt;x\\,,\\,y&gt;|\\leq ||x||\\,||y||\\] Le cas d’égalité signifie que ce discriminant est nul. Dans ce cas, il existe \\(t\\) réel tel que \\(x=ty\\), ce qui signifie exactement que \\(x\\) et \\(y\\) sont colinéaires. \\(\\square\\) Dans le cadre de la théorie des probabilités, l’inégalité de Cauchy-Schwarz est souvent appliquée dans l’epace \\(L^2(\\Omega, \\mathcal{P}(\\Omega), \\mathbb{P})\\). L’espace \\(L^2(\\Omega)\\). On note \\(L^2(\\Omega, \\mathcal{P}(\\Omega),\\mathbb{P})\\), ou plus simplement \\(L^2(\\Omega)\\), l’ensemble des variables aléatoires \\(X:(\\Omega,\\mathcal{P}(\\Omega),\\mathbb{P})\\longrightarrow\\mathbb{R}\\) telles que \\(\\mathbb{E}(X^2)&lt;\\infty\\). Cet espace peut être muni d’un produit scalaire : \\[\\forall X,Y\\in L^2(\\Omega),\\, &lt;X\\,,\\,Y&gt;=\\mathbb{E}(XY)\\] La norme associée est définie par : \\[\\forall X\\in L^2(\\Omega),\\,||X||=\\sqrt{\\mathbb{E}(X^2)}\\] Dans \\(L^2(\\Omega)\\), l’inégalité de Cauchy-Schwarz prend donc la forme suivante : Inégalité de Cauchy-Schwarz dans \\(L^2(\\Omega)\\). Soient \\(X,Y\\in L^2(\\Omega)\\) deux variables aléatoires discrètes. Alors : \\[|\\mathbb{E}(XY)|\\leq\\sqrt{\\mathbb{E}(X^2)}\\,\\sqrt{\\mathbb{E}(Y^2)}\\] Cette inégalité s’écrit aussi : \\[\\left|\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})\\,X(\\omega)\\,Y(\\omega)\\right|\\leq\\sqrt{\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})\\,X^2(\\omega)}\\sqrt{\\sum\\limits_{\\omega\\in\\Omega}\\mathbb{P}(\\{\\omega\\})\\,Y^2(\\omega)}\\] Avec le théorème de transfert, on peut aussi écrire : \\[\\left|\\sum\\limits_{k\\in K}\\sum\\limits_{l\\in L}\\mathbb{P}(X=x_k, Y=y_l)\\,x_k\\,y_l\\right|\\leq\\sqrt{\\sum\\limits_{k\\in K}\\mathbb{P}(X=x_k)\\,x_k^2}\\,\\sqrt{\\sum\\limits_{l\\in L}\\mathbb{P}(Y=y_l)\\,y_l^2}\\] "]]
