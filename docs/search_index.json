[["variables-aléatoires-discrètes.html", "Chapitre 3 Variables aléatoires discrètes 3.1 Définition et premières propriétés 3.2 Transformation d’une variable aléatoire discrète 3.3 Vecteurs aléatoires", " Chapitre 3 Variables aléatoires discrètes Supposons que vous jouiez avec un ami au jeu suivant. Votre ami lance un dé équilibré et vous convenez des règles suivantes : si le dé tombe sur \\(1\\) ou \\(2\\), vous donnez \\(3\\) euros à votre ami ; si le dé tombe sur \\(2\\) ou \\(3\\), votre ami vous donne \\(3\\) euros ; si le dé tombe sur \\(5\\) ou \\(6\\), aucun de vous deux ne gagne ni ne perd d’argent. On note \\(X\\) votre gain algébrique. Alors, \\(X\\) est un nombre aléatoire dont les valeurs possibles sont \\(-3, 3\\) et \\(0\\). L’expérience aléatoire qui consiste à lancer ce dé et à relever son numéro peut être modélisée par l’univers probabilisé \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\), où \\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\(\\mathcal{A}=\\mathcal{P}(\\Omega)\\) et \\(\\mathbb{P}\\) est la mesure équirépartie : \\(\\forall\\omega\\in\\Omega, \\,\\mathbb{P}(\\{\\omega\\})=\\frac{1}{6}\\). Dans ce cas, votre gain \\(X\\) peut être vu comme une application \\[X:\\Omega=\\{1,2,3,4,5,6\\}\\longrightarrow\\{-3, 0, 3\\}\\] définie par \\[X(1)=X(2)=-3\\] \\[X(3)=X(4)=3\\] \\[X(5)=X(6)=0\\] Imaginons maintenant qu’un ami commun prenne connaissance de votre gain à ce jeu, mais sans prendre connaissance du jeu lui-même (ni les issues possibles, ni les règles définissant le gain), et encore moins du numéro du dé que vous avez obtenu. De son point de vue, l’expérience qui aboutira à l’observation de votre gain sera également une expérience aléatoire, cependant l’espace probabilisé la modélisant ne sera plus \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) mais plutôt \\((\\Omega_X, \\mathcal{A}_X, \\mathbb{P}_X)\\), où \\[\\Omega_X=X(\\Omega)=\\{-3, 0, 3\\}\\] \\[\\mathcal{A}_X=\\mathcal{P}(\\{-3,0,3\\})\\] \\[\\mathbb{P}_X \\text{ donnée par } \\mathbb{P}_X(\\{-3\\})=\\mathbb{P}_X(\\{0\\})=\\mathbb{P}_X(\\{0\\})=\\frac{1}{3}\\] Dans ce genre de situation, on dit que \\(X\\) est une variable aléatoire, et on appelle loi de \\(X\\) la mesure de probabilité \\(\\mathbb{P}_X\\). D’une certaine façon, la variable aléatoire \\(X\\) a donc transformé l’espace probabilisé de départ \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) en un nouvel espace probabilisé \\((\\Omega_X, \\mathcal{A}_X,\\mathbb{P}_X)\\). Dans la plupart des expériences aléatoires, on cherchera à mesurer une grandeur (un gain à un jeu de hasard, la durée d’attente à un feu rouge, le nombre de coquilles dans un texte, le nombre buts marqués dans un match de foot, etc.), si bien que ce qui nous intéressera ne sera pas tant l’espace de départ \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) mais plutôt son image \\((\\Omega_X, \\mathcal{A}_X, \\mathbb{P}_X)\\) par cette grandeur. Cela a une conséquence pratique lorsqu’on résout un exercice de probabilités mettant en scène une variable aléatoire \\(X\\) : sauf dans des cas très simples, on n’explicitera pas \\(\\Omega\\) qu’on supposera donné (un peu à la façon de votre ami commun qui est aveugle aux numéros du dé) mais on cherchera plutôt à déterminer \\(X(\\Omega)\\). La tribu \\(\\mathcal{A}_X\\) sera, elle, généralement passée sous silence (en pratique, on aura souvent \\(\\mathcal{A}_X=\\mathcal{P}(X(\\Omega)\\)). Enfin, on accordera toute l’attention sur la loi de \\(X\\), autrement dit sur la mesure de probabilité \\(\\mathbb{P}_X\\), à partir de laquelle on pourra calculer différents indicateurs (espérance, variance, quantiles etc.). Ce chapitre s’intéresse aux variables alétoires discrètes, autrement dit les variables aléatoires dont les images forment un ensemble discret, soit parce que cet ensemble est fini, soit parce-qu’il est infini mais dénombrable (comme l’ensemble des entiers naturels ou des nombres rationnels). Le chapitre suivant traitera des variables aléatoires continues : ce sont les variables aléatoires dont l’ensemble des valeurs est continu, comme par exemple l’ensemble des nombres réels. 3.1 Définition et premières propriétés 3.1.1 Définition Variables aléatoires discrètes Soit \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) un espace probabilisé. On appelle variable aléatoire discrète (réelle) sur \\(\\Omega\\) toute application \\[X:\\Omega\\longrightarrow F=X(\\Omega)\\subset\\mathbb{R}\\] où \\(F=X(\\Omega)\\) est : soit un ensemble fini : \\(F=\\{x_1,\\dots, x_n\\}\\) soit un ensemble infini dénombrable : \\(F=\\{x_n,\\,n\\in\\mathbb{N}\\}\\) On dira alors que \\(F\\) est au plus dénombrable, et on utilisera souvent la notation unifiée \\[F=X(\\Omega)=\\{x_i, \\, i\\in I\\}, \\, I\\subset\\mathbb{N}\\] Exemples. i. On reprend l’exemple des deux dés équilibrés présenté dans le chapitre précédent : L’expérience aléatoire associée à cette expérience aléatoire est modélisée par l’espace probabilisé \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\), avec \\(\\Omega=\\{1,2,3,4,5,6\\}^2\\), \\(\\mathcal{A}=\\mathcal{P}(\\Omega)\\) et \\(\\mathbb{P}\\) la mesure de probabilité équirépartie. La somme \\(S\\) des deux numéros obtenus est une variable aléatoire \\[X:\\Omega \\longrightarrow X(\\Omega)\\] définie, pour \\(\\omega=(\\omega_1, \\omega_2)\\in\\Omega\\), par \\(S(\\omega)=\\omega_1+\\omega_2\\). On a \\[X(\\Omega)=[\\![2;12]\\!]\\] où pour tout couple d’entiers \\((a,b)\\) tel que \\(a\\leq b\\), \\([\\![a;b]\\!]\\) désigne l’ensemble de tous les entiiers entre \\(a\\) et \\(b\\) (notation que nous réutiliserons régulièrement dans ce cours). Ainsi, \\(X(\\Omega)\\) est fini, et donc \\(X\\) est une variable aléatoire discrète. ii. Une urne contient \\(4\\) boules blanches et \\(6\\) boules noires. On tire une boule au hasard. Si elle est noire on s’arrête là, sinon on remet la boule dans l’urne, et on recommence jusqu’à obtenir une boule noire. On note \\(N\\) le nombre de boules tirées. \\(N\\) est une variable aléatoire, prenant des valeurs entières et non majorée. Ainsi \\(N(\\Omega)=\\mathbb{N}^*\\) et \\(N\\) est discrète. iii. Dans une file d’attente, on note \\(T\\) le temps de passage entre deux clients. \\(T\\) est une variable aléatoire à valeurs dans \\(\\mathbb{R}_+\\). Elle n’est donc pas discrète, mais continue. 3.1.2 Loi d’une variable aléatoire discrète Pour une variable aléatoire discrète (réelle) définie sur un espace probabilisé \\(\\left(\\Omega, \\, \\mathcal{P}(\\Omega), \\, \\mathbb{P}\\right)\\), on peut définir la loi de \\(X\\). Théorème (Loi d’une variable aléatoire discrète). Soit \\(X\\) une variable aléatoire discrète définie sur un espace probabilisé \\((\\Omega,\\, \\mathcal{P}(\\Omega),\\, \\mathbb{P})\\), à valeurs dans \\(F=X(\\Omega)\\). Sur l’espace probabilisable \\((F,\\, \\mathcal{P}(F))\\) on peut alors définir une probabilité \\(\\mathbb{P}_X\\) en posant, pour tout \\(x_i\\) dans \\(F\\) : \\[\\mathbb{P}_X(\\{x_i\\})=\\mathbb{P}(X^{-1}(\\{x_i\\}))\\] On notera plus simplement \\((X=x_i)\\) l’événement \\(X^{-1}(\\{x_i\\})\\). La loi de \\(X\\) est donc définie par : la donnée de \\(F=X(\\Omega)\\), i.e. l’ensemble de toutes les valeurs prises par \\(X\\). Cet ensemble s’appelle le support de la loi de \\(X\\) ; la donnée, pour tout \\(x_i\\) dans \\(X(\\Omega)\\), de la probabilité \\(\\mathbb{P}(X=x_i)\\). Cette loi est unique à des événements de probabilité nulle près. Démonstration. Admis. Remarques. i. On définit \\(\\mathbb{P}_X\\) à partir des \\(\\mathbb{P}_X(\\{x_i\\})\\) : les \\(\\{x_i\\}\\) sont des éléments de (la tribu) \\(\\mathcal{P}(F)\\), donc \\(\\mathbb{P}_X\\) est bien une mesure de probabilité sur l’espace probabilisable \\((F,\\,\\mathcal{P}(F))\\) ; par ailleurs, \\(\\mathbb{P}_X(\\{x_i\\})\\) est définie par \\(\\mathbb{P}(X^{-1}(\\{x_i\\}))\\) et \\(X^{-1}(\\{x_i\\})\\) est un élément de la tribu \\(\\mathcal{P}(\\Omega)\\) sur laquelle est définie la probabilité \\(\\mathbb{P}\\), donc cette définition a bien un sens. ii. La loi de \\(X\\) est définie par la donnée des couples \\((x_i, p_i)\\) tels que \\(x_i\\in X(\\Omega)\\) et \\(p_i=\\mathbb{P}(X=x_i)\\). Dans cette définition, on peut se restreindre aux couples \\((x_i, p_i)\\) pour lesquels \\(p_i&gt;0\\). La loi de \\(X\\) n’est donc pas unique au sens strict du terme, mais elle l’est bien à des événements élémentaires de probabilité nulle près. Par exemple, dans l’exercice 2 du sujet du concours interne de 2012 (exercice 2.7. de ce cours) la variable aléatoire \\(X\\) prend a priori les valeurs \\(0,1,2,3\\), mais a posteriori on a \\(\\mathbb{P}(X=0)=0\\), donc on peut enlever \\(0\\) de \\(X(\\Omega)\\). Exemple. i. On reprend l’exemple sur la somme des deux dés. On a vu que \\(X(\\Omega)=[\\![2;12]\\!]\\). On calcule maintenant toutes les probablités \\(\\mathbb{P}(X=i)\\) pour \\(i\\in [\\![2;12]\\!]\\). On montre en fait facilement que \\[\\forall i\\in [\\![2;6]\\!],\\, \\mathbb{P}(X=i)=\\frac{i-1}{36}\\] \\[\\forall i\\in [\\![7;12]\\!], \\, \\mathbb{P}(X=i)=\\frac{13-i}{36}\\] On peut vérifier la cohérence de ce résultat : \\[\\begin{align} \\sum\\limits_{i=2}^{6}\\frac{i-1}{36}+\\sum\\limits_{i=7}^{12}\\frac{13-i}{36} &amp;= \\sum\\limits_{i=1}^{5}\\frac{i}{36}+\\sum\\limits_{i=1}^{6}\\frac{i}{36} \\\\ &amp;= \\frac{2\\sum\\limits_{i=1}^5 i +6}{36} \\\\ &amp;= \\frac{6\\times 5+6}{36} \\\\ &amp;= 1 \\\\ \\end{align}\\] ii. On reprend l’exemple de l’urne contenant \\(4\\) boules blanches et \\(6\\) boules noires. On répète des tirages successifs avec remise jusqu’à obtenir une boule noire, et \\(N\\geq 1\\) désigne le nombre de tirages. Pour \\(n\\in\\mathbb{N}^*\\), l’événement \\((N=n)\\) est réalisé lorsque les \\(n-1\\) premiers tirages amènent une boule blanche et le tirage numéro \\(n\\) amène une boule noire. Les tirages étant effectués avec remise ils sont indépendants, donc \\[\\mathbb{P}(N=n)=\\left(\\frac{2}{5}\\right)^{n-1}\\frac{3}{5}\\] ce qui définit complètement la loi de \\(N\\). Remarques. i. On peut vérifier de façon immédiate que la série \\(\\sum\\limits_{n}\\mathbb{P}(N=n)\\) est convergente de somme \\(1\\) : c’est, au facteur \\(\\frac{3}{5}\\) près, une série géométrique de raison \\(\\frac{2}{5}\\in]-1;1[\\), donc elle converge vers \\(\\frac{3}{5}\\frac{1}{1-\\frac{2}{5}}=1\\). ii. \\(N\\) suit une loi géométrique de paramètre \\(p=\\frac{3}{5}\\) (voir un peu plus loin la définition des lois géométriques). 3.1.3 Calcul de \\(\\mathbb{P}(X\\in B)\\) Théorème (calcul de \\(\\mathbb{P}(X\\in B)\\)). Soit \\(X:\\Omega\\longrightarrow X(\\Omega)\\) une variable aléatoire discrète (réelle), avec \\[X(\\Omega)=\\{x_i,\\,\\,i\\in I\\} \\text{, où } I\\subset\\mathbb{N}\\] Pour \\(B\\in\\mathcal{P}(X(\\Omega))\\), on note \\((X\\in B)\\) l’événement \\[(X\\in B)=X^{-1}(B)=\\left\\{\\omega\\in\\Omega, X(\\omega)\\in B\\right\\}\\] La probabilité d’un tel événement se calcule ainsi : \\[\\begin{align} \\mathbb{P}(X\\in B)&amp;=\\mathbb{P}\\left(\\bigsqcup\\limits_{i\\in I/ x_i\\in B} (X=x_i)\\right) \\\\ &amp;=\\sum\\limits_{i\\in I/ x_i\\in B}\\mathbb{P}(X=x_i) \\end{align}\\] Démonstration. Les événements \\((X=x_i)\\) tels que \\(i\\in I, x_i\\in B\\) forment une partition de l’événement \\((X\\in B)\\). On conclut en utilisant le fait qu’une probabilité d’une réunion disjointe d’événements \\(A_i\\) est la somme des probablités \\(\\mathbb{P}(A_i)\\). \\(\\square\\) Exemple. Dans l’exemple précédent de l’urne, on cherche maintenant la probabilité que \\(X\\) soit impaire. On a \\[\\begin{align} \\mathbb{P}(X\\in 2\\mathbb{N}+1) &amp;= \\sum\\limits_{n=0}^{\\infty}\\mathbb{P}(X=2n+1) \\\\ &amp;=\\sum\\limits_{n=0}^{\\infty}\\left(\\frac{2}{5}\\right)^{2n}\\frac{3}{5} \\\\ &amp;=\\frac{3}{5}\\sum\\limits_{n=0}^{\\infty}\\left(\\frac{4}{25}\\right)^{n} \\\\ &amp;=\\frac{3}{5}\\frac{1}{1-\\frac{4}{25}} \\\\ &amp;=\\frac{5}{7} \\\\ \\end{align}\\] 3.1.4 Fonction de répartition La fonction de répartition d’une variable aléatoire discrète (ou même continue comme on le verra dans le prochain chapitre) réelle est définie par la donnée des probabilités \\(\\mathbb{P}(X\\leq x)=\\mathbb{P}(X\\in ]-\\infty\\,;\\,x])\\) : Fonction de répartition Soit \\(X\\) une variable aléatoire discrète (réelle). On appelle fonction de répartition de \\(X\\) la fonction \\(F_X\\) définie sur \\(\\mathbb{R}\\) par \\[\\forall x\\in\\mathbb{R},\\,F_X(x)=\\mathbb{P}(X\\leq x)\\] Quand le contexte le permet, on la note plus simplement \\(F\\). Note : cette définition de la fonction de répartition est valable pour toutes les variables aléatoires, qu’elles suivent ou non une loi discrète. Calcul pratique. On note \\(x_1,\\dots x_n\\) (resp. \\(x_1,\\dots, x_n, \\dots\\)) les éléments de \\(X(\\Omega)\\) rangés dans l’ordre croissant si \\(X(\\Omega)\\) est fini (resp. infini dénombrable). Soient \\(x\\in\\mathbb{R}\\) et \\(i_0\\) le plus grand entier tel que \\(x_{i_0}\\leq x\\). Alors, d’après le théorème précédent : \\[F(x)=\\sum\\limits_{i=1}^{i_0}\\mathbb{P}(X=x_i)\\] Exemple. On considère une variable aléatoire \\(X\\) telle que \\(X(\\Omega)=\\{1,2,3,4\\}\\) et \\(\\mathbb{P}(X=i)\\) est proportionnel à \\(i\\). On souhaite déterminer sa fonction de répartition. On note \\(\\alpha=\\mathbb{P}(X=1)\\). On a donc \\[\\mathbb{P}(X=i)=\\alpha\\, i\\] On a donc \\(\\alpha\\sum\\limits_{i=1}^4 i=1\\), soit \\(\\alpha=\\frac{1}{10}\\) et donc \\[\\forall i\\in [\\![1;4]\\!],\\, \\mathbb{P}(X=i)=\\frac{i}{10}\\] La fonction de répartition \\(F\\) de \\(X\\) est alors donnée par \\[F(x)=\\left \\{ \\begin{array}{lcl} 0&amp;\\text{ si }&amp; x&lt;1 \\\\ \\frac{1}{10}&amp;\\text{ si }&amp; 1\\leq x&lt;2 \\\\ \\frac{3}{10}&amp;\\text{ si }&amp; 2\\leq x&lt;3 \\\\ \\frac{3}{5}&amp;\\text{ si }&amp; 3\\leq x&lt;4 \\\\ 1&amp;\\text{ si }&amp; x\\geq 4 \\\\ \\end{array} \\right.\\] Propriétés des fonctions de répartition Soit \\(F\\) la fonction de répartition d’une variable aléatoire réelle (discrète ou non). Alors : i. \\(F\\) est une fonction croissante sur \\(\\mathbb{R}\\) ii. \\(F\\) est continue à droite iii. \\(\\lim\\limits_{x\\to -\\infty}F(x)=0\\) iv. \\(\\lim\\limits_{x\\to +\\infty}F(x)=1\\) Note : ces propriétés résultent directement de la défintion précédente, et sont donc vraies pour toutes les variables aléatoires, qu’elles soient discrètes ou non. Démonstration. On note \\(X\\) une variable aléatoire réelle discrète ayant \\(F\\) pour fonction de répartition. i. Soient \\(x,y\\) deux réels tels que \\(x\\leq y\\). Alors l’événement \\(\\{X\\leq x\\}\\) est inclus dans l’événement \\(\\{X\\leq y\\}\\). Par croissance des probabilités on a donc \\(\\mathbb{P}(X\\leq x)\\leq\\mathbb{P}(X\\leq y)\\), i.e. \\(F(x)\\leq F(y)\\). On en déduit que \\(F\\) est croissante. ii. Soit \\(x\\) un réel. Les événements \\(\\left\\{X\\in\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]\\right\\}\\) forment une suite décroissante (par rapport à \\(n\\)) pour l’inclusion, donc d’après la propriété de continuité décroissante des probabilités, on a \\[\\mathbb{P}\\left(\\bigcap_{n=1}^{\\infty}\\left\\{X\\in\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]\\right\\}\\right)=\\lim\\limits_{n\\to\\infty}\\mathbb{P}\\left(X\\in\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]\\right)\\] i.e. \\[\\mathbb{P}\\left(X\\in \\bigcap_{n=1}^{\\infty}\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]\\right)=\\lim\\limits_{n\\to\\infty}\\mathbb{P}\\left(X\\in\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]\\right)\\] Or, \\(\\bigcap\\limits_{n=1}^{\\infty}\\left]-\\infty\\,;\\,x+\\frac{1}{n}\\right]=]-\\infty ; x]\\), donc le terme de gauche est égal à \\(\\mathbb{P}(X\\leq x)=F(x)\\). Par ailleurs le terme de droite est égal à \\(\\lim\\limits_{n\\to\\infty}F\\left(x+\\frac{1}{n}\\right)\\), et donc : \\[F(x)=\\lim\\limits_{n\\to\\infty}F\\left(x+\\frac{1}{n}\\right)\\] ce qui traduit exactement la continuité à droite de \\(F\\). iii. La suite d’événements \\(\\left\\{X\\leq -n\\right\\}_n\\) est décroissante, donc d’après la propriété de continuité décroissante \\[\\begin{align} \\lim\\limits_{n\\to\\infty}F(-n)&amp;=\\mathbb{P}\\left(\\bigcap\\limits_{n=0}^{\\infty}\\{X\\leq -n\\}\\right) \\\\ &amp;=\\mathbb{P}(\\emptyset) \\\\ &amp;=0 \\\\ \\end{align}\\] Par croissance de \\(F\\), on en déduit que \\(\\lim\\limits_{x\\to -\\infty}F(x)=0\\). iv. On utilise exactement le même raisonnement avec la suite croissante \\(\\left\\{X\\geq n\\right\\}_n\\). \\(\\square\\) Remarque. L’hypothèse d’une loi discrète n’étant utilisée nulle part dans cette démonstration, ces propriétés sont donc effectivement vraies pour toutes les lois de probabilités, discrètes ou non. Nous avons montré que les fonctions de répartition (de lois discrètes ou non) étaient toujours continues à droite. Pour avoir une propriété de continuité, il faudrait donc qu’elles soient également continues à gauche (rappel d’analyse : \\(f\\) est continue en \\(a\\) si et seulement si elle est continue à droite et à gauche en \\(a\\)). Mais cette propriété n’est pas vraie en toute généralité : Théorème (discontinuités d’une fonction de répartition). Soit \\(X\\) une variable aléatoire réelle (discrète ou non) définie sur un espace probabilisé \\((\\Omega, \\, \\mathcal{P}(\\Omega), \\, \\mathbb{P})\\). Pour tout réel \\(x\\) on a : \\[F(x)=F(x^{-})+\\mathbb{P}(X=x)\\] où \\(F(x^{-})=\\lim\\limits_{t\\to x^{-}}F(t)\\). Autrement dit, la fonction de répartition de \\(F\\) est continue partout, sauf aux points \\(x\\) tels que \\(p_x:=\\mathbb{P}(X=x)&gt;0\\) en lesquels elle présente un saut d’amplitude \\(p_x\\). En particulier, si \\(X\\) est discrète sa fonction de répartition présente en chaque point \\(x\\) de son support un saut d’amplitude \\(p_x\\). Démonstration. Pour tout réel \\(x\\) on a \\[F(x)=\\mathbb{P}(X&lt;x)+\\mathbb{P}(X=x)\\] Or, \\((X&lt;x)=\\bigcup\\limits_{n=1}^{\\infty} \\left(X\\in\\left]-\\infty\\,;\\, x-\\frac{1}{n}\\right]\\right)\\), et les événements \\(\\left(X\\in\\left]-\\infty\\,;\\, x-\\frac{1}{n}\\right]\\right)_{n\\geq 1}\\) forment une suite croissante pour l’inclusion, donc par continuité croissante de \\(\\mathbb{P}\\) on a : \\[\\begin{align} \\mathbb{P}(X&lt;x)&amp;=\\mathbb{P}\\left(\\bigcup_{n=1}^{\\infty}\\left(X\\in\\left]-\\infty\\,;\\,x-\\frac{1}{n}\\right]\\right)\\right) \\\\ &amp;=\\lim\\limits_{n\\to\\infty}\\mathbb{P}\\left(X\\in\\left]-\\infty\\,;\\,x-\\frac{1}{n}\\right]\\right) \\\\ &amp;=\\lim\\limits_{n\\to\\infty}F\\left(x-\\frac{1}{n}\\right) \\\\ &amp;=F(x^{-}) \\end{align}\\] ce qui montre l’égalité annoncée et permet de conclure. \\(\\square\\) Remarque. Les variables aléatoires ayant une fonction de répartition continue sont appelées des lois continues. Elles font l’objet du chapitre suivant (on se restreindra au cas où l’espace d’arrivée est l’ensemble des réels). D’après le résultat précédent, si \\(X\\) est une variable aléatoire de loi continue on a donc \\(\\mathbb{P}(X=x)=0\\) pour tout réel \\(x\\). Théorème (fonction de répartition et loi). Soit \\(X\\) une variable aléatoire réelle discrète définie sur un espace probabilisé \\((\\Omega, \\,\\mathcal{P}(\\Omega), \\mathbb{P})\\) et de fonction de répartition \\(F\\). Alors : si \\(a\\) et \\(b\\) sont des nombres réels tels que \\(a\\leq b\\) on a \\[\\mathbb{P}(X\\in]a\\,;\\,b])=F(b)-F(a)\\] supposons que \\(X(\\Omega)=\\{x_i,\\,i\\in I\\}\\) avec les \\(x_i\\) rangés dans l’ordre croissant. Alors \\[\\mathbb{P}(X=x_0)=F(x_0)\\] et \\[\\forall i\\geq 1,\\, \\mathbb{P}(X=x_i)=F(x_i)-F(x_{i-1})\\] Démonstration. On a \\[]-\\infty\\,;\\,b]=]-\\infty\\,;\\,a]\\,\\sqcup\\,]a\\,;\\,b]\\] donc \\[F(b)=F(a)+\\mathbb{P}(X\\in ]a\\,;\\,b])\\] ce qui montre la première égalité. Comme \\(x_0=\\inf X(\\Omega)\\), on a \\((X=x_0)=(X\\leq x_0)\\) et donc ces deux événements ont la même probabilité, i.e. \\(\\mathbb{P}(X=x_0)=F(x_0)\\). Soit \\(i\\geq 1\\). D’après le théorème précédent, on a \\[\\begin{align} \\mathbb{P}(X=x_i)&amp;=F(x_i)-F(x_i^{-}) \\\\ &amp;=F(x_i)-\\mathbb{P}(X&lt;x_i) \\\\ &amp;=F(x_i)-\\mathbb{P}(X\\leq x_{i-1}) \\\\ &amp;=F(x_i)-F(x_{i-1}) \\\\ \\end{align}\\] \\(\\square\\) On déduit du résultat précédent : Théorème. La fonction de répartition d’une variable aléatoire réelle discrète caractérise sa loi. Autrement dit, si \\(X\\) et \\(Y\\) sont deux variables aléatoires réelles discrètes, on a \\[F_X=F_Y \\text{ ssi } \\mathbb{P}_X=\\mathbb{P}_Y\\] Démonstration. La loi d’une variable aléatoire réelle discrète \\(X\\) est complètement définie par la donnée des probabilités \\(\\mathbb{P}(X=x_i)\\), qui elles-mêmes sont complètement définies par la fonction \\(F\\) d’après le théorème précédent, d’où le résultat. \\(\\square\\) Remarque. Le résultat précédent autorise donc à parler de fonction de répartition associée à une loi, ou même réciproquement de loi associée à une fonction de répartition. 3.1.5 Quantiles Pour définir la notion de quantile, on a besoin de définir la notion d’inverse généralisé à gauche. Inverse généralisé à gauche Soit \\(F\\) une fonction définie sur \\(\\mathbb{R}\\) et à valeurs dans \\([0,1]\\), croissante et continue à droite. On adopte les conventions suivantes : \\[F(-\\infty)=\\lim\\limits_{x\\to -\\infty}F(x)\\] \\[F(+\\infty)=1\\] \\[\\inf\\,\\emptyset=+\\infty\\] On appelle alors fonction inverse généralisée à gauche de \\(F\\), et on note \\(F^{-1}\\), la fonction définie sur \\([0,1]\\) par \\[\\forall p\\in [0,1],\\, F^{-1}(p)=\\inf\\{x\\in\\mathbb{R},\\,F(x)\\geq p\\}\\] Il s’agit d’une fonction croissante sur \\(\\mathbb{R}\\). Démonstration. Soient \\(p\\) et \\(q\\) deux réels tels que \\(p\\leq q\\). si \\(\\{x\\in\\mathbb{R},\\,F(x)\\geq p\\}=\\emptyset\\), alors \\(\\{x\\in\\mathbb{R}, \\, F(x)\\geq q\\}=\\emptyset\\) et donc \\(F^{-1}(p)=F^{-1}(q)=+\\infty\\). supposons maintenant que \\(\\{x\\in\\mathbb{R},\\,F(x)\\geq p\\}\\neq\\emptyset\\) : il existe donc un réel \\(x\\) tel que \\(F^{-1}(p)=x\\). On diistingue deux cas : si \\(\\{x\\in\\mathbb{R}, \\, F(x)\\geq q\\}=\\emptyset\\), alors \\(F^{-1}(q)=+\\infty\\), et donc \\(F^{-1}(p)=x&lt;+\\infty=F^{-1}(q)\\). si \\(\\{x\\in\\mathbb{R},\\,F(x)\\geq q\\}\\neq\\emptyset\\), alors il existe un réel \\(y\\) tel que \\(y=F^{-1}(q)\\). Par définition de \\(y\\), on a \\(F(y)\\geq q\\). Mais comme \\(q\\geq p\\), on en déduit que \\(F(y)\\geq p\\). Par définition de \\(x\\), on en déduit que \\(y\\geq x\\), i.e. que \\(F^{-1}(q)\\geq F^{-1}(p)\\). Ainsi, dans tous les cas, si \\(p\\leq q\\) alors \\(F^{-1}(p)\\leq F^{-1}(q)\\), ce qui montre que \\(F^{-1}\\) est croissante. \\(\\square\\) Remarque. Cette notion d’inverse généralisé à gauche permet de définir un pseudo-inverse pour des fonctions qui ne sont pas inversibles (on en verra un exemple un peu plus bas en application de la définition de la fonction quantile). Dans le cas où la fonction \\(F\\) est strictement croissante et continue, elle est inversible, et son inverse et son inverse généralisé à gauche coïncident. Il s’agit donc bien d’une généralisation de l’inverse d’une fonction croissante et continue à droite. La fonction quantile d’une variable aléatoire réelle \\(X\\) se définit alors ainsi : Fonction quantile, quantiles Soient \\(X\\) une variable aléatoire réelle (discrète ou non) et \\(F\\) sa fonction de répartition. On appelle fonction quantile de \\(X\\) la fonction inverse généralisée à gauche \\(F^{-1}\\) de \\(F\\). De plus, pour tout réel \\(p\\) dans \\([0,1]\\), on appelle quantile d’ordre \\(p\\) le réel \\(F^{-1}(p)\\). Exemples usuels de quantiles : \\(m_e=F^{-1}\\left(\\frac{1}{2}\\right)\\) est la médiane de \\(X\\) ; \\(Q_1=F^{-1}\\left(\\frac{1}{4}\\right)\\) et \\(Q_3=F^{-1}\\left(\\frac{3}{4}\\right)\\) sont les quartiles de \\(X\\) ; pour \\(i=1,\\dots,9\\), les \\(D_i=F^{-1}\\left(\\frac{i}{10}\\right)\\) sont les déciles de \\(X\\). Exemple. Dans un exemple précédent, on a introduit une variable aléatoire discrète \\(X\\) de fonction de répartition \\(F\\) donnée par \\[F(x)=\\left \\{ \\begin{array}{lcl} 0&amp;\\text{ si }&amp; x&lt;1 \\\\ \\frac{1}{10}&amp;\\text{ si }&amp; 1\\leq x&lt;2 \\\\ \\frac{3}{10}&amp;\\text{ si }&amp; 2\\leq x&lt;3 \\\\ \\frac{3}{5}&amp;\\text{ si }&amp; 3\\leq x&lt;4 \\\\ 1&amp;\\text{ si }&amp; x\\geq 4 \\\\ \\end{array} \\right.\\] Déterminons sa médiane et ses quartiles : \\(F(x)\\geq\\frac{1}{2}\\Leftrightarrow x\\geq 3\\), donc \\(m_e=3\\) ; \\(F(x)\\geq\\frac{1}{4}\\Leftrightarrow x\\geq 2\\), donc \\(Q_1=2\\) ; \\(F(x)\\geq\\frac{3}{4}\\Leftrightarrow x\\geq 4\\), donc \\(Q_3=4\\). Un intérêt des quantiles. Il est fréquent de vouloir résumer une distribution statistique à l’aide d’indicateurs. Un indicateur couramment utilisé est la moyenne. Il présente toutefois pour inconvénient majeur d’être fortement sensible aux valeurs extrêmes. Ainsi, une seule valeur atypique d’une distribution suffit à perturber considérablement la moyenne. Une alternative est alors de recourir à un quantile, comme par exemple la médiane, qui est plus robuste aux valeurs atypiques. 3.1.6 Exemples classiques de lois discrètes Pour \\(X\\) une variable aléatoire réelle discrète et \\(\\mathcal{L}\\) une loi de probabilité, la notation \\(X\\sim\\mathcal{L}\\) signfiera que \\(X\\) suit la loi \\(\\mathcal{L}\\). Exemple 1 : loi uniforme sur un ensemble fini. La loi uniforme affecte les mêmes probabilités à tous les éléments d’un ensemble fini \\(X(\\Omega)=\\{x_1,\\dots, x_n\\}\\) : \\[\\forall 1\\leq i\\leq n,\\, \\mathbb{P}(X=x_i)=\\frac{1}{n}\\] C’est cette loi à laquelle on doit penser lorsqu’on parle de tirer au hasard parmi un ensemble fini. C’est aussi cette loi qu’on utilise si on veut modéliser un phénomène aléatoire sur un ensemble fini en l’absence de toute information sur le tirage. On suppose les \\(x_i\\) rangés dans l’ordre croissant. Alors, la fonction de répartition de cette loi est la fonction \\(F\\) donnée par \\[F(x)=\\left \\{ \\begin{array}{lcl} 0&amp;\\text{ si }&amp; x&lt;x_1 \\\\ \\frac{i}{n}&amp;\\text{ si }&amp; x_i\\leq x&lt;x_{i+1}\\, \\text{, avec } 1\\leq i\\leq n-1 \\\\ 1&amp;\\text{ si }&amp; x\\geq x_n \\\\ \\end{array} \\right.\\] Exemple 2 : loi de Bernoulli \\(\\mathcal{B}(p)\\). Ici, \\(p\\in[0,1]\\). Cette loi est généralement mobilisée lorsque l’on souhaite modéliser l’issue d’une expérience de Bernoulli, autrement dit une expérience ayant deux issues nommées réussite et échec. Il s’agit donc d’une loi à deux issues, généralement notées \\(0\\) (représentant généralement l’échec) et \\(1\\) (représentant généralement la réussite) : \\[X(\\Omega)=\\{0,1\\}\\] Une telle loi est définie de façon unique à partir du paramètre \\(p=\\mathbb{P}(X=1)\\). De façon immédiate, on a \\(\\mathbb{P}(X=0)=1-p\\). On note souvent \\(q=1-p\\). La fonction de répartition de la loi de Benoulli \\(\\mathcal{B}(p)\\) est donnée par \\[F(x)=\\left \\{ \\begin{array}{lcl} 0&amp;\\text{ si }&amp; x&lt;0 \\\\ p&amp;\\text{ si }&amp; 0\\leq x&lt;1 \\\\ 1&amp;\\text{ si }&amp; x\\geq 1 \\\\ \\end{array} \\right.\\] Exemple 3 : loi binomiale \\(\\mathcal{B}(n,p)\\). \\(n\\) est un entier naturel non nul et \\(p\\in [0,1]\\). La loi binomiale sert à modéliser le nombre de succès lors de la répétition de \\(n\\) expériences de Bernoulli identiques et indépendantes. On a donc \\[X(\\Omega)=\\{0,1,\\dots, n\\}\\] Les probabilités de la loi binomiale \\(\\mathcal{B}(n,p)\\) font intervenir les coefficients binomiaux \\(\\binom{n}{k}\\) : Probabilités d’une loi binomiale. Soit \\(X\\) une variable aléatoire telle que \\(X\\sim\\mathcal{B}(n,p)\\). Alors, pour tout entier \\(0\\leq k\\leq n\\), on a \\[\\mathbb{P}(X=k)=\\binom{n}{k}\\,p^k\\,(1-p)^{n-k}\\] Démonstration. Cette formule est une conséquence de la définition de la loi \\(\\mathcal{B}(n,p)\\). On peut écrire \\[X=\\sum\\limits_{i=1}^n X_i\\] où les \\(X_i\\) sont des variables aléatoires de Bernoulli de paramètre \\(\\mathcal{B}(p)\\), représentant l’issue de l’expérience de Bernoulli numéro \\(i\\). Soit \\(k\\) un entier tel que \\(0\\leq k\\leq n\\). Notons \\[E_k=\\left\\{(x_1,\\dots, x_n)\\in\\{0,1\\}^n,\\, \\sum\\limits_{i=1}^n x_i=k\\right\\}\\] Pour \\((x_1,\\dots, x_n)\\in E_k\\), les événements \\((X_1=x_1),\\dots,(X_n=x_n)\\) sont indépendants, puisque les expériences de Bernoulli associées aux \\(X_i\\) sont indépendantes. Par conséquent, on a \\[\\begin{align} \\mathbb{P}(X_1=x_1,\\dots, X_n=x_n)&amp;=\\prod\\limits_{i=1}^n\\mathbb{P}(X=x_i) \\\\ &amp;=p^k\\,(1-p)^{n-k} \\\\ \\end{align}\\] puisque le vecteur \\((x_1,\\dots, x_n)\\) est constitué de \\(k\\) composantes égales à \\(1\\) et \\(n-k\\) composantes égales à \\(0\\). Par ailleurs, \\(\\text{Card }(E_k)=\\binom{n}{k}\\) donc : \\[\\begin{align} \\mathbb{P}(X=k)&amp;=\\mathbb{P}\\left(\\sum\\limits_{i=1}^n X_i=k\\right) \\\\ &amp;=\\mathbb{P}\\left(\\bigsqcup\\limits_{(x_1,\\dots, x_n)\\in E_k} (X_1=x_1,\\dots, X_n=x_n)\\right) \\\\ &amp;=\\sum\\limits_{(x_1,\\dots,x_n)\\in E_k}\\mathbb{P}\\left(X_1=x_1,\\dots, X_n=x_n\\right) \\\\ &amp;=\\sum\\limits_{(x_1,\\dots, x_n)\\in E_k} p^k\\,(1-p)^{n-k} \\\\ &amp;=\\text{Card }(E_k)\\,p^k\\,(1-p)^{n-k} \\\\ &amp;=\\binom{n}{k}\\,p^k\\,(1-p)^{n-k} \\\\ \\end{align}\\] \\(\\square\\) Remarque. On déduit de l’expression des \\(\\mathbb{P}(X=k)\\) l’identité \\[\\sum\\limits_{k=0}^n\\binom{n}{k}\\,p^k\\,(1-p)^{n-k}=1\\] qui n’est autre qu’un cas particulier de la formule du binôme de Newton : \\[(p+(1-p))^n=\\sum\\limits_{k=0}^n\\binom{n}{k}\\,p^k\\,(1-p)^{n-k}\\] La fonction de répartition de la loi binomiale \\(\\mathcal{B}(n,p)\\) est donnée par \\[F(x)=\\left \\{ \\begin{array}{lcl} 0&amp;\\text{ si }&amp; x&lt;0 \\\\ \\sum\\limits_{k=0}^l \\binom{n}{k}\\,p^k\\,(1-p)^{n-k} &amp;\\text{ si }&amp; l\\leq x&lt;l+1, \\,0\\leq l&lt;n \\\\ 1&amp;\\text{ si }&amp; x\\geq n \\\\ \\end{array} \\right.\\] Exemple 4 : loi de Poisson \\(\\mathcal{P}(\\lambda)\\). \\(\\lambda\\) est un réel strictement positif. La loi de Poisson \\(\\mathcal{P}(\\lambda)\\) permet de modéliser le nombre (aléatoire) \\(X\\) d’événements se produisant sur une période \\(T\\), lorsqu’on sait qu’en moyenne \\(\\lambda\\) événements se produisent sur une telle période. Elle est généralement appliquée pour des événements rares (accidents, fautes dans un texte, etc.). On peut aussi l’utiliser pour des domaines spatiaux plutôt que des intervalles temporels. On a \\[X(\\Omega)=\\mathbb{N}\\] et les probabilités \\(\\mathbb{P}(X=n)\\) pour \\(n\\in\\mathbb{N}\\) sont données par la formule suivante : Probabilités d’une loi de Poisson \\(\\mathcal{P}(\\lambda)\\). Soit \\(X\\) une variable aléatoire telle que \\(X\\sim\\mathcal{P}(\\lambda)\\). Alors : \\[\\forall k\\in\\mathbb{N}, \\, \\mathbb{P}(X=k)=e^{-\\lambda}\\frac{\\lambda^k}{k!}\\] Justification de cette formule. On considère un événement qui se produit aléatoirement et de façon répétée dans le temps, selon les règles suivantes : sur tout intervalle de temps de longueur (petite) \\(\\Delta t\\) : cet événement se produit une fois avec une probabilité \\(p\\) très petite ; pour tout \\(k\\geq 2\\), la probabilité qu’il se produise \\(k\\) fois est négligeable ; sur deux intervalles de temps disjoints de longueur \\(\\Delta t\\), les survenues (ou non) de cet événement sont indépendantes. On compte alors le nombre d’occurences \\(X\\) de cet événement sur un intervalle de temps \\([a\\,;\\,a+n\\Delta t]\\), avec \\(a&gt;0\\) et \\(n\\) un entier très grand. Pour tout entier \\(k\\), on note \\(X_k\\) la variable aléatoire prenant la valeur \\(1\\) si l’événement s’est produit sur l’intervalle de temps \\([a+k\\Delta t \\, ; \\, a+(k+1)\\Delta t[\\) et \\(0\\) sinon, de sorte que \\[X=\\sum\\limits_{k=0}^{n-1}X_k\\] D’après les hypothèses faites plus haut, les variables \\(X_k\\) suivent toutes la loi de Bernoulli \\(\\mathcal{B}(p)\\) et les événements \\((X_1=\\varepsilon_1),\\dots,(X_n=\\varepsilon_n)\\) sont indépendantes pour tout \\((\\varepsilon_1,\\dots,\\varepsilon_n)\\in\\{0,1\\}^n\\), donc \\(X\\) suit une loi binomiale \\(\\mathcal{B}(n,p)\\). Ainsi \\[\\forall k\\in\\{0,1,\\dots, n\\}, \\,\\mathbb{P}(X=k)=\\binom{n}{k}\\,p^k\\,(1-p)^{n-k}\\] La loi de Poisson découle alors d’une approximation de la formule précédente pour de très grandes valeurs de \\(n\\) et une très petite valeur de \\(p\\). En posant \\(\\lambda = np\\), on a en effet : \\[\\begin{align} \\mathbb{P}(X=k)&amp;=\\binom{n}{k}\\,\\left(\\frac{\\lambda}{n}\\right)^k\\,\\left(1-\\frac{\\lambda}{n}\\right)^{n-k} \\\\ &amp;=\\frac{n(n-1)\\dots(n-k+1)}{n^k} \\frac{\\lambda^k}{k!}\\left(1-\\frac{\\lambda}{n}\\right)^{n-k} \\\\ &amp;=\\left(1-\\frac{1}{n}\\right)\\dots \\left(1-\\frac{k-1}{n}\\right) \\frac{\\lambda^k}{k!}e^{(n-k)\\,\\log\\left(1-\\frac{\\lambda}{n}\\right)} \\\\ &amp;\\approx \\left(1-\\frac{1}{n}\\right)\\dots \\left(1-\\frac{k-1}{n}\\right) \\frac{\\lambda^k}{k!}e^{-(n-k)\\,\\left(\\frac{\\lambda}{n}+o\\left(\\frac{1}{n} \\right)\\right)} \\\\ &amp;\\approx \\left(1-\\frac{1}{n}\\right)\\dots \\left(1-\\frac{k-1}{n}\\right) \\frac{\\lambda^k}{k!}e^{-\\lambda+O\\left(\\frac{1}{n}\\right)} \\\\ &amp;\\to \\frac{\\lambda^k}{k!}e^{-\\lambda}\\, \\text{ lorsque } n\\to\\infty \\end{align}\\] Remarque. Comme \\(X\\) suit une loi binomiale \\(\\mathcal{B}(n,p)\\), on a \\(\\mathbb{E}(X)=np\\). Le paramètre \\(\\lambda\\) d’une loi de Poisson \\(\\mathcal{P}(\\lambda)\\) s’interprète donc comme le nombre moyen d’événements ayant lieu pendant une période de référence. Exemple 5 : loi géométrique \\(\\mathcal{G}(p)\\). \\(p\\) est un réel appartenant à \\(]0\\,;\\,1[\\) et on considère une succession d’épreuves de Bernoulli indépendantes (donc se soldant par un succès ou un échec). On dit que \\(X\\) suit la loi géométrique de paramètre \\(p\\) si \\(X\\in\\mathbb{N}^{*}\\) est le numéro du premier succès. Probabilités d’une loi géométrique. Soit \\(X\\) une variable aléatoire telle que \\(X\\sim\\mathcal{G}(p)\\). Alors, pour tout entier \\(k\\geq 1\\) on a \\[\\mathbb{P}(X=k)=(1-p)^{k-1}p\\] Démonstration. Soit \\(k\\) un entier supérieur ou égal à \\(1\\). Dire que \\(X=k\\) revient à dire que les \\(k-1\\) premières expériences se sont soldées par des échecs et que l’expérience numéro \\(k\\) a été un succès. En notant \\(S_k\\) l’événement L’expérience numéro \\(k\\) s’est soldée par un succès et \\(E_k\\) l’événement L’expérience numéro \\(k\\) s’est soldée par un échec, on a donc \\[\\begin{align} \\mathbb{P}(X=k)&amp;=\\mathbb{P}(S_1\\cap S_2\\cap\\dots\\cap S_{k-1}\\cap E_k) \\\\ &amp;=\\mathbb{P}(S_1)\\mathbb{P}(S_2)\\dots\\mathbb{P}(S_{k-1})\\mathbb{P}(E_k) \\, \\text{ par indépendance} \\\\ &amp;=(1-p)^{k-1}p \\\\ \\end{align}\\] \\(\\square\\) Exemple 6 : loi hypergéométrique. La loi hypergéométrique est, comme la loi binomiale, utilisée dans un contexte où l’on souhaite compter le nombre de succès dans une succession d’épreuves de Bernoulli. La différence avec la loi binomiale étant que maintenant, ces épreuves de Bernoulli ne sont plus identiques ni indépendantes. On suppose qu’une population de taille \\(N\\), exactement \\(D\\) individus possèdent une certaine caractéristique \\(\\mathcal{C}\\) (donc \\(0\\leq D\\leq N\\)). On tire un échantillon de taille \\(n\\) dans cette population, sans remise (donc \\(0\\leq n\\leq N\\)) et de façon équiprobable. On compte le nombre \\(X\\) d’individus de l’échantillon possédant la caractéristique \\(\\mathcal{C}\\). On dit alors que \\(X\\) suit la loi hypergéométrique \\(\\mathcal{H}(N,D,n)\\). On a alors : Support et probabilités d’une loi hypergéométrique. Pour \\(X\\sim\\mathcal{H}(N,D,n)\\), on a : i. Support de X. \\[\\max(0 \\,; \\,n-N+D)\\leq X\\leq \\min(n\\,;\\,D)\\] ii. Probabilités. Pour tout entier \\(\\max(0 \\,; \\,n-N+D)\\leq k\\leq \\min(n\\,;\\,D)\\) : \\[\\mathbb{P}(X=k)=\\frac{\\binom{D}{k}\\binom{N-D}{n-k}}{\\binom{N}{n}}\\] Démonstration. i. On a nécessairement : \\(0\\leq X\\leq n\\) : l’échantillon étant de taille \\(n\\), on tire au plus \\(n\\) individus ayant la propriété \\(\\mathcal{C}\\) ; \\(0\\leq X\\leq D\\) : le tirage de l’échantillon étant sans remise, on ne peut pas tirer plus d’unités ayant la propriété \\(\\mathcal{C}\\) qu’il n’y en a dans la population. De façon symétrique, on fait exactement le même raisonnement pour le tirage des individus n’ayant pas la propriété \\(\\mathcal{C}\\) : \\(0\\leq n-X\\leq n\\) : l’échantillon étant de taille \\(n\\), on tire au plus \\(n\\) individus n’ayant pas la propriété \\(\\mathcal{C}\\). On remarque que cet encadrement est automatiquement vérifié dès que le premier encadrement (sa version symétrique) l’est ; \\(0\\leq n-X \\leq N-D\\) : on ne peut pas tirer plus d’individus n’ayant pas la propriété \\(\\mathcal{C}\\) qu’il n’y en a dans la population. Les deux premiers encadrements s’écrivent plus simplement \\[0\\leq X\\leq \\min(n,D)\\] et le dernier encadrement s’écrit \\[\\max(0,n-N+D)\\leq X\\leq n\\] Enfin, ces deux encadrements s’écrivent \\[\\max(0,n-N+D)\\leq X\\leq\\min(n,D)\\] ii. Soit \\(k\\in R_X\\). Dénombrons le nombre d’échantillons de taille \\(n\\) satisfaisant la condition \\(X=k\\). La donnée d’un tel échantillon repose sur : le choix de \\(k\\) individus parmi les \\(D\\) ayant la caractéristique \\(\\mathcal{C}\\), soit \\(\\binom{D}{k}\\) choix possibles ; le choix de \\(n-k\\) individus parmi les \\(N-D\\) n’ayant pas la caractéristique \\(\\mathcal{C}\\), soit \\(\\binom{N-D}{n-k}\\) choix possibles. Pour \\(k\\) fixé, ces deux choix sont complètement indépendants, donc le nomnre \\(N_k\\) de choix d’un tel échantillon s’obtient par produit : \\(N_k=\\binom{D}{k}\\binom{N-D}{n-k}\\). Enfin, tous ces échantillons sont équiprobables, donc \\[\\mathbb{P}(X=k)=\\frac{\\binom{D}{k}\\binom{N-D}{n-k}}{\\binom{N}{n}}\\] \\(\\square\\) Exemple. Une urne contient \\(20\\) boules, parmi lesquelles \\(14\\) exactement sont rouges. On tire \\(12\\) boules dans l’urne, sans remise, et on compte le nombre \\(X\\) de boules rouges obtenues. Alors, \\(X\\sim\\mathcal{H}(20, 8, 5)\\). Le support de \\(X\\) est \\(R_X= [\\![6;12]\\!]\\) et \\[\\forall k\\in R_X, \\, \\mathbb{P}(X=k)=\\frac{\\binom{14}{k}\\binom{6}{12-k}}{\\binom{20}{12}}\\] 3.1.7 Simulation d’une variable aléatoire réelle 3.1.8 Moments d’une variable aléatoire Espérance, variance, moments d’ordres supérieurs inégalité de Markov, inégalité de Bieanymé-Tchébychev (exemples + intérêt) 3.2 Transformation d’une variable aléatoire discrète 3.2.1 Définition Définition Cas particuliers : bijection continue un unique extremum Déterminer la loi de \\(f(X)\\) en pratique (message = passer par la fonction de répartition) 3.2.2 Théorème de transfert (cas discret) Théorème Exemple 3.3 Vecteurs aléatoires 3.3.1 Définition 3.3.2 Loi jointe, loi marginales 3.3.3 Loi conditionnelle \\(\\mathcal{L}(Y|X)\\) 3.3.4 Loi d’un couple de VA indépendantes Définition Somme de deux VA indépendantes (produit de convolution discret) 3.3.5 Espérance conditionnelle, variance conditionnelle "]]
