[["index.html", "Cours de probabilités-statistiques pour le concours interne d’administrateur Insee Chapitre 1 Présentation du cours 1.1 Généralités 1.2 Coquilles et erreurs", " Cours de probabilités-statistiques pour le concours interne d’administrateur Insee Olivier Guin 2024-03-30 Chapitre 1 Présentation du cours 1.1 Généralités Généralités. Ce document est un cours de probabilités et statistiques à destination des candidats au concours interne d’administrateur de l’Insee. Il est encore en construction et pour le moment très incomplet. Seule la partie Dénombrement et probabilités et la partie Statistique inférentielle sont à ce jour complètes. La partie Variables aléatoires discrètes est en cours de rédaction. A terme, il devrait contenir les parties suivantes : Dénombrement et probabilités Variables aléatoires discrètes Variables aléatoires à densité Convergence Statistique descriptive Statistique inférentielle Certaines des notions présentées ici, sans être explicitement au programme du concours, sont à la frontière de celui-ci. Concrètement, cela signifie que’on peut les retrouver dans un sujet d’écrit ou d’oral, mais qu’aucun prérequis les concernant n’est nécessaire pour traiter le sujet. Mais les avoir déjà rencontrées peut aider pour résoudre les questions… C’est le cas par exemple, dans la partie Statistique inférentielle, de l’information de Fisher, des statistiques exhaustives et de la borne de Cramer-Rao, qui sont présentes dans le sujet d’Administrateur interne de 2022 (sans être toutefois explicitement nommées). Même type de remarque pour les démonstrations. Celles qui sont présentées ici ne sont pas toutes indispensables pour aborder ce concours. Mais elles utilisent des méthodes de calcul ou de raisonnement qui reviennent souvent, et qui peuvent inspirer pour la résolution d’un exercice. Comme toujours en mathématiques, la seule façon de progresser est de faire. Ne pas hésiter donc, à passer un peu de temps sur un exercice, même si on sèche complètement. 1.2 Coquilles et erreurs La loi de Poisson est souvent utilisée pour modéliser le nombre d’erreurs ou de coquilles inévitablement présentes dans un document. Celui-ci n’échappe pas à la règle et j’espère juste que le \\(\\lambda\\) n’est pas trop grand… Pour m’aider à le réduire, n’hésitez pas à me les signaler. Plus généralement, vos commentaires permettent d’améliorer la qualité de ce document : ils sont donc les bienvenus. "],["dénombrement-et-probabilités.html", "Chapitre 2 Dénombrement et probabilités 2.1 Rappels sur les opérations ensemblistes 2.2 Dénombrement 2.3 Langage et formalisme des probabilités 2.4 Indépendance 2.5 Probabilités conditionnelles 2.6 Formule des probabilités totales 2.7 Formule de Bayes", " Chapitre 2 Dénombrement et probabilités 2.1 Rappels sur les opérations ensemblistes Un ensemble est une collection d’objets, dont la nature peut être extrêment variée : des nombres, des droites, des matrices, etc. Pour \\(E\\) un ensemble, la notation \\(x\\in E\\) signifie que \\(x\\) est un élément de \\(E\\), et se lit x appartient à E. Inclusion, réunion, intersection, complémentaire Soient \\(E\\) et \\(F\\) deux ensembles quelconques. Ensemble vide. L’ensemble vide est l’ensemble n’admettant aucun élément. Inclusion. On dit que \\(F\\) est inclus dans \\(E\\), et on note \\(F\\subset E\\) si dès que \\(x\\) appartient à \\(F\\), il appartient aussi à \\(E\\) : \\[(F\\subset E) \\Leftrightarrow \\left((x\\in F)\\Rightarrow (x\\in E)\\right)\\] Réunion. \\(E\\cup F\\) est l’ensemble des éléments qui appartiennent à au moins l’un des deux ensembles \\(E\\) et \\(F\\) : \\[E\\cup F=\\{x, \\, x\\in E \\text{ ou } x\\in F\\}\\] Intersection. \\(E\\cap F\\) est l’ensemble des éléments qui appartiennent à la fois à \\(E\\) et à \\(F\\) : \\[E\\cap F=\\{x, \\, x\\in E \\text{ et } x\\in F\\}\\] Complémentaire. Si \\(F\\subset E\\), le complémentaire de \\(F\\) dans \\(E\\), noté \\(\\overline{F}^E\\) est défini par \\[\\overline{F}^E=\\{x\\in E, \\, x\\not\\in F\\}\\] Lorsque le contexte n’est pas ambigu, on allège la notation en l’écrivant plus simplement \\(\\overline{F}\\). D’autres notations existent : \\(F^c\\), \\(E\\backslash F\\), etc. Toutes les propriétés qu’on présente ici (sans démonstration) sont d’un usage très fréquent dans les calculs des probabilités. Commutativité de \\(\\cup\\) et \\(\\cap\\). Soient \\(A\\) et \\(B\\) deux ensembles. Alors : \\[A\\cup B=B\\cup A\\] \\[A\\cap B=B\\cap A\\] Associativité de \\(\\cup\\) et \\(\\cap\\). Soient \\(A, B, C\\) trois ensembles. Alors on a : \\[A\\cup(B\\cup C)=(A\\cup B)\\cup C\\] \\[A\\cup(B\\cap C)=(A\\cap B)\\cap C\\] Autrement dit, on peut calculer une succession de réunions ou d’intersections d’ensemble dans l’ordre qu’on veut, ce qui nous autorise à enlever les parenthèses : \\[A\\cup B\\cup C\\] \\[A\\cap B\\cap C\\] Plus généralement, étant donné une famille quelconque d’ensembles \\((E_i)_{i\\in I}\\), on peut définir de façon complètement analogue et sans amibuité leur réunion \\(\\bigcup\\limits_{i\\in I}E_i\\) et leur intersection \\(\\bigcap\\limits_{i\\in I}E_i\\) L’ensemble vide est un minorant de tout ensemble. Pour tout ensemble \\(E\\), on a : \\[\\emptyset\\subset E\\] L’ensemble vide est neutre pour la réunion. Pour tout ensemble \\(E\\), on a \\[E\\cup\\emptyset=\\emptyset\\cup E=E\\] L’ensemble vide est absorbant pour l’intersection. Pour tout ensemble \\(E\\), on a \\[E\\cap\\emptyset=\\emptyset\\cap E=\\emptyset\\] Le passage au complémentaire est involutif. Pour tout ensemble \\(E\\) et pour tout sous-ensemble \\(F\\) de \\(E\\), on a : \\[\\overline{\\overline{F}}=F\\] Les propriétés suivantes précisent comment la réunion, l’intersection et le passage complémentaire interagissent : Lois de Morgan. Pour tout ensemble \\(E\\), pour tout couple \\((A, B)\\) de sous-ensembles de \\(E\\), on a : \\[\\overline{A\\cup B}=\\overline{A}\\cap\\overline{B}\\] \\[\\overline{A\\cap B}=\\overline{A}\\cup\\overline{B}\\] Cette propriété se généralise à toute famille \\((F_i)_{i\\in, I}\\) d’un ensemble \\(E\\) quelconque : \\[\\overline{\\bigcup\\limits_{i\\in I} F_i}=\\bigcap\\limits_{i\\in I}\\overline{F_i}\\] \\[\\overline{\\bigcap\\limits_{i\\in I} F_i}=\\bigcup\\limits_{i\\in I}\\overline{F_i}\\] On peut résumer ces propriétés que l’opération de passage au complémentaire inverse la réunion et l’intersection. Distributivité. Soient \\(A, B, C\\) trois ensembles. Alors on a : \\[A\\cap(B\\cup C)=(A\\cap B)\\cup(A\\cap C)\\] \\[A\\cup(B\\cap C)=(A\\cup B)\\cap(A\\cup C)\\] 2.2 Dénombrement On commence par quelques éléments d’analyse combinatoire. Ces résultats sont utilisés dans le cas où, lors d’une expérience aléatoire, tous les événements élémentaires (on parle aussi d’issues) sont de même probabilité. On parle dans ce cas d’équiprobabilité ou d’équirépartition des résultats. Des exemples classiques de tirages équirépartis : lancer d’un dé à 6 faces non truqué. Dans ce cas, chaque face a une probabilité d’apparition de \\(\\frac{1}{6}\\). dans une urne composée de 10 boules rouges, 10 boules blanches et 10 boules noires, tirage au hasard d’une boule. Les trois couleurs que l’on peut obtenir sont équiprobables, de probabilité commune \\(\\frac{1}{3}\\). L’utilité du dénombrement dans le cas équiprobable vient de la formule que l’on apprend au lycée : \\[\\mathbb{P}(A)=\\frac{\\text{Nombre de cas favorables à } A}{\\text{Nombre total de cas}}\\] Cette formule, qui n’est valable que dans le cas équiréparti, suppose de savoir compter le nombre de cas où l’événement \\(A\\) se réalise ainsi que de savoir compter le nombre total d’issues de l’expérience aléatoire que l’on étudie, autrement dit il s’agit bien de savoir dénombrer. Cette première partie présente les types de dénombrements les plus classiques. Si les concepts sont très simples (on reste vraiment sur du niveau lycée), on peut assez facilement mal s’y prendre (ce qui voudra dire essentiellement : oublier de compter des cas, ou au contraire compter plusieurs fois le même cas) et passer complètement à côté du résultat. Bref, malgré les apparences, les questions de dénombrement (assez peu courantes au concours ces dernières années cela dit) sont potentiellement piégeuses… C’est donc typiquement le genre de questions qu’il ne faut pas sous-estimer et qu’il faut traiter en prenant son temps, à plus forte raison si elle est posée en début de sujet, et qu’elle est donc potentiellement structurante pour la suite. 2.2.1 Produit cartésien et principe multiplicatif Produit cartésien Soient \\(k\\) un entier naturel non nul et \\(E_1,\\dots E_k\\) des ensembles finis de cardinaux respectifs \\(n_1,\\dots, n_k\\). Le produit cartésien de \\(E_1,\\dots, E_k\\) est l’ensemble noté \\(E_1\\times\\dots\\times E_k\\) de toutes les listes ordonnées \\((x_1,\\dots,x_k)\\) telles que, pour tout \\(i\\in\\{1,\\dots, k\\}\\) l’élément numéro \\(i\\) noté \\(x_i\\) appartient à l’ensemble \\(E_i\\). On dit aussi que \\((x_1,\\dots, x_k)\\) est un k-uplet. Cas particuliers : i. Les listes ordonnées à 2 éléments sont appelées des couples, celles à 3 élements sont appelées des triplets et les listes à 4 éléments sont les quadruplets. ii. Lorsque tous les ensembles \\(E_1,\\dots E_k\\) sont égaux, i.e. \\(E_1=\\dots=E_k=E\\), le produit cartésien \\(E\\times\\dots\\times E\\) est noté plus simplement \\(E^k\\). Remarques. Le mot important dans cette définition est ordonnée. L’ordre a en effet une importance ici, autrement dit \\((1, 2)\\in\\mathbb{R}^2\\) et \\((2, 1)\\in\\mathbb{R}^2\\) sont bien considérés comme deux couples distincts de réels. Le premier résultat de ce cours, qui est absolument fondamental lorsqu’on pratique le dénombrement, et donc lorsqu’on est en situation d’équiprobabilité, est le principe multiplicatif. Ce principe, à la fois très simple et très intuitif, répond à la question Combien existe-t-il de k-uplets ? Principe multiplicatif : Avec les notations de la définition précédente, le nombre d’élements du produit cartésien \\(E_1\\times \\dots\\times E_k\\) est égal à \\(n_1\\times\\dots\\times E_k\\). Formule que l’on peut aussi écrire (en notant \\(\\text{Card}\\,(E)\\) le cardinal d’un ensemble \\(E\\), i.e. le nombre d’éléments de \\(E\\)) : \\[\\text{Card }(E_1\\times\\dots\\times E_k)=\\text{Card }(E_1)\\times\\dots\\times\\text{Card }(E_k)\\] Si on veut faire chic, on peut dire aussi que \\[\\textit{Le cardinal d&#39;un produit est le produit des cardinaux}\\] Exemple 1 : expériences aléatoires successives. On réalise successivement les deux expériences aléatoires suivantes : lancer d’une pièce : 2 résultats possibles P ou F ; puis lancer d’un dé cubique : 6 résultats possibles notés de 1 à 6. L’ensemble des issues de cette double expérience aléatoire peut être modélisé par le produit cartésien \\(\\{P, F\\}\\times\\{1,2,3,4,5,6\\}\\). C’est un ensemble à 12 éléments : \\[(P,1), (P,2), (P,3), (P, 4), (P,5), (P, 6), (F,1), (F,2), (F,3), (F, 4), (F,5), (F, 6)\\] Cet ensemble peut facilement être représenté par un arbre de dénombrement : Exemple 2 : compter des poignées de mains. Soit \\(n\\geq 2\\) un entier. Compter le nombre de poignées de mains possibles dans un groupe de \\(n\\) personnes. Solution 2.a. On note \\(1,\\dots n\\) les personnes de ce groupe, et le couple \\((i, j)\\) modélise le fait que \\(i\\) sert la main de \\(j\\). On compte alors successivement : le nombre de couples : il y en a \\(n^2\\) d’après le principe multiplicatif ; le nombre de couples \\((i, i)\\) qui représenteraient le fait que \\(i\\) se sert la man à lui-même, situtation qu’on ne veut pas dénombrer et dont il faut donc soustraire le nombre d’occurences au nombre précédent. Il y en a \\(n\\), donc il y a \\(n^2-n=n(n-1)\\) façons qu’une personne \\(i\\) serre la main d’une autre personne \\(j\\) du goupe ; le nombre de couples correspondant à une poignée de mains : il s’agit de \\(2\\), puisque une poignée de mains entre deux personnes \\(i\\) et \\(j\\) correspond à exactement deux couples : \\((i,j)\\) et \\((j,i)\\). Il faut donc diviser par deux le nombre trouvé précédemment, ce qui fait un total de \\(\\frac{n(n-1)}{2}\\) poignées de mains. Solution 2.b.(plus directe) Une poignée de mains implique deux personnes différentes. On a \\(n\\) choix possibles pour la première personne, et \\(n-1\\) choix possibles pour la deuxième personne, soit \\(n(n-1)\\) choix de couples possibles. En l’état, on compte deux fois trop de poignées de mains (même raisonnement que dans l’exemple 2.a.), donc il y a en réalité \\(\\frac{n(n-1)}{2}\\) poignées de mans possibles.$ 2.2.2 Principe additif Un deuxième grand principe de dénombrement, tout aussi intuitif et tout aussi fondamental, est le principe additif : Principe additif : Si \\(E_1,\\dots E_k\\) sont \\(k\\) ensembles deux à deux disjoints (i.e. \\(i\\neq j\\Rightarrow E_i\\cap E_j=\\emptyset\\)) alors (en reprenant les mêmes notations que dans la définition précédente) leur union \\(E_1\\cup\\dots\\cup E_k\\) a pour cardinal \\(n_1+\\dots+n_k\\), ce que l’on peut aussi écrire : \\[\\text{Card }\\left(E_1\\cup\\dots\\cup E_k\\right)=\\text{Card }(E_1)+\\dots+\\text{Card }(E_k)\\] On pourra retenir que : \\[\\textit{Le cardinal d&#39;une union disjointe est la somme des cardinaux}\\] Remarque. Lorsqu’un ensemble \\(E\\) peut s’écrire sous la forme \\[E=E_1\\cup E_2\\cup\\dots\\cup E_k\\] avec \\(E_1, E_2, \\dots, E_k\\) deux à deux disjoints, on dit que \\(E_1, E_2,\\dots E_k\\) forment une partition de l’ensemble \\(E\\). Exemple 3 : compter des carrés. Combien la figure suivante compte-t-elle de carrés ? Solution. Tout carré de cette figure a pour côté 1, 2, 3 ou 4 (en supposant avoir fixé une unité de longueur, correspondant au côté d’un “petit” carré). L’ensemble \\(E\\) des carrés de cette figure peut donc s’écrire \\[E=E_1\\cup E_2\\cup E_3\\cup E_4\\] où, pour \\(k\\in\\{1,2,3,4\\}\\), \\(E_k\\) désigne l’ensemble des carrés de côté \\(k\\) de cette figure. Les \\(E_k\\) sont deux à deux disjoints (un carré de la figure ne peut pas avoir un côté de deux longueurs différentes) et donc pour compter le nombre de carrés possibles, il suffit de compter les carrés de côté 1, de côté 2, de côté 3, de côté 4 et d’ajouter tous ces nombres. On trouve : \\[\\begin{align} \\text{Card }(E_1) &amp;= 16 \\\\ \\text{Card }(E_2) &amp;= 9 \\\\ \\text{Card }(E_3) &amp;= 4 \\\\ \\text{Card }(E_4) &amp;= 1 \\\\ \\end{align}\\] d’où \\(\\text{Card }(E)=16+9+4+1=30\\). Exemple 4 (poignées de mains, à nouveau). On peut répondre à cette question en utilisant le principe additif. On note \\(E_1\\) l’ensemble des poignées de mains de la personne \\(1\\). Puis on note \\(E_2\\) l’ensemble des poignées de mains de la personne \\(2\\), hormis celle avec la personne \\(1\\) qui a déjà été comptée, \\(E_3\\) l’ensemble des poignées de mains de la personne \\(3\\) hormis celles avec les personnes \\(1\\) et \\(2\\) qui ont déjà été comptées, et ainsi de suite jusqu’à \\(E_{n}\\). Alors, \\(E_1,E_2,\\dots, E_n\\) forment une partition de l’ensemble \\(E\\) de toutes les poignées de mains du groupe, on va donc compter les cardinaux de \\(E_1,E_2,\\dots, E_n\\) et utiliser le principe additif : la personne \\(1\\) serre la main des \\(2\\) à \\(n\\), donc \\(E_1=n-1\\) ; les poignées de mains non encore comptées de la personne \\(2\\) sont celles avec les personnes \\(3\\) à \\(n\\) donc \\(E_2=n-2\\) ; les poignées de mains non encore comptées de la personne \\(3\\) sont celles avec les personnes \\(4\\) à \\(n\\) donc \\(E_2=n-3\\) ; … une seule poignée de mains n’a pas été comptée pour la personne \\(n-1\\), celle avec la personnes \\(n\\) donc \\(E_{n-1}=1\\) ; enfin, toutes les poignées de mains de la personne \\(n\\) ont été comptées, donc \\(E_n=0\\). En vertu du principe additif, le nombre de poignées de mains est donc égal à \\[0+1+2+\\dots+(n-1)=\\frac{n(n-1)}{2}\\] 2.2.3 Formule de Poincaré Il existe une formule lorsqu’on relâche l’hypothèse de non-djsjonction deux à deux, connue sous le nom de formule de Poincaré. C’est une formule que l’on utilise souvent dans le cas \\(k=2\\), de temps en temps dans le cas \\(k=3\\), plus rarement (mais ça peut arriver dans un sujet du concours) dans le cas \\(k\\geq 4\\) voire dans le cas général. Formule de Poincaré. Soit \\(E\\) un ensemble fini, qui peut s’écrire sous la forme \\[E=E_1\\cup E_2\\cup\\dots\\cup E_k\\] avec \\(E_1,E_2,\\dots E_k\\) des sous-ensembles de \\(E\\) non nécessairement disjoints deux à deux. Alors : \\[\\text{Card }(E)=\\sum\\limits_{i=1}^k (-1)^i \\sum\\limits_{1\\leq j_1 &lt; j_2 &lt;...&lt; j_i\\leq n} \\text{Card }\\left(E_{j_1}\\cap E_{j_2}\\cap\\dots\\cap E_{j_i}\\right)\\] Cas particulier \\(k=2\\) : \\[\\text{Card }(A\\cup B)=\\text{Card }(A)+\\text{Card }(B)-\\text{Card }(A\\cap B)\\] Cas particulier \\(k=3\\) : \\[\\begin{align} \\text{Card }(A\\cup B\\cup C)&amp;=\\text{Card }(A)+\\text{Card }(B)+\\text{Card }(C) \\\\ &amp;-\\text{Card }(A\\cap B)-\\text{Card }(A\\cap C)-\\text{Card }(B\\cap C) \\\\ &amp;+\\text{Card }(A\\cap B\\cap C) \\end{align}\\] Démonstration dans le cas \\(k=2\\). L’intutition de la démonstration est évidente : pour compter tout ce qu’il y a dans la réunion de \\(A\\) et \\(B\\), on compte tout ce qu’il y a dans \\(A\\), tout ce qu’il y a dans \\(B\\) et on ajoute le tout. Mais en faisant cela, on compte deux fois - c’est-à-dire une fois de trop - tout ce qui est à la fois dans \\(A\\) et dans \\(B\\), donc on doit ensuite soustraire l’excédent. Plus formellement, on écrit \\(A\\cup B\\) comme une union disjointe, puis on applique le principe additif. On a, en posant \\(A\\backslash B=A\\cap\\overline{B}\\) et \\(B\\backslash A=B\\cap\\overline{A}\\) : \\[A\\cup B = (A\\backslash B)\\cup(A\\cap B)\\cup (B\\backslash A)\\] Les trois ensembles du membre de droite de cette égalité dont deux à deux disjoints, donc on peut appliquer le principe additif : \\[\\text{Card }(A\\cup B)=\\text{Card }(A\\backslash B)+\\text{Card }(A\\cap B)+\\text{Card }(B\\backslash A)\\] Par ailleurs \\[A=(A\\backslash B)\\cup (A\\cap B)\\] \\[B=(B\\backslash A)\\cup (B\\cap A)\\] avec à nouveau des ensembles deux à disjoints dans les membres de droite. Donc, en appliquant deux fois le principe additif \\[\\text{Card }(A\\backslash B)=\\text{Card }(A)-\\text{Card }(A\\cap B)\\] \\[\\text{Card }(B\\backslash A)=\\text{Card }(B)-\\text{Card }(A\\cap B)\\] et donc finalement \\[\\begin{align} \\text{Card }(A\\cup B)&amp;=\\text{Card }(A\\backslash B)+\\text{Card }(A\\cap B)+\\text{Card }(B\\backslash A) \\\\ &amp;=\\text{Card }(A)-\\text{Card }(A\\cap B)+\\text{Card }(A\\cap B)+\\text{Card }(B)-\\text{Card }(A\\cap B) \\\\ &amp;=\\text{Card }(A)+\\text{Card }(B)-\\text{Card }(A\\cap B) \\end{align}\\] \\(\\square\\) 2.2.4 Dénombrement par bijection Une technique classique de dénombrement d’un ensemble fini \\(E\\) est l’utilisation d’un bijection entre \\(E\\) et un ensemble fini \\(F\\) dont on connaît le cardinal : Conservation du cardinal par bijection. Soient \\(E\\) un ensemble, \\(F\\) un ensemble fini. S’il existe une bijection \\(\\varphi : E\\longrightarrow F\\), alors \\(E\\) est un ensemble fini et il est de même cardinal que \\(F\\). Application classique : nombre de parties d’un ensemble fini. Soit \\(E\\) un ensemble de cardinal \\(n\\). Alors l’ensemble \\(\\mathcal{P}(E)\\) des parties de \\(E\\) (i.e. l’ensemble de tous les sous-ensembles de \\(E\\), y compris l’ensemble vide et \\(E\\) lui-même) est égal à \\(2^n\\) : \\[\\text{Card }(E)=n\\Rightarrow\\text{Card }(\\mathcal{P}(E))=2^n\\] En effet, notons \\(\\{0,1\\}^E\\) l’ensemble de toutes les fonctions possibles de \\(E\\) dans \\(\\{0,1\\}\\). Soit alors \\(\\varphi\\) l’application \\(\\varphi:\\{0,1\\}^E\\longrightarrow\\mathcal{P}(E)\\) définie, pour toute fonction \\(f\\in\\{0,1\\}^E\\) par \\[\\varphi(f)=\\{x\\in E, \\,f(x)=1\\}\\] L’application \\(\\varphi\\) est bien définie (si \\(f=g\\) on a clairement \\(\\varphi(f)=\\varphi(g)\\)). Elle est injective : si \\(\\varphi(f)=\\varphi(g)\\), alors \\(f(x)=1\\) si et seulement si \\(g(x)=1\\), et donc \\(f\\) et \\(g\\) ne pouvant prendre que \\(0\\) et \\(1\\) comme valeurs on en déduit que \\(f=g\\). Enfin, \\(\\varphi\\) est surjective. En effet, si \\(P\\in\\mathcal{P}(E)\\), alors en posant, pour tout \\(x\\) dans \\(E\\), \\(f(x)=1\\) si \\(x\\in P\\) et \\(f(x)=0\\) si \\(x\\not\\in P\\), on a \\(f\\in\\{0,1\\}^E\\) et \\(\\varphi(f)=P\\). Enfin, en vertu du principe multiplicatif on a \\(\\text{Card }(\\{0,1\\}^E)=2^n\\). On en déduit que \\(\\text{Card }(\\mathcal{P}(E))=2^n\\). \\(\\square\\) Intutivement, la démonstration précédente montre que toute partie \\(P\\) d’un ensemble fini \\(E\\) peut être codé de façon unique en une fonction sur \\(E\\) à valeurs dans \\(\\{0,1\\}\\), prenant la valeur \\(1\\) pour les éléments de \\(P\\) et \\(0\\) pour les élements qui ne sont pas dans \\(P\\). 2.2.5 Permutations Permutation d’un ensemble fini Soient \\(n\\) un entier naturel non nul et \\(E=\\{x_1,\\dots, x_n\\}\\)} un ensemble fini à \\(n\\) éléments. On appelle permutation de \\(E\\) tout réarragement ordonné et sans répétition des éléments de \\(E\\). De façon équivalente, une permutation est une bijection de \\(E\\) dans lui-même. Notation. L’ensemble des permutations d’un ensemble fini \\(E\\) est noté \\(\\mathfrak{S}(E)\\). Dans le cas particulier où \\(E=\\{1,2,\\dots, n\\}\\), on le note plus simplement \\(\\mathfrak{S}_n\\). Exemple. \\(E=\\{a,b,c\\}\\), les permutations de \\(E\\) sont \\[(a,b,c), (a,c,b), (b,a,c), (b,c,a), (c,a,b), (c,b,a)\\] Ces permutations peuvent aussi s’écrire comme des bijections \\(\\sigma_1,\\dots,\\sigma_6\\) de \\(E\\) dans lui-même : \\[\\sigma_1(a)=a,\\,\\sigma_1(b)=b,\\,\\sigma_1(c)=c\\] \\[\\sigma_2(a)=a,\\,\\sigma_2(b)=c,\\,\\sigma_2(c)=b\\] \\[\\sigma_3(a)=b,\\,\\sigma_3(b)=a,\\,\\sigma_3(c)=c\\] \\[\\sigma_4(a)=b,\\,\\sigma_4(b)=c,\\,\\sigma_4(c)=a\\] \\[\\sigma_5(a)=c,\\,\\sigma_5(b)=a,\\,\\sigma_5(c)=b\\] \\[\\sigma_6(a)=a,\\,\\sigma_6(b)=b,\\,\\sigma_6(c)=a\\] Le nombre de permutations d’un ensemble fini est facile à dénombrer : Théorème (nombre de permutations) : Soit \\(n\\) un entier naturel non nul. Le nombre de permutations d’un ensemble fini à \\(n\\) éléments est égal à \\(n!=1\\times 2\\times 3\\times\\dots\\times n\\). Démonstration. On note \\(x_1,\\dots,x_n\\) les éléments d’un ensemble de cardinal \\(n\\). Choisir une permutation \\(\\sigma\\) de \\(E\\), c’est choisir successivement : l’image \\(\\sigma(x_1)\\) parmi les \\(n\\) éléments \\(x_1,\\dots,x_n\\) : \\(n\\) choix possibles ; l’image \\(\\sigma(x_2)\\) parmi les \\(n-1\\) éléments restants : \\(n-1\\) choix possibles ; l’image \\(\\sigma(x_3)\\) parmi les \\(n-2\\) éléments restants : \\(n-2\\) choix possibles ; … l’image \\(\\sigma(x_n)\\) parmi le seul élément de \\(x_1,\\dots, x_n\\) qui n’a pas encore été choisi : \\(1\\) seul choix possible. D’après le principe multiplicatif, le nombre de permutations de \\(E\\) est donc égal à \\[n\\times(n-1)\\times(n-2)\\times\\dots\\times 1=n!\\] \\(\\square\\) Remarque. En filigrane, le théorème précédént dit aussi que le nombre de permutations d’un ensemble fini \\(E\\) ne dépend de \\(E\\) qu’à travers son cardinal. Autrement dit, peu importe l’ensemble \\(E\\) que l’on choisit, dès lors qu’il a \\(n\\) éléments le nombre de permutations de cet ensemble est \\(n!\\). Ce résultat est une simple conséquence du principe de dénombrement par bijection évoqué plus haut. Exemple : nombre d’anagrammes. Quel est le nombre d’anagrammes du mot MATHS ? Du mot ANAGRAMME ? Solution. i. Une anagramme du mot MATHS correspond à une permutation de l’ensemble \\(\\{M,A,T,H,S\\}\\). Il y en a donc \\(5!=120\\). ii. Pour le mot ANAGRAMME c’est un peu plus compliqué car certaines lettres apparaissent plusieurs fois. On commence par numéroter ces lettres-là, en les traitant comme des lettres différentes, autrement dit on commence par compter le nombre de permutations de l’ensemble \\(\\{A_1,N,A_2,G,R,A_3,M_1,M_2,E\\}\\) : il y en a \\(9!\\). Les lettres n’étant en réalité pas numérotées dans notre problème, il n’y a pas lieu de distinguer, par exemple, l’anagramme \\(A_1NA_2GRA_3M_1M_2E\\) de l’anagramme \\(A_2NA_1GRA_3M_1M_2E\\). Ainsi, la lettre \\(A\\) étant de multiplicité \\(3\\) dans le mot ANAGRAMME, chacune des \\(3!=6\\) permutations de cette lettre fournit exactement le même mot, de sorte que la numérotation de la lettre \\(A\\) conduit à compter \\(6\\) fois plus de permutations qu’il n’y en a en réalité. De même, la lettre \\(M\\) est de multiplicité \\(2\\), et donc en la numérotant on compte \\(2!=2\\) fois plus de permutations qu’il y en a réellement. Finalement, on en déduit que le nombre d’anagrammes du mot ANAGRAMME est égal à \\(\\frac{9!}{3!2!}=3\\780\\) 2.2.6 Arrangements Arrangements Soient \\(n\\) et \\(0\\leq k\\leq n\\) deux entiers naturels, et \\(E\\) un ensemble à \\(n\\) éléments. On appelle arrangement de \\(k\\) éléments pris parmi les \\(n\\) éléments de \\(E\\), tout sous-ensemble ordonné à \\(k\\) éléments de \\(E\\). De la même façon qu’on peut définir les permutations par la notion de bijection, on peut définir les arrangements par la notion d’injection : Définition équivalente des arrangements Soient \\(n\\) et \\(0\\leq k\\leq n\\) deux entiers naturels, et \\(E\\) un ensemble à \\(n\\) éléments. Un arrangement de \\(k\\) éléments pris parmi les \\(n\\) éléments de \\(E\\) peut aussi être vu comme une injection de \\(\\{1,2,\\dots, k\\}\\) dans \\(E\\). Exemple. Si \\(E=\\{1,2,3\\}\\), les arrangements à \\(2\\) éléments de \\(E\\) sont les couples \\((1,2), (1,3), (2,1), (2,3), (3, 1), (3,2)\\). On utilise bien la notion de couple pour modéliser les arrangements car l’ordre a une importance : les arrangements \\((1,2)\\) et \\((2,1)\\) sont bien considérés comme différents. Il y a donc six arrangements de \\(2\\) éléments de \\(E\\). Plus généralement, on a une formule qui permet de calculer le nombre d’arrangements de \\(k\\) éléments pris parmi \\(n\\) éléments : Théorème (nombre d’arrangements). On note \\(A_n^k\\) le nombre d’arrangements à \\(k\\) éléments pris dans un ensemble à \\(n\\) éléments. Alors, on a la formule : \\[A_n^k=\\frac{n!}{(n-k)!}\\] Remarque. Ici aussi, le nombre d’arrangements à \\(k\\) éléments pris dans un ensemble à \\(n\\) éléments ne dépend que de \\(n\\) (et de \\(k\\)). Démonstration. C’est exactement la même démarche que pour le dénombrement des permutations : \\(n\\) façons de choisir le premier élément ; \\(n-1\\) façons de choisir le deuxième élément ; … \\(n-k+1\\) façons de choisir l’élément numéro \\(k\\). D’après le principe multiplicatif on a donc : \\[\\begin{align} A_n^k &amp;= n(n-1)\\dots(n-k+1) \\\\ &amp;= \\frac{n!}{(n-k)!} \\end{align}\\] \\(\\square\\) Remarque. Dans le cas où \\(k=n\\), on a \\(A_n^n=n!\\). Ce résultat était prévisible, puisqu’un arrangement de \\(n\\) éléments parmi \\(n\\) éléments est une injection de \\(\\{1,2,\\dots, n\\}\\) dans lui-même, autrement dit une bijection de \\(\\{1,2,\\dots,n\\}\\) dans lui-même. Il s’agit donc d’une permutation de \\(\\{1,2,\\dots,n\\}\\). 2.2.7 Combinaisons Les combinaisons sont l’équivalent non ordonné des arrangements : Combinaisons Soient \\(n\\) et \\(0\\leq k\\leq n\\) deux entiers naturels, et \\(E\\) un ensemble à \\(n\\) éléments. On appelle combinaison de \\(k\\) éléments pris parmi les \\(n\\) éléments de \\(E\\), tout sous-ensemble non ordonné à \\(k\\) éléments de \\(E\\). Exemples. Si \\(E=\\{1,2,3\\}\\), on a vu que les arrangements à \\(2\\) éléments de \\(E\\) sont les couples \\[(1,2), (1,3), (2,1), (2,3), (3, 1), (3,2)\\] Du point de vue des combinaisons, les couples \\((1,2)\\) et \\((2,1)\\) (resp. \\((1,3)\\) et \\((3,1)\\), \\((2,3)\\) et \\((3,2)\\)) sont considérés comme équivalents. Il y a donc trois combinaisons à \\(2\\) éléments de \\(E\\) : \\[\\{1,2\\}, \\{1,3\\} \\text{ et } \\{2,3\\}\\] Remarque. Bien faire attention à la différence de notation : la notation avec parenthèses \\((a_1, a_2,\\dots, a_n)\\) désigne un \\(n-\\)uplet, c’est-à-dire un objet ordonné. Alors que la notation ensembliste \\(\\{a_1,a_2,\\dots a_n\\}\\) désigne un objet non ordonné. On a donc, pour toute permutation \\(\\sigma\\in\\mathfrak{S}_n\\) différente de l’identité : \\[(a_{\\sigma(1)},a_{\\sigma(Z)},\\dots, a_{\\sigma_(n)})\\neq (a_1,a_2,\\dots, a_n)\\] mais \\[\\{a_{\\sigma(1)},a_{\\sigma(Z)},\\dots, a_{\\sigma_(n)}\\}=\\{a_1,a_2,\\dots, a_n\\}\\] Comme pour les permutations et les arrangements, on a une formule simple pour compter les combinaisons : Théorème (nombre de combinaisons). Soient \\(n\\) et \\(0\\leq k\\leq n\\) des entiers naturels. Le nombre de combinaisons de \\(k\\) éléments pris parmi les \\(n\\) éléments d’un ensemnble \\(E\\) quelconque est noté \\(C_n^k\\) ou \\(\\binom{n}{k}\\). Ce nombre, appelé coefficient binomial, est égal à : \\[\\binom{n}{k}=\\frac{n!}{k!\\,(n-k)!}\\] On peut aussi définir de façon cohérente le coefficient binomial pour \\(k\\) et \\(n\\) des entiers naturels avec \\(k&gt;n\\) en posant \\[\\binom{n}{k}=0\\] Démonstration. On commence par compter les arrangements de \\(k\\) éléments parmi \\(n\\) : il y en a \\(A_n^k=\\frac{n!}{(n-k)!}\\). Par ailleurs, toute combinaison \\((a_1,\\dots, a_k)\\) de \\(k\\) éléments parmi \\(n\\) génère \\(k!\\) arrangements distincts \\((a_{\\sigma(1)},\\dots, a_{\\sigma(k)})\\) distincts \\((\\sigma\\in\\mathfrak{S}_k)\\). Il y a donc \\(k!\\) fois plus d’arrangements que de combinaisons. D’où : \\[\\begin{align} \\binom{n}{k} &amp;= \\frac{A_n^k}{k!} \\\\ &amp;= \\frac{n!}{k!(n-k)!} \\end{align}\\] \\(\\square\\) Plusieurs formules impliquent les combinaisons : Formules usuelles sur les combinaisons. Soient \\(n\\) et \\(0\\leq k\\leq n\\) deux entiers naturels. Alors : i. (Cas particuliers) \\[\\binom{n}{0}=1\\] \\[\\binom{n}{n}=1\\] \\[\\binom{n}{1}=n\\] \\[\\binom{n}{2}=\\frac{n(n-1)}{2}\\] ii. (Complémentaire) \\[\\binom{n}{k}=\\binom{n}{n-k}\\] iii. (Triangle de Pascal) \\[\\binom{n}{k}+\\binom{n}{k+1}=\\binom{n+1}{k+1}\\] iv. (Formule du binôme de Newton) Sous la convention \\(0^0=1\\), pour \\(a\\) et \\(b\\) des réels quelconques et \\(n\\) un entier naturel : \\[(a+b)^n=\\sum\\limits_{k=0}^n \\binom{n}{k}a^k b^{n-k}\\] (si on rejette la convention \\(0^0=1\\), alors la formule est toujours vraie sauf dans le cas où \\(n=0\\) et \\(a=-b\\)). En particulier, pour \\(a=b=1\\) on obtient : \\[\\sum\\limits_{k=0}^n \\binom{n}{k}=2^n\\] Pour \\(a=-1\\) et \\(b=1\\) on obtient : \\[\\sum\\limits_{k=0}^n (-1)^k\\binom{n}{k}=0\\] Pour \\(a=x\\) et \\(b=1\\) on obtient : \\[\\sum\\limits_{k=0}^n \\binom{n}{k}x^k=(x+1)^n\\] Pour \\(a=-1\\) et \\(b=x\\) on obtient : \\[\\sum\\limits_{k=0}^n \\binom{n}{k}(-1)^kx^{n-k}=(x-1)^n\\] Démonstration. i. \\(\\binom{n}{0}=\\frac{n!}{0!(n-0)!}=\\frac{n!}{n!}=1\\) L’égalité \\(\\binom{n}{n}=1\\) est une conséquence de la formule précédente et de la formule ii. qui va être montrée après. \\(\\binom{n}{1}=\\frac{n!}{1!(n-1)!}=\\frac{n(n-1)!}{(n-1)!}=n\\) \\(\\binom{n}{2}=\\frac{n!}{2! (n-2)!}=\\frac{n(n-1)(n-2)!}{2(n-2)!}=\\frac{n(n-1)}{2}\\) Autre méthode. Soit \\(E=\\{1,2, \\dots, n\\}\\). Le seul sous-ensemble de \\(E\\) à zéro élément est \\(\\emptyset\\), donc \\(\\binom{n}{0}=1\\). Le seul sous-ensemble de \\(E\\) à \\(n\\) éléments est \\(E\\) lui-même, donc \\(\\binom{n}{n}=1\\). Les seuls sous-ensembles de \\(E\\) à un élément sont les \\(n\\) singletons \\(\\{1\\}, \\{2\\}, \\dots, \\{n\\}\\), donc \\(\\binom{n}{1}=n\\). Enfin, les sous-ensembles à deux éléments de \\(E\\) sont : \\[\\begin{align} &amp;\\{1,2\\}, \\{1,3\\}, \\dots, \\{1,n\\} \\\\ &amp;\\{2,3\\}, \\dots ,\\{2,n\\} \\\\ &amp;\\dots \\\\ &amp;\\{n-1, n\\} \\end{align}\\] Il y en a donc \\(n+(n-1)+\\dots+1=\\frac{n(n-1)}{2}\\) ii. \\[\\begin{align} \\binom{n}{k}&amp;=\\frac{n!}{k!(n-k)!} \\\\ &amp;=\\frac{n!}{(n-k)! k!} \\\\ &amp;=\\frac{n!}{(n-k)!(n-(n-k))!} \\\\ &amp;=\\binom{n}{n-k} \\end{align}\\] Autre méthode. Choisir un sous-ensemble \\(F\\subset E\\) à \\(k\\) éléments revient à choisir son complémentaire \\(\\overline{F}\\) dans \\(E\\), qui contient \\(n-k\\) éléments. Donc \\(\\binom{n}{k}=\\binom{n}{n-k}\\). iii. \\[\\begin{align} \\binom{n}{k}+\\binom{n}{k+1}&amp;=\\frac{n!}{k!(n-k)!}+\\frac{n!}{(k+1)!(n-k-1)!} \\\\ &amp;=\\frac{n!(k+1)}{(k+1)!(n-k)!}+\\frac{n!(n-k)}{(k+1)!(n-k)!} \\\\ &amp;=\\frac{n!(k+1+n-k)}{(k+1)!(n-k)!} \\\\ &amp;=\\frac{n!(n+1)}{(k+1)!(n-k)!} \\\\ &amp;=\\frac{(n+1)!}{(k+1)!((n+1)-(k+1))!} \\\\ &amp;=\\binom{n+1}{k+1} \\end{align}\\] Autre méthode. On sépare les sous-ensembles à \\(k+1\\) éléments de \\(E=\\{1,2,\\dots, n, n+1\\}\\) en deux parties disjointes : les sous-ensembles \\(F\\) qui contiennent \\(n+1\\). Ils sont de la forme \\(\\{x_1,\\dots, x_k\\}\\cup\\{n+1\\}\\), et il y en a donc autant que de façons de choisir un sous-ensemble à \\(k\\) éléments \\(\\{x_1,\\dots, x_k\\}\\) de l’ensemble \\(E&#39;=\\{1,2,\\dots, n\\}\\), i.e. il y en a exactement \\(\\binom{n}{k}\\). les sous-ensembles \\(F\\) qui ne contiennent pas \\(n+1\\). Ils s’écrivent donc sous la forme \\(F=\\{x_1,x_2,\\dots, x_{k+1}\\}\\), avec les \\(x_{k+1}\\) pris dans \\(E&#39;=\\{1,2,\\dots, n\\}\\). Il y en a donc exactement \\(\\binom{n}{k+1}\\). Commes ces deux parties sont disjointes, on peut appliquer le principe additif, pour affirmer que le nombre de sous-ensembles à \\(k+1\\) éléments d’un ensemble à \\(n+1\\) éléments est égal à \\(\\binom{n}{k}+\\binom{n}{k+1}\\). Par ailleurs, le nombre de sous-ensembles à \\(k+1\\) éléments d’un ensemble à \\(n+1\\) éléments est égal à \\(\\binom{n+1}{k+1}\\) (par défintion des coefficients binomiaux). D’où l’égalité \\(\\binom{n}{k}+\\binom{n}{k+1}=\\binom{n+1}{k+1}\\). iv. On montre la formule par récurrence sur \\(n\\). Pour \\(n=0\\), cette formule s’écrit \\((a+b)^0=\\binom{0}{0}a^0b^0\\), soit \\(1=1\\) (sous la convention \\(0^0=1\\), on a quel que soit \\(x\\) réel, \\(x^0=1\\)). Supposons la formule établie pour un entier naturel \\(n\\) donné. Alors : \\[\\begin{align} (a+b)^{n+1} &amp;= (a+b)(a+b)^n \\\\ &amp;= (a+b).\\sum\\limits_{k=0}^n \\binom{n}{k} a^k b^{n-k} \\\\ &amp;\\text{(d&#39;après l&#39;hypothèse de récurrence)} \\\\ &amp;= \\sum\\limits_{k=0}^n \\binom{n}{k} a^{k+1} b^{n-k}+\\sum\\limits_{k=0}^n \\binom{n}{k} a^{k} b^{n-k+1} \\\\ &amp;=\\sum\\limits_{k=1}^{n+1} \\binom{n}{k-1} a^{k} b^{n-k+1}+\\sum\\limits_{k=0}^n \\binom{n}{k} a^{k} b^{n-k+1} \\\\ &amp;=\\binom{n}{n} a^{n+1}+\\sum\\limits_{k=1}^n \\left(\\binom{n}{k-1}+\\binom{n}{k}\\right) a^kb^{n-k+1}+\\binom{n}{0}b^{n+1} \\\\ &amp;=a^{n+1}+\\sum\\limits_{k=1}^n \\binom{n+1}{k} a^k b^{n+1-k} +b^{n+1} \\\\ &amp;\\text{(d&#39;après la formule du triangle de Pascal)} \\\\ &amp;= \\sum\\limits_{k=0}^{n+1}\\binom{n+1}{k} a^k b^{n+1-k} \\\\ \\end{align}\\] qui est la formule attendue au rang \\(n+1\\). Autre méthode. En développant le produit \\[(a+b)^n=(a+b).(a+b)\\dots (a+b)\\] on obtient une somme de termes de la forme \\(a^kb^{n-k}\\). Pour obtenir un tel terme, on doit choisir \\(k\\) fois le terme \\(a\\) parmi les \\(n\\) facteurs \\((a+b)\\) (et donc, de façon complémentaire, \\(n-k\\) fois le terme \\(b\\) parmi ces mêmes facteurs). On en déduit, par définition des coefficients binomiaux, que le terme \\(a^kb^{n-k}\\) apparaît exactement \\(\\binom{n}{k}\\) fois dans la somme. Autrement dit on a bien \\((a+b)^n=\\sum\\limits_{k=0}^n \\binom{n}{k}a^k b^{n-k}\\). \\(\\square\\) Remarques. i. Comme souvent en analyse combinatoire, la démonstration d’une égalité peut se faire soit par le calcul, soit en utilisant une approche de dénombrement pur (qui en général est plus élégante mais peut-être un peu moins évidente à trouver). ii. La deuxième démonstration de la formule du triangle de Pascal repose sur une approche classique en dénombrement : compter la même chose de deux façons différentes. 2.3 Langage et formalisme des probabilités On introduit maintenant les notions de base des probabilités. Le but est de construire progressivement un triplet de la forme \\[(\\Omega, \\mathcal{A},\\mathbb{P})\\] où : \\(\\Omega\\) s’appellera l’univers ; \\(\\mathcal{A}\\) s’appellera une tribu : dans le cadre du programme c’est en fait un mot que nous n’utiliserons quasiment jamais, et sauf cas particulier nous n’expliciterons pas cet élément ; \\(\\mathbb{P}\\) s’appellera une probabilité. On va donc construire successivement : l’univers \\(\\Omega\\) ; l’espace probablisable \\((\\Omega, \\mathcal{A})\\), qui est un enrichissement de \\(\\Omega\\) ; l’espace probabilisé \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\), qui est un enrichissement de \\((\\Omega, \\mathcal{A})\\). 2.3.1 L’univers \\(\\Omega\\) d’une expérience aléatoire Tout commence avec la notion d’expérience aléatoire, i.e. une expérience dont l’issue est incertaine. La première chose à faire est de dresser la liste de tous les résultats potentiellement réalisables à lorsqu’on effectue une telle expérience. Un tel résultat s’appelle une issue ou un événement élémentaire. L’ensemble des issues est appelé univers de l’expérience, il est généralement noté \\(\\Omega\\). Exemples. i. Lancer d’un dé cubique. On note ses faces par des entiers de \\(1\\) à \\(6\\). Dans ce cas, l’univers \\(\\Omega\\) est fini et \\[\\Omega=\\{1,2,3,4,5,6\\}\\] ii. Echantillonnage d’une population. Afin d’estimer les revenus moyens au sein d’une population \\(\\mathcal{U}=\\{1,2,\\dots, N\\}\\), on tire un échantillon aléatoire de taille \\(n\\) au sein de cette population. Pour l’expérience aléatoire consistant à tirer un tel échantillon, l’univers \\(\\Omega\\) est l’ensemble de toutes les parties de \\(\\mathcal{U}\\) à \\(n\\) éléments : \\[\\Omega=\\{S\\in\\mathcal{P}(\\mathcal{U}), \\, \\text{Card }(S)=n\\}\\] L’univers \\(\\Omega\\) est fini et \\[\\text{Card }(\\Omega)=\\binom{N}{n}\\] iii. Répétition de lancers avec condition d’arrêt. On lance une pièce dont les faces sont notées \\(P\\) et \\(F\\). On relance la pièce tant que PILE n’est pas obtenue. Les issues de cette expérience sont tous les lancers possibles. Comme on ne sait pas à l’avance combien de lancers vont être nécessaires pour stoper l’expérience, il s’agit bien d’une expérience aléatoire. Son univers est infini dénombrable : \\[\\Omega=\\{P, FP, FFP, FFFP, \\dots, FFFFFFFFFP, \\dots \\}\\] iv. Nombre de lancers. On reprend l’expérience précédente, mais cette fois on s’intéresse au nombre de lancers effectués. Il s’agit toujours d’une expérience aléatoire, mais cette fois : \\[\\Omega=\\{1,2,3,4,\\dots, 1\\,000,\\dots\\}=\\mathbb{N}^*\\] L’univers est donc là aussi infini dénombrable. v. Durée de vie d’une lampe. On observe la durée de vie d’une lampe, exprimée en jours. On peut à nouveau assimiler cette expérience à une expérience aléatoire. Cette fois, l’univers associé n’est ni fini ni dénombrable : \\[\\Omega=[0\\,;\\,+\\infty[=\\mathbb{R}_+\\] 2.3.2 L’espace probabilisable \\((\\Omega, \\mathcal{A})\\) Souvent, on définira des événements plus complexes que les événements élémentaires, par exemple des événements composites comme l’événement A : Le nombre obtenu est un nombre impair ou encore l’événement B: Le nombre obtenu est un nombre premier. Il faut donc enrichir l’univers \\(\\Omega\\) d’un ensemble qui décrit précisément quels sont les événements observables associés à une expérience aléatoire. Evénements, tribu, espace probabilisable Soit \\(\\Omega\\) l’univers d’une expérience aléatoire. On appelle tribu sur \\(\\Omega\\) tout sous-ensemble de l’ensemble des parties de \\(\\Omega\\) : \\[\\mathcal{A}\\subset\\mathcal{P}(\\Omega)\\] vérifiant les propriétés suivantes : \\(\\Omega\\in\\mathcal{A}\\) si \\((A_n)_{n\\in\\mathbb{N}}\\) est une famille finie ou dénombrable d’éléments de \\(\\mathcal{A}\\) (i.e. chacun des \\(A_n\\) est un élement de \\(\\mathcal{A}\\)), alors leur réunion est encore dans \\(\\mathcal{A}\\) : \\[\\bigcup\\limits_{n} A_n\\in\\mathcal{A}\\] si \\(A\\in\\mathcal{A}\\) alors \\(\\overline{A}\\in\\mathcal{A}\\). Les éléments de \\(\\mathcal{A}\\) sont appelés des événements ou des observables. En particulier : \\(\\Omega\\) s’appelle l’événement certain ; Pour tout événement \\(A\\), l’événement \\(\\overline{A}\\) s’appelle l’événement contraire de \\(A\\). On dit que le couple \\((\\Omega, \\mathcal{A})\\) est un espace probabilsable. La famille \\(\\mathcal{A}\\) formalise tous les observables relatifs à une expérience aléatoire, autrement dit tout ce qu’on est susceptible d’observer relativement à cette expérience (et dont on aimerait ensuite mesurer le niveau de crédibilité). Exemples. On reprend les exemples i. à v. de la section précédente. Dans les exemples i. et ii., \\(\\Omega\\) est fini. Dans les exemples iii. et iv., \\(\\Omega\\) est infini dénombrable. Dans ce cas on peut prendre \\(\\mathcal{A}=\\mathcal{P}(\\Omega)\\), comme c’est l’usage pour les univers finis ou dénombrables. L’exemple v. est plus complexe car \\(\\Omega\\) est infini et non dénombrable. On pourrait prendre \\(\\mathcal{A}=\\mathbb{P}(\\Omega)\\), mais cela ferait une tribu extrêmement grande, sur laquelle il serait certainement plus difficile par la suite de définir une probabilté. Dans ce genre de cas, on essaie en général de réduire la taille de la tribu à quelque chose de plus raisonnable. De manière un peu floue, on définit une classe d’événemenents que l’on aimerait pouvoir mesurer (i.e. dont on aimerait pouvoir calculer la probabilité) et on définit notre tribu comme la plus petite tribu contenant cette classe d’ensembles (on parle alors de tribu engendrée). Dans le cas présent, comme souvent lorsque \\(\\Omega\\) est un sous-ensemble de \\(\\mathbb{R}\\) non dénombrable, on prend pour \\(\\mathcal{A}\\) la tribu engendrée par les ouverts de \\(\\mathbb{R_+}\\). Une telle tribu s’appelle une tribu borélienne (plus généralement, pour un espace topologique \\((X, \\mathcal{T})\\) donné, la tribu borélienne est définie comme la tribu engendrée par les ouverts de cette topologie, i.e. les éléments de \\(\\mathcal{T}\\)). Il est difficile, pour ne pas dire impossible, de se représenter exactement à quoi cette tribu ressemble. En pratique, on s’y intérresse de toute façon assez peu. Tout cela étant largement hors-programme du concours d’administrateur, vous n’aurez pas du tout à vous en soucier dans votre préparation ! D’autres exemples. i. Lancer d’une pièce. L’univers associé au lancer d’une pièce est \\(\\Omega=\\{P,F\\}\\). On pose \\(\\mathcal{A}=\\left\\{\\emptyset, \\{P\\},\\{F\\}, \\{P,F\\}\\right\\}=\\mathcal{P}(\\Omega)\\). Alors, \\(\\mathcal{A}\\) est une tribu et donc le couple \\((\\Omega, \\mathcal{A})\\) est un espace probabilisable. ii. Si \\(\\Omega=\\{1,2,3,4\\}\\) alors \\(\\mathcal{A}=\\left\\{\\emptyset, \\{1\\}, \\{2,3,4\\}, \\Omega\\right\\}\\) est une tribu. \\(\\mathcal{A}&#39;=\\left\\{\\emptyset, \\{1,2\\}, \\{3, 4\\}, \\Omega\\right\\}\\) est une autre tribu. Remarques. i. Pour tout ensemble \\(\\Omega\\) modélisant l’univers d’une expérience aléatoire, on peut toujours poser \\(\\mathcal{A}=\\mathcal{P}(\\Omega)\\) et défnir ainsi une tribu, et donc un espace probabilisable \\((\\Omega, \\mathcal{P}(\\Omega))\\). C’est d’ailleurs assez souvent ce qui est fait lorsque l’ensemble \\(\\Omega\\) est fin ou dénombrable. Une telle tribu s’appelle la tribu discrète. Il s’agit de la plus grande tribu (au sens de l’inclusion) sur \\(\\Omega\\). ii. On peut aussi définir la tribu grossière : \\[\\mathcal{A}=\\{\\emptyset, \\Omega\\}\\] Il s’agit de la plus petite tribu (au sens de l’inclusion) sur \\(\\Omega\\). iii. Même si la notion de tribu n’est pas explicitement au programme (voire même est explicitement hors-programme), il faut tout de même retenir que la notion d’événement est stable par réunion dénombrable et par passage au complémentaire. Autrement dit : on est toujours capable d’observer la survenue ou non de \\(\\emptyset\\) et \\(\\Omega\\) ; si on est capable d’observer la survenue d’un événement \\(A\\), alors on est capable d’observer la survenue de l’événement contraire \\(\\overline{A}\\) ; si on est capable, pour tout entier naturel \\(n\\), d’observer la survenue d’un événement \\(A_n\\), alors on est capable d’observer la survenue de la réunion dénombrable \\(\\bigcup\\limits_{n\\in\\mathbb{N}} A_n\\) (et donc, à plus forte raison on est capable d’observer la survenue d’une réunion finie \\(\\bigcup\\limits_{n=0}^N A_n\\), puisqu’une réunion finie de \\(0\\) à \\(N\\) est un cas particulier d’une réunion finie sur \\(\\mathbb{N}\\) en posant \\(A_n=\\emptyset\\) pour \\(n\\geq N+1\\)). On peut en fait aller un peu plus loin : Stabilité de la notion d’événement. La notion d’événement est stable par toute opération de réunion finie ou dénombrable, d’intersection finie ou dénombrable et par passage au complémentaire. Autrement dit, si \\((A_n)_{n\\in \\mathcal{I}}\\) est une suite d’événements finie (cas où \\(\\mathcal{I}\\) est fini) ou infinie dénombrable (cas où \\(\\mathcal{I}\\) est infini dénombrable), alors \\(\\bigcup\\limits_{n\\in\\mathcal{I}} A_n\\), \\(\\bigcap\\limits_{n\\in\\mathcal{I}} A_n\\) et les \\(\\overline{A_n}\\) sont des événements. Démonstration. La notion d’événement est, par définition, stable par réunion dénombrable et par passage au complémentaire. Il reste donc à démontrer qu’elle est aussi stable par intersection dénombrable. Or \\[\\bigcap\\limits_{n\\in\\mathcal{I}} A_n=\\overline{\\bigcup\\limits_{n\\in\\mathcal{I}}\\overline{A_n}}\\] En effet, d’après l’une des lois de Morgan on a \\[\\overline{\\bigcup\\limits_{n\\in\\mathcal{I}}\\overline{A_n}}=\\bigcap\\limits_{n\\in\\mathcal{I}} \\overline{\\overline{A_n}}\\] et comme \\(\\overline{\\overline{A_n}}=A_n\\) on en déduit l’égalité annoncée. Par ailleurs : pour tout \\(n\\) dans \\(\\mathcal{I}\\), \\(\\overline{A_n}\\) est un événement (stabilité par passage au complémentaire) donc \\(\\bigcup\\limits_{n\\in\\mathcal{I}}\\overline{A_n}\\) est un événement (stabilité par réunion dénombrable) d’où l’on déduit que \\(\\overline{\\bigcup\\limits_{n\\in\\mathcal{I}}\\overline{A_n}}\\) est aussi un événement (stabilité par passage au complémentaire) Avec l’égalité démontrée plus haut, on obtient finalement que \\(\\bigcap\\limits_{n\\in\\mathcal{I}} A_n\\) est un événement. \\(\\square\\) Conséquence. Cette proposition a pour conséquence immédiate que si les \\((A_n)_{n\\in \\mathcal{I}}\\) forment une suite finie ou dénombrable d’événements, alors toute combinaison - aussi complexe sot-elle - de ces événements à partir des opérateurs \\(\\bigcup, \\bigcap\\) et de passage au complémentaire est encore un événement. Par exemple : \\(\\overline{\\bigcup_{n\\in\\mathcal{I}}\\bigcap_{k\\geq n}\\overline{A_k}}\\) est encore un événement ; \\(\\bigcap\\limits_{n\\in\\mathcal{I}}\\overline{\\bigcup_{k\\leq 2n} \\overline{A_k}}\\) est encore un événement ; \\(\\bigcup\\limits_{n\\in\\mathcal{I}}\\bigcup\\limits_{5\\leq p\\leq n}\\bigcap\\limits_{k\\geq p}\\bigcup\\limits_{l\\leq k}\\overline{A_l}\\) est encore un événement. On voit maintenant des exemples de combinaisons d’événements qui reviennent fréquemment dans les sujets du concours d’administrateur : Exemples classiques d’événements complexes Soit \\(A_1,A_2,\\dots,A_n,\\dots\\) une suite d’événements. \\(\\bigcup\\limits_{n=1}^{\\infty}A_n\\) est l’événement L’un au moins des \\(A_n\\) est réalisé \\(\\bigcup\\limits_{n=1}^{\\infty}\\overline{A_n}\\) est l’événement L’un au moins des \\(A_n\\) n’est pas réalisé \\(\\bigcap\\limits_{n=1}^{\\infty}A_n\\) est l’événement Tous les \\(A_n\\) sont réalisés \\(\\bigcap\\limits_{n=1}^{\\infty}\\overline{A_n}\\) est l’événement Aucun \\(A_n\\) n’est réalisé \\(\\bigcup\\limits_{n=0}^{\\infty}\\bigcap\\limits_{k\\geq n}A_k\\) est l’événement Tous les \\(A_n\\) sont réalisés à partir d’un certain rang. Cet événement est aussi la limite inférieure des \\(A_n\\) : \\[\\lim\\inf\\limits_{n\\to\\infty}A_n=\\bigcup\\limits_{n=0}^{\\infty}\\bigcap\\limits_{k\\geq n}A_k\\] \\(\\bigcap\\limits_{n=0}^{\\infty}\\bigcup\\limits_{k\\geq n}A_k\\) est l’événement Les \\(A_n\\) sont réalisés un nombre infini de fois. Cet événement est aussi la limite supérieure des \\(A_n\\) : \\[\\lim\\sup\\limits_{n\\to\\infty}A_n=\\bigcap\\limits_{n=0}^{\\infty}\\bigcup\\limits_{k\\geq n}A_k\\] Exercice. Ecrire l’événement Les \\(A_n\\) ne sont réalisés qu’un nombre fini de fois à partir des \\(\\overline{A_k}\\). Solution. Soit \\(B\\) l’événement Les \\(A_n\\) ne sont réalisés qu’un nombre fini de fois. Avec ce qui précède, on a, par application des lois de Morgan : \\[\\begin{align} B &amp;= \\overline{\\bigcap\\limits_{n\\to\\infty}\\bigcup\\limits_{k\\geq n}A_k} \\\\ &amp;= \\bigcup\\limits_{n\\to\\infty}\\bigcap\\limits_{k\\geq n}\\overline{A_k} \\end{align}\\] 2.3.3 L’espace probabilisé \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) Maintenant qu’on a défini la notion d’événement, on a envie de pouvoir mesurer le niveau de crédibilité de survenue d’un événement donné. Pour cela, on part d’une expérience aléatoire et on définit une application sur l’ensemble de tous les événements associés à cette expérience, et à valeurs dans \\([0,1]\\). Cela revient à enrichir l’espace probabilisable \\((\\Omega, \\mathcal{A})\\) pour le transformer en un espace probabilisé \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) : Probabilité, espace probabilisé Soit \\((\\Omega,\\mathcal{A})\\) un espace probabilisable. On appelle probabilité (ou mesure de probabilité) sur cet espace toute application \\[\\mathbb{P}:\\mathcal{A}\\longrightarrow [0,1]\\] vérifiant les axiomes suivants : L’univers est certain : \\(\\mathbb{P}(\\Omega)=1\\) \\(\\sigma-\\)additivité : si \\((A_n)_n\\) est une suite d’événements deux à deux incompatibles (i.e. si \\(A_n\\cap A_p=\\emptyset\\) dès que \\(n\\neq p\\)) alors la série \\(\\sum\\limits_{n}\\mathbb{P}(A_n)\\) est convergente et \\[\\mathbb{P}\\left(\\bigcup\\limits_{n\\to\\infty}A_n\\right)=\\sum\\limits_{n=0}^{\\infty}\\mathbb{P}(A_n)\\] On dit alors que le triplet \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) est un espace probabilisé. Remarque. Le \\(\\sigma\\) de la \\(\\sigma-\\)additivité fait référence au caractère infini de la propriété additivité. On peut aussi parler d’additivité (sans le \\(\\sigma\\)) d’une application \\(P\\) mais dans ce cas on parle plutôt d’une application \\(P\\) telle que \\[P\\left(\\bigcup\\limits_{n=0}^N A_n\\right)=\\sum\\limits_{n=0}^N P(A_n)\\] La \\(\\sigma-\\)additivité est strictement plus forte que l’additivité : \\[(P \\text{ est } \\sigma-\\text{ additive}) \\Rightarrow (P \\text{ est additive})\\] \\[\\text{mais}\\] \\[(P \\text{ est additive}) \\not\\Rightarrow (P \\text{ est } \\sigma-\\text{ additive})\\] Comme on souhaite considérer des événements composites s’écrivant comme réunion disjointe d’un nombre infini d’événements, il est plus naturel d’exiger d’une mesure de probabilité la propriété de \\(\\sigma-\\)additivité. On déduit de façon immédiate un certain nombre de propriétés des mesures de probabilité : Propriétés élémentaires des mesures de probabilité Soit \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) un espace probabilisé. Alors : L’événement impossible est de probabilité nulle. Autrement dit : \\[\\mathbb{P}(\\emptyset)=0\\] Probabilité de l’événement complémentaire. Pour tout événement \\(A\\), la probabilité de l’événement complémentaire \\(\\overline{A}\\) est donnée par \\[\\mathbb{P}(\\overline{A})=1-\\mathbb{P}(A)\\] Croissance de la probablité. Soient \\(A\\) et \\(B\\) deux événements tels que \\(A\\subset B\\). Alors : \\[\\mathbb{P}(A)\\leq\\mathbb{P}(B)\\] Crible de Poincaré. Soient \\(A\\) et \\(B\\) deux événements tels que \\(A\\subset B\\). Alors : \\[\\mathbb{P}(A\\cup B)=\\mathbb{P}(A)+\\mathbb{P}(B)-\\mathbb{P}(A\\cap B)\\] Plus généralement, étant donné une suite finie \\(A_1,A_2,\\dots A_n\\) d’événements, on a la formule \\[\\mathbb{P}\\left(\\bigcup\\limits_{k=1}^{n} A_k\\right)=\\sum\\limits_{k=1}^{n}(-1)^{k+1}\\sum\\limits_{1\\leq i_1&lt;i_2&lt;\\dots &lt;i_k}\\mathbb{P}\\left(\\bigcap\\limits_{j=1}^k A_{i_j}\\right)\\] Démonstration. Pour tout événement \\(A\\), \\(A\\) et \\(\\overline{A}\\) sont incompatibles, et par ailleurs \\(A\\cup\\overline{A}=\\Omega\\), donc : \\[\\begin{align} 1 &amp;= \\mathbb{P}(\\Omega) \\\\ &amp;= \\mathbb{P}(A\\cup\\overline{A}) \\\\ &amp;= \\mathbb{P}(A)+\\mathbb{P}(\\overline{A}) \\end{align}\\] et donc on a bien \\[\\mathbb{P}(\\overline{A})=1-\\mathbb{P}(A)\\] Par ailleurs, comme \\(\\emptyset=\\overline{\\Omega}\\) et \\(\\mathbb{P}(\\Omega)=1\\), on en déduit que \\[\\mathbb{P}(\\emptyset)=0\\] la formule du crible de Poincaré se démontre exactement comme la formule déjà vue pour le cardinal. Le point important de la démonstration - celui qui fait que tout fonctionne bien - dans la formule avec le cardinal est le fait que l’application cardinal : \\[\\text{Card }:A\\in\\mathcal{A}\\mapsto\\text{Card }(A)\\] est additive. Or, l’additivité (et même la \\(\\sigma-\\)additivité) est au coeur même de la construction des probabilités : l’application \\[\\mathbb{P}:A\\in\\mathcal{A}\\longrightarrow\\mathbb{P}(A)\\] est elle aussi additive (et même \\(\\sigma-\\)additive). Donc la démonstration de la formule de Poincaré pour les probabilités est une recopie exacte de celle pour les cardinaux, en remplaçant simplement l’application \\(\\text{Card}\\) par l’application \\(\\mathbb{P}\\). enfin, soient \\(A\\) et \\(B\\) des événements tels que \\(A\\subset B\\). Alors : \\[B= A\\cup (B\\cap\\overline{A})\\] \\[A\\cap(B\\cap\\overline{A})=\\emptyset\\] Avec ce qui précède on a donc \\[\\begin{align} \\mathbb{P}(B) &amp;= \\mathbb{P}(A)+\\mathbb{P}(B\\cap\\overline{A}) \\\\ &amp; \\geq\\mathbb{P}(A) \\end{align}\\] car \\(\\mathbb{P}(B\\cap\\overline{A})\\geq 0\\) (une probabilté est toujours positive). D’où le résultat. \\(\\square\\) Un cas particulier important est celui de l’équiprobabilité : Equiprobabilité Soit \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) un espace probabilisé tel que \\(\\Omega\\) soit fini à \\(n\\) éléments. On dit qu’il y a équiprobabilité lorsque toutes les probabilités des événements élémentaires \\(\\{\\omega\\}, \\omega\\in\\Omega\\) sont égales. Dans ce cas on a : \\[\\forall\\omega\\in\\Omega, \\,\\mathbb{P}(\\{\\omega\\})=\\frac{1}{n}\\] et plus généralement : \\[\\text{Pour tout événement } A, \\,\\mathbb{P}(A)=\\frac{\\text{Card }(A)}{\\text{Card }(\\Omega)}=\\frac{\\text{Card }(A)}{n}\\] Démonstration. On note \\(\\Omega=\\{\\omega_1,\\dots,\\omega_n\\}\\) et \\(p\\) la probabilité commune des événements élémentaires \\(\\{\\omega_i\\}\\). Les \\(\\{\\omega_i\\}\\) étant deux à deux incompatibles, on a alors : \\[\\begin{align} 1 &amp;= \\mathbb{P}(\\Omega) \\\\ &amp;= \\mathbb{P}\\left(\\bigcup\\limits_{i=1}^n \\{\\omega_i\\}\\right) \\\\ &amp;= \\sum\\limits_{i=1}^n \\mathbb{P}(\\{\\omega_i\\}) \\\\ &amp;= \\sum\\limits_{i=1}^n p \\\\ &amp;= np \\\\ \\end{align}\\] et donc \\[\\forall i\\in\\{1,\\dots,n\\}, \\,\\mathbb{P}(\\{\\omega_i\\})=\\frac{1}{n}\\] Soit maintenant \\(A=\\{\\omega_{i_1},\\dots,\\omega_{i_k}\\}\\) un événement (son cardinal est donc égal à \\(k\\)). Par un raisonnement analogue, on a : \\[\\begin{align} \\mathbb{P}(A) &amp;= \\mathbb{P}\\left(\\bigcup\\limits_{j=1}^k \\{\\omega_{i_j}\\}\\right) \\\\ &amp;= \\sum\\limits_{j=1}^k \\mathbb{P}(\\{\\omega_{i_j}\\}) \\\\ &amp;= \\sum\\limits_{i=1}^k \\frac{1}{n} \\\\ &amp;= \\frac{k}{n} \\\\ &amp;= \\frac{\\text{Card }(A)}{\\text{Card }(\\Omega)} \\\\ \\end{align}\\] \\(\\square\\) Cette formule montre donc que, en situtation d’équiprobabilité, calculer des probabilités revient à dénombrer. C’est typiquement la façon dont les probabilités étaient introduites avant dans les classes de lycée, avec les applications classiques sur les cartes, les boules dans des urnes, etc. Remarque. Lorsqu’on effectue un tirage alétoire dans un ensemble fini de façon équiprobable, on dit souvent qu’on effectue un tirage au hasard. Exemples. i. Course hippique. Lors d’une course hippique, on suppose que les \\(n\\) chevaux au départ ont la même probabilité de gagner. Quelle est la probabilité d’avoir un tiercé gagnant avec un ticket : dans l’ordre d’arrivée ? dans l’ordre d’arrivée ou dans un ordre différent ? dans un ordre différent ? Solution. On calcule d’abord le nombre de tiercés possibles. C’est le nombre de façons ordonnées de choisir tros chevaux parmi un ensemble de \\(n\\) chevaux. Il y en a donc \\[\\begin{align} A_n^3 &amp;= \\frac{n!}{(n-3)!} \\\\ &amp;= n(n-1)(n-2) \\\\ \\end{align}\\] il n’y a qu’un seul tiercé gagnant dans l’ordre, la probabilité \\(p_1\\) cherchée est \\[p_1=\\frac{1}{n(n-1)(n-2)}\\] - le nombre de tiercés gagnant dans l’ordre ou dans un ordre différent est égal au nombre de permutations d’un ensemble à trois éléments, soit \\(3!=6\\). La probabilité \\(p_2\\) cherchée est donc égale à \\[p_2=\\frac{6}{n(n-1)(n-2)}\\] le nombre de tiercés gagnants dans le désordre est \\(6-1=5\\) donc la probabilité \\(p_3\\) cherchée est \\[p_3=\\frac{5}{n(n-1)(n-2)}\\] ii. Permutations avec \\(n-2\\) points fixes. Soit \\(n\\) entier naturel tel que \\(n\\geq 3\\). On tire au hasard une permutation aléatoire \\(\\sigma\\) de \\(\\mathfrak{S}_n\\). Quelle est la probablité qu’elle ait exactement \\(n-2\\) points fixes ? (on dit qu’un entier \\(i\\in\\{1,2,\\dots, n\\}\\) est un point fixe de \\(\\sigma\\) lorsque \\(\\sigma(i)=i\\)). Solution. Soit \\(A_n\\) l’événement La permutation \\(\\sigma\\) a exactement \\(n-2\\) points fixes. Choisir une telle permutation \\(\\sigma\\) revient exactement à : choisir \\(n-2\\) points fixes parmi les \\(n\\) entiers de \\(1\\) à \\(n\\) : il y a \\(\\binom{n}{n-2}=\\binom{n}{2}=\\frac{n(n-1)}{2}\\) choix possibles ; choisir les deux points non fixes : mais le choix des \\(n-2\\) points fixes à l’étape précédente détermine de façon unique celui des deux points restants ; choisir les images des entiers \\(1,2,\\dots, n\\). Mais une fois qu’on a fait les choix précédents, il n’y a plus qu’une seule permutation \\(\\sigma\\) qui convienne : pour les \\(n-2\\) points fixes \\(i_1, i_2,\\dots i_{n-2}\\) on a, par définition \\(\\sigma(i_j)=i_j\\) ; pour les deux points \\((i_{n-1}, i_n)\\) qui ne sont pas fixes, on a \\(\\sigma(i_{n-1})=i_n\\) et \\(\\sigma(i_n)=i_{n-1}\\). D’après le principe multiplicatif, il y a donc \\(\\frac{n(n-1)}{2}\\) permutations de \\(\\mathfrak{S}_n\\) à \\(n-2\\) points fixes. Par ailleurs, il y a exactement \\(n!\\) permutations de \\(\\mathfrak{S}_n\\). On en déduit que \\[\\mathbb{P}(A_n)=\\frac{n(n-1)}{2\\,n!}=\\frac{1}{2\\,(n-2)!}\\] 2.4 Indépendance Indépendance de deux événements Soit \\((\\Omega, \\mathcal{A},\\mathbb{P})\\) un espace probabilisé. Deux événements \\(A\\) et \\(B\\) sont dits indépendants si \\(\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\,\\mathbb{P}(B)\\). Remarque. La notion d’indépendance est relative à un espace probabilisé \\((\\Omega, \\mathcal{A},\\mathbb{P})\\). Dit autrement, si on a deux espaces probabilisés \\((\\Omega, \\mathcal{A},\\mathbb{P})\\) et \\((\\Omega&#39;, \\mathcal{A}&#39;,\\mathbb{P}&#39;)\\) et \\(A\\) et \\(B\\) qui sont des événements pour ces deux espaces probabilisés à la fois, alors \\(A\\) et \\(B\\) peuvent être indépendants pour l’un des espaces mais pas pour l’autre. Cela peut notamment arriver si on prend deux mesures de probabilité dfférentes \\(\\mathbb{P}\\) et \\(\\mathbb{P}&#39;\\) pour un même espace probabilisable \\((\\Omega, \\mathcal{A})\\). Exemple. On lance deux dés cubiques équilibrés. On note : \\(A\\) l’événement La somme des deux numéros obtenus est 7 \\(B\\) l’événement Le produit des deux nombres obtenus est 6. Les événements \\(A\\) et \\(B\\) sont-ils indépendants ? Solution. L’univers \\(\\Omega\\) de cette expérience aléatoire est \\(\\Omega=\\{1,2,3,4,5,6\\}^2\\), de cardinal \\(36\\). Par ailleurs : \\[A=\\{(1,6),(2,5),(3,4),(4,3),(5,2), (6,1)\\}\\] \\[B=\\{(1,6), (2,3), (3,2), (6,1)\\}\\] \\[A\\cap B=\\{(1,6), (6,1)\\}\\] Les dés étant équililibrés, les événements élémentaires de \\(\\Omega\\) ont tous la même probabilité \\(p=\\frac{1}{36}\\), donc : \\[\\mathbb{P}(A\\cap B)=\\frac{2}{36}=\\frac{1}{18}\\] \\[\\mathbb{P}(A)\\mathbb{P}(B)=\\frac{6}{36}\\frac{4}{36}=\\frac{1}{54}\\] Donc, \\(\\mathbb{P}(A\\cap B)\\neq\\mathbb{P}(A)\\mathbb{P}(B)\\) : les événements \\(A\\) et \\(B\\) ne sont pas indépendants. Si on considère plus de deux événements, on peut définir deux notions d’indépendance : Indépendance mutuelle, indépendance deux à deux Soient \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) un espace probabilisé et \\(A_1,\\dots A_m\\) des événements. \\(A_1,\\dots, A_m\\) sont dits mutuellement indépendants lorsque pour toute partie \\(\\{i_1,\\dots i_p\\}\\subset\\{1,\\dots, m\\}\\) on a \\[\\mathbb{P}\\left(\\bigcap\\limits_{j=1}^p A_{i_j}\\right)=\\prod\\limits_{j=1}^p\\mathbb{P}(A_{i_j})\\] \\(A_1,\\dots, A_m\\) sont dits deux à deux indépendants lorsque pour tout couple \\((j,k)\\in\\{1,\\dots, m\\}^2\\) tel que \\(j\\neq k\\), on a \\[\\mathbb{P}(A_j\\cap A_k)=\\mathbb{P}(A_j)\\mathbb{P}(A_k)\\] Remarques. i. L’indépendance mutuelle est une notion plus forte que l’indépendance deux à deux : l’indépendance deux à deux dit que pour toute partie \\(\\{i_1, i_2\\}\\subset\\{1,\\dots, m\\}\\), \\(\\mathbb{P}(A_{i_1}\\cap A_{i_2})=\\mathbb{P}(A_{i_1})\\mathbb{P}(A_{i_2})\\), alors que l’indépendance mutuelle généralise ce type d’égalité à un nombre \\(p\\) quelconque d’événements, \\(p\\) étant compris entre \\(1\\) et \\(n\\). Autrement dit, l’indépendance mutuelle implique l’indépendance deux à deux. on peut trouver des exemples où trois événements \\(A_1, A_2, A_3\\) sont deux à deux indépendants sans être mutuellement indépendants. Si on lance une pièce équilibrée deux fois, et que l’on note \\(A_1\\) l’événement Obtenir PILE au premier lancer \\(A_2\\) l’événement Obtenir FACE au deuxième lancer \\(A_3\\) l’événement Obtenir le même résultat aux deux lancers alors on a \\[\\mathbb{P}(A_1)=\\mathbb{P}(A_2)=\\mathbb{P}(A_3)=\\frac{1}{2}\\] \\[\\mathbb{P}(A_1\\cap A_2)=\\mathbb{P}(A_1\\cap A_3)=\\mathbb{P}(A_2\\cap A_3)=\\frac{1}{4}\\] \\[\\mathbb{P}(A_1\\cap A_2\\cap A_3)=0\\] Ainsi, pour \\(i\\neq j\\) : \\[\\mathbb{P}(A_i\\cap A_j)=\\mathbb{P}(A_i)\\mathbb{P}(A_j)=\\frac{1}{4}\\] donc \\(A_1,A_2,A_3\\) sont deux à deux indépendants. Mais \\[\\mathbb{P}(A_1\\cap A_2\\cap A_3)=0\\neq\\mathbb{P}(A_1)\\mathbb{P}(A_2)\\mathbb{P}(A_3)=\\frac{1}{8}\\] donc \\(A_1, A_2, A_3\\) ne sont pas mutuellement indépendants. L’indépendance deux à deux n’implique donc pas nécessairement l’indépendance mutuelle. ii. Ces deux notions coïncident cependant de façon évidente pour deux événements. 2.5 Probabilités conditionnelles Supposons qu’on lance deux dés équilibrés et que l’on relève leurs numéros respectifs. La probabilité que leur somme soit égale à \\(8\\) est égale à \\(\\frac{5}{36}\\). Si maintenant quelqu’un nous dit que leur produit est égal à \\(12\\), alors avec la connaissance de cette information supplémentaire cette probabilité monte à \\(\\frac{1}{2}\\). Dans le premier cas, l’univers est \\(\\Omega=\\{1,2,3,4,5,6\\}^2\\) (de cardinal \\(36\\)) et l’événement \\(A=\\) La somme vaut \\(8\\) est réalisé par les couples \\((2,6), (3,5), (4,4), (5,3)\\) et \\((6,2)\\), et il est donc de cardinal \\(5\\). Donc on a bien \\(\\mathbb{P}(A)=\\frac{5}{36}\\). Dans le second cas, l’information sur le produit nous fait changer d’univers. Le nouvel univers est l’événement \\(B=\\) Le produit vaut 12 \\(=B=\\{(2,6), (3,4), (4,3), (6,2)\\}\\), de cardinal \\(4\\). Dans ce nouvel univers, l’événement \\(A\\) est réalisé par deux couples de \\(B\\) : \\((2, 6)\\) et \\((6, 2)\\). La probabilité de \\(A\\) est donc mise à jour suite à l’information apportée par la réalisation de \\(B\\). Cette nouvelle probabilité est notée \\(\\mathbb{P}(A|B)\\) et elle vaut donc \\(\\mathbb{P}(A|B)=\\frac{1}{2}\\). Comment l’a-t’on-calculée ? on a compté le cardinal \\(\\text{Card }(B)\\) du nouvel univers \\(B\\) ; on a compté le nombre d’événements élémentaires de \\(B\\) qui réalisent l’événement \\(A\\), autrement dit on a compté \\(\\text{Card }(A\\cap B)\\) ; étant en situation d’équiprobabilité, on a calculé \\(\\mathbb{P}(A|B)=\\frac{\\text{Card }(A\\cap B)}{\\text{Card }(B)}\\), que l’on peut aussi écrire \\[\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\] La définition qui suit est une extension de cette formule au cas général, i.e. sans faire d’hypothèse d’équirépartition des événements élémentaires. Probabilité conditionelle Soient \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) un espace probabilisé, et \\(A\\) et \\(B\\) deux événements tels que \\(\\mathbb{P}(B)&gt;0\\). On appelle probabilité conditionnelle de \\(B\\) sachant \\(A\\), ou encore probabilité de \\(B\\) conditionnellement à \\(A\\), le nombre \\[\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\] Cette probabilité conditionnelle est parfois aussi notée \\(\\mathbb{P}_B(A)\\). Une probabilité conditionnelle est en fait une probabilité comme une autre : Théorème. Avec les notations précédentes, l’application \\[\\mathbb{P}(\\,.\\,|B):A\\in\\mathcal{A}\\mapsto\\mathbb{P}(A|B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\] est une mesure de probabilité sur l’espace probabilisable \\((\\Omega, \\mathcal{A})\\) (et donc, \\((\\Omega, \\mathcal{A}, \\mathbb{P}(\\,.\\,|B))\\) est un espace probabilisé). Démonstation. Tout d’abord, on a \\[\\begin{align} \\mathbb{P}(\\Omega|B) &amp;= \\frac{\\mathbb{P}(\\Omega\\cap B)}{\\mathbb{P}(B)} \\\\ &amp;= \\frac{\\mathbb{P}(B)}{\\mathbb{P}(B)} \\\\ &amp;= 1 \\end{align}\\] Par ailleurs, pour \\((A_n)_n\\) une suite d’événements deux à deux incompatibles, on a \\[\\begin{align} \\mathbb{P}\\left(\\bigcup\\limits_{n=0}^{\\infty} A_n\\vert B\\right) &amp;=\\frac{\\mathbb{P}\\left(\\left(\\bigcup\\limits_{n=0}^{\\infty} A_n\\right)\\cap B\\right)}{\\mathbb{P}(B)} \\\\ &amp;=\\frac{\\mathbb{P}\\left(\\bigcup\\limits_{n=0}^{\\infty} \\left(A_n\\cap B\\right)\\right)}{\\mathbb{P}(B)} \\\\ &amp;= \\frac{\\sum\\limits_{n=0}^{\\infty}\\mathbb{P}\\left(A_n\\cap B\\right)}{\\mathbb{P}(B)} \\\\ &amp; \\text{(car les } A_n\\cap B \\text{ sont deux à deux incompatibles)} \\\\ &amp;=\\sum\\limits_{n=0}^{\\infty}\\frac{\\mathbb{P}\\left(A_n\\cap B\\right)}{\\mathbb{P}(B)} \\\\ &amp;=\\sum\\limits_{n=0}^{\\infty}\\mathbb{P}\\left(A_n | B\\right) \\end{align}\\] D’où le résultat. \\(\\square\\) Remarques. i. On vient de montrer qu’une probabilité conditionnelle est une probabilité. La réciproque est également vraie : une probabilité est une probabilité conditionnelle. Plus précisément, pour tout espace probabilisé \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\), on a \\[\\mathbb{P}=\\mathbb{P}(\\,.\\,\\vert\\Omega)\\] Les probabilités et les probabilités conditionnelles sont donc exactement les mêmes objets. Conditionner par \\(A\\), c’est juste passer d’un univers \\(\\Omega\\) à l’univers \\(A\\). ii. Puisqu’une probabilité conditionnelle est une probabilité, toutes les propriétés des probabilités sont également vraies pour les probabilités conditionnelles. Par exemple, si \\(A\\) et \\(B\\) sont deux événements tels que \\(\\mathbb{P}(B)&gt;0\\) (ce qui autorise à conditionner par \\(A\\)), alors \\(\\mathbb{P}(\\overline{A}\\vert B)=1-\\mathbb{P}(A\\vert B)\\). iii. Dans l’expression \\(\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}\\), la partie \\(A\\) que l’on mesure apparaît uniquement au numérateur. Le terme au dénominateur est uniquement un facteur de normalisation, qui permet de s’assurer que l’application \\(A\\in\\mathcal{A}\\mapsto\\mathbb{P}(A\\vert B)\\) somme bien à \\(1\\). La notion d’indépendance présentée plus haut s’interprète de façon très intuitive : Théorème (indépendance et conditionnement). Soient \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) un espace probabilisé, et \\(A\\) et \\(B\\) deux événements tels que \\(\\mathbb{P}(A)&gt;0\\) et \\(\\mathbb{P}(B)&gt;0\\). Alors : \\[\\text{(}A \\text{ et } B \\text{ sont indépendants )} \\Leftrightarrow\\text{( }\\mathbb{P}(A\\vert B)=\\mathbb{P}(A) \\text{ et } \\mathbb{P}(B\\vert A)=\\mathbb{P}(B)\\text{ )}\\] Autrement dit, dire que \\(A\\) et \\(B\\) sont indépendants revient à dire que l’information apportée par la survenue de l’un de ces deux événements n’affecte en rien celle de la survenue de l’autre. Démonstration. Supposons \\(A\\) et \\(B\\) indépendants. Alors \\[\\begin{align} \\mathbb{P}(A\\vert B) &amp;= \\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)} \\\\ &amp;= \\frac{\\mathbb{P}(A)\\mathbb{P}(B)}{\\mathbb{P}(B)} \\\\ &amp; \\text{(par indépendance de} A \\text{ et } B\\text{)} \\\\ &amp;= \\mathbb{P}(A) \\\\ \\end{align}\\] En inversant les rôles joués par \\(A\\) et \\(B\\) (et étant donné que \\(A\\cap B=B\\cap A\\)) on en déduit l’autre égalité \\(\\mathbb{P}(B\\vert A)=\\mathbb{P}(B)\\). Réciproquement, supposons que \\(\\mathbb{P}(A\\vert B)=\\mathbb{P}(A)\\) et \\(\\mathbb{P}(B\\vert A)=\\mathbb{P}(B)\\). De la première égalité on déduit que \\[\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}=\\mathbb{P}(A)\\] autrement dit \\[\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\mathbb{P}(B)\\] et \\(A\\) et \\(B\\) sont donc indépendants. \\(\\square\\) La formule \\(\\mathbb{P}(A\\cap B)=\\mathbb{P}(A\\vert B)\\mathbb{P}(B)\\) (pour \\(B\\) tel que \\(\\mathbb{P}(B)&gt;0\\)), qui découle de la définition de \\(\\mathbb{P}(A\\vert B)\\), admet une généralisation au cas où l’on intersecte un nombre quelconque \\(n\\) événements. Théorème (formule des probabilités composées). Soient \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) un espace probabilisé et \\(A_1, A_2,\\dots, A_n\\) des événements tels que \\(\\mathbb{P}(A_1\\cap A_2\\cap\\dots A_n)&gt;0\\). Alors on a la formule de chaînage : \\[\\mathbb{P}(A_1\\cap A_2\\cap\\dots\\cap A_n)=\\mathbb{P}(A_1)\\mathbb{P}(A_2\\vert A_1)\\mathbb{P}(A_3\\vert A_1\\cap A_2)\\dots\\mathbb{P}(A_n\\vert A_1\\cap A_2\\dots\\cap A_{n-1})\\] ce que l’on peut écrire de façon condensée : \\[\\mathbb{P}\\left(\\bigcap\\limits_{i=1}^n A_i\\right)=\\prod\\limits_{i=1}^n \\mathbb{P}\\left(A_i\\vert\\bigcap\\limits_{j=1}^{i-1} A_j\\right)\\] Démonstration. Par récurrence sur \\(n\\in\\mathbb{N}^*\\) : pour \\(n=1\\) c’est évident (l’égalité s’écrit \\(\\mathbb{P}(A_1)=\\mathbb{P}(A_1)\\). Pour \\(n=2\\), c’est une conséquence de la définition de \\(\\mathbb{P}(A_1\\vert A_2)\\). supposons l’égalité vraie pour \\(n\\) événements quelconques, montrons qu’elle est vraie pour \\(n+1\\) événements quelconques. On considère donc \\(n+1\\) événements \\(A_1, A_2,\\dots, A_n, A_{n+1}\\). Alors \\[\\begin{align} \\mathbb{P}(A_1\\cap\\dots\\cap A_n\\dots\\cap A_{n+1}) &amp;= \\mathbb{P}((A_1\\cap A_2\\dots\\cap A_n)\\cap A_{n+1}) \\\\ &amp;= \\mathbb{P}(A_{n+1} \\cap (A_1\\cap\\dots\\cap A_n)) \\\\ &amp;= \\mathbb{P}(A_{n+1}\\vert A_1\\dots\\cap A_n)\\mathbb{P}(A_1\\cap\\dots\\cap A_n) \\\\ &amp; \\text{(formule pour deux événements)} \\\\ &amp;= \\mathbb{P}(A_{n+1}\\vert A_1\\cap\\dots\\cap A_n)\\mathbb{P}(A_1)\\mathbb{P}(A_2\\vert A_1)\\dots\\mathbb{P}(A_n\\vert A_1\\cap\\dots\\cap A_{n-1}) \\\\ &amp; \\text{(hypothèse de récurrence)} \\\\ &amp;= \\mathbb{P}(A_1)\\mathbb{P}(A_2\\vert A_1)\\dots\\mathbb{P}(A_n\\vert A_1\\cap\\dots\\cap A_{n-1})\\mathbb{P}(A_{n+1}\\vert A_1\\cap\\dots\\cap A_n) \\\\ \\end{align}\\] ce qui permet de conclure. \\(\\square\\) Exemple. Une urne contient six boules rouges et quatre boules blanches. On tire successivement trois boules sans remise dans l’urne. Quelle est la probabilité d’avoir tiré trois boules blanches ? Solution. Pour \\(1\\leq i\\leq 3\\), on note \\(A_i\\) l’événement La boule tirée lors du tirage numéro \\(i\\) est blanche. On veut donc calculer \\(\\mathbb{P}(A_1\\cap A_2\\cap A_3)\\). D’après la formule des probablités composées, on a \\[\\mathbb{P}(A_1\\cap A_2\\cap A_3)=\\mathbb{P}(A_1)\\mathbb{P}(A_2\\vert A_1)\\mathbb{P}(A_3\\vert A_1\\cap A_2)\\] Or : \\(\\mathbb{P}(A_1)=\\frac{4}{10}=\\frac{2}{5}\\) \\(\\mathbb{P}(A_2\\vert A_1)=\\frac{3}{9}=\\frac{1}{3}\\) \\(\\mathbb{P}(A_3\\vert A_1\\cap A_2)=\\frac{2}{8}=\\frac{1}{4}\\) On a donc \\[\\begin{align} \\mathbb{P}(A_1\\cap A_2\\cap A_3) &amp;= \\frac{2}{5}\\times\\frac{1}{3}\\times\\frac{1}{4} \\\\ &amp; = \\frac{1}{30} \\\\ &amp; \\approx 0,033 \\end{align}\\] 2.6 Formule des probabilités totales La formule des probabilités totales est très utile pour calculer une probabilité lorsque l’on dispose d’un système complet d’événements : Système complet d’événements Soit \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) un espace probabilisé. On dit qu’une suite finie ou dénombrable d’événements \\((A_n)_n\\) est un système complet d’événements, ou un système exhaustif lorsque : la réunion des \\(A_n\\) recouvre complètement l’univers \\(\\Omega\\) : \\[\\Omega=\\bigcup\\limits_{n}A_n\\] les événements \\(A_n\\) sont deux à deux incompatibles : \\[\\forall (m,n) \\text{ t.q. } m\\neq n, \\, A_m\\cap A_n=\\emptyset\\] Remarque. Dans ce cas, pour tout événement \\(B\\), on peut écrire \\[B=\\bigcup\\limits_{n}(B\\cap A_n)\\] et les événements \\(B\\cap A_n\\) sont deux à deux incompatibles. Exemples. i. Pour tout événement \\(A\\), le système \\(\\{A, \\overline{A}\\}\\) est un système complet d’événements. ii. On tire aléatoirement deux nombres \\(A\\) et \\(B\\) dans \\(\\{0, 1, 2\\}\\) et on relève le couple \\((A, B)\\). L’univers associé à cette expérience est \\(\\Omega=\\{0, 1, 2\\}^2\\). On peut créer un système complet d’événements à partir de la somme \\(S\\) de \\(A\\) et \\(B\\). Pour cela, on note \\(\\{S=i\\}\\) l’événement \\[\\{S=i\\}=\\{(A, B)\\in\\Omega, \\, S=A+B=i\\}\\] Alors, le système \\[\\left\\{\\{S=0\\}, \\{S=1\\}, \\{S=2\\}, \\{S=3\\}, \\{S=4\\}\\right\\}\\] est un système complet d’événements de \\(\\Omega\\). Formule des probabilités totales. Soit \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) un espace probabilisé. On suppose qu’on dispose d’un système complet d’événements \\((A_n)_n\\). Alors, pour tout événement \\(B\\), on a \\[\\mathbb{P}(B)=\\sum\\limits_{n}\\mathbb{P}(B\\cap A_n)=\\sum\\limits_{n}\\mathbb{P}(B\\vert A_n)\\mathbb{P}(A_n)\\] Démonstration. Comme dit précémment, les événements \\(B\\cap A_n\\) sont deux à deux incompatibles, donc \\[\\begin{align} \\mathbb{P}(B) &amp;= \\mathbb{P}\\left(\\bigcup\\limits_{n} B\\cap A_n\\right) \\\\ &amp;= \\sum\\limits_{n}\\mathbb{P}(B\\cap A_n) \\\\ &amp; \\text{(par } \\sigma-\\text{addivité)} \\\\ &amp;= \\sum\\limits_{n}\\mathbb{P}(B\\vert A_n)\\mathbb{P}(A_n) \\\\ &amp; \\text{(par définition de la probabilité conditionnelle)} \\\\ \\end{align}\\] \\(\\square\\) Exemple. On dispose de trois urnes \\(A\\), \\(B\\) et \\(C\\) : l’urne \\(A\\) contient \\(3\\) boules blanches et \\(7\\) boules noires ; l’urne \\(B\\) contient \\(8\\) boules blanches et \\(2\\) boules noires ; l’urne \\(C\\) contient \\(4\\) boules blanches et \\(6\\) boules noires. On choisit aléatoirement une urne, avec la même probabilité pour toutes les urnes. On tire successivement et sans remise deux boules dans cette urne. Quelle est la probabilité d’avoir une boule blanche et une boule noire ? Solution. On note \\(A\\) (resp. \\(B\\), \\(C\\)), l’événement l’urne choisie est \\(A\\) (resp. \\(B\\), \\(C\\)). Pour \\(i=1,2\\), on note \\(N_i\\) (resp. \\(B_i\\)) l’événement la boule tirée au tirage numéro \\(i\\) est noire (resp. la boule tirée au tirage numéro \\(i\\) est blanche). L’événement \\(E=\\) Avoir une boule blanche et une boule noire s’écrit donc \\[E=\\left(B_1\\cap N_2\\right)\\cup\\left(N_1\\cap B_2\\right)\\] Les événements \\(B_1\\cap N_2\\) et \\(N_1\\cap B_2\\) sont incompatibles. On a donc \\[\\begin{align} \\mathbb{P}(E) &amp;= \\mathbb{P}\\left(\\left(B_1\\cap N_2\\right)\\cup\\left(N_1\\cap B_2\\right)\\right) \\\\ &amp;= \\mathbb{P}(B_1\\cap N_2)+\\mathbb{P}(N_1\\cap B_2) \\\\ \\end{align}\\] \\(\\{A, B, C\\}\\) est un système complet d’événements, donc d’après la formule des probabilités totales on a \\[\\begin{align} \\mathbb{P}(B_1\\cap N_2) &amp;= \\mathbb{P}(B_1\\cap N_2\\vert A)\\mathbb{P}(A)+\\mathbb{P}(B_1\\cap N_2\\vert B)\\mathbb{P}(B)+\\mathbb{P}(B_1\\cap N_2\\vert C)\\mathbb{P}(C) \\\\ &amp;= \\frac{1}{3}\\left(\\mathbb{P}(B_1\\cap N_2\\vert A)+ \\mathbb{P}(B_1\\cap N_2\\vert B)+\\mathbb{P}(B_1\\cap N_2\\vert C)\\right) \\\\ &amp;= \\frac{1}{3}\\left(\\mathbb{P}(N_2\\vert A\\cap B_1)\\mathbb{P}(B_1|A)+\\mathbb{P}(N_2\\vert B\\cap B_1)\\mathbb{P}(B_1|B)+\\mathbb{P}(N_2\\vert C\\cap B_1)\\mathbb{P}(B_1|C) \\right) \\\\ &amp;= \\frac{1}{3}\\left(\\frac{7}{9}\\times\\frac{3}{10}+\\frac{2}{9}\\times\\frac{8}{10}+\\frac{6}{9}\\times\\frac{4}{10}\\right) \\\\ &amp;= \\frac{61}{210} \\\\ \\end{align}\\] et \\[\\begin{align} \\mathbb{P}(N_1\\cap B_2) &amp;= \\mathbb{P}(N_1\\cap B_2\\vert A)\\mathbb{P}(A)+\\mathbb{P}(N_1\\cap B_2\\vert B)\\mathbb{P}(B)+\\mathbb{P}(N_1\\cap B_2\\vert C)\\mathbb{P}(C) \\\\ &amp;= \\frac{1}{3}\\left(\\mathbb{P}(N_1\\cap B_2\\vert A)+ \\mathbb{P}(N_1\\cap B_2\\vert B)+\\mathbb{P}(N_1\\cap B_2\\vert C)\\right) \\\\ &amp;= \\frac{1}{3}\\left(\\mathbb{P}(B_2\\vert A\\cap N_1)\\mathbb{P}(N_1|A)+\\mathbb{P}(B_2\\vert B\\cap N_1)\\mathbb{P}(N_1|B)+\\mathbb{P}(B_2\\vert C\\cap N_1)\\mathbb{P}(N_1|C) \\right) \\\\ &amp;= \\frac{1}{3}\\left(\\frac{3}{9}\\times\\frac{7}{10}+\\frac{8}{9}\\times\\frac{2}{10}+\\frac{4}{9}\\times\\frac{6}{10}\\right) \\\\ &amp;= \\frac{61}{210} \\\\ \\end{align}\\] On en déduit que \\[\\mathbb{P}(E)=\\frac{61}{105}\\approx 0,58\\] Autre méthode. On peut aussi écrire \\[\\mathbb{P}(B_1\\cap N_2)=\\mathbb{P}(B_1\\cap N_2\\cap A)+\\mathbb{P}(B_1\\cap N_2\\cap B)+\\mathbb{P}(B_1\\cap N_2\\cap C)\\] d’après la formule des probabilités totales. Puis, on utilise la formule des proabilités composées pour en déduire que \\[\\begin{align} \\mathbb{P}(B_1\\cap N_2) &amp;= \\mathbb{P}(A)\\mathbb{P}(B_1\\vert A)\\mathbb{P}(N_2\\vert B_1\\cap A) +\\mathbb{P}(B)\\mathbb{P}(B_1\\vert B)\\mathbb{P}(N_2\\vert B_1\\cap B) \\\\ &amp; +\\mathbb{P}(C)\\mathbb{P}(B_1\\vert C)\\mathbb{P}(N_2\\vert B_1\\cap C) \\end{align}\\] On fait ensuite exactement le même type de calcul pour \\(\\mathbb{P}(N_1\\cap B_2)\\). 2.7 Formule de Bayes La formule de Bayes a ceci de particulier qu’elle est à la fois extrêmement simple et pourtant absolument fondamentale. Formule de Bayes. Soit \\((\\Omega, \\mathcal{A}, \\mathbb{P})\\) un espace probabilisé. Soient \\(A\\) et \\(B\\) deux événements tels que \\(\\mathbb{P}(A)&gt;0\\) et \\(\\mathbb{P}(B)&gt;0\\). Alors \\[\\mathbb{P}(B\\vert A)=\\frac{\\mathbb{P}(A\\vert B)\\,\\mathbb{P}(B)}{\\mathbb{P}(A)}\\] Variantes. i. On la trouve parfois sous cette forme : \\[\\mathbb{P}(B\\vert A)=\\frac{\\mathbb{P}(A\\vert B)\\,\\mathbb{P}(B)}{\\mathbb{P}(A\\vert B)\\,\\mathbb{P}(B)+\\mathbb{P}(A\\vert\\overline{B})\\,\\mathbb{P}(\\overline{B})}\\] ii. Plus généralement, si l’on dispose d’un système complet d’événements \\(\\{B_i\\}_{i\\in I}\\), alors pour tout \\(i\\) dans \\(I\\) on a \\[\\mathbb{P}(B_i\\vert A)=\\frac{\\mathbb{P}(A\\vert B_i)\\,\\mathbb{P}(B_i)}{\\sum\\limits_{j\\in I} \\mathbb{P}(A\\vert B_j)\\,\\mathbb{P}(B_j)}\\] Démonstration. Comme \\(A\\cap B=B\\cap A\\), on a \\[\\begin{align} \\mathbb{P}(A\\vert B)\\mathbb{P}(B) &amp;= \\mathbb{P}(A\\cap B) \\\\ &amp;= \\mathbb{P}(B\\cap A) \\\\ &amp;= \\mathbb{P}(B\\vert A)\\mathbb{P}(A) \\\\ \\end{align}\\] d’où \\[\\mathbb{P}(B\\vert A)=\\frac{\\mathbb{P}(A\\vert B)\\,\\mathbb{P}(B)}{\\mathbb{P}(A)}\\] Si \\(\\{B_i\\}_{i\\in I}\\) est un système complet d’événements alors d’après la formule des probabilités totales \\[\\mathbb{P}(A)=\\sum\\limits_{j\\in I}\\mathbb{P}(A\\vert B_j)\\mathbb{P}(B_j)\\] et donc en appliquant la formule de Bayes avec \\(B=B_i\\) et en remplaçant \\(\\mathbb{P}(A)\\) par l’expression ci-dessus, on obtient \\[\\mathbb{P}(B_i\\vert A)=\\frac{\\mathbb{P}(A\\vert B_i)\\,\\mathbb{P}(B_i)}{\\sum\\limits_{j\\in I} \\mathbb{P}(A\\vert B_j)\\,\\mathbb{P}(B_j)}\\] En particulier, \\(\\{B, \\overline{B}\\}\\) étant un système complet d’événements, on a donc \\[\\mathbb{P}(B\\vert A)=\\frac{\\mathbb{P}(A\\vert B)\\,\\mathbb{P}(B)}{\\mathbb{P}(A\\vert B)\\,\\mathbb{P}(B)+\\mathbb{P}(A\\vert\\overline{B})\\,\\mathbb{P}(\\overline{B})}\\] \\(\\square\\) Interprétation de la formule de Bayes. On peut voir la formule de Bayes comme une mise à jour de nos croyances, lorsqu’on acquière de l’information. Pour illustrer ce point, on reprend l’exemple des trois urnes \\(A, B\\) et \\(C\\) vu plus haut. Imaginons un jeu dans lequel on doit deviner l’urne choisie secrètement par une autre personne. En l’absence de toute information, nous n’avons aucune raison de privilégier une urne à l’autre, et donc on décide de retenir un modèle de choix d’urne équiprobabiliste : \\[\\mathbb{P}(A)=\\mathbb{P}(B)=\\mathbb{P}(C)=\\frac{1}{3}\\] Imaginons maintenant qu’on nous donne une information supplémentaire. La personne qui a choisi l’urne y a tiré une boule au hasard, et elle a obtenu une boule blanche. Cette information va affecter notre modèle probabliste du choix de l’urne. Intutivement, sans faire explicitement de calcul, on a envie d’attribuer une probabilité plus grande à l’urne \\(B\\). Plus formellement, les niveaux de crédibilité qu’on va attribuer aux trois urnes \\(A\\), \\(B\\) et \\(C\\) sont désormais \\(\\mathbb{P}(A\\vert B_1)\\), \\(\\mathbb{P}(B\\vert B_1)\\) et \\(\\mathbb{P}(C\\vert B_1)\\) et on a : \\[\\mathbb{P}(B\\vert B_1)&gt;\\mathbb{P}(C\\vert B_1)&gt;\\mathbb{P}(A\\vert B_1)\\] L’ajout de cette information a donc modifié notre système de croyances sur l’urne choisie, en mettant à jour les probabilités associées à chacune des urnes. Le calcul de ces probablités via l’utilisation de la formule de Bayes confirme notre intuition : \\[\\begin{align} \\mathbb{P}(A\\vert B_1) &amp;= \\frac{\\mathbb{P}(B_1\\vert A)\\mathbb{P}(A)}{\\mathbb{P}(B_1\\vert A)\\mathbb{P}(A)+\\mathbb{P}(B_1\\vert B)\\mathbb{P}(B)+\\mathbb{P}(B_1\\vert C)\\mathbb{P}(C)} \\\\ &amp;= \\frac{\\mathbb{P}(B_1\\vert A)}{\\mathbb{P}(B_1\\vert A)+\\mathbb{P}(B_1\\vert B)+\\mathbb{P}(B_1\\vert C)} \\\\ &amp;= \\frac{\\frac{3}{10}}{\\frac{3}{10}+\\frac{8}{10}+\\frac{4}{10}} \\\\ &amp;= \\frac{3}{15} \\end{align}\\] \\[\\begin{align} \\mathbb{P}(B\\vert B_1) &amp;= \\frac{\\mathbb{P}(B_1\\vert B)\\mathbb{P}(B)}{\\mathbb{P}(B_1\\vert A)\\mathbb{P}(A)+\\mathbb{P}(B_1\\vert B)\\mathbb{P}(B)+\\mathbb{P}(B_1\\vert C)\\mathbb{P}(C)} \\\\ &amp;= \\frac{\\mathbb{P}(B_1\\vert B)}{\\mathbb{P}(B_1\\vert A)+\\mathbb{P}(B_1\\vert B)+\\mathbb{P}(B_1\\vert C)} \\\\ &amp;= \\frac{\\frac{3}{10}}{\\frac{3}{10}+\\frac{8}{10}+\\frac{4}{10}} \\\\ &amp;= \\frac{8}{15} \\end{align}\\] \\[\\begin{align} \\mathbb{P}(C\\vert B_1) &amp;= \\frac{\\mathbb{P}(B_1\\vert C)\\mathbb{P}(C)}{\\mathbb{P}(B_1\\vert A)\\mathbb{P}(A)+\\mathbb{P}(B_1\\vert B)\\mathbb{P}(B)+\\mathbb{P}(B_1\\vert C)\\mathbb{P}(C)} \\\\ &amp;= \\frac{\\mathbb{P}(B_1\\vert C)}{\\mathbb{P}(B_1\\vert A)+\\mathbb{P}(B_1\\vert B)+\\mathbb{P}(B_1\\vert C)} \\\\ &amp;= \\frac{\\frac{4}{10}}{\\frac{3}{10}+\\frac{8}{10}+\\frac{4}{10}} \\\\ &amp;= \\frac{4}{15} \\end{align}\\] L’information apportée a donc modifié nos croyances de la façon suivante : \\[\\mathbb{P}(A\\vert B_1)=\\frac{3}{15}\\] \\[\\mathbb{P}(B\\vert B_1)=\\frac{8}{15}\\] \\[\\mathbb{P}(C\\vert B_1)=\\frac{4}{15}\\] Probabilité a priori, probabilité a posteriori, vraisemblance Dans la formule de Bayes \\[\\mathbb{P}(B\\vert A)=\\frac{\\mathbb{P}(A\\vert B)\\,\\mathbb{P}(B)}{\\mathbb{P}(A)}\\] chaque terme a un nom : \\(\\mathbb{P}(B)\\) est la probabilité a priori de \\(B\\) : ce terme modélise notre croyance sur \\(B\\) en l’absence de toute information ; \\(\\mathbb{P}(B\\vert A)\\) est la probabilité a posteriori de \\(B\\) sachant l’événement \\(A\\) : il s’agit de notre niveau de notre confiance en \\(B\\) après avoir pris connaissance de l’information \\(A\\) ; \\(\\mathbb{P}(A\\vert B)\\) est la fonction de vraisemblance de \\(A\\) : ce terme nous dit à quel point l’événement \\(B\\) rend \\(A\\) vraisemblable ; \\(\\mathbb{P}(B)\\) est la marginale ou probabilité a priori de \\(B\\) : il s’agit juste d’un terme de normalisation, qui est souvent ignoré en statistique bayésienne (les calculs étant alors faits à une constante près). Remarques. i. La mise à jour de la probabilité de \\(B\\) repose donc sur deux termes : la probabilité a priori de \\(B\\) et la fonction de vraisemblance. Ces deux termes ont des rôles bien spécfiques : une probabilité a priori élevée tend à augmenter la probabilité a posteriori. Ce terme favorise donc une persistance de nos croyances ; il peut être contrebalancé par une vraisemblance faible. Si je crois en \\(B\\), mais que je sais par ailleurs que \\(B\\) rend l’événement \\(A\\) peu probable, toutes choses égales par ailleurs la survenue de \\(A\\) va réduire mon niveau de croyance en \\(B\\). ii. La formule de Bayes est aussi appelée formule de probabilité des causes, car elle permet de calculer la probabilité d’une cause à partir de l’observation de ses conséquences. Cette formule est le point de départ de l’inférence bayésienne, qui envisage les probabilités comme des niveaux de croyance qui sont sans cesse remis à jour au fur et à mesure que de nouvelles données sont disponibles. Elle diffère de l’inférence fréquentiste qui considère une probabilité comme une fréquence limite, via l’utilisation de la loi des grands nombres. L’inférence bayésienne repose sur l’utilisation de probabilités a priori, qui sont souvent considérées comme des probabilités à dire d’expert. Ses détracteurs y voient là une faiblesse de la théorie, qui laisse à leurs yeux une place trop importante à la subjectivité. "],["variables-aléatoires-discrètes.html", "Chapitre 3 Variables aléatoires discrètes 3.1 Définition et premières propriétés 3.2 Transformation d’une variable aléatoire discrète 3.3 Vecteurs aléatoires", " Chapitre 3 Variables aléatoires discrètes 3.1 Définition et premières propriétés 3.1.1 Définition 3.1.2 Loi d’une variable aléatoire discrète 3.1.3 Définition de \\(p(X\\in A)\\) 3.1.4 Fonction de répartition, quantiles 3.1.5 Exemples classiques : loi uniforme sur un ensemble fini loi de Bernoulli loi binomiale loi de Poisson loi géométrique loi hypergéométrique 3.1.6 Moments d’une variable aléatoire Espérance, variance, moments d’ordres supérieurs inégalité de Markov, inégalité de Bieanymé-Tchébychev (exemples + intérêt) 3.2 Transformation d’une variable aléatoire discrète 3.2.1 Définition Définition Cas particuliers : bijection continue un unique extremum Déterminer la loi de \\(f(X)\\) en pratique (message = passer par la fonction de répartition) 3.2.2 Théorème de transfert (cas discret) Théorème Exemple 3.3 Vecteurs aléatoires 3.3.1 Définition 3.3.2 Loi jointe, loi marginales 3.3.3 Loi conditionnelle \\(\\mathcal{L}(Y|X)\\) 3.3.4 Loi d’un couple de VA indépendantes Définition Somme de deux VA indépendantes (produit de convolution discret) 3.3.5 Espérance conditionnelle, variance conditionnelle "],["variables-aléatoires-à-densité.html", "Chapitre 4 Variables aléatoires à densité 4.1 Définition et premières propriétés 4.2 Transformation d’une variable aléatoire à densité 4.3 Vecteurs aléatoires", " Chapitre 4 Variables aléatoires à densité 4.1 Définition et premières propriétés 4.1.1 Définition 4.1.2 Loi d’une variable aléatoire à densité 4.1.3 Définition de \\(p(X\\in A)\\) 4.1.4 Fonction de répartition, quantiles 4.1.5 Exemples classiques : loi uniforme sur un segment loi normale loi exponentielle loi gamma \\(\\gamma(p\\,;\\,\\theta)\\) loi log-normale loi du Chi-Deux loi de Student loi de Fisher 4.1.6 Moments d’une variable aléatoire Espérance, variance, espaces \\(L^1\\) et \\(L^2\\) moments d’ordres supérieurs inégalité de Markov, inégalité de Bieanymé-Tchébychev (exemples + intérêt) 4.2 Transformation d’une variable aléatoire à densité 4.2.1 Définition Définition Cas particuliers : bijection continue un unique extremum Déterminer la loi de \\(f(X)\\) en pratique (message = passer par la fonction de répartition) 4.2.2 Théorème de transfert (cas à densité) Théorème Exemple 4.3 Vecteurs aléatoires 4.3.1 Définition 4.3.2 Loi jointe, loi marginales 4.3.3 Loi conditionnelle \\(\\mathcal{L}(Y|X)\\) 4.3.4 Loi d’un couple de VA indépendantes Définition Somme de deux VA indépendantes (produit de convolution à densité) 4.3.5 Espérance, matrice de variance-covariance exemple : vecteurs gaussiens en dimension 2 4.3.6 Espérance conditionnelle, variance conditionnelle "],["convergence.html", "Chapitre 5 Convergence 5.1 Différents modes de convergence 5.2 Loi Faible des Grands Nombres, Loi Forte des Grands Nombres 5.3 Théorème Central Limite (TCL) 5.4 Variantes du TCL (hors-programme)", " Chapitre 5 Convergence 5.1 Différents modes de convergence 5.1.1 Convergence en probabilité 5.1.2 Convergence dans les espaces \\(L^p\\) focus sur les cas \\(p=1\\) et \\(p=2\\) 5.1.3 Convergence en loi 5.1.4 Convergence presque-sûre (hors-prgramme ?) 5.1.5 Liens entre les différents modes de convergence 5.1.6 Approximations approximation de la loi binomiale \\(\\mathcal{B}(n\\,;\\,p)\\approx\\mathcal{N}(np\\,;\\,np(1-p))\\) approximation de la loi de Poisson \\(\\mathcal{P}(\\lambda)\\approx\\mathcal{N}(\\lambda\\,;\\,\\lambda)\\) (bien préciser les hypothèses sous-jcantes à ces approximations) 5.2 Loi Faible des Grands Nombres, Loi Forte des Grands Nombres énoncé théorique exemples avec illustration en R 5.3 Théorème Central Limite (TCL) énoncé théorique exemples avec illustration en R 5.4 Variantes du TCL (hors-programme) "],["statistique-descriptive.html", "Chapitre 6 Statistique descriptive 6.1 Vocabulaire 6.2 Analyse statistique univariée 6.3 Analyse statistique bivariée", " Chapitre 6 Statistique descriptive 6.1 Vocabulaire 6.1.1 Population, individus, échantillon 6.2 Analyse statistique univariée 6.2.1 Notion de série statistique univariée série statistique à une variable valeurs variable statistique 6.2.2 Indicateurs d’une série statistique univariée modalités, effectif, fréquence effectifs cumulées croissants, fréquences cumulées croissantes indicateurs de position, indicateurs de dispersion indicateurs de concentration courbe de Lorenz indice de Gini quantiles 6.2.3 Représentations graphiques 6.3 Analyse statistique bivariée 6.3.1 Notion de série statistique bivariée série statistique à deux variables 6.3.2 Indicateurs propres à l’analyse statistique multivariée distribution marginale effectif marginal fréquence marginale covariance empirique distribution conditionnelle formule de Huygens-Koenig coefficient de corrélation linéaire empirique 6.3.3 Nuage de points 6.3.4 Ajustement des moindres carrés "],["statistique-inférentielle.html", "Chapitre 7 Statistique inférentielle 7.1 Estimation 7.2 Tests statistiques", " Chapitre 7 Statistique inférentielle 7.1 Estimation On s’intéresse à une loi probabiliste \\(\\mathcal{L}_{\\theta}\\), qui est entièrement décrite par la donnée d’un paramètre inconnu \\(\\theta\\). Pour mieux appréhender cette loi, il serait intéressant de connaître la valeur de \\(\\theta\\). Plutôt que de chercher à déterminer la valeur exacte de \\(\\theta\\), on peut essayer de l’approcher. Dans le cadre de la statistique inférentielle, on suppose qu’on dispose d’un échantillon i.i.d. de \\(\\mathcal{L}_{\\theta}\\), autrement dit d’un certain nombre de réalisations \\((Y_1,\\dots, Y_n)\\) indépendantes et identiquement distribuées de la loi \\(\\mathcal{L}_{\\theta}\\). La donnée d’un tel échantillon constitue un ensemble d’informations qui vont nous être utiles pour estimer le paramètre \\(\\theta\\). on fait donc bien ici de l’inférence - ou encore de l’induction - dans le sens où on part d’observations particulières (les réalisations \\(Y_1,\\dots, Y_n)\\) pour énoncer une règle générale (le fait que ces réalisations sont issues de la loi \\(\\mathcal{L}_{\\theta}\\)). 7.1.1 Premières définitions Estimateurs Soit \\(Y\\) une variable aléatoire de loi \\(\\mathcal{L}(Y)\\), paramétrée par un réel \\(\\theta\\) inconnu. Soit \\((Y_1,\\dots, Y_n)\\) un échantillon i.i.d. de loi \\(\\mathcal{L}(Y)\\). On appelle estimateur de \\(\\theta\\) toute fonction de \\(Y_1,\\dots, Y_n\\), i.e. \\[\\widehat{\\theta}_n=S(Y_1,\\dots, Y_n)\\] On veut estimer la moyenne d’une loi normale \\(\\mathcal{N}(\\mu\\,;\\,1)\\), à partir d’un échantillon d’observations i.i.d. \\((Y_1,\\dots, Y_n)\\) tirées sous cette loi. Une façon naturelle d’estimer \\(\\mu=\\mathbb{E}(Y_1)\\) est de poser \\(\\widehat{\\mu}_n=\\frac{Y_1+\\dots Y_n}{n}\\). Ici, on estime donc une moyenne théorique par sa contrepartie empirique. Biais, erreur quadratique Soit \\(\\widehat{\\theta}_n\\) un estimateur de \\(\\theta\\) admettant un moment d’ordre \\(1\\). On appelle biais de \\(\\widehat{\\theta}_n\\) la quantité \\(b_{\\theta}(\\widehat{\\theta}_n)=\\mathbb{E}(\\widehat{\\theta}_n)-\\theta\\). Un estimateur est dit sans biais lorsque son biais est nul, i.e. \\(\\mathbb{E}(\\widehat{\\theta}_n)=\\theta\\). Il est dit asymptotiquement sans biais lorsque son biais tend vers \\(0\\), i.e. \\(b_{\\theta}(\\widehat{\\theta}_n)\\underset{n\\to +\\infty}{\\longrightarrow}0\\). Pour un estimateur des moments d’ordre \\(1\\) et \\(2\\), on appelle erreur quadratique moyenne la quantité (positive) \\(\\text{EQM}_{\\theta}(\\widehat{\\theta}_n)=\\mathbb{E}\\left(\\left(\\widehat{\\theta}_n-\\theta\\right)^2\\right)\\) L’erreur quadratique moyenne s’écrit à l’aide de l’espérance et de la variance : Théorème : Soit \\(\\widehat{\\theta}_n\\) un estimateur de \\(\\theta\\) admettant des moments d’ordres \\(1\\) et \\(2\\). Son erreur quadratique moyenne peut se décomposer en biais au carré/variance : \\[\\text{EQM}_{\\theta}(\\widehat{\\theta}_n)=b_{\\theta}^2(\\widehat{\\theta}_n)+\\mathbb{V}(\\widehat{\\theta}_n)\\] Autrement dit, réduire l’erreur (quadratique moyenne) d’un estimateur revient à essayer de réduire son biais et/ou sa variance. En pratique, uune réduction du biais implique souvent une augmentation de la variance (et vice-versa) et il faut trouver un compromis entre les deux, i.e. un estimateur pour lequel la combinaison (biais, variance) implique une faible erreur quadratique moyenne. On parle alors de compromis biais-variance. 7.1.2 Convergence d’un estimateur Estimateurs convergents Un estimateur \\(\\widehat{\\theta}_n\\) de \\(\\theta\\) est dit convergent lorsqu’il converge en probabilité vers \\(\\theta\\) i.e. lorsque \\[\\forall\\varepsilon &gt;0, \\mathbb{P}\\left(|\\widehat{\\theta}_n-\\theta|&gt;\\varepsilon\\right)\\longrightarrow 0\\] La convergence d’un estimateur sans biais peut se montrer à l’aide du critère pratique suivant : Théorème (critère pratique de convergence) : Un estimateur \\(\\widehat{\\theta}_n\\) sans biais de \\(\\theta\\) est convergent dès que sa variance tend vers \\(0\\), i.e. \\[\\left(\\mathbb{E}_{\\theta}(\\widehat{\\theta}_n)=0 \\text{ et } \\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)\\longrightarrow 0\\right)\\Rightarrow \\left(\\widehat{\\theta}_n \\underset{n \\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}\\theta\\right)\\] Démonstration. Compte-tenu du fait que \\(\\widehat{\\theta}_n\\) est un estimateur sans biais pour \\(\\theta\\), l’inégalité de Bieanymé-Tchebychev s’écrit \\(\\mathbb{P}(|\\widehat{\\theta}_n-\\theta|&gt;\\varepsilon)\\leq\\frac{\\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)}{\\varepsilon^2}\\), ce qui permet de conclure. \\(\\square\\) On peut même affaiblir un peu l’hypothèse d’absence de biais par une hypothèse de biais asymptotiquement nul : Théorème (critère pratique de convergence (suite)) : Un estimateur \\(\\widehat{\\theta}_n\\) asymtotiquement sans biais de \\(\\theta\\) est convergent dès que sa variance tend vers \\(0\\), i.e. \\[\\left(\\mathbb{E}_{\\theta}(\\widehat{\\theta}_n)\\underset{n\\to +\\infty}{\\longrightarrow}\\theta \\text{ et } \\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)\\longrightarrow 0\\right)\\Rightarrow \\left(\\widehat{\\theta}_n \\underset{n \\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}\\theta\\right)\\] 7.1.3 Exemples classiques Quelques exemples très classiques d’estimateurs : Exemple 1 : moyenne empirique. Soit \\(X_1,\\dots X_n\\) une suite de \\(VAR\\) i.i.d. de même loi que \\(X\\), admettant une espérance \\(\\mu\\). La moyenne empirique est l’estimateur \\[\\overline{X_n}=\\frac{X_1+\\dots + X_n}{n}\\] Théorème : Quelle que soit la loi suivie par \\(X\\), la moyenne empirique \\(\\overline{X_n}\\) est un estimateur sans biais de l’espérance \\(\\mu=\\mathbb{E}(X)\\). Si, de plus, \\(X\\) admet une variance \\(\\sigma^2\\), alors \\(\\overline{X_n}\\) admet également une variance et celle-ci est donnée par \\(\\mathbb{V}(\\overline{X_n})=\\frac{\\sigma^2}{n}\\). Démonstration. Par linéarité de l’espérance : \\(\\mathbb{E}(\\overline{X_n})=\\frac{1}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i)=\\frac{1}{n}\\sum\\limits_{i=1}^n\\mu=\\mu\\). Si \\(X\\) admet une variance, alors \\(\\overline{X_n}\\) aussi et \\(\\mathbb{V}(\\overline{X_n})=\\frac{1}{n^2}\\sum\\limits_{i=1}^n\\mathbb{V}(X_i)=\\frac{\\sigma^2}{n}\\), par indépendance de \\(X_1,\\dots X_n\\). \\(\\square\\) Corollaire : La moyenne empirique est un estimateur convergent de l’espérance (lorsqu’elle existe). Démonstration. L’estimateur \\(\\overline{X_n}\\) est sans biais et \\(\\mathbb{V}(\\overline{X_n})=\\frac{\\sigma^2}{n}\\longrightarrow 0\\). C’est donc un estimateur convergent de l’espérance. \\(\\square\\). Exemple 2 : estimation d’une proportion. Au sein d’une population, une proportion \\(p\\) d’individus présente une caractéristique. On suppose que la présence de cette caractéristique est distribuée de façon identique et indépendante d’un individu à l’autre suivant la loi de Bernoulli de paramètre \\(p\\). On peut donc estimer la proportion \\(p\\) au niveau population par la proportion \\(\\widehat{p_n}\\) au niveau échantillon : cet estimateur est la moyenne empirique, il est sans biais et de variance (inconnue) \\(\\frac{p(1-p)}{n}\\). Exemple 3 : variance empirique. Si \\(X\\) admet une variance \\(\\sigma^2\\) et \\(X_1,\\dots, X_n\\) sont i.i.d. de même loi que \\(X\\), alors un estimateur de \\(\\sigma^2\\) est donné par la variance empirique \\(S_n^{&#39;2}=\\frac{1}{n}\\sum\\limits_{i=1}^n(X_i-\\overline{X_n})^2\\). Théorème : La variance empirique \\(S_n^{&#39;2}\\) est un estimateur biaisé de la variance \\(\\sigma^2\\). Plus précisément, on a \\[\\mathbb{E}(S_n^{&#39;2})=\\frac{n-1}{n}\\sigma^2\\] Démonstration. \\[\\begin{align} \\mathbb{E}(S_n^{&#39;2}) &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i^2)-\\frac{2\\overline{X_n}}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i)+\\frac{1}{n}\\sum\\limits_{i=1}^n\\mathbb{E}(\\overline{X_n}^2) \\\\ &amp;= \\mathbb{E}(X^2)-\\mathbb{E}(\\overline{X_n}^2) \\end{align}\\] Par ailleurs : \\[\\begin{align} \\mathbb{E}(\\overline{X_n}^2)&amp;=\\frac{1}{n^2}\\sum\\limits_{i=1}^n\\mathbb{E}(X_i^2)+\\frac{1}{n^2}\\sum\\limits_{i\\neq j}\\mathbb{E}(X_iX_j) \\\\ &amp;= \\frac{1}{n}^2\\sum\\limits_{i=1}^n\\mathbb{E}(X_i^2)+\\frac{1}{n^2}\\sum\\limits_{i\\neq j}\\mathbb{E}(X_i)\\mathbb{E}(X_j) \\\\ &amp;= \\frac{1}{n}\\mathbb{E}(X^2)+\\frac{n-1}{n}\\left(\\mathbb{E}(X)\\right)^2 \\end{align}\\] Avec la formule de Huygens \\(\\mathbb{V}(X)=\\mathbb{E}(X^2)-\\mathbb{E}(X)^2\\), on en déduit que \\[\\mathbb{E}(S_n^{&#39;2})=\\frac{n-1}{n}\\sigma^2\\] \\(\\square\\) Remarque. Le biais de l’estimateur \\(S_n^{&#39;2}\\) devient cependant très faible pour \\(n\\) suffisamment grand. Il s’agit d’un estimateur asymptotiquement sans biais de la variance \\(\\sigma^2\\) : \\(\\mathbb{E}(S_n^{&#39;2})\\longrightarrow \\sigma^2\\). Exemple 4 : variance empirique corrigée. En modifiant l’estimateur de la variance empirique par un petit facteur correctif, on obtient un estimateur sans biais de la variance. Il suffit de poser \\[S_n^2=\\frac{1}{n-1}\\sum\\limits_{i=1}^n(X_i-\\overline{X_n})^2\\] Cet estimateur s’appelle la variance empirique corrigée. Théorème : La variance empirique corrigée \\(S_n^2=\\frac{1}{n-1}\\sum\\limits_{i=1}^n (X_i-\\overline{X_n})^2\\) est un estimateur sans biais de la variance \\(\\sigma^2=\\mathbb{V}(X)\\) : \\[\\mathbb{E}(S_n^2)=\\sigma^2\\] 7.1.4 Méthodes de construction des estimateurs On présente ici deux méthodes classiques de construction des estimateurs ; la méthode des moments et la méthode du maximum de vraisemblance. 7.1.4.1 La méthode des moments La méthode des moments Soit \\(X\\) une variable aléatoire réelle de loi \\(\\mathcal{L}_{\\theta}\\), où \\(\\theta\\) est un paramètre inconnu. On considère une fonction \\(f\\) de \\(I\\subset\\mathbb{R}\\) dans \\(\\mathbb{R}\\) telle que \\(f(X)\\) admette une espérance. Comme la loi de \\(X\\) dépend de \\(\\theta\\), il en est de même de \\(\\mathbb{E}(f(X))\\). La méthode des moments suppose qu’on sait expliciter une telle dépendance, i.e. qu’on connaisse une fonction \\(g\\) telle que \\[\\mathbb{E}(f(X))=g(\\theta)\\] La contrepartie empirique du membre de gauche de cette égalité est \\(\\frac{1}{n}\\sum\\limits_{i=1}^n f(X_i)\\), et la méthode des moments consiste alors à résoudre l’équation en \\(\\widehat{\\theta}\\) : \\[g(\\widehat{\\theta})=\\frac{1}{n}\\sum\\limits_{i=1}^n f(X_i)\\] Exemple 5 : estimation du paramètre d’une loi exponentielle. Soit \\(X\\sim\\mathcal{E}(\\lambda)\\), où \\(\\lambda&gt;0\\) est un paramètre inconnu que l’on veut estimer. La variable aléatoire \\(X\\) admet une espérance, et celle-ci est donnée par \\(\\mathcal{E}(X)=\\frac{1}{\\lambda}\\). La méthode des moments consiste alors à résoudre l’équation \\[\\frac{1}{\\widehat{\\lambda_n}}=\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\] Cette équation est très simple, elle admet pour solution \\[\\widehat{\\lambda_n}=\\frac{1}{\\overline{X_n}}\\] C’est l’estimateur que l’on obtient par la méthode des moments. Remarque. En reprenant les notations explicitées ci-dessus, on peut identifier les fonctions \\(f\\) et \\(g\\) : \\[f(x)=x\\] \\[g(x)=\\frac{1}{x}\\] et ici évidemment \\(\\theta=\\lambda\\). En général, la méthode des moments s’utilise de façon complètement intuitive sans qu’on ait même à expliciter forcément les fonctions \\(f\\) et \\(g\\). 7.1.4.2 La méthode du maximum de vraisemblance Une autre méthode de construction d’estimateurs est celle du maximum de vraisemblance. L’idée générale de cette méthode est la suivante. On suppose qu’on dispose de réalisations \\(x_1,\\dots x_n\\) d’une même variable aléatoire, dont la loi appartient à une famille paramétrique \\(\\left\\{\\mathcal{L}_{\\theta}\\,;\\,\\theta\\in\\Theta\\right\\}\\) et on cherche à estimer \\(\\theta\\). Si par exemple on dispose d’une série de cinq obersations \\((0.12, -0.65, 1.35, 1.04, -1.19, 0.08)\\) et qu’on veut inférer sur \\(\\theta\\) à partir de ces observations, on est enclin à penser que la valeur \\(\\theta=0\\) est plus plausible que la valeur \\(\\theta=-10\\). La vraisemblance est une formalisation de l’idée intuitive de plausibilité d’un paramètre à partir d’une observation ou d’un ensemble d’observations. A nouveau, \\(X\\) désigne une variable aléatoire de loi dépendant d’un paramètre inconnu \\(\\theta\\), et \\(x\\) une réalisation de \\(X\\). La vraisemblance \\(L(x,.)\\) est une fonction de \\(\\theta\\) définie par \\[L(x;\\theta)=\\left\\{ \\begin{array}{lll} \\mathbb{P}_{\\theta}(X=x) &amp;\\text{; si } X \\text{ est discrète} \\\\ f(x;\\theta) &amp;\\text{; si } X \\text{ est une continue de densité } f(.;\\theta) \\\\ \\end{array} \\right.\\] Remarque : D’autres notations existent dans la littérature, comme \\(L(x|\\theta), \\mathbb{P}(X=x|\\theta), f(x|\\theta)\\). Ces notations viennent de la statistique bayésienne (hors programme du concours) qui envisage \\(\\theta\\) comme une variable aléatoire de distribution inconnue. Dans ce cas, la vraisemblance s’interprète comme une probabilité ou une densité de probabilité. La définition précédente s’étend au cas d’un échantillon \\((X_1,\\dots X_n)\\) de VA de même loi que \\(X\\). Dans ce cas, on note souvent \\(L_n(x;\\theta)\\) la vraisemblance, pour faire apparaître la dépendance en \\(n\\). Un cas particulier important est celui où ces VA sont i.i.d. Dans ce cas, la vraisemblance est définie par \\[L_n(x;\\theta)=L_n(x_1,\\dots,x_n ; \\theta)=\\left\\{ \\begin{array}{lll} \\prod\\limits_{i=1}^n\\mathbb{P}_{\\theta}(X_i=x_i) &amp;\\text{; si } X \\text{ est discrète} \\\\ \\prod\\limits_{i=1}^n f(x_i,\\theta) &amp;\\text{; si } X \\text{ est une continue de densité } f(.;\\theta) \\\\ \\end{array} \\right.\\] La méthode du maximum de vraisemblance consiste juste à dire que si toute l’information dont on dispose sur la variable aléatoire \\(X\\) est l’observation de l’échantillon \\((x_1, \\dots, x_n)\\), alors la meilleure estimation que l’on puisse faire de \\(\\theta\\) à partir de cette information est celle qui maximise la fonction de vraisemblance. Autrement dit, on cherche la valeur de \\(\\theta\\) qui rend l’observation \\((x_1,\\dots, x_n)\\) la plus plausible. Formellement : Méthode du maximum de vraisemblance Etant donné une collection de \\(n\\) réalisations \\(x=(x_1,\\dots, x_n)\\) des VA \\((X_1,\\dots X_n)\\) de même loi \\(\\mathcal{L}_{\\theta}\\) de paramètre inconnu \\(\\theta\\), on appelle estimation du maximum de vraisemblance toute estimation \\(\\widehat{\\theta}_n=\\widehat{\\theta}_n(x_1,\\dots,x_n)\\) vérifiant \\[\\widehat{\\theta}_n\\in \\arg\\max\\limits_{\\theta\\in\\Theta}L_n(x;\\theta)\\] Cas particulier : si la fonction \\(\\theta\\mapsto L_n(x;\\theta)\\) est deux fois dérivable sur \\(\\Theta\\), alors on peut chercher à résoudre (en \\(\\theta\\)) le système \\[\\left\\{ \\begin{array}{lll} \\frac{\\partial}{\\partial\\theta}L_n(x;\\theta)=0 \\\\ \\frac{\\partial^2}{\\partial\\theta^2}L_n(x;\\theta)&lt;0 \\\\ \\end{array} \\right.\\] Les solutions de ce système fournissent des estimations par maximum de vraisemblance. Log-vraisemblance. Il est souvent plus commode de considérer la log-vraisemblance \\(l_n(x;\\theta)=\\ln L_n(x;\\theta)=\\sum\\limits_{i=1}^n \\ln L_n(x_i;\\theta)\\). La fonction \\(\\ln\\) étant croissante sur \\(\\mathbb{R}_{+}^*\\), maximiser la vraisemblance équivaut à maximiser la log-vraisemblance. Maximisation de la log-vraisemblance En supposant que \\(L_n(x;\\theta)&gt;0\\) pour tout \\(\\theta\\in\\Theta\\), on note \\(l_n(x;\\theta)=\\ln L_n(x;\\theta)\\) la log-vraisemblance. Sous les mêmes hypothèses que ci-dessus, on cherche \\[\\widehat{\\theta}_n\\in\\arg\\max\\limits_{\\theta\\in\\Theta}\\left(l_n(x;\\theta)\\right)\\] Cas particulier : si la fonction \\(\\theta\\mapsto L_n(x;\\theta)\\) est deux fois dérivable sur \\(\\Theta\\), alors la fonction \\(\\theta\\mapsto l_n(x;\\theta)\\) l’est aussi et on peut chercher à résoudre (en \\(\\theta\\)) le système \\[\\left\\{ \\begin{array}{lll} \\frac{\\partial}{\\partial\\theta}l_n(x;\\theta)=0 \\\\ \\frac{\\partial^2}{\\partial\\theta^2}l_n(x;\\theta)&lt;0 \\\\ \\end{array} \\right.\\] Les solutions de ce système fournissent des estimations par maximum de vraisemblance. Exemple 6 : loi normale. \\(\\mathcal{N}(\\mu, 1)\\). On veut estimer le paramètre inconnu \\(\\mu\\) par maximum de vraisemblance. La vraisemblance est donnée par \\[\\begin{align} L_n(x;\\mu)&amp;=\\prod\\limits_{i=1}^n\\left(\\frac{e^{-\\frac{(x_i-\\mu)^2}{2}}}{\\sqrt{2\\pi}}\\right)\\\\ &amp;=\\frac{1}{(2\\pi)^{\\frac{n}{2}}}e^{-\\sum\\limits_{i=1}^n (x_i-\\mu)^2} \\end{align}\\] La log-vraisemblance est plus facile à manipuler : \\[\\begin{align} l_n(x;\\mu)&amp;=\\ln L_n(x;\\mu) \\\\ &amp;= -\\frac{n}{2}\\ln(2\\pi)-\\sum\\limits_{i=1}^n(x_i-\\mu)^2 \\end{align}\\] La fonction \\(\\mu\\mapsto l_n(x;\\mu)\\) est deux fois dérivable sur \\(\\mathbb{R}\\) et \\(\\frac{\\partial}{\\partial\\mu}l_n(x;\\mu)=2\\sum_{i=1}^n(\\mu-x_i)\\). Une seule valeur de \\(\\mu\\) l’annule : \\[\\widehat{\\mu}_n=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i=\\overline{x}_n\\] Par ailleurs \\(\\frac{\\partial^2}{\\partial\\mu^2}l_n(x;\\mu)=2n&gt;0\\), et donc \\(\\widehat{\\mu}_n\\in\\arg\\max\\limits_{\\mu\\in\\mathbb{R}}l(x;\\mu)\\). Finalement, un estimateur par maximum de vraisemblance est donné par \\[\\widehat{\\mu}_n=\\overline{X}_n=\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\] Remarque. Comme souvent en statistique, on commet un léger abus de notation en désignant par la même lettre l’estimateur \\(\\widehat{\\mu}_n=\\frac{X_1+\\dots+X_n}{n}=\\widehat{\\mu}_n(X_1,\\dots,X_n)\\) (qui est une statistique, i.e. une fonction de \\((X_1,\\dots,X_n\\)) et l’estimation \\(\\widehat{\\mu}_n=\\frac{x_1+\\dots+x_n}{n}=\\widehat{\\mu}_n(x_1,\\dots, X_n)\\) qui en est une réalisation. Conditionnellement à \\((X_1,\\dots,X_n)\\) (i.e. si l’on suppose que l’on observe \\((X_1,\\dots, X_n)\\)) ces deux objets sont bien les mêmes. Exemple 7 : loi exponentielle. Soit \\((X_1,\\dots,X_n)\\) un échantillon i.i.d. tiré selon une loi exponentielle \\(\\mathcal{E}(\\lambda)\\) de paramètre \\(\\lambda&gt;0\\) inconnu. La vraisemblance est donnée par \\[\\begin{align} L_n(x;\\lambda)&amp;=\\prod\\limits_{i=1}^n (\\lambda e^{-\\lambda x_i}\\mathbb{1}_{x_i\\geq 0}) \\\\ \\end{align}\\] Si l’un des \\(x_i\\) est négatif elle vaut \\(0\\). Sinon on calcule la log-vraisemblance \\[l_n(x;\\lambda)=n\\ln(\\lambda)-\\lambda\\sum_{i=1}^n x_i\\] La fonction \\(\\lambda\\in\\mathbb{R}_{+}^*\\mapsto l_n(x;\\lambda)\\) est deux fois dérivable et \\(\\frac{\\partial}{\\partial\\lambda}l_n(x;\\lambda)=\\frac{n}{\\lambda}-\\sum\\limits_{i=1}^n x_i\\), qui s’annule en \\(\\lambda=\\frac{n}{\\sum\\limits_{i=1}^n x_i}=\\frac{1}{\\overline{x}_n}\\). De plus, \\(\\frac{\\partial^2}{\\partial\\lambda^2}l_n(x;\\lambda)=-\\frac{n}{\\lambda^2}&lt;0\\) et donc à \\(x\\) fixé, \\(l_n(x;\\lambda)\\) atteint son maximum en \\(\\frac{1}{\\overline{x_n}}\\). L’estimateur du maximum de vraisemblance est donc \\(\\widehat{\\lambda}_n=\\frac{1}{\\overline{X}_n}\\). On remarque qu’on retrouve ici le même estimateur que celui obtenu par la méthode des moments. 7.1.5 Compléments (hors-programme) On présente dans cette partie les notions suivantes : information de Fisher borne de Cramer-Rao statistique exhaustive famille exponentielle amélioration d’un estimateur Ces notions ne sont pas au programme du concours, mais elles sont clairement dans sa périphérie immédiate. On les retrouve d’ailleurs dans le sujet d’interne 2022, mais leur connaissance n’est pas requise pour traiter le sujet. 7.1.5.1 Information de Fisher Soient \\(X\\) une variable aléatoire (discrète ou continue) à valeurs dans \\(\\mathcal{X}\\) de loi \\(L(x;\\theta)&gt;0\\), avec \\(\\theta\\in\\mathbb{R}\\). On fait les hypothèses suivantes : existence de \\(\\frac{\\partial L}{\\partial\\theta}(x;\\theta)\\) et de \\(\\frac{\\partial^2}{\\partial\\theta^2}L(x;\\theta)\\) on peut échanger tous les opérateurs de dérivation (à l’ordre \\(1\\) et \\(2\\)) et d’intégration On considère un échantillon i.i.d. \\((X_1,\\dots,X_n)\\) tel que chacun des \\(X_i\\) suit la même loi que \\(X\\). Pour \\(x=(x_1,\\dots,x_n)\\) une réalisation de l’échantillon aléatoire \\((X_1,\\dots, X_n)\\), On note \\(L_n(x;\\theta)\\) la vraisemblance de \\((x_1,\\dots, x_n)\\) : \\[L_n(x;\\theta)=\\prod\\limits_{i=1}^n L(x_i;\\theta)\\] On appelle alors score la quantité (aléatoire) \\(\\frac{\\partial}{\\partial\\theta}\\,\\ln L_n(X;\\theta)=\\frac{\\partial}{\\partial\\theta}\\, l_n(X;\\theta)\\), i.e. la dérivée de la log-vraisemblance par rapport à \\(\\theta\\). Théorème : On a \\[\\mathbb{E}_{\\theta}\\left(\\frac{\\partial }{\\partial\\theta}\\, l_n(X;\\theta)\\right)=0\\] i.e. le score est d’espérance nulle. Démonstration. On démontre cette égalité dans le cas à densité : \\[\\begin{align} \\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta}\\, l_n(X ; \\theta)\\right) &amp;= \\int_{\\mathbb{R}^n} \\frac{\\partial}{\\partial\\theta} \\,l_n(x;\\theta)\\,L_n(x;\\theta)\\,dx \\\\ &amp;=\\int_{\\mathbb{R}^n}\\frac{\\frac{\\partial L_n}{\\partial\\theta}(x;\\theta)}{L_n(x;\\theta)}\\,L_n(x;\\theta)\\,dx \\\\ &amp;= \\int_{\\mathbb{R}^n} \\frac{\\partial L_n}{\\partial\\theta}(x;\\theta)\\,dx \\\\ &amp;=\\frac{\\partial}{\\partial\\theta}\\int_{\\mathbb{R}^n} L_n(x;\\theta) \\, dx \\text{ (on permute intégrale et dérivée)} \\\\ &amp;= 0 \\text{ (car } \\int_{\\mathbb{R}^n} L_n(x;\\theta)\\,dx=1\\text{)} \\\\ \\end{align}\\] \\(\\square\\) L’information de Fisher est définie à partir du score de la façon suivante : Information de Fisher L’information de Fisher est la quantité définie par \\[I_n(\\theta)\\equiv\\mathbb{E}_{\\theta}\\left(\\left(\\frac{\\partial }{\\partial\\theta}\\, l_n(X;\\theta)\\right)^2\\right)=\\mathbb{V}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta}l_n(X;\\theta)\\right)\\] Lorsque le domaine de \\(X\\) ne dépend pas de \\(\\theta\\), l’information de Fisher est aussi égale à \\[I_n(\\theta)=-\\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2} l_n(X;\\theta)\\right)\\] Cette dernière expression est généralement plus facile à calculer. Interprétation de l’information de Fisher. On utilise généralement l’information de Fisher lorsqu’on veut inférer sur un paramètre inconnu \\(\\theta\\) par maximum de vraisemblance. Par construction, l’estimation \\(\\widehat{\\theta}\\) que l’on obtient par cette méthode est celle qui maximise la log-vraisemblance \\(\\ln L_n(X;\\theta)\\), pour une observation de \\(X\\) donnée. L’expression \\(I_n(\\theta)=-\\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2}\\ln L_n(X;\\theta)\\right)\\) montre que l’information de Fisher correspond (au signe près) à la courbure de la log-vraisemblance. Plus celle-ci est importante, plus la courbe présente un “pic” autour du maximum, et donc plus la valeur estimée de ce maximum est précise. Au contraire, si la courbure est faible, la courbe est aplatie autour du maximum, et donc l’estimation de \\(\\theta\\) sera moins précise. Dit autrement, l’information de Fisher quantifie le niveau d’information que nous apporte l’observation relativement au paramètre \\(\\theta\\). Démonstration. Etant donné que \\(\\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right)=0\\) on a \\(\\mathbb{V}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right)=\\mathbb{E}_\\theta\\left(\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta\\right)^2\\right)\\), ce qui démontre la première égalité. Pour démontrer la deuxième égalité, on dérive par rapport à \\(\\theta\\) l’égalité \\(\\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right)=0\\). Pour cela, on utilise la permutation \\(\\frac{\\partial}{\\partial\\theta}\\int=\\int\\frac{\\partial}{\\partial\\theta}\\) qui est possible car le domaine de \\(X\\) ne dépend pas de \\(\\theta\\). On obtient donc : \\[\\begin{align} 0 &amp;= \\frac{\\partial}{\\partial\\theta}\\mathbb{E}_{\\theta}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right) \\\\ &amp;= \\frac{\\partial}{\\partial\\theta}\\int_{\\mathbb{R}^n}\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right) L_n(x;\\theta)\\,dx \\\\ &amp;=\\int_{\\mathbb{R}^n}\\frac{\\partial}{\\partial\\theta}\\left(\\left(\\frac{\\partial}{\\partial\\theta} \\,l_n(X;\\theta)\\right) L_n(x;\\theta)\\right)\\,dx \\\\ &amp;=\\int_{\\mathbb{R}^n}\\left(\\frac{\\partial^2}{\\partial\\theta^2}l_n(x;\\theta)\\right)L_n(x;\\theta)\\,dx+\\int_{\\mathbb{R}^n}\\frac{\\partial}{\\partial\\theta}l_n(x;\\theta)\\frac{\\partial}{\\partial\\theta}L_n(x;\\theta)\\,dx \\\\ &amp;= \\int_{\\mathbb{R}^n}\\left(\\frac{\\partial^2}{\\partial\\theta^2}l_n(x;\\theta)\\right)L_n(x;\\theta)\\,dx+\\int_{\\mathbb{R}^n}\\left(\\frac{\\partial}{\\partial\\theta}l_n(x;\\theta)\\right)^2 L_n(x;\\theta)\\,dx \\\\ &amp;= \\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2} l_n(X;\\theta)\\right)+\\mathbb{E}_{\\theta}\\left(\\left(\\frac{\\partial}{\\partial\\theta} l_n(X;\\theta)\\right)^2\\right) \\end{align}\\] d’où \\[\\mathbb{E}_{\\theta}\\left(\\frac{\\partial^2}{\\partial\\theta^2} l_n(X;\\theta)\\right)=-\\mathbb{E}_{\\theta}\\left(\\left(\\frac{\\partial}{\\partial\\theta} l_n(X;\\theta)\\right)^2\\right)\\] ce qui achève la démonstration. \\(\\square\\) L’information de Fisher vérifie une propriété d’additivité : Théorème (additivité de l’information de Fisher) : Si l’ensemble \\(\\left\\{x\\in\\mathbb{R}^n, f(x;\\theta)&gt;0\\right\\}\\) ne dépend pas de \\(\\theta\\), alors l’information de Fisher est additive, i.e. \\[I_n(\\theta)=n\\,I_1(\\theta)\\] Si le domaine de \\(X\\) ne dépend pas de \\(\\theta\\), l’information de Fisher apportée par un échantillon \\((X_1,\\dots,X_n)\\) est donc égale à \\(n\\) fois l’information de Fisher apportée par chacune des observations \\(X_i\\). Cela signifie que chaque observation apporte la même information de Fisher. 7.1.5.2 Borne de Fréchet-Darmois-Cramer-Rao Sous certaines hypothèses, on peut montrer que la variance d’un estimateur sans biais ne peut être inférieure à une certaine borne, appelée borne de Fréchet-Darmois-Cramer-Rao, liée à l’information de Fisher : Théorème : On suppose que les hypothèses suivantes, appelées hypothèses de Cramer-Rao, sont vérifiées : (H1) : \\(\\Theta\\) est un ouvert sur lequel \\(f(x;\\theta)&gt;0\\) et \\(\\theta\\mapsto f(x;\\theta)\\) est dérivable pour tout \\(x\\) (H2) : on peut permuter \\(\\int\\) et \\(\\frac{\\partial}{\\partial\\theta}\\) (H3) : \\(\\forall\\theta\\in\\Theta, \\, I_n(\\theta)&gt;0\\) (H4) : \\(g:\\Theta\\longrightarrow\\mathbb{R}\\) est une fonction dérivable Alors, pour tout estimateur sans biais \\(T_n=T_n(X_1,\\dots, X_n)\\) de \\(g(\\theta)\\) on a l’inégalité \\[\\mathbb{V}_{\\theta}(T_n)\\geq\\frac{\\left(g&#39;(\\theta)\\right)^2}{I_n(\\theta)}\\] Le nombre \\(\\frac{\\left(g&#39;(\\theta)\\right)^2}{I_n(\\theta)}\\) s’appelle la borne de Fréchet-Darmois-Cramer-Rao (FDCR). Dans le cas particulier où \\(T_n=\\widehat{\\theta}_n\\) est un estimateur sans biais de \\(\\theta\\) (cas où \\(g(\\theta)=\\theta\\)) on a \\(\\mathbb{V}_{\\theta}(\\widehat{\\theta}_n)\\geq\\frac{1}{I_n(\\theta)}\\). Ce théorème est admis. La borne FDCR n’est pas nécessairement atteinte. Quand elle l’est, l’estimateur qui l’atteint est dit efficace : Estimateurs efficaces Un estimateur \\(T_n\\) sans biais de \\(g(\\theta)\\) tel que \\(\\mathbb{V}_{\\theta}(T_n)=\\frac{\\left(g&#39;(\\theta)\\right)^2}{I_n(\\theta)}\\) est appelé un estimateur efficace. 7.1.5.3 Statistiques exhaustives Tout échantillon \\((X_1,\\dots, X_n)\\) tel que \\(X_i\\sim\\mathcal{L}_{\\theta}\\) apporte de l’information sur le paramètre inconnu \\(\\theta\\), et donc sur la loi inconnue \\(\\mathcal{L}_{\\theta}\\). Plutôt que de faire de l’inférence à partir de l’échantillon \\((X_1,\\dots, X_n)\\) on préfère en général utiliser une statistique \\(T_n=T(X_1,\\dots,X_n)\\), qui est une sorte de résumé de l’échantillon tout entier. La contrepartie est qu’en général, le passage de \\((X_1,\\dots,X_n)\\) à son résumé \\(T_n\\) génère une perte d’information sur \\(\\theta\\). Une statistique exhaustive est une statistique qui n’engendre pas de telle perte, autrement dit elle contient toute l’information sur \\(\\theta\\) contenue dans l’échantillon \\((X_1,\\dots, X_n)\\). On formalise cette idée de la façon suivante : Statistiques exhaustives Une statistique \\(T_n\\) est dite exhaustive si la loi conditionnelle \\(\\mathcal{L}(X|T_n=t)\\) est indépendante de \\(\\theta\\). Conditionnellement à l’observation \\(T=t\\), la loi de \\(X\\) ne dépend plus de \\(\\theta\\) : \\[\\mathbb{P}(X=x|T=t,\\theta)=\\mathbb{P}(X=x|T=t) \\text{ (pour une loi discrète)}\\] \\[f(x|T=t,\\theta)=f(x|T=t) \\text{ (pour une loi continue)}\\] Dit autrement, une fois que l’on sait que \\(T_n=t\\), ajouter la connaissance de \\(X\\) n’apporte plus aucune information supplémentaire sur \\(\\theta\\). Cette définition n’est pas très commode à manipuler, et en pratique pour démontrer qu’une statistique est (ou n’est pas) exhaustive on utilise plutôt le théorème de factorisation de Neyman-Fisher : Théorème (factorisation de Neyman-Fisher) : Une statistique \\(T_n\\) est exhaustive si, et seulement s’il existe deux fonctions mesurables positives \\(g\\) et \\(h\\) telles qu’on ait la factorisation suivante : \\[L_n(x;\\theta)=g(T_n(x);\\theta).h(x)\\] Remarques : i. La notion de mesurabilité n’est pas au programme du concours. Il s’agit d’une classe très générale de fonctions, qui englobe en particulier les fonctions continues, continues par morceaux etc. Il est même assez compliqué de construire une fonction non mesurable. En pratique : pour démontrer qu’une statistique est exhaustive, il suffit de montrer qu’une telle décomposition existe avec \\(g\\) et \\(h\\) continues (car continue implique mesurable) ; pour démontrer qu’une telle statistique n’est pas exhaustive, il suffit de démontrer qu’une telle décomposition avec \\(g\\) et \\(h\\) quelconques est impossible (elle sera en particulier impossible avec \\(g\\) et \\(h\\) mesurables). ii. Il n’y a pas unicité du couple \\((g,h)\\). Par exemple, si \\((g,h)\\) permet une factorisation, alors pour tout \\(\\lambda\\) strictement positif \\(\\left(\\lambda g, \\frac{h}{\\lambda}\\right)\\) aussi. 7.1.5.4 Famille exponentielle Les densités suivantes assurent l’existence d’une statistique exhaustive : Théorème de Darmois : Soit \\(\\theta\\in\\Theta\\subset\\mathbb{R}\\). Soit \\(f(x;\\theta)\\) une densité telle que l’ensemble \\(\\{x\\in\\mathbb{R}^n, \\, f(x;\\theta)&gt;0\\}\\) ne dépend pas de \\(\\theta\\). Alors, l’échantillon \\((X_1,\\dots,X_n)\\) admet une statistique exhaustive si et seulement si \\(f(x;\\theta)\\) est de la forme \\[f(x;\\theta)=\\exp\\left(a(x)\\alpha(\\theta)+b(x)+\\beta(\\theta)\\right)\\] Par ailleurs, si l’application \\(a\\) est de classe \\(\\mathcal{C}^1\\), alors \\(T_n\\equiv\\sum\\limits_{i=1}^n a(X_i)\\) est une statistique exhaustive. La famille des densités \\(f(x;\\theta)\\) vérifiant ces propriétés s’appelle la famille exponentielle. Remarque. Ici, on convient de parler de densité aussi bien pour une variable discrète que pour une variable continue. Pour une variable discrète, la densité est par définition \\(f(x;\\theta)\\equiv\\mathbb{P}_{\\theta}(X=x)\\). Exemple (loi de Poisson). La densité d’une loi de Poisson de paramètre \\(\\lambda\\) est \\(f(x;\\lambda)=e^{-\\lambda}\\frac{\\lambda^x}{x!}\\mathbb{1}_{x\\in\\mathbb{N}}\\). L’ensemble \\(\\left\\{x\\in\\mathbb{R},\\,f(x;\\theta)&gt;0\\right\\}\\) est \\(\\mathbb{N}\\), qui ne dépend pas de \\(\\lambda\\). Par ailleurs : \\[f(x;\\lambda)=\\exp\\left(-\\lambda+x\\,\\ln(\\lambda)-\\sum\\limits_{i=1}^x \\ln i\\right)\\] On reconnait bien la forme générale d’une densité de la famille exponentielle, avec \\(a(x)=x\\), \\(\\alpha(\\lambda)=\\ln(\\lambda)\\), \\(b(x)=\\sum\\limits_{i=1}^x \\ln i\\), \\(\\beta(\\lambda)=-\\lambda\\). L’application \\(a\\) est par ailleurs de classe \\(\\mathcal{C}^1\\). On en déduit avec le théorème de Darmois que la statistique \\(T_n=\\sum\\limits_{i=1}^n X_i\\) est une statistique exhaustive pour \\(\\theta\\). La famille exponentielle permet de construire des estimateurs efficaces. Théorème : On suppose les hypothèses de Cramer-Rao vérifiées. On suppose également que \\(\\theta\\mapsto \\frac{\\partial}{\\partial\\theta}f(x;\\theta)\\) est continue en \\(\\theta\\). Soit \\(T_n\\) un estimateur sans biais de \\(g(\\theta)\\). Alors, \\(T_n\\) est un estimateur efficace si et seulement si la densité \\(f(x;\\theta)\\) appartient à la famille exponentielle. 7.1.5.5 Rao-Blackwellisation d’un estimateur Le théorème de Rao-Blackwell montre comment améliorer un estimateur. Théorème de Rao-Blackwell : Soient \\(T_n\\) une statistique exhaustive et \\(S\\) un estimateur sans biais de \\(g(\\theta)\\). Alors, l’estimateur \\(\\mathbb{E}_{\\theta}(S|T_n)\\) est sans biais et \\(\\mathbb{V}_{\\theta}(\\mathbb{E}_{\\theta}(S|T_n))\\leq\\mathbb{V}_{\\theta}(S)\\). L’estimateur \\(\\mathbb{E}_{\\theta}(S|T_n)\\) est dit préférable à l’estimateur \\(S\\). 7.1.6 Estimation des coefficients d’une régression linéaire 7.1.6.1 Présentation du modèle \\(X\\) et \\(Y\\) sont deux variables aléatoires pour lesquelles on dispose d’observations \\(x_1,\\dots, x_n\\) et \\(y_1,\\dots y_n\\). On considère le modèle \\[Y_i=aX_i+b+u_i\\] où \\((a,b)\\) est un couple de réels inconnus et \\(u_i\\) est un terme d’erreur (inconnu lui aussi). Le but est d’estimer des coefficients \\((a,b)\\) à partir de l’échantillons d’observations \\((x_i, y_i)\\) et de donner des propriétés des estimateurs obtenus sous certaines hypothèses. Hypothèses du modèle. On fait les hypothèses suivantes : (H1) : Les couples \\((X_i, Y_i)\\) sont i.i.d. (H2) : Les termes d’erreur \\(u_i\\) sont indépendants des \\(X_i\\) (H3) : \\(\\mathbb{E}(u_i|X_i)=0\\) (hypothèse d’exogénéité) (H4) : \\(\\mathbb{V}(u_i|X_i)=\\sigma_u^2\\) ne dépend pas de \\(X_i\\) (hypothèse d’homoscédasticité) (H5) : \\(u_i|X_i\\sim\\mathcal{N}(0, \\sigma_u^2)\\) (hypothèse de normalité des termes d’erreur) On présente deux approches différentes pour estimer \\(a\\) et \\(b\\) : par la méthode des moindres carrés et par maximum de vraisemblance. Bien que différentes, ces méthodes vont fournir les mêmes estimateurs. Avant cela, on rappelle quelques résultats classiques de statistique descriptive. 7.1.6.2 Rappels utiles Avant de présenter cette méthode, on rappelle des égalités qui àa la fois très utiles et très classiques. Il faut les connaître pour le concours et savoir les redémontrer. Moyenne, covariance, variance Pour \\(x=(x_1,\\dots, x_n)\\in\\mathbb{R}^n\\) on note \\(\\overline{x}_n=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i\\) la moyenne de \\(x\\) \\(\\sigma_x^2=\\frac{1}{n}\\sum\\limits_{i=1}^n(x_i-\\overline{x}_n)^2\\) la variance de \\(x\\) si de plus \\(y=(y_1,\\dots, y_n)\\), \\(\\sigma_{xy}=\\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n)\\) est la covariance de \\(x\\) et \\(y\\). On a alors les égalités suivantes : 1. \\(\\sigma_{xx}=\\sigma_x^2\\) 2. \\(\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)=0\\) 3. Différentes formules de la covariance : \\[\\begin{align} \\sigma_{xy} &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n) \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n(x_i-\\overline{x}_n)y_i \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_i(y_i-\\overline{y}_n) \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_iy_i-\\overline{x}_n\\overline{y}_n \\end{align}\\] 4. Différentes formules de la variance : \\[\\begin{align} \\sigma_x^2 &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)^2 \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_i^2-(\\overline{x}_n)^2 \\end{align}\\] Démonstration. 1. Evidente 2. \\[\\begin{align} \\sum\\limits_{i=1}^n (x_i-\\overline{x}_n) &amp;= \\sum\\limits_{i=1}^n x_i -n\\overline{x}_n \\\\ &amp;= n\\overline{x}_n-n\\overline{x}_n \\\\ &amp; =0 \\end{align}\\] 3. \\[\\begin{align} \\sigma_{xy} &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n) \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)y_i-\\frac{\\overline{y}_n}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n) \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)y_i \\end{align}\\] d’après l’égalité 2. Par symétrie des rôles joués par \\(x\\) et \\(y\\) on a donc aussi \\(\\sigma_{xy}=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i(y_i-\\overline{y}_n)\\). On montre la dernière égalité : \\[\\begin{align} \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)(y_i-\\overline{y}_n) &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)y_i \\\\ &amp;= \\frac{1}{n}\\sum\\limits_{i=1}^n x_iy_i-\\overline{x}_n\\frac{1}{n}\\sum\\limits_{i=1}^n y_i \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n x_iy_i-\\overline{x}_n\\overline{y}_n \\end{align}\\] 4. On applique la dernière égalité de 4 dans le cas particulier où \\(x=y\\). On obtient alors \\[\\frac{1}{n}\\sum\\limits_{i=1}^n (x_i-\\overline{x}_n)^2=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i^2-\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n x_i\\right)^2\\] \\(\\square\\) 7.1.6.3 Estimation de \\(a\\) et \\(b\\) par la méthode des moindres carrés On montre maintenant les formules des estimateurs de \\(a\\) et \\(b\\) par application de la méthode des moindres carrés : Estimation de \\(a\\) et \\(b\\) par la méthode des moindres carrés La méthode des moindres carrés consiste à minimiser l’erreur quadratique globale \\[E(\\alpha,\\beta)\\equiv\\sum\\limits_{i=1}^n (Y_i-\\alpha X_i-\\beta)^2\\] qui représente l’erreur globale faite en approchant \\(Y_i\\) par \\(\\alpha X_i+\\beta\\). Cette méthode fournit les estimateurs suivants de \\(a\\) et \\(b\\) : \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\widehat{a} &amp;= \\frac{\\overline{\\sigma_{XY}}}{\\overline{\\sigma^2_X}} \\\\ \\widehat{b} &amp;= \\overline{Y}_n-\\widehat{a}\\overline{X}_n \\end{array} \\right. \\end{align}\\] où on note \\(\\overline{\\sigma_{XY}}=\\frac{1}{n}\\sum\\limits_{i=1}^n(X_i-\\overline{X}_n)(Y_i-\\overline{Y}_n)\\) et \\(\\overline{\\sigma^2_X}=\\overline{\\sigma_{XX}}=\\frac{1}{n}\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\). Démonstration. La fonction \\((\\alpha, \\beta)\\mapsto E(\\alpha, \\beta)\\) est deux fois dérivable par rapport à chacune de ses variables. Conditions de premier ordre (CPO) : Les conditions du premier ordre s’écrivent \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\frac{\\partial}{\\partial\\alpha} E(\\alpha, \\beta) &amp;=0 \\\\ \\frac{\\partial}{\\partial\\beta} E(\\alpha, \\beta) &amp;=0 \\\\ \\end{array} \\right. \\end{align}\\] i.e. \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\sum\\limits_{i=1}^n X_i Y_i-\\alpha\\sum\\limits_{i=1}^n X_i^2-\\beta\\sum\\limits_{i=1}^n X_i&amp;=0 \\\\ \\sum\\limits_{i=1}^n Y_i-\\alpha\\sum\\limits_{i=1}^n X_i-n\\beta &amp;= 0 \\\\ \\end{array} \\right. \\end{align}\\] Il s’agit d’un système de deux équations à deux inconnues \\((\\alpha, \\beta)\\). Sa résolution donne \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\alpha &amp;= \\frac{\\frac{1}{n}\\sum\\limits_{i=1}^n X_iY_i-\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\right)\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n Y_i\\right)}{\\frac{1}{n}\\sum\\limits_{i=1}^n X_i^2-\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\right)^2} \\\\ \\beta &amp;= \\overline{Y}_n-\\alpha\\overline{X}_n \\end{array} \\right. \\end{align}\\] soit encore \\[\\begin{align} \\left\\{ \\begin{array}{ll} \\alpha &amp;= \\frac{\\overline{\\sigma_{XY}}}{\\overline{\\sigma^2_X}} \\\\ \\beta &amp;= \\overline{Y}_n-\\alpha\\overline{X}_n \\end{array} \\right. \\end{align}\\] Par ailleurs, pour tout couple \\((x, y)\\) de réels, la fonction \\((\\alpha, \\beta)\\mapsto (y-\\alpha x-\\beta)^2\\) est convexe. Le point critique trouvé ci-dessus est donc un minimum. On en déduit le résultat. \\(\\square\\) 7.1.6.4 Estimation de \\(a\\) et \\(b\\) par la méthode du maximum de vraisemblance La méthode par maximum de vraisemblance requiert une information supplémentaire : celle de la distribution de la variable de terme d’erreur \\(u\\). Or, une telle information est justement donnée ici par l’hypothèse (H5) de distribution normale du terme d’erreur. Estimation de \\(a\\) et \\(b\\) par la méthode du maximum de vraisemblance. Sous l’hypothèse \\((H5)\\) de distribution normale des termes d’erreur, la méthode par maximum de vraisemblance fournit les mêmes estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) que la méthode des moindres carrés. Démonstration. La vraisemblance est donnée par \\[L_n((\\alpha,\\beta);u)=\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi}\\sigma_u}e^{-\\frac{(Y_i-\\alpha X_i-\\beta)^2}{2\\sigma_u^2}}\\] On passe à la log-vraisemblance, qui est plus simple à dériver \\[l_n((\\alpha,\\beta);u)=-n\\ln(\\sqrt{2\\pi}\\sigma_u^2)-\\frac{(Y_i-\\alpha X_i-\\beta)^2}{2\\sigma_u^2}\\] On résout alors en \\((\\alpha, \\beta)\\) le système d’équations \\[\\begin{align} \\frac{\\partial l_n}{\\partial\\alpha}l((\\alpha,\\beta);u) &amp;= 0 \\\\ \\frac{\\partial l_n}{\\partial\\beta}l((\\alpha,\\beta);u) &amp;= 0 \\\\ \\end{align}\\] soit \\[\\begin{align} \\frac{X_i(Y_i-\\alpha X_i-\\beta)}{2\\sigma_u^2} &amp;= 0 \\\\ \\frac{Y_i-\\alpha X_i-\\beta}{2\\sigma_u^2} &amp;= 0 \\\\ \\end{align}\\] On vérifie facilement qu’on obtient le même couple de solution qu’avec la méthode des moindres carrés, et que ce couple constitue bien un maximum de la log-vraisemblance. \\(\\square\\) Remarque : Dans des approches plus générales que celle présentée ici, aucune hypothèse n’est faite sur la distribution des termes d’erreur. Dans ce cas, la méthode par maximum de vraisemblance n’est plus applicable. On peut cependant toujours utiliser la méthode des moindres carrés. 7.1.6.5 Absence de biais des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) Théorème : (absence de biais des estimateurs MCO) Les estimateurs \\[\\widehat{a}=\\frac{\\overline{\\sigma_{XY}}}{\\overline{\\sigma_X^2}}\\] et \\[\\widehat{b}=\\overline{Y}_n-\\widehat{a}\\overline{X}_n\\] sont des estimateurs sans biais de \\(a\\) et \\(b\\). Démonstration. On remarque d’abord qu’avec l’hypothèse d’exogénéité (H3) \\(\\mathbb{E}(u_i|X_i)=0\\) on a \\(\\mathbb{E}(Y_i|X_i)=aX_i+b\\) et donc \\(\\mathbb{E}(Y_i-\\overline{Y}_n|X_1,\\dots, X_n)=a(X_i-\\overline{X}_n)\\). D’où \\[\\begin{align} \\mathbb{E}(\\widehat{a}|X_1,\\dots, X_n) &amp;= \\mathbb{E}\\left(\\left.\\frac{\\frac{1}{n}\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)(Y_i-\\overline{Y}_n)}{\\overline{\\sigma_X^2}}\\right|X_1,\\dots, X_n\\right) \\\\ &amp;=\\frac{1}{\\overline{\\sigma_X^2}}\\frac{1}{n}\\sum\\limits_{i=1}^n(X_i-\\overline{X}_n)\\mathbb{E}(\\left. Y_i-\\overline{Y}_n\\right|X_1\\,\\dots,X_n) \\\\ &amp;= a\\frac{1}{\\overline{\\sigma_X^2}}\\frac{1}{n}\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2 \\\\ &amp; =a\\frac{\\overline{\\sigma_X^2}}{\\overline{\\sigma_X^2}} \\\\ &amp; =a \\end{align}\\] Par ailleurs \\[\\begin{align} \\mathbb{E}(\\widehat{b}|X_1,\\dots,X_n)&amp;=\\mathbb{E}(\\overline{Y}_n-\\widehat{a}\\overline{X}_n|X_1,\\dots,X_n) \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n \\mathbb{E}(Y_i|X_1,\\dots,X_n)-\\overline{X}_n\\mathbb{E}(\\widehat{a}|X_1,\\dots,X_n) \\\\ &amp;=\\frac{1}{n}\\sum\\limits_{i=1}^n (aX_i+b)-a\\overline{X}_n \\\\ &amp;= a\\overline{X}_n+b-a\\overline{X}_n \\\\ &amp;= b \\end{align}\\] \\(\\square\\) 7.1.6.6 Variance des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) Théorème (variance des estimateurs MCO) Les estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) ont pour variances \\[\\begin{align} \\mathbb{V}(\\widehat{a}|X_1,\\dots, X_n) &amp;= \\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2} \\\\ \\mathbb{V}(\\widehat{b}|X_1,\\dots,X_n) &amp;=\\sigma_u^2\\left(\\frac{1}{n}+ \\frac{\\overline{X}_n^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}\\right) \\end{align}\\] Démonstration. On remarque tout d’abord que \\[\\mathbb{V}(Y_i|X_1,\\dots,X_n)=\\sigma_u^2\\] En effet \\[\\begin{align} \\mathbb{V}(Y_i|X_1,\\dots,X_n) &amp;= \\mathbb{V}(aX_i+b+u_i|X_1,\\dots, X_n) \\\\ &amp;= \\mathbb{V}(u_i|X_1,\\dots,X_n) \\\\ &amp;= \\sigma_u^2 \\end{align}\\] Le passage de la première à la deuxième ligne vient du fait qu’à \\(X_1,\\dots, X_n\\) fixées, \\(aX_i+b\\) est considérée comme une constante, et donc ce terme a une contribution à la variance conditionnellement à \\(X_1,\\dots X_n\\). On a donc \\[\\begin{align} \\mathbb{V}(\\widehat{a}|X_1,\\dots X_n) &amp;= \\mathbb{V}\\left(\\left.\\frac{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)Y_i}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}\\right|X_1,\\dots, X_n\\right) \\\\ &amp;= \\frac{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\mathbb{V}(Y_i|X_1,\\dots,X_n)}{\\left(\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\right)^2} \\\\ &amp; \\text{ (somme de VA i.i.d.)} \\\\ &amp;= \\frac{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\sigma_u^2}{\\left(\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2\\right)^2} \\\\ &amp;= \\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2} \\end{align}\\] et \\[\\begin{align} \\mathbb{V}(\\widehat{b}|X_1,\\dots,X_n) &amp;= \\mathbb{V}(\\overline{Y}_n-\\widehat{a}\\overline{X}_n|X_1,\\dots,X_n) \\\\ &amp;= \\mathbb{V}(a\\overline{X}_n+b+\\overline{u}_n-\\widehat{a}\\overline{X}_n|X_1,\\dots,X_n) \\\\ &amp;= \\mathbb{V}((a-\\widehat{a}\\overline{X}_n)+b+\\overline{u}_n|X_1,\\dots, X_n) \\\\ &amp;= \\overline{X}_n^2\\underbrace{\\mathbb{V}(\\widehat{a}|X_1,\\dots,X_n)}_{=\\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}}+\\underbrace{\\mathbb{V}(\\overline{u}_n|X_1,\\dots,X_n)}_{=\\frac{\\sigma_u^2}{n} \\text{ car } u_i \\text{ i.i.d. de variance } \\sigma_u^2} \\\\ &amp;= \\overline{X}_n^2\\frac{\\sigma_u^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}+\\frac{\\sigma_u^2}{n} \\\\ &amp;= \\sigma_u^2\\left(\\frac{1}{n}+\\frac{\\overline{X}_n^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}\\right) \\end{align}\\] \\(\\square\\) 7.1.6.7 Résidus La variance \\(\\sigma_u^2\\) des termes d’erreur \\(u_i\\) n’est pas connue. Cependant, elle peut être estimée. Pour cela, on introduit la notion de résidu. Le résidu \\(\\widehat{u}_i\\) est défini comme l’écart entre la vraie valeur \\(Y_i\\) et sa prédiction \\(\\widehat{Y}_i=\\widehat{a}X_i+\\widehat{b}\\) : \\[\\widehat{u}_i\\equiv Y_i-\\widehat{Y}_i\\] On a donc \\[\\widehat{u}_i=Y_i-\\widehat{a}X_i-\\widehat{b}\\] Il s’agit d’une estimation (sans biais) de la vraie erreur \\[u_i=Y_i-aX_i-b\\] Théorème (estimation de la variance) : \\(\\sigma_u^2\\) La variance \\(\\sigma_u^2\\) est estimée par \\[s^2=\\frac{1}{n-2}\\sum\\limits_{i=1}^n \\widehat{u}_i^2\\] 7.1.6.8 Distributions des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) On admet alors le résultat suivant Théorème : Sous l’hypothèse de normalité des termes d’erreur \\(u_i\\), on a \\[\\frac{(n-2)s^2}{\\sigma_u^2}\\sim\\chi^2_{(n-2)}\\] et les statistiques \\[\\frac{\\widehat{a}-a}{s\\sqrt{\\frac{1}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}}}\\] et \\[\\frac{\\widehat{b}-b}{s\\sqrt{\\frac{1}{n}+\\frac{\\overline{X}_n^2}{\\sum\\limits_{i=1}^n (X_i-\\overline{X}_n)^2}}}\\] suivent une loi de Student à \\(n-2\\) degrés de liberté. 7.1.6.9 Convergence des estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) Si on suppose que les \\(X_i\\) admettent des moments d’ordre \\(1\\) et \\(2\\), alors on peut montrer que les estimateurs \\(\\widehat{a}\\) et \\(\\widehat{b}\\) sont des estimateurs convergents. On sait déjà qu’ils sont sans biais, il suffit donc de démontrer que leurs variances tendent vers \\(0\\). Or, comme \\(X_i\\) admet des moments d’ordres \\(1\\) et \\(2\\) on a, conditionnellement à \\(X_1,\\dots,X_n\\) : \\[\\overline{X}_n\\approx\\mathbb{E}(X)\\] et \\[\\sum\\limits_{i=1}^n(X_i-\\overline{X}_n)^2\\approx n\\mathbb{V}(X_1)\\] On en déduit que \\[\\mathbb{V}(\\widehat{a}|X_1,\\dots, X_n)\\approx\\frac{\\sigma_u^2}{n\\mathbb{V}(X_1)}\\longrightarrow 0\\] et \\[\\mathbb{V}(\\widehat{b}|X_1,\\dots,X_n)\\approx\\sigma_u^2\\left(\\frac{1}{n}+\\frac{\\overline{X}_n^2}{n\\mathbb{V}(X_1)}\\right)\\longrightarrow 0\\] \\(\\widehat{a}\\) et \\(\\widehat{b}\\) sont des estimateurs sans biais de \\(a\\) et \\(b\\) de variances asymptotiquement nulles. Ce sont donc des estimateurs convergents de \\(a\\) et \\(b\\). 7.1.7 Intervalles de confiance Jusqu’à présent, l’estimation était uniquement envisagée du point de vue de l’estimation ponctuelle : il s’agissait, à partir de l’observation d’un échantillon \\((X_1,\\dots,X_n)\\) de fournir une valeur ponctuelle \\(\\widehat{\\theta}_n\\) approchant la vraie valeur inconnue d’un paramètre \\(\\theta\\). Cependant, la valeur estimée dépend de l’échantillon tiré. En effet, si l’on tire \\(1,000\\) échantillons différents, on va obtenir \\(1\\,000\\) estimations \\(\\widehat{\\theta}^{(1)}_n,\\dots,\\widehat{\\theta}^{(1\\,000)}_n\\) a priori différentes également. Certaines de ces estimations peuvent être des valeurs atypiques. Se pose donc la question de la confiance que l’on peut accorder à l’estimation obtenue à partir d’une seule réalisation particulière \\((x_1,\\dots,x_n)\\) de l’échantillon, puisqu’en pratique c’est tout ce dont on dispose pour inférer sur \\(\\theta\\). L’approche présentée jusqu’ici ne répond pas à cette question. Le bon outil pour aborder ce problème est la notion d’intervalle de confiance. Intervalles de confiance Soit \\(\\theta\\) un paramètre inconnu et \\(\\alpha\\) un réel compris entre \\(0\\) et \\(1\\). On appelle intervalle de confiance de niveau \\(1-\\alpha\\) du paramètre \\(\\theta\\) tout intervalle \\([a;b]\\) tel que \\[\\mathbb{P}\\left(\\theta\\in [a;b]\\, \\right)=1-\\alpha\\] Remarques : i. Les réels \\(a\\) et \\(b\\) dépendent de \\(\\theta\\), du niveau de confiance \\(1-\\alpha\\). En pratique, pour les déterminer on utilise l’échantillon \\((X_1,\\dots, X_n)\\), ou plus précisément un résumé \\(T_n\\) de cet échantillon, i.e. une statistique \\(T_n=T_n(X_1,\\dots,X_n)\\). On a donc \\[\\begin{align} a &amp;= a_n(T_n\\,;\\,\\theta\\,;\\,\\alpha) \\\\ b &amp;= b_n(T_n\\,;\\,\\theta\\,;\\,\\alpha) \\\\ \\end{align}\\] Ce sont donc des variables aléatoires, que l’on notera désormais plus simplement \\(a_n\\) et \\(b_n\\). L’intervalle de confiance est donc lui-même un objet aléatoire. ii. Idéalement, on aimerait savoir avec certitude que \\(\\theta\\in [a,b]\\). Comme les réels \\(a\\) et \\(b\\) dépendent de l’échantillon tiré, on ne peut espérer mieux qu’une probabilité d’appartenance de \\(\\theta\\) à \\([a,b]\\). A défaut qu’elle soit égale à 1, on la veut proche de \\(1\\), autrement dit on veut \\(\\alpha\\) proche de \\(0\\). En pratique, on prendra souvent \\(\\alpha=0,05\\), parfois \\(\\alpha=0,01\\). iii. Le réel \\(\\alpha\\) représente un risque : celui de donner un intervalle de confiance qui ne contienne pas la vraie valeur de \\(\\theta\\). iv. Réduire la valeur de \\(\\alpha\\) n’est pas gratuit. Le prix à payer est un élargissement de l’intervalle de confiance \\([a,b]\\), ce qui signifie des intervalles de confiance moins fins et donc moins informatifs sur la vraie valeur de \\(\\theta\\). Inversement, si on veut des intervalles de confiance plus fins, il faut assumer un risque plus grand d’avoir un intervalle de confiance laissant échapper le vrai \\(\\theta\\). On voit maintenant une méthode générale de construction de \\([a_n\\,;\\,b_n]\\). Construction d’un intervalle de confiance On cherche un couple de réels \\((a_n,b_n)\\) tel que \\[\\mathbb{P}\\left(a_n\\leq \\theta\\leq b_n\\right)=1-\\alpha\\] On suppose qu’on dispose d’une statistique \\(T_n\\) à partir de laquelle on calcule ces réels : \\[\\begin{align} a_n &amp;= a_n(T_n) \\\\ b_n &amp;= b_n(T_n) \\end{align}\\] On cherche alors à transformer l’écriture \\(\\theta\\in[a_n(T_n)\\,;\\,b_n(T_n)]\\) en une écriture équivalente du type \\(T_n\\in[\\alpha_n(\\theta)\\,;\\,\\beta_n(\\theta)]\\), autrement dit on veut \\[\\theta\\in[a_n(T_n)\\,;\\,b_n(T_n)]\\Leftrightarrow T_n\\in[\\alpha_n(\\theta)\\,;\\,\\beta_n(\\theta)]\\] Dans ce cas, on doit avoir \\[\\mathbb{P}\\left(T_n\\in[\\alpha_n(\\theta)\\,;\\,\\beta_n(\\theta)]\\right)=1-\\alpha\\] Il s’agit donc de trouver un couple de réels \\((\\alpha_n,\\beta_n)=(\\alpha_n(\\theta),\\beta_n(\\theta))\\) tel que \\[F_{T_n}(\\beta_n)-F_{T_n}(\\alpha_n)=1-\\alpha\\] ou, de façon équivalente \\[\\mathbb{P}(T_n&lt;\\alpha_n)+\\mathbb{P}(T_n&gt;\\beta_n)=\\alpha\\] Remarque. La dernière égalité s’interprète comme un risque à répartir entre \\(\\mathbb{P}(T_n&lt;\\alpha_n)\\) et \\(\\mathbb{P}(T_n&gt;\\alpha_n)\\). Une première approche pour construire des intervalles de confiance consiste à utiliser, lorsque cela est possible, l’inégalité de Bienaymé-Tchebychev : Construction d’intervalles de confiance par application de l’inégalité de Bienaymé-Tchebychev Soit \\(\\widehat{\\theta}_n\\) un estimateur sans biais de \\(\\theta\\) et admettant une variance \\(\\sigma^2\\) que l’on suppose connue. On peut donc appliquer l’inégalité de Bienaymé-Tchebychev : \\[\\mathbb{P}\\left(|\\widehat{\\theta}_n-\\theta|\\geq\\varepsilon\\right)\\leq\\frac{\\sigma^2}{\\varepsilon^2}\\] soit \\[\\mathbb{P}\\left(|\\widehat{\\theta}_n-\\theta|&lt;\\varepsilon \\right)&gt;1-\\frac{\\sigma^2}{\\varepsilon^2}\\] On choisit \\(\\varepsilon\\) de façon à avoir \\(\\alpha=\\frac{\\sigma^2}{\\varepsilon^2}\\), i.e. on pose \\[\\varepsilon=\\frac{\\sigma}{\\sqrt{\\alpha}}\\] Par inversion des inégalités on a \\(|\\widehat{\\theta}_n-\\theta|&lt;\\varepsilon\\Leftrightarrow\\widehat{\\theta}_n-\\varepsilon&lt;\\theta&lt;\\widehat{\\theta}_n+\\varepsilon\\). On en déduit un intervalle de confiance de \\(\\theta\\) au niveau de confiance \\(1-\\alpha\\) : \\[IC^{1-\\alpha}_m=\\left[\\widehat{\\theta}_n-\\frac{\\sigma}{\\sqrt{\\alpha}}\\,;\\,\\widehat{\\theta}_n+\\frac{\\sigma}{\\sqrt{\\alpha}}\\right]\\] Cet intervalle de confiance est bien calculable en pratique puisqu’on a supposé \\(\\sigma^2\\) connue. Exemple (moyenne empirique). Soient \\(X\\) une VA admettant une espérance \\(m\\) et une variance \\(\\sigma^2\\), et \\((X_1,\\dots, X_n)\\) des VA i.i.d. de même loi que \\(X\\). La moyenne empirique \\(\\widehat{\\theta}_n\\equiv\\overline{X}_n\\) est un estimateur sans biais de \\(\\theta\\equiv m\\) et admettant comme variance \\(\\frac{\\sigma^2}{n}\\), on peut donc appliquer ce qui précède et obtenir un intervalle de confiance de \\(m\\) au niveau de confiance \\(1-\\alpha\\) : \\[IC^{1-\\alpha}_m=\\left[\\overline{X}_n-\\frac{\\sigma}{\\sqrt{n\\alpha}}\\,;\\,\\overline{X}_n+\\frac{\\sigma}{\\sqrt{n\\alpha}}\\right]\\] Pour le concours d’administrateur, il est précisé que la construction d’intervalle de confiances est abordée dans un contexte d’application du théorème central limite (Construction d’un intervalle de confiance dans le cadre des modèles d’échantillonnage, dans le cas où le théorème central limite s’applique.). En d’autres termes, il s’agit de se ramener - si l’on n’y est pas déjà - au cas d’une loi normale et d’en déduire un intervalle de confiance (asymptotique). On commence par considérer le cas où la statistique \\(T_n\\) est gaussienne. Construction d’intervalles de confiance dans le cas gaussien Supposons que \\(X\\) suive une loi normale : \\[X\\sim\\mathcal{N}(m,\\sigma^2)\\] Exemple : estimation de \\(m\\) lorsque \\(\\sigma\\) est connu. \\(m\\) est l’espérance de \\(X\\), on peut l’estimer par la moyenne empirique \\[\\overline{X}_n\\sim\\mathcal{N}\\left(m\\,;\\,\\frac{\\sigma^2}{n}\\right)\\] on commence par centrer et réduire \\(\\overline{X}_n\\) pour se ramener à une loi normale standard \\(\\mathcal{N}(0,1)\\). On pose donc \\[Z_n\\equiv\\frac{\\overline{X}_n-m}{\\frac{\\sigma}{\\sqrt{n}}}\\] on cherche ensuite un intervalle \\([-v,v]\\) de niveau de confiance \\(1-\\alpha\\) pour \\(Z_n\\). Comme \\(Z_n\\) est symétrique par rapport à \\(0\\), il est plus simple de le chercher sous la forme \\([-v,v]\\). On résout donc, en notant \\(\\Phi\\) la fonction de répartition d’un loi normale standard et en remarquant que \\(\\Phi(-x)=1-\\Phi(x)\\) : \\[\\begin{align} \\Phi(v)-\\Phi(-v) &amp;= 1-\\alpha \\\\ 2\\Phi(v)-1 &amp;= 1-\\alpha \\\\ \\Phi(v) &amp;= 1-\\frac{\\alpha}{2} \\\\ v &amp;= \\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right) \\end{align}\\] on en déduit un intervalle de confiance de niveau \\(1-\\alpha\\) pour \\(m\\) : \\[\\begin{align} &amp; -v\\leq Z_n \\leq v \\\\ \\text{ssi } &amp; -v\\leq\\frac{\\overline{X}_n-m}{\\frac{\\sigma}{\\sqrt{n}}}\\leq n \\\\ \\text{ssi } &amp; \\overline{X}_n-\\frac{\\sigma}{\\sqrt{n}}v\\leq m\\leq \\overline{X}_n+\\frac{\\sigma}{\\sqrt{n}}v &amp; \\\\ \\end{align}\\] Un intervalle de confiance de \\(m\\) au niveau \\(1-\\alpha\\) est donc \\[\\text{IC}^m_{1-\\alpha}\\equiv\\left[\\overline{X}_n-\\frac{\\sigma}{\\sqrt{n}}\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right) \\, , \\, \\overline{X}_n+\\frac{\\sigma}{\\sqrt{n}}\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\right]\\] On peut calculer cet intervalle de confiance à partir de l’échantillon pusiqu’on a supposé \\(\\sigma\\) connu. On considère maintenant un cas où la stastistique n’est plus gaussienne, mais où il est possible d’appliquer le théorème central-limite, et donc se ramener à une loi approximativement gaussienne. Dans ce cas, peut obtenir des intervalles de confiance asymptotiques : Construction d’intervalles de confiance asymptotiques dans un cas d’application du TCL On suppose que \\(X\\) suit une loi normale centrée : \\[X_n\\sim\\mathcal{N}(0,\\sigma^2)\\] Exemple : estimation de \\(\\sigma\\). On considère la statistique \\[D_n\\equiv\\frac{1}{n}\\sum\\limits_{i=1}^n |X_i|\\] On vérifie facilement que l’intégrale \\(\\int_{\\mathbb{R}} |x|\\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{x^2}{2\\sigma^2}}\\,dx\\) est convergente et vaut \\(\\sqrt{\\frac{2}{\\pi}}\\sigma\\). Ainsi, la variable aléatoire \\(|X|\\) admet une espérance et \\[\\mathbb{E}(|X|)=\\sqrt{\\frac{2}{\\pi}}\\,\\sigma\\] On en déduit un estimateur sans biais de \\(\\sigma\\) : \\[T_n\\equiv\\sqrt{\\frac{\\pi}{2}}\\,D_n\\] Avec la loi faible des grands nombres, \\(T_n\\) est un estimateur convergent de \\(\\sigma\\). Par ailleurs, \\(|X|\\) admet un moment d’ordre \\(2\\) (\\(\\mathbb{E}(|X|^2)=\\mathbb{E}(X^2)=\\sigma^2\\)) et \\[\\begin{align} \\mathbb{V}(|X|) &amp;= \\mathbb{E}(X^2)-(\\mathbb{E}(|X|))^2 \\\\ &amp;= \\left(1-\\frac{2}{\\pi}\\right)\\sigma^2 \\end{align}\\] On en déduit que \\(T_n\\) admet une variance et que \\[\\mathbb{V}(T_n)=\\left(\\frac{\\pi}{2}-1\\right)\\frac{\\sigma^2}{n}\\] Avec le théorème central limite on a l’approximation en loi \\[\\frac{T_n-\\sigma}{\\frac{\\sigma}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\approx\\mathcal{N}(0,1)\\] En posant \\(u_{\\alpha}=\\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right)\\), avec toujours \\(\\Phi\\) la fonction de répartition de la loi normale standard, on a donc \\[\\mathbb{P}\\left(-u_{\\alpha}\\leq\\sqrt{n}\\frac{T_n-\\sigma}{\\sigma\\sqrt{\\frac{\\pi}{2}-1}}\\leq u_{\\alpha}\\right)\\approx 1-\\alpha\\] Or \\[-u_{\\alpha}\\leq\\sqrt{n}\\frac{T_n-\\sigma}{\\sigma\\sqrt{\\frac{\\pi}{2}-1}}\\leq u_{\\alpha}\\Leftrightarrow \\frac{T_n}{1+\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\leq\\sigma\\leq\\frac{T_n}{1-\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\] On en déduit un intervalle de confiance asymptotique de \\(\\sigma\\) au niveau de confiance \\(1-\\alpha\\) : \\[\\text{IC}^{1-\\alpha}_{\\sigma}\\equiv\\left[\\frac{T_n}{1+\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\, ;\\, \\frac{T_n}{1-\\frac{u_{\\alpha}}{\\sqrt{n}}\\sqrt{\\frac{\\pi}{2}-1}}\\right]\\] 7.2 Tests statistiques 7.2.1 Définition et principes On s’intéresse à un phénomène réel que l’on modélise par une variable aléatoire \\(X\\) dont la loi est modélisée statistiquement par une famille paramétrique de distributions \\(\\{P_{\\theta}, \\theta\\in\\Theta\\}\\). On suppose que l’espace \\(\\Theta\\) de tous les paramètres possibles est partitionné en deux sous-ensembles \\(\\Theta_0\\) et \\(\\Theta_1\\). On note \\(\\theta\\) la vraie valeur associée à la loi de \\(X\\). On considère alors les deux hypothèses suivantes : \\[(H_0):\\,\\theta\\in\\Theta_0\\] \\[(H_1):\\,\\theta\\in\\Theta_1\\] L’hypothèse \\((H_0)\\) s’appelle l’hypothèse nulle alors que l’hypothèse \\((H_1)\\) s’appelle l’hypothèse alternative. Construire un test revient à construire une partition de \\(\\mathbb{R}^n\\) : \\[\\mathbb{R}^n=W\\cup\\overline{W}\\] tel que, pour toute réalisation \\((x_1,\\dots,x_n)\\) d’un échantillon aléatoire \\((X_1,\\dots,X_n)\\) de variables aléatoires i.i.d. \\(X_i\\) de loi \\(P_{\\theta}\\), on suive la règle de décision suivante : \\[\\hbox{Si } (x_1,\\dots, x_n)\\in W \\hbox{ alors on rejette l&#39;hypothèse nulle } (H_0)\\] \\[\\hbox{Si } (x_1,\\dots, x_n)\\in \\overline{W} \\hbox{ alors on ne rejette pas l&#39;hypothèse nulle } (H_0)\\] La partie \\(W\\) s’appelle la région de rejet de \\((H_0)\\), ou encore la région critique. La partie \\(\\overline{W}\\) s’appelle la région d’acceptation de l’hypothèse nulle \\((H_0)\\). Construire un test, c’est donc décider d’une partition particulière \\((W, \\overline{W})\\) de \\(\\mathbb{R}^n\\). Les tests constituent un outil d’aide à la décision. On en présente ici une méthodlogie générale : Méthodologie des tests d’hypothèse On suit généralement les étapes suivantes : on définit l’hypothèse nulle \\((H_0)\\) et l’hypothèse alternative \\((H_1)\\) ; on choisit une statistique de test \\(T=T(X_1,\\dots, X_n)\\) ; on détermine la distribution de \\(T\\) sous l’hypothèse nulle \\((H_0)\\) ; on choisit un niveau de significativité \\(\\alpha\\) du test, et on calcule, à partir de la distibution de \\(T\\) obtenue à l’étape précédente, la région de rejet de \\((H_0)\\) ; on calcule, à partir des données observées \\((x_1,\\dots x_n)\\) (qui constituent une réalisation de l’échantillon aléatoire \\((X_1,\\dots, X_n)\\)) la valeur \\(T(x_1,\\dots, x_n)\\) prise par \\(T\\) ; à partir de cette dernière valeur et de la région de rejet, on prend une décision. Cette méthodologie correspond en gros à un raisonnement par l’absurde probabiliste. En effet, dans un raisonnement par l’absurde classique : on veut démontrer une certaine affirmation \\(A\\) ; sous l’hypothèse contraire \\(\\overline{A}\\), on en déduit quelque chose que l’on sait faux ; on conclut que notre hypothèse de départ \\(\\overline{A}\\) est fausse, i.e. on rejette \\(\\overline{A}\\), ou, de façon équivalente, on conclut que \\(A\\) est vraie. Lorsqu’on fait un test : on définit une hypothèse nulle \\((H_0)\\), qui est l’hypothèse que l’on aimerait pouvoir rejeter ; on calcule la distribution de \\(T\\) et on calcule par ailleurs la valeur \\(T(x_1,\\dots, x_n)\\) ; si la probabilité sous l’hypothèse nulle que \\(T\\) prenne cette valeur est très faible, i.e. en dessous d’un certain seuil (le seuil standard étant 5 %), on rejette l’hypothèse nulle. Si en revanche cette probabilité est au-dessus de ce seuil, on ne rejette pas l’hypothèse nulle. Remarques. i En résumé, on suit donc le principe suivant : je suppose \\((H_0)\\) vraie, j’arrive à un résultat très improbable, je conclus que \\((H_0)\\) est fausse. ii. A la différence d’un raisonnement par l’absurde classique, cette conclusion peut toutefois être erronée. Autrement dit, il est possible de rejeter à tort \\((H_0)\\). Toutefois, ce risque de rejet à tort est maitrisable : il s’agit du seuil de significativité \\(\\alpha=\\mathbb{P}(\\hbox{on rejette } H_0\\,|\\, H_0)\\). Donc, si on choisit \\(\\alpha\\) petit, ce risque -appelé risque de première espèce- sera très limité. iii. Lorsqu’on tente de faire un raisonnement par l’absurde, mais qu’on ne parvient pas à aboutir à une contradiction, il est incorrect de conclure que l’hypothèse initiale est vraie. Notre raisonnement ne nous a juste pas permis de conclure qu’elle était fausse… ce qui ne signifie pas qu’elle est vraie. Dans un tel cas, on ne peut tout simplement rien conclure. De manière analogue, si la probabilité calculée dans un test est au-dessus du seuil de significativité, il serait incorrect d’accepter l’hypothèse nulle. Même si on trouve parfois l’expression accepter \\((H_0)\\) dans la littérature, il s’agit d’un abus de langage et on lui préfèrera l’expression ne pas rejeter \\((H_0)\\). Cela ne signifie pas que \\((H_1)\\) est probablement vraie, mais plutôt que notre test ne nous a pas permis de conclure que \\((H_0)\\) était probablement fausse, ce qui est assez différent. iv. De la même façon que l’on peut rejeter à tort l’hypothèse nulle \\((H_0)\\), il est possible de ne pas rejeter à tort \\((H_0)\\). La probabilité d’un tel événement est \\(\\mathbb{P}(\\hbox{ne pas rejeter } H_0\\,|\\, H_1)\\). Cette probabilité s’appelle le risque de deuxième espèce. v. Tout test présente une dyssymétrie dans sa façon de traiter \\((H_0)\\) et \\((H_1)\\). Parmi les deux types d’erreurs que l’on peut commettre dans la conclusion d’un test, il y en a généralement l’une des deux que l’on veut éviter en priorité. Par exemple, un test médical peut amener deux types d’erreurs : les faux positifs et les faux négatifs. On préfère en général avoir des tests pour lesquels la probabilité de faux négatif est faible, car conclure que le patient n’est pas malade (et donc ne pas le traiter) alors qu’il l’est est en général plus ennuyeux que conclure qu’il est malade (et donc le traiter) alors qu’il ne l’est pas. On retient le plus souvent la convention suivante : l’erreur de première espèce est celle que l’on veut éviter, on veut donc maitriser le risque de première espèce \\(\\alpha=\\mathbb{P}(\\hbox{rejeter } H_0\\,|\\,H_0)\\). On choisit un \\(\\alpha\\) petit et on en déduit une région de rejet \\(W=W_{\\alpha}\\). La valeur \\(\\beta=\\mathbb{P}(\\hbox{ne pas rejeter } H_0\\,|\\, H_1)\\) dépend alors du choix de \\(\\alpha\\), on ne la contrôle pas. 7.2.2 Tests unilatéraux, tests bilatéraux On note \\(\\theta\\) le paramètre inconnu associé à la loi de \\(X\\). Test bilatéral Un test bilatéral est un test dont les hypothèses nulle \\((H_0)\\) et alternative \\((H_1)\\) sont de la forme \\[(H_0):\\,\\theta=\\theta_0\\] \\[(H_1):\\,\\theta\\neq\\theta_0\\] Exemple : tester si une pièce est équilibrée. On veut s’assurer qu’une pièce est équilibrée en utilisant un test statistique. On note \\(p\\) sa probabilité de tomber sur pile. La pièce est équilibrée si et seulement si \\(p=\\frac{1}{2}\\). On définit alors le test suivant : \\[(H_0):\\,p=\\frac{1}{2}\\] \\[(H_1):\\, p\\neq\\frac{1}{2}\\] Il s’agit d’un test bilatéral. De même, il existe des tests unilatéraux : Test unilatéral Un test unilatéral est un test dont les hypothèses nulle \\((H_0)\\) et alternative \\((H_1)\\) sont soit de la forme \\[(H_0):\\,\\theta=\\theta_0\\] \\[(H_1):\\,\\theta&gt;\\theta_0\\] soit de la forme \\[(H_0):\\,\\theta=\\theta_0\\] \\[(H_1):\\,\\theta&lt;\\theta_0\\] Un test unilatéral suppose donc connu le signe de la différence \\(\\theta-\\theta_0\\), contrairement à un test bilatéral. Exemple : tester l’efficacité d’un médicament. Le fabricant d’un médicament annonce une efficacité à \\(90/,/%\\) pour l’un de ses produits. Sur un échantillon de 200 personnes, ce médicament a fonctionné pour 160 personnes. On souhaite déterminer si l’afformation du fabrication est exacte au seuil de significativité \\(\\alpha=1\\,\\%\\). On va ici prendre pour hypothèses \\[(H_0):\\,p=0,9\\] \\[(H_1):\\,p&lt;0,9\\] où \\(p\\) est la probabilité que le médicament soit efficace. Il s’agit d’un test unilatéral gauche. 7.2.3 Exemples On reprend les deux exemples précédents. Exemple 1 : tester si une pièce est équilibrée. On effectue \\(n=1\\,000\\) lancers de cette pièce. Sur ces \\(10\\,000\\) lancers, la pièce est tombée \\(4\\,880\\) fois sur pile. On veut déterminer si cette pièce est équilirée au seuil de significativité \\(\\alpha = 5\\,\\%\\). Pour \\(1\\leq i\\leq n\\), on note \\(X_i\\in\\{0,1\\}\\) la variable aléatoire qui prend la valeur \\(1\\) si la pièce est tombée sur pile au lancer numéro \\(i\\), qui prend la valeur \\(0\\) si elle est tombée sur face. Les variables aléatoires \\(X_1,\\dots,X_n\\) sont i.i.d. de loi de Bernoulli \\(\\mathcal{B}(p)\\) où \\(p\\) est la probabilité que la pièce tombe sur pile : \\(p=\\mathbb{P}(X_i=1)\\). La variable aléatoire \\(S_n\\equiv\\sum\\limits_{i=1}^n X_i\\) suit une loi binomiale \\(\\mathcal{B}(n, p)\\). On rappelle l’énoncé du théorème de Moivre-Laplace, qui n’est qu’un cas particulier du théorème central limite : Théorème de Moivre-Laplace. Si la variable aléatoire \\(X_n\\) suit une loi binomiale \\[X_n\\sim\\mathcal{B}(n, \\,p)\\] alors la variable aléatoire \\[Z_n\\equiv\\frac{X_n-np}{\\sqrt{np(1-p)}}\\] converge en loi vers la loi normale standard \\(\\mathcal{N}(0,1)\\). En pratique, dès lors que les conditions suivantes sont vérifiées : \\(n\\geq 30\\) \\(np\\geq 5\\) \\(n(1-p)\\geq 5\\)$ on peut écrire l’approximation en loi \\[Z_n\\equiv\\frac{X_n-np}{\\sqrt{np(1-p)}}\\approx\\mathcal{N}(0,1)\\] Sous l’hypothèse nulle \\((H_0):\\,p=\\frac{1}{2}\\), on a \\[S_n\\sim\\mathcal{B}\\left(n, \\frac{1}{2}\\right)\\] Les trois conditions à vérifier sont bien satisfaites : \\(n=10\\,000\\geq 30\\) \\(np=5\\,000\\geq 5\\) \\(n(1-p)=5\\,000\\geq 5\\) si bien que \\[Z_n\\equiv\\frac{S_n-np}{\\sqrt{np(1-p)}}\\approx\\mathcal{N}(0,1)\\] i.e. \\[Z_n\\equiv\\frac{S_n-5\\,000}{50}\\approx\\mathcal{N}(0,1)\\] La variable aléatoire \\(Z_n\\) est notre statistique de test. On vient de déterminer sa loi, on peut donc en déduire la zone de rejet de notre test. Pour une loi normale standard \\(Z_n\\), on a \\[\\mathbb{P}\\left(-1,96\\leq Z_n\\leq 1,96\\right)\\approx 0,95\\] La région d’acceptation du test au seuil de significativité \\(\\alpha=5\\,\\%\\) est donc \\(\\overline{W}=[-1,96\\,;\\,1,96]\\) et son complémentaire \\(W=]-\\infty\\;\\,-1,96[\\cup]1,96\\,;\\,+\\infty[\\) est donc la région de rejet. On applique donc la règle de décision suivante : \\[\\hbox{Si } z_n\\not\\in \\overline{W}=[-1,96\\,;\\,1,96] \\hbox{ on rejette l&#39;hypothèse nulle} (H_0)\\] \\[\\hbox{Si } z_n\\in\\overline{W}=[-1,96\\,;\\,1,96] \\hbox{ on ne rejette pas l&#39;hypothèse nulle} (H_0)\\] Or, la valeur observée de \\(Z_n\\) sur l’échantillon tiré est \\(z_n=\\frac{4\\,880-5\\,000}{50}=-2,4\\). Elle appartient à la région de rejet. Conclusion. Au seuil de significativité \\(5\\,\\%\\) on rejette donc l’hypothèse nulle, ce qui revient à dire qu’on conclut que la pièce est désiquilibrée. Remarque. Si on avait obtenu \\(4\\,920\\) fois pile sur nos \\(5\\,000\\) tirages, on aurait calculé \\(z_n=-1,6\\) qui est dans la zone d’acceptation. On n’aurait donc pas rejeté l’hypothèse nulle, autrement dit on n’aurait pas rejeté l’hypothèse d’une pièce équilibrée. Exemple 2 : tester l’efficacité d’un médicament. Pour \\(i\\) compris entre \\(1\\) et \\(200\\), on pose \\(X_i=1\\) si le médicament a été efficace pour l’individu numéro \\(i\\), et \\(X_i=0\\) dans le cas contraire. Comme dans l’exemple 1, sous l’hypothèse nulle \\((H_0):\\,p=0,9\\) les \\(X_i\\) sont i.i.d. et suivent une loi de Benoulli, de paramètre \\(p\\). On en déduit que leur somme \\(S_n=\\sum\\limits_{i=1}^{200}X_i\\) suit une loi binomiale de paramètre \\(np=180\\). On a \\(n=200\\geq 30\\) \\(np=180\\geq 5\\) \\(n(1-p)=20\\geq 5\\) On a donc \\[Z_n\\equiv\\frac{S_n-180}{\\sqrt{18}}\\approx\\mathcal{N}(0,1)\\] Il s’agit de notre statistique de test. Sur l’échantillon observé, elle prend comme valeur \\[z_n=\\frac{160-180}{\\sqrt{0.5}}\\approx -4,71\\] La région de rejet est \\(W=]-\\infty, t]\\) avec \\(t\\) l’unique réel tel que \\(\\mathbb{P}(Z_n\\leq t)=0,01\\). Grâce à la table de la loi normale standard, on obtient \\(t\\approx -2,33\\), donc \\(W=]-\\infty\\,;\\,-2,33]\\). Ainsi, \\(z_n\\) est dans la région de rejet. On rejette donc l’hypothèse nulle : l’affirmation du fabricant est fausse au seuil de significativité \\(1\\,\\%\\). "],["méthodologie.html", "Chapitre 8 Méthodologie 8.1 Convergence", " Chapitre 8 Méthodologie Le but de cette partie est de recenser des méthodes qui reviennent fréquemment dans les sujets de concours. La liste n’est pas exhaustive, mais l’idée est surtout de construire (progressivement) une boite à outils qui devrait être utile autant pour les écrits que les oraux. 8.1 Convergence Les sujets du concours d’administrateur regorgent de questions sur la convergence en loi et la convergence en probabilité. Les techniques qui reviennent souvent sont les suivantes : Comment démontrer la convergence en loi d’une suite de variables aléatoires ? Méthode 1 : revenir à la définition Si on montre que pour toute fonction \\(\\phi\\) continue et bornée \\[\\lim\\limits_{n\\to +\\infty}\\mathbb{E}(\\phi(X_n))\\underset{n\\to +\\infty}\\longrightarrow\\mathbb{E}(\\phi(X))\\] on peut alors conclure que \\[X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}\\longrightarrow} X\\] Méthode 2 : utiliser la fonction de répartition On considère la fonction de répartition \\(F_n\\) de \\(X_n\\). Si on peut montrer que \\(\\lim\\limits_{n\\to +\\infty}F_n(x) = F(x)\\) en tout point où \\(F\\) est continue, et que \\(F\\) est une fonction de répartition (éventuellement la fonction de répartition d’une loi usuelle), alors on peut conclure que \\((X_n)_n\\) converge en loi vers la loi associée à cette fonction de répartition. Exemple. On suppose que \\(X_n\\) suit une loi uniforme sur \\(\\left\\{\\frac{1}{n},\\dots,\\frac{n-1}{n}, 1\\right\\}\\) et on veut montrer que \\((X_n)_n\\) converge en loi vers la loi uniforme \\(\\mathcal{U}([0\\,,\\,1])\\). Soit \\(x\\in [0\\,;\\,1]\\). Il existe un unique entier naturel \\(k\\in [0\\,;\\,n]\\) tel que \\(\\frac{k}{n}\\leq x &lt;\\frac{k+1}{n}\\). Cet encadrement s’écrit aussi \\(nx-1 &lt;k\\leq nx\\), i.e. \\(nx\\leq k &lt;nx+1\\). On en déduit que \\(k=\\lfloor nx\\rfloor\\). Comme \\(X_n\\) est entier, on a donc \\[X_n\\leq x \\Leftrightarrow X_n\\leq\\frac{\\lfloor nx \\rfloor}{n}\\] et donc \\(F_{X_n}(x)=F_{X_n}\\left(\\frac{\\lfloor nx \\rfloor}{n}\\right)=\\frac{\\lfloor nx\\rfloor}{n}\\). On en déduit que \\[x\\leq F_{X_n}(x)&lt;x+\\frac{1}{n}\\] et donc \\[\\lim\\limits_{n\\to +\\infty} F_{X_n}(x)=x\\] Or, la fonction \\(F\\) définie par \\(F(x)=x\\) est la fonction de répartition de la loi uniforme sur \\(\\mathcal{U}([0\\,;\\,1])\\). On a donc finalement \\[X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}\\longrightarrow}\\mathcal{U}([0\\,;\\,1])\\] Méthode 3 : utiliser le théorème central limite C’est le résultat auquel il faut penser lorsqu’on voit une somme \\(S_n\\equiv\\sum\\limits_{i=1}^n X_i\\) de variables aléatoires i.i.d. Pour pouvoir l’appliquer, les \\(X_i\\) doivent admettre une espérance \\(\\mu\\) et une variance \\(\\sigma^2&gt;0\\). La version centrée-réduite de \\(S_n\\) converge alors en loi vers la loi normale standard \\(\\mathcal{N}(0,1)\\) : \\[\\frac{S_n-n\\mu}{n\\,\\sigma}\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\mathcal{N}(0\\,;1)\\] De façon équivalente, on a aussi \\[\\sqrt{n}\\,\\frac{\\overline{X_n}-\\mu}{\\sigma}\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\mathcal{N}(0\\,;1)\\] ou encore \\[\\sqrt{n}\\left(\\overline{X_n}-\\mu\\right)\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\mathcal{N}(0\\,;\\sigma^2)\\] Exemple. Soit \\((X_n)_n\\) une suite de variables aléatoires i.i.d. de loi \\(\\mathcal{E}(b)\\). On pose \\[Z_n\\equiv\\sqrt{n}\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n X_i-\\frac{1}{b}\\right)\\] et on nous demande de démontrer que \\((Z_n)_n\\) converge en loi, et de déterminer sa limite. On reconnaît une expression du type \\(\\sqrt{n}(\\overline{X}_n-\\mu)\\), qui doit activer l’automatisme utilisation du TCL… On a en effet \\(\\mathbb{E}(X_n)=\\frac{1}{b}\\) et \\(\\mathbb{V}(X_n)=\\frac{1}{b^2}\\) avec des variables \\(X_i\\) i.i.d., et donc le théorème central limite permet d’écrire \\[Z_n=\\sqrt{n}\\left(\\frac{1}{n}\\sum\\limits_{i=1}^n X_i-\\frac{1}{b}\\right)\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\mathcal{N}\\left(0\\,;\\,\\frac{1}{b^2} \\right)\\] Méthode 4 : Montrer la convergence en probabilité Si \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}X\\) alors \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}X\\). Méthode 5 : Utiliser le continuous mapping theorem Si on a déjà montré que \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}X\\) et qu’on veut montrer que \\(Y_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}Y\\) (la recherche de \\(Y\\) pouvant éventuellement être laissée à la charge du candidat…), on peut regarder si on peut écrire \\(X_n\\) sous la forme \\(X_n=f(Y_n)\\). Si c’est le cas et si \\(f\\) est une fonction continue, alors le continuous mapping theorem permet de conclure que \\(X_n=f(Y_n)\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}f(Y)=:X\\). Ce théorème peut s’utiliser en invoquant simplement la stabilité de la convergence en loi par les applications continues. Exemples. Si \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}X\\), alors \\(X_n^2\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}X^2\\), \\(\\sqrt{X_n}\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\sqrt{X}\\) (sous réserve d’existence), \\(\\frac{1}{X_n}\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\frac{1}{X}\\) (sous réserve d’existence), etc. Méthode 6 : Utiliser le lemme de Slutsky Pour rappel, ce lemme affirme que si \\((X_n)\\) converge en loi vers \\(X\\) et \\(Y_n\\) converge en probabilité vers \\(Y\\), alors le couple aléatoire \\((X_n, \\, Y_n)\\) converge en loi vers le couple \\((X,\\, Y)\\). On utilise en général plutôt une conséquence de ce lemme : pour toute fonction continue \\(f:\\mathcal{U}\\subset\\mathbb{R}^2\\longrightarrow\\mathbb{R}\\) (en fait mesurable suffit, mais c’est hors-programme…) la variable aléatoire \\(Z_n=f(X_n\\,Y_n)\\) converge en loi vers \\(Z=f(X,\\,Y)\\). Exemples. Typiquement, on a donc \\(X_n+Y_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}X+Y\\), \\(X_nY_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}XY\\), \\(\\frac{X_n}{Y_n}\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}\\frac{X}{Y}\\), etc. Comment montrer la convergence en probabilité d’une suite de variables aléatoires ? Méthode 1 : revenir à la défintion Autrement dit si on parvient à montrer que pour tout réel \\(\\varepsilon &gt;0\\) quelconque \\[\\mathbb{P}(|X_n-X|\\geq\\varepsilon)\\underset{n\\to +\\infty}\\longrightarrow 0\\] alors on peut conclure que \\((X_n)_n\\) converge en probabilité vers \\(X\\). Exemple. \\((X_n)_n\\) est une suite de variables aléatoires telles que \\[\\begin{align} \\mathbb{P}(X_n=0) &amp;= 1-\\frac{1}{n} \\\\ \\mathbb{P}(X_n=n) &amp;= \\frac{1}{n} \\end{align}\\] et on veut montrer que \\((X_n)_n\\) converge en probabilité. On fixe donc un \\(\\varepsilon &gt;0\\) quelconque. \\((X_n)_n\\) est à valeurs dans \\(\\{0, n\\}\\) car \\(\\mathbb{P}(X_n=0)+\\mathbb{P}(X_n=n)=1\\), donc \\[\\begin{align} \\mathbb{P}(|X_n|&gt;\\varepsilon) &amp;= \\mathbb{P}(X_n=n) \\\\ &amp;= \\frac{1}{n} \\end{align}\\] Ainsi, \\(\\mathbb{P}(|X_n|\\geq\\varepsilon)\\underset{n\\to +\\infty}\\longrightarrow 0\\), et donc la suite \\((X_n)\\) converge en probabilité vers \\(0\\). Méthode 2 : utiliser la loi faible des grands nombres Pour rappel, la loi faible des grands nombres affirme que si les \\(X_i\\) sont des variables aléatoires i.i.d. admettant une espérance \\(\\mu\\), alors la suite des moyennes empiriques \\(\\overline{X}_n\\) converge en probabilité vers \\(\\mu\\) : \\[\\overline{X}_n\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}\\mu=\\mathbb{E}(X)\\] C’est un outil auquel il faut donc penser dès que l’on nous demande de montrer la convergence en probabilité d’une moyenne empirique vers une constante. Exemple. Si les \\(X_i\\) sont i.i.d. de loi \\(\\mathcal{E}(2)\\), alors \\[\\frac{X_1+\\dots +X_n}{n}\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}\\frac{1}{2}\\] Méthode 3 : utiliser une inégalité de concentration Intuitivement, une inégalité de concentration nous dit qu’une variable aléatoire a peu de chance de prendre une valeur trop éloignée de la moyenne, ou une valeur trop grande (en valeur absolue). Le programme du concours suppose connues deux inégalités de concentration : l’inégalité de Markov : si \\(X\\) est positive et admet une espérance, alors pour tout \\(\\varepsilon &gt;0\\), on a \\[\\mathbb{P}(X&gt;\\varepsilon)\\leq\\frac{\\mathbb{E}(X)}{\\varepsilon}\\] l’inégalité de Bieanymé-Tchebychev qui est une conséquence de l’inégalité de Markov (appliquée à \\(Y\\equiv (X-\\mathbb{E}(X))^2\\)) : si \\(X\\) admet une espérance et une variance, alors pour tout \\(\\varepsilon &gt;0\\) : \\[\\mathbb{P}(|X-\\mathbb{E}(X)|\\geq\\varepsilon)\\leq\\frac{\\mathbb{V}(X)}{\\varepsilon^2}\\] Exemple. On sait que \\(X_n\\) (de signe quelconque) est telle que \\(\\mathbb{E}(|X_n|)\\underset{n\\to +\\infty}\\longrightarrow 0\\) et on veut montrer que la suite \\((X_n)_n\\) converge en probabilité et déterminer sa limite. D’après l’inégalité de Markov appliquée à \\(Y_n\\equiv|X_n|\\), pour tout \\(\\varepsilon &gt;0\\) on a \\[0\\leq \\mathbb{P}(|X_n|\\geq\\varepsilon)\\leq\\frac{\\mathbb{E}(|X_n|)}{\\varepsilon}\\] et le théorème des gendarmes nous permet de conclure que, pour tout \\(\\varepsilon &gt;0\\) on a \\(\\lim\\limits_{n\\to +\\infty}\\mathbb{P}(|X_n|\\geq\\varepsilon)=0\\), et donc \\((X_n)\\) converge en probabilité vers \\(0\\). Méthode 4 : montrer la convergence en loi vers une constante Pour rappel : la convergence en probabilité implique toujours la convergence en loi la réciproque est fausse dans le cas général. Toutefois, elle est vraie si la limite est constante. D’après le deuxième point, pour montrer que \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}a\\) avec \\(a\\in\\mathbb{R}\\) une constante, il suffit de démontrer que \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathcal{L}}{\\longrightarrow}}a\\) Exemple. On sait que \\(X_n\\) admet pour fonction de répartition la fonction \\(F_n\\) telle que \\(F_n(x)=0\\) si \\(x\\leq 1-\\frac{1}{n}\\), \\(F_n(x)=1\\) si \\(x\\geq 1\\) et \\(F_n\\) est affine sur \\(\\left[1-\\frac{1}{n}\\,;\\,1\\right]\\). On veut montrer que \\((X_n)_n\\) converge en probabilité vers \\(1\\). Pour cela, il suffit donc de démontrer que \\((X_n)_n\\) converge en loi vers \\(1\\). Or, pour tout réel \\(x\\), \\(F_n(x)\\underset{n\\to +\\infty}\\longrightarrow F(x)=\\mathbb{1}_{x\\leq 1}\\). On reconnait la fonction de répartition de la variable aléatoire constante égale à \\(1\\) : la suite \\((X_n)_n\\) converge donc en loi vers la constante 1, et donc elle converge en probabilité vers \\(1\\). Méthode 5 : utiliser le continuous mapping theorem Ce théorème fonctionne aussi pour la convergence en probabilité Autrement dit, la convergence en probabilité est stable par les applications continues: si \\(X_n\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}X\\), alors pour toute fonction continue \\(f\\) on a aussi \\(f(X_n)\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}{\\longrightarrow}}f(X)\\). Exemple. On sait que \\(X_n\\) est telle que \\(\\mathbb{E}(|X_n|)\\underset{n\\to +\\infty}\\longrightarrow 0\\) et on veut montrer que la suite \\((Y_n)_n\\) définie par \\(Y_n=e^{X_n}\\) converge en probabilité et déterminer sa limite. On a déjà démontré dans l’exemple de la méthode 3 que \\((X_n)_n\\) converge en probabilité vers \\(0\\) via l’inégalité de Markov. Par application de la fonction exponentielle, qui est continue, la suite \\((Y_n)_n\\) converge donc en probabilité vers \\(1\\). Un autre exemple. Supposons que l’on ait une suite de variables aléatoires i.i.d. \\(X_1,\\dots, X_n,\\dots\\), avec \\(\\mathbb{E}(X_i)=0\\) et que l’on veuille montrer que la suite \\((Y_n)_n\\) définie par \\(Y_n\\equiv e^{\\frac{1}{n}\\sum\\limits_{i=1}^n X_i}\\) converge en probabilité. Alors on peut procéder ainsi : les \\(X_i\\) étant i.i.d. et admettant une espérance, on peut appliquer la loi faible des grands nombres : \\[\\frac{1}{n}\\sum\\limits_{i=1}^n X_i\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}\\longrightarrow}0\\] l’application \\(\\exp\\) étant continue en \\(0\\), on a d’après le continuous mapping theorem \\(e^{\\frac{1}{n}\\sum\\limits_{i=1}^n X_i}\\underset{n\\to +\\infty}{\\overset{\\mathbb{P}}\\longrightarrow}e^0=1\\). \\(\\fbox{Concours}\\) L’exercice 1 du sujet du concours externe de 2022 est un bon exemple d’exercice mobilisant ces techniques, parfois de façon combinée. "],["exercices.html", "Chapitre 9 Exercices 9.1 Dénombrement et probabilités", " Chapitre 9 Exercices 9.1 Dénombrement et probabilités On commence par quelques exercices de dénombrement, très classiques lorqu’on découvre le calcul des probabilités. Si ce type d’exercices a en soi très peu de chances de tomber au concours, on peut toujours imaginer un sujet dans lequel quelques questions isolées nécessitent des réflexes d’analyse combinatoire. Exercice 2.1. Dans un jeu de 52 cartes, on tire 5 cartes sans remise. Quelle est la probabilité de tirer : 1. 5 coeurs ? 2. 2 piques et 3 coeurs ? 3. 5 trèfles ou 5 coeurs ? 4. 5 cartes de la même couleur (pique, coeur, carreau, trèfle) ? 5. 3 cartes d’une couleur et 2 d’une autre ? 6. les 4 as et une autre carte ? Solution. Le nombre de main à \\(5\\) cartes dans un jeu de \\(52\\) cartes est \\(\\binom{52}{5}\\). 1. Il y a \\(13\\) coeurs dans un jeu de \\(52\\) cartes, donc il y a \\(\\binom{13}{5}\\) mains à \\(5\\) coeurs. La probabilité de tirer \\(5\\) coeurs est donc \\(\\frac{\\binom{13}{5}}{\\binom{52}{5}}\\). 2. Le nombre de façons de tirer \\(2\\) piques et \\(3\\) coeurs est \\(\\binom{8}{2}\\times\\binom{8}{3}\\). La probabilité d’un tel tirage est donc \\(\\frac{\\binom{8}{2}\\times\\binom{8}{3}}{\\binom{52}{5}}\\). 3. Les événements obtenir 5 trèfles et obtenir 5 coeurs étant incompatibles, la probabilité que l’un ou l’autre soit réalisé est la somme des probabilités, soit \\(\\frac{\\binom{13}{5}}{\\binom{52}{5}}+\\frac{\\binom{13}{5}}{\\binom{52}{5}}=\\frac{2\\,\\binom{13}{5}}{\\binom{52}{5}}\\). 4. Avec le même raisonnement qu’à la question 3., la probabilité d’avoir \\(5\\) cartes de la même couleur est \\(\\frac{4\\,\\binom{13}{5}}{\\binom{52}{5}}\\). 5. choisir deux couleurs parmi quatre : \\(A_4^2\\) possibilités (l’ordre des couleurs compte, puisque les nombres de cartes de chaque couleur sont différents) ; pour une couleur choisir \\(3\\) cartes : \\(\\binom{13}{3}\\) possibilités ; pour l’autre couleur choisir \\(2\\) cartes : \\(\\binom{13}{2}\\) possibilités. Donc, en vertu du principe mulitplicatif, il y a \\(\\binom{4}{2}\\times\\binom{13}{3}\\times\\binom{13}{2}\\) mains de \\(5\\) cartes, avec \\(3\\) cartes d’une couleur et \\(2\\) cartes d’une autre. La probabilité d’un tel tirage est donc égale à \\(\\frac{\\binom{4}{2}\\times\\binom{13}{3}\\times\\binom{13}{2}}{\\binom{52}{5}}\\). 6. choisir les quatre as : une seule possibilité ; choisir n’importe quelle carte parmi les \\(48\\) cartes restantes : \\(48\\) possibilités. Donc, la probabilité de tirer les quatre as et une autre carte (quelconque) est égale à \\(\\frac{48}{\\binom{13}{5}}\\). Exercice 2.2. On s’intéresse à une famille et on considère les événements suivants : \\(A\\) : la famille a des enfants des deux sexes \\(B\\) : la famille a au plus un garçon 1. Démontrer que si la famille a deux enfants, alors \\(A\\) et \\(B\\) sont dépendants. 2. Démontrer que si la famille a trois enfants, alors \\(A\\) et \\(B\\) sont indépendants. Solution. On suppose que la probabilité d’avoir une fille et celle d’avoir un garçon sont égales à \\(\\frac{1}{2}\\). On note \\(G_i\\) l’événement : l’enfant numéro \\(i\\) est un garçon ; \\(F_i\\) l’événement : l’enfant numéro \\(i\\) est une fille. 1. On vérifie facilement que \\(A\\cap B=A=(F_1\\cap G_2)\\cup (F_2\\cap G_1)\\). Il s’agit d’une réunion disjointe de deux événements de probabilité commune \\(\\frac{1}{4}\\), donc \\(\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)=\\frac{1}{2}\\). Comme \\(\\mathbb{P}(B)&gt;0\\), on en déduit que \\(\\mathbb{P}(A\\cap B)\\neq\\mathbb{P}(A)\\mathbb{P}(B)\\), et donc \\(A\\) et \\(B\\) sont dépendants. 2. \\(\\overline{A}=(F_1\\cap F_2\\cap F_3)\\cup(G_1\\cap G_2\\cap G_3)\\) donc \\[\\mathbb{P}(A)=1-\\mathbb{P}(F_1\\cap F_2\\cap F_3)-\\mathbb{P}(G_1\\cap G_2\\cap G_3)=1-\\frac{1}{8}-\\frac{1}{8}=\\frac{3}{4}\\] \\(\\overline{B}=(F_1\\cap F_2\\cap F_3)\\cup(G_1\\cap F_2\\cap F_3)\\cup (G_1\\cap F_2\\cap F_3)\\cup (G_1\\cap F_2\\cap F_3)\\).Il s’agit d’une réunion disjointe de quatre événements de probabilité commune \\(\\frac{1}{8}\\) donc \\(\\mathbb{P}(\\overline{B})=\\frac{4}{8}=\\frac{1}{2}\\). D’où \\(\\mathbb{P}(B)=\\frac{1}{2}\\). \\(A\\cap B=(G_1\\cap F_2\\cap F_3)\\cup (F_1\\cap G_2\\cap F_3)\\cup (F_1\\cap F_2\\cap G_3)\\). Il s’agit d’une réunion disjointe de trois événements de probabilité commune \\(\\frac{1}{8}\\). Donc, \\(\\mathbb{P}(A\\cap B)=\\frac{3}{8}=\\mathbb{P}(A)\\mathbb{P}(B)\\). Les événements \\(A\\) et \\(B\\) sont donc indépendants. Exercice 2.3 (coefficients binomiaux). 1. Soit \\(1\\leq p\\leq n\\). On considère \\(n\\) boules et deux boîtes \\(A\\) et \\(B\\) vides. Un échantillon est constitué d’une boule que l’on met dans la boîte \\(A\\) et \\(p-1\\) boules que l’on met dans la boîte \\(B\\). En dénombrant de deux façons différentes l’ensemble de tous les échantillons que l’on peut ainsi obtenir, établir la formule \\[n\\binom{n-1}{p-1}=p\\binom{n}{p}\\] Démontrer cette formule par le calcul. 2. Démontrer que pour \\(1\\leq p\\leq n\\) on a la formule \\[\\sum\\limits_{k=p}^n\\binom{k}{p}=\\binom{n+1}{p+1}\\] 3. (Extension de la formule de Pascal). Soient \\(m, p, q\\) des entiers naturels tels que \\(q\\leq p\\leq m\\). Démontrer par un dénombrement la formule : \\[\\sum\\limits_{j=0}^q \\binom{q}{j}\\binom{m-q}{p-j}=\\binom{m}{p}\\] 4. Soit \\(n\\) un entier tel que \\(n\\geq 1\\). Démontrer par un dénombrement la formule : \\[\\sum\\limits_{k=0}^n \\binom{n}{k}^2=\\binom{2n}{n}\\] Solution. 1. Première méthode de dénombrement des échantillons : choisir une boule à mettre dans la boîte \\(A\\) : \\(n\\) choix possibles ; choisir \\(p-1\\) boules parmi les \\(n-1\\) boules restantes, à mettre dans la boîte \\(B\\) : \\(\\binom{n-1}{p-1}\\) choix possibles. En appliquant le principe multiplicatif, on en déduit qu’il y a donc \\(n\\times\\binom{n-1}{p-1}\\) échantillons. Deuxième méthode de dénombrement des échantillons : choisir \\(p\\) boules parmi \\(n\\) boules à mettre dans l’ensemble des deux boîtes \\(A\\) et \\(B\\) : \\(\\binom{n}{p}\\) choix possibles ; choisir une boule parmi ces \\(p\\) boules à mettre dans la boîte \\(A\\) (les autres vont ditrectement dans la boîte \\(B\\)) : \\(p\\) choix possibles. En appliquant le principe multiplicatif, on en déduit qu’il y a donc \\(p\\times\\binom{n}{p}\\) échantillons. Ces deux méthodes comptent le même nombre d’échantillons. On en déduit que \\[n\\times\\binom{n-1}{p-1}=p\\times\\binom{n}{p}\\] Approche calculatoire. On peut démontrer cette formule par le calcul (c’est plus simple mais moins élégant) : \\[\\begin{align} n\\times\\binom{n-1}{p-1} &amp;= n\\frac{(n-1)!}{(p-1)!(n-p)!} \\\\ &amp;= \\frac{n!}{(p-1)!(n-p)!} \\\\ &amp;=p\\frac{n!}{p!(n-p)!} \\\\ &amp;=p\\times\\binom{n}{p} \\\\ \\end{align}\\] 2. On choisit \\(p+1\\) nombres parmi les entiers \\(1,2,\\dots,n+1\\) : \\(\\binom{n+1}{p+1}\\) choix possibles. On peut aussi dénombrer le nombre de choix possibles de la manière suivante : fixer le maximum \\(k\\) des \\(p+1\\) nombres tirés : ce maximum est nécessairement compris entre \\(p+1\\) et \\(n+1\\) (inclus) ; choisir les \\(p\\) nombres restants parmi \\(1,2,\\dots, k-1\\) : à \\(k\\) fixé, on a \\(\\binom{p}{k-1}\\) choix possibles. On en déduit que le nombre de façons de choisir \\(p+1\\) nombres parmi les entiers \\(1,2,\\dots n+1\\) est égal à \\(\\sum\\limits_{k=p+1}^{n+1}\\binom{p}{k-1}=\\sum\\limits_{k=p}^n\\binom{p}{k}\\). Ces deux méthodes de dénombrement doivent mener au même résultat, donc \\[\\sum\\limits_{k=p}^n\\binom{p}{k}=\\binom{n+1}{p+1}\\] 3. On choisit \\(p\\) entiers parmi les entiers \\(1,2,\\dots,m\\) : \\(\\binom{m}{p}\\) choix possbles. Pour choisir ces \\(p\\) entiers on peut aussi procéder de la manière suivante : on choisit \\(j\\) entiers parmi les entiers \\(1,2,\\dots,q\\). Cela n’est évidemment possible que pour \\(0\\leq j\\leq q\\), et pour chaque entier \\(j\\) vérifiant cet encadrement on a \\(\\binom{q}{j}\\) façons différentes de choisir ces \\(j\\) entiers. on complète notre sélection en choisissant les \\(p-j\\) entiers restants parmi \\(q+1,q+2,\\dots, m\\) : \\(\\binom{m-q}{p-j}\\) choix possibles. En vertu du principe multiplicatif, à \\(j\\) fixé compris entre \\(0\\) et \\(q\\) inclus, on a donc \\(\\binom{q}{j}\\binom{m-q}{p-j}\\) façons de choisir \\(p\\) entiers parmi \\(1,2,\\dots m\\) de sorte que \\(j\\) de ces entiers soient compris entre \\(1\\) et \\(q\\) et les \\(p-j\\) entiers restants soient compris entre \\(q+1\\) et \\(m\\). Par ailleurs, l’entier \\(j\\) peut prendre n’importe quelle valeur comprise entre \\(0\\) et \\(q\\), et pour deux valeurs de \\(j\\) distinctes on a deux sélections d’entiers distinctes. En vertu du principe additif, le nombre de façons de choisir \\(p\\) entiers parmi \\(1,2,\\dots, q\\) est donc finalement égal à \\(\\sum\\limits_{j=0}^q \\binom{q}{j}\\binom{m-q}{p-j}\\). On a dénombré de deux façons différentes le même ensemble, ces deux approches doivent aboutir au même résultat. On a donc \\[\\sum\\limits_{j=0}^q \\binom{q}{j}\\binom{m-q}{p-j}=\\binom{m}{p}\\] 4. On applique la formule de la question précédente avec \\(q=n\\), \\(p=n\\) et \\(m=2n\\) : \\[\\sum\\limits_{k=0}^n \\binom{n}{k}\\binom{n}{n-k}=\\binom{2n}{n}\\] Par la formule de symétrie des coefficients binomiaux \\(\\binom{n}{n-k}=\\binom{n}{k}\\), on en déduit que \\[\\sum\\limits_{k=0}^n \\binom{n}{k}^2=\\binom{2n}{n}\\] Exercice 2.4 (Interne, 2023). Montrer que pour tout entier naturel \\(n\\), on a \\(\\sum\\limits_{k=0}^n\\binom{2n+1}{k}=\\sum\\limits_{k=0}^n\\binom{2n+1}{n+k+1}\\), et calculer la valeur commune de ces sommes. b. Montrer que pour tout entier naturel non nul \\(n\\), on a \\(\\sum\\limits_{k=0}^{n-1}\\binom{2n}{k}=\\sum\\limits_{k=1}^n\\binom{2n}{n+k}=2^{2n-1}-\\frac{1}{2}\\binom{2n}{n}\\). c. Déduire de ce qui précède le résultat suivant : \\(\\forall n\\in\\mathbb{N}^{*}, \\sum\\limits_{k=1}^n k\\binom{2n}{n+k}=\\frac{n}{2}\\binom{2n}{n}\\). Solution. 1. \\[\\begin{align} \\sum\\limits_{k=0}^n\\binom{2n+1}{k}&amp;=\\sum\\limits_{k=0}^n\\binom{2n+1}{n-k} \\\\ &amp; \\text{(changement de variable } k\\mapsto n-k \\text{)} \\\\ &amp;=\\sum\\limits_{k=0}^n\\binom{2n+1}{(2n+1)-(n-k)} \\\\ &amp; \\text{(symétrie des coefficients binomiaux : } \\binom{n}{k}=\\binom{n}{n-k} \\text{)} \\\\ &amp;=\\sum\\limits_{k=0}^n\\binom{2n+1}{n+k+1} \\\\ \\end{align}\\] On pose \\(S_n:=\\sum\\limits_{k=0}^n\\binom{2n+1}{k}\\). On a donc \\[\\begin{align} 2S_n&amp;=\\sum\\limits_{k=0}^n\\binom{2n+1}{k}+\\sum\\limits_{k=0}^n\\binom{2n+1}{n+k+1} \\\\ &amp;=\\sum\\limits_{k=0}^{2n+1}\\binom{2n+1}{k} \\\\ &amp;=2^{2n+1} \\\\ \\end{align}\\] D’où : \\[S_n=2^{2n}\\] 2. L’égalité \\(\\sum\\limits_{k=0}^{n-1}\\binom{2n}{k}=\\sum\\limits_{k=1}^n\\binom{2n}{n+k}\\) se démontre de façon tout à fait analogue. On note \\(S&#39;_n\\) la valeur commune de ces deux sommes. Alors \\[\\begin{align} 2S&#39;_n &amp;= \\sum\\limits_{k=0}^{n-1}\\binom{2n}{k}+\\sum\\limits_{k=1}^n\\binom{2n}{n+k} \\\\ &amp;= \\sum\\limits_{k=0}^{2n}\\binom{2n}{k}-\\binom{2n}{n} \\\\ &amp;= 2^{2n}-\\binom{2n}{n} \\\\ \\end{align}\\] On en déduit que \\[S&#39;_n=2^{2n-1}-\\frac{1}{2}\\binom{2n}{n}\\] 3. Pour tout réel \\(x\\), on a d’après la formule du binôme de Newton \\((1+x)^{2n}=\\sum\\limits_{k=0}^{2n}\\binom{2n}{k}x^k\\). En dérivant par rapport à \\(x\\) on obtient donc \\[2n(1+x)^{2n-1}=\\sum\\limits_{k=1}^{2n}k\\binom{2n}{k}x^{k-1}\\] On évalue cette égalité en \\(x=1\\) : \\[n2^{2n}=\\sum\\limits_{k=1}^{2n}k\\binom{2n}{k}\\] D’où \\[\\begin{align} n2^{2n}&amp;=\\sum\\limits_{k=1}^{n}k\\binom{2n}{k}+\\sum\\limits_{k=n+1}^{2n}k\\binom{2n}{k} \\\\ &amp;=\\sum\\limits_{k=1}^{n}k\\binom{2n}{k}+\\sum\\limits_{k=1}^{n}(n+k)\\binom{2n}{n+k} \\\\ &amp;=\\sum\\limits_{k=1}^{n}k\\binom{2n}{k}+n\\sum\\limits_{k=1}^{n}\\binom{2n}{n+k}+\\sum\\limits_{k=1}^{n}k\\binom{2n}{n+k} \\\\ &amp;=\\sum\\limits_{k=1}^{n}k\\binom{2n}{k}+n\\left(2^{2n-1}-\\frac{1}{2}\\binom{2n}{n}\\right)+\\sum\\limits_{k=1}^{n}k\\binom{2n}{n+k} \\end{align}\\] d’après 2. Par ailleurs, on a facilement \\[k\\binom{2n}{k}=2n\\binom{2n-1}{k-1}\\] D’où \\[\\begin{align} \\sum\\limits_{k=1}^n k\\binom{2n}{k}&amp;=2n\\sum\\limits_{k=1}^n \\binom{2n-1}{k-1} \\\\ &amp;= 2n\\sum\\limits_{k=0}^{n-1}\\binom{2n-1}{k} \\\\ &amp;= n2^{2n-1} \\\\ \\end{align}\\] Ainsi \\[n2^{2n}=n2^{2n-1}+n2^{2n-1}-\\frac{n}{2}\\binom{2n}{n}+\\sum\\limits_{k=1}^n k\\binom{2n}{n+k}\\] et donc \\[\\sum\\limits_{k=1}^n k\\binom{2n}{n+k}=\\frac{n}{2}\\binom{2n}{n}\\] Exercice 2.5 (Interne, 2012). On considère trois événements \\(A, B, C\\) d’un espace probabilisé tels que \\[\\mathbb{P}(A)=0,4 \\hspace{1cm} \\mathbb{P}(B)=0,2 \\hspace{1cm} \\mathbb{P}(C)=0,3\\] \\[\\mathbb{P}(A\\cap B)=0,2 \\hspace{1cm} \\mathbb{P}(A\\cap C)=0,12 \\hspace{1cm} \\mathbb{P}(B\\cap C)=0\\] 1. Parmi les événements \\(A, B\\) et \\(C\\), quels sont les deux événements indépendants ? 2. La réalisation de l’un des trois événements implique la réalisation de l’un des deux autres. De quel événement s’agit-il ? 3. Déterminer la probabilité \\(\\mathbb{P}(A\\cap B\\cap C)\\). 4. Calculer la probabilité qu’au moins l’un des événements \\(A, B, C\\) se réalise. 5. On considère maintenant l’expérience aléatoire pour laquelle les événements \\(A, B\\) ou \\(C\\), et seulement eux, peuvent se réaliser. On note \\(X\\) le nombre d’événements qui se sont réalisés, parmi \\(A, B, C\\). Pour quelles valeurs de \\(i\\) a-t-on \\(\\mathbb{P}(X=i)&gt;0\\) ? Pour chacune de ces valeurs \\(i\\), déterminer \\(\\mathbb{P}(X=i)\\). Solution. 1. \\(\\mathbb{P}(A\\cap C)=\\mathbb{P}(A)\\mathbb{P}(C)=0,12\\), donc \\(A\\) et \\(C\\) sont indépendants. 2. \\(\\mathbb{P}(A\\vert B)=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}=\\frac{0,2}{0,2}=1\\), donc sachant que \\(B\\) est réalisé, \\(A\\) est réalisé avec probabilité \\(1\\). 3. \\(A\\cap B\\cap C\\subset B\\cap C\\), et \\(\\mathbb{P}(B\\cap C)=0\\). D’après la propriété de croissance des probabilités, on en déduit que \\(\\mathbb{P}(A\\cap B\\cap C)=0\\). 4. On veut calculer \\(\\mathbb{P}(A\\cup B\\cup C)\\). On peut utiliser la formule de Poincaré : \\[\\begin{align} \\mathbb{P}(A\\cup B\\cup C)&amp;=\\mathbb{P}(A)+\\mathbb{P}(B)+\\mathbb{P}(C)-\\mathbb{P}(A\\cap B)-\\mathbb{P}(A\\cap C)-\\mathbb{P}(B\\cap C)+\\mathbb{P}(A\\cap B\\cap C) \\\\ &amp;=0,4+0,2+0,3-0,2-0,12-0+0 \\\\ &amp;=0,58 \\\\ \\end{align}\\] 5. Remarquons d’abord qu’a priori \\(X\\in\\{0,1,2,3\\}\\). Par ailleurs : \\[A\\cup B\\cup C=(X\\geq 1)\\] \\[A\\cap B\\cap C=(X=3)\\] On en déduit que \\[\\mathbb{P}(X=0\\vert A\\cup B\\cup C)=\\mathbb{P}(X=0\\vert X\\geq 1)=0\\] et, d’après 3 : \\[\\mathbb{P}(X=3\\vert A\\cup B\\cup C)=\\frac{\\mathbb{P}(X=3, X\\geq 1)}{\\mathbb{P}(X\\geq 1)}=\\frac{\\mathbb{P}(X=3)}{\\mathbb{P}(X\\geq 1)}=\\frac{\\mathbb{P}(A\\cap B\\cap C)}{\\mathbb{P}(X\\geq 1)}=0\\] De plus \\[\\begin{align} \\mathbb{P}(X=2\\vert A\\cup B\\cup C)&amp;=\\frac{\\mathbb{P}(X=2\\vert X\\geq 1)}{\\mathbb{P}(X\\geq 1)} \\\\ &amp;=\\frac{\\mathbb{P}(X=2, X\\geq 1)}{\\mathbb{P}(X\\geq 1)} \\\\ &amp;=\\frac{\\mathbb{P}(X=2)}{\\mathbb{P}(X\\geq 1)} \\text{ ; car } (X=2)\\subset (X\\geq 1) \\\\ &amp;=\\frac{\\mathbb{P}(A\\cap B\\cap\\overline{C})+\\mathbb{P}(A\\cap \\overline{B}\\cap C)+\\mathbb{P}(\\overline{A}\\cap B\\cap C)}{\\mathbb{P}(X\\geq 1)} \\\\ &amp;=\\frac{\\mathbb{P}(A\\cap B)+\\mathbb{P}(A\\cap C)+\\mathbb{P}(B\\cap C)}{\\mathbb{P}(X\\geq 1)} \\text{ ; car } \\mathbb{P}(A\\cap B\\cap C)=0 \\\\ &amp;=\\frac{0,32}{0,58} \\\\ &amp;=\\frac{16}{29} \\\\ \\end{align}\\] On en déduit enfin que \\[\\begin{align} \\mathbb{P}(X=1\\vert A\\cup B\\cup C)&amp;=\\mathbb{P}(X\\geq 1\\vert A\\cup B\\cup C)-\\mathbb{P}(X=2\\vert A\\cup B\\cup C)-\\mathbb{P}(X=3\\vert A\\cup B\\cup C) \\\\ &amp;= \\frac{0,58}{0,29}-\\frac{0,32}{0,29}-0 \\\\ &amp;= \\frac{0,26}{0,39} \\\\ &amp;=\\frac{2}{3} \\\\ \\end{align}\\] Commentaire sur cette dernière question. Il s’agit typiquement du genre de question qui peut facilement devenir assez chronophage si l’on n’est pas un peu astucieux. Il y a plusieurs astuces / points à ne pas manquer pour s’économiser du temps de calcul : bien traduire \\((X\\geq 1)\\) par \\(A\\cup B\\cup C\\) et \\(X=3\\) par \\(A\\cap B\\cap C\\). constater que le calcul de \\(\\mathbb{P}(X=1\\vert A\\cup B\\cup C)\\) et \\(\\mathbb{P}(X=2\\vert A\\cup B\\cup C)\\) se ramène en fait au calcul d’un seul de ces deux termes. Pour voir cela, il faut penser à utiliser l’égalité \\(\\mathbb{P}(X\\geq 1\\vert A\\cup B\\cup C)=\\mathbb{P}(X=1\\vert A\\cup B\\cup C)+\\mathbb{P}(X=2\\vert A\\cup B\\cup C)\\) qui résulte de \\(\\mathbb{P}(X=3\\vert A\\cup B\\cup C)=0\\). remarquer que \\(\\mathbb{P}(X=1\\vert A\\cup B\\cup C)\\) est plus rapide à calculer que \\(\\mathbb{P}(X=2\\vert A\\cup B\\cup C)\\). Pour s’en convaincre, il suffit de calculer directement \\(\\mathbb{P}(X=2\\vert A\\cup B\\cup C)\\) : cela n’a rien de difficile, mais c’est plus long. Exercice 2.6 (Interne, 2011). 1. Soit \\(\\Omega\\) un ensemble fondamental tel que \\(\\Omega=A_1\\cup A_2\\), où les \\(A_i\\) (\\(i=1,2\\)) sont des événements donnés. On suppose \\(\\Omega\\) muni d’une probabilité \\(\\mathbb{P}\\) telle que \\(\\mathbb{P}(A_1)=0,8\\) et \\(\\mathbb{P}(A_2)=0,5\\). Donner la valeur de \\(\\mathbb{P}(A_1\\cap A_2)\\). 2. Un individu oublie sa carte bancaire 10 % du temps, son chéquier 5 % du temps et ces deux instruments de paiement 2 % du temps. Calculer : la probabilité pour que, à un moment donné, il détienne ces deux instruments sur lui ; la probabilité qu’il trouve sa carte bancaire dans ses poches sachant qu’il a déjà trouvé son chéquier. 3. Une automobile est classée comme étant “de luxe” si son moteur possède au moins 6 cylindres ou une cylindrée d’au moins 3 litres. On observe que 15 % des véhicules ont au moins 6 cylindres, que 10 % au moins 3 litres de cylindrées et que 80 % des véhicules d’au moins 3 litres ont au moins 6 cylindres. Calculer la proportion de véhicules de luxe dans le parc automobile. 4. Soient \\(\\Omega\\) un ensemble fondamental et \\(A\\) et \\(B\\) deux parties de \\(\\Omega\\). Montrer que \\[\\mathbb{P}(A\\cap B)\\leq\\mathbb{P}(A)\\leq\\mathbb{P}(A\\cup B)\\leq\\mathbb{P}(A)+\\mathbb{P}(B)\\] 5. Soient \\(A\\) et \\(B\\) deux événements indépendants en probabilité et tels que \\(\\mathbb{P}(B)=2\\,\\mathbb{P}(A)\\) et \\(\\mathbb{P}(A\\cup B)=5/8\\). Calculer \\(\\mathbb{P}(A)\\) et \\(\\mathbb{P}(B)\\). 6. Chaque jour ouvrable de la semaine, le professeur Statys reçoit du courrier au collège avec une probabilité de \\(1/3\\). Par ailleurs, il a annoncé qu’il viendra aujourd’hui avec une probabilité de \\(2/5\\). Or, on observe que sa boite aux lettres est vide. Sachant cela, calculer la probabilité que Statys soit venu aujourd’hui. 7.a. Démontrer que l’on peut généraliser (une récurrence est indiquée) la formule de base \\[\\mathbb{P}(A_1\\cup A_2)=\\mathbb{P}(A_1)+\\mathbb{P}(A_2)-\\mathbb{P}(A_1\\cap A_2)\\] au cas de \\(N\\) événements \\(A_n\\) (\\(n=1\\dots N\\)), autrement dit \\[\\begin{align} \\mathbb{P}(A_1\\cup\\dots A_n)&amp;=\\sum\\limits_{n=1}^N\\mathbb{P}(A_n)-\\sum\\limits_{i&lt;j}\\mathbb{P}(A_i\\cap A_j)+\\sum\\limits_{i&lt;j&lt;k}\\mathbb{P}(A_i\\cap A_j\\cap A_k) \\\\ &amp; +\\dots+(-1)^{N-1}\\mathbb{P}\\left(\\bigcap\\limits_{n=1}^N A_n\\right) \\\\ \\end{align}\\] b. Que se passe-t-il : si la suite \\((A_n)_{n=1\\dots N}\\) est emboitée de façon décroissante (\\(A_1\\supset A_2\\supset\\dots\\supset A_N\\)) ? si la suite \\((A_n)_{n=1\\dots N}\\) est emboitée de façon croissante (\\(A_1\\subset A_2\\subset\\dots\\subset A_N\\)) ? Solution. 1. \\(\\mathbb{P}(A_1\\cup A_2)=\\mathbb{P}(A_1)+\\mathbb{P}(A_2)-\\mathbb{P}(A_1\\cap A_2)=0,8+0,5-1=0,3\\). 2. On note \\(A\\) et \\(B\\) les événements \\(A\\) : l’individu a sa carte bancaire \\(B\\) : l’individu a son chéquier On doit donc déterminer \\(\\mathbb{P}(A\\cap B)\\) et \\(\\mathbb{P}(A\\vert B)\\). On a : \\[\\begin{align} \\mathbb{P}(A\\cap B)&amp;=1-\\mathbb{P}(\\overline{A}\\cup\\overline{B}) \\\\ &amp;=1-\\left(\\mathbb{P}(\\overline{A})+\\mathbb{P}(\\overline{B})-\\mathbb{P}(\\overline{A}\\cap\\overline{B})\\right) \\\\ &amp;=0,87 \\end{align}\\] et \\[\\begin{align} \\mathbb{P}(A\\vert B)&amp;=\\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)} \\\\ &amp;= \\frac{\\mathbb{P}(A\\cap B)}{1-\\mathbb{P}(\\overline{B})} \\\\ &amp;= \\frac{0,87}{1-0,05} \\\\ &amp;\\approx 0,92 \\\\ \\end{align}\\] 3. On note : \\((N\\geq 6)\\) l’événement : la voiture a au moins \\(6\\) cylindres ; \\((C\\geq 3)\\) l’événement : la voiture a une cylindrée d’au moins \\(3\\) litres ; \\(L\\) l’événement : la voiture est un véhicule de luxe. On a donc \\(L=(N\\geq 6)\\cup (C\\geq 3)\\), et \\[\\begin{align} \\mathbb{P}(L)&amp;=\\mathbb{P}\\left((N\\geq 6)\\cup (C\\geq 3)\\right) \\\\ &amp;= \\mathbb{P}(N\\geq 6)+\\mathbb{P}(C\\geq 3)-\\mathbb{P}(N\\geq 6, C\\geq 3) \\\\ &amp;= \\mathbb{P}(N\\geq 6)+\\mathbb{P}(C\\geq 3)-\\mathbb{P}(N\\geq 6\\vert C\\geq 3)\\mathbb{P}(C\\geq 3) \\\\ &amp;= 0,15+0,10-0,80\\times 0,10 \\\\ &amp;= 0,17 \\\\ \\end{align}\\] La proportion de véhicules de luxe dans le parc automobile est donc égale à \\(17\\,\\%\\). 4. \\((A\\cap B)\\subset A\\subset (A\\cup B)\\) donc \\(\\mathbb{P}(A\\cap B)\\leq\\mathbb{P}(A)\\leq\\mathbb{P}(A\\cup B)\\). De plus, \\(\\mathbb{P}(A\\cup B)=\\mathbb{P}(A)+\\mathbb{P}(B)-\\mathbb{P}(A\\cap B)\\leq\\mathbb{P}(A)+\\mathbb{P}(B)\\), d’où le résultat. 5. Par indépendance de \\(A\\) et \\(B\\) et étant donné la relation \\(\\mathbb{P}(B)=2\\mathbb{P}(A)\\), on a \\[\\begin{align} \\frac{5}{8}&amp;= \\mathbb{P}(A\\cup B) \\\\ &amp;=\\mathbb{P}(A)+\\mathbb{P}(B)-\\mathbb{P}(A\\cap B) \\\\ &amp;=\\mathbb{P}(A)+\\mathbb{P}(B)-\\mathbb{P}(A)\\mathbb{P}(B) \\\\ &amp;=3\\mathbb{P}(A)-2\\mathbb{P}(A)^2 \\\\ \\end{align}\\] Posons \\(x=\\mathbb{P}(A)\\). Alors, \\(x\\) est solution de l’équation \\[3x-2x^2=\\frac{5}{8}\\] soit \\[16x^2-24x+5=0\\] Il s’agit d’une équation du second degré, qui admet deux racines réelles : \\[x_1=\\frac{1}{4} \\text{ et } x_2=\\frac{5}{4}\\] Comme \\(\\frac{5}{4}&gt;1\\), on en déduit que \\(\\mathbb{P}(A)=\\frac{1}{4}\\), et donc \\(\\mathbb{P}(B)=\\frac{1}{2}\\). 6. La question a été posée telle quelle lors des écrits du concours interne de 2011. Toutefois, l’énoncé ne semble pas très clair, et en l’état il semble difficile de répondre. On peut commencer par noter \\(V\\) et \\(C\\) les événements \\(V\\) : M.Statys vient au collège ; \\(C\\) : M.Statys reçoit du courrier. On veut calculer \\(\\mathbb{P}(V\\vert \\overline{C})\\) : \\[\\begin{align} \\mathbb{P}(V\\vert\\overline{C})&amp;=\\frac{\\mathbb{P}(V\\cap\\overline{C})}{\\mathbb{P}(\\overline{C})} \\\\ &amp;=\\frac{\\mathbb{P}(V)-\\mathbb{P}(V\\cap C)}{1-\\mathbb{P}(C)} \\\\ \\end{align}\\] On connaît \\(\\mathbb{P}(V)\\) et \\(\\mathbb{P}(C)\\), mais pas \\(\\mathbb{P}(V\\cap C)\\). Cette probabilité n’est pas donnée dans l’énoncé, et sa détemination semble impossible en l’absence d’hypothèse supplémentaire… Voici deux hypothèses que l’on pourrait envisager, et leurs conséquences sur le calcul de \\(\\mathbb{P}(V\\vert\\overline{C})\\) : Hypothèse 1 : \\(V\\) et \\(C\\) sont indépendants. Dans ce cas, \\(V\\) et \\(\\overline{C}\\) aussi sont indépendants, et l’exercice devient trivial : \\(\\mathbb{P}(V\\vert\\overline{C})=\\mathbb{P}(V)=\\frac{2}{5}\\). Hypothèse 2 : \\(C\\subset V\\). On peut imaginer - mais c’est un peu tiré par les cheveux - que l’expression M. Statys reçoit du courrier comme M. Statys ouvre son courrier. Dans ce cas, pas le choix : s’il ouvre son courrier (le jour où il le reçoit), c’est qu’il est présent ! Et donc on a bien \\(C\\subset V\\). Alors \\[\\begin{align} \\mathbb{P}(V\\vert\\overline{C})&amp;=\\frac{\\mathbb{P}(V)-\\mathbb{P}(V\\cap C)}{1-\\mathbb{P}(C)} \\\\ &amp;=\\frac{\\mathbb{P}(V)-\\mathbb{P}(C)}{1-\\mathbb{P}(C)} \\\\ &amp;=\\frac{\\frac{2}{5}-\\frac{1}{3}}{1-\\frac{1}{3}} \\\\ &amp;=\\frac{1}{10} \\\\ \\end{align}\\] L’hypothèse \\(2\\) me semble plus crédible que l’hypothèse \\(1\\), peut-être est-ce ainsi qu’il fallait interpréter l’énoncé ? 7.a. Voir cours. b. Si la suite \\((A_n)_{1\\leq n\\leq N}\\) est décroissante, alors \\(\\bigcup\\limits_{n=1}^N A_n=A_1\\), et donc dans le membre de droite de la formule de Poincaré, toutes les probablités s’annulent après simplification, sauf \\(\\mathbb{P}(A_1)\\). De même, si la suite \\((A_n)_{1\\leq n\\leq N}\\) est croissante, alors \\(\\bigcup\\limits_{n=1}^N A_n=A_N\\), et donc dans le membre de droite de la formule de Poincaré, toutes les probablités s’annulent après simplification, sauf \\(\\mathbb{P}(A_N)\\). Exercice 2.7 (Interne, 2012). On considère une population dont les individus sont susceptibles de présenter une maladie \\(\\mathcal{M}\\). Pour chaque individu de la population considérée, on envisage trois facteurs de risque possibles de cette maladie : \\(A, B\\) et \\(C\\) . Grâce à une étude statistique, on dispose des renseignements suivants : \\(\\mathbb{P}(A)=0,4 \\hspace{1cm} \\mathbb{P}(B)=0,06 \\hspace{1cm} \\mathbb{P}(A\\cap B)=0,06 \\hspace{1cm} \\mathbb{P}(A\\cap C)= 0,1\\) \\(A\\) et \\(C\\) sont indépendants \\(B\\) et \\(C\\) sont incompatibles 1. Déterminer \\(\\mathbb{P}(C)\\), \\(\\mathbb{P}(B\\cap C)\\) et \\(\\mathbb{P}(A\\cap B\\cap C)\\). 2. Calculer la probabilité pour qu’au moins un individu présente un facteur de risque. 3. On note \\(X\\) le nombre de facteurs de risque présents chez un individu. Quelles valeurs \\(X\\) peut-elle prendre ? Pour chacune de ces valeurs \\(i\\), calculer \\(\\mathbb{P}(X=i)\\). 4. On note \\(M\\) l’événement L’individu est atteint de la maladie \\(\\mathcal{M}\\). On donne les probabilités conditionelles suivantes : \\[\\mathbb{P}_{\\overline{A}}(M)=0 \\hspace{1cm} \\mathbb{P}_{A\\cap B}(M)=0,06 \\hspace{1cm} \\mathbb{P}_{A\\cap C}(M)=0,05 \\hspace{1cm} \\mathbb{P}_{A\\cap \\overline{B}\\cap\\overline{C}}(M)=0\\] a. Interpréter ces quatre valeurs. b. Calculer la probabilité \\(\\mathbb{P}(M)\\). Solution. Remarquons d’abord que cet exercice, posé lors des épreuves écrites du concours interne de 2012, est très proche dans l’esprit de l’exercice 5, lui aussi posé lors de ces épreuves ! Ce type d’exercices, de niveau lycée, est peu présent dans les sujets des précédentes années. 1. - Comme \\(A\\) et \\(C\\) sont indépendants, \\(\\mathbb{P}(C)=\\frac{\\mathbb{P}(A\\cap C)}{\\mathbb{P}(A)}=\\frac{1}{4}\\). \\(B\\cap C=\\emptyset\\), donc \\(\\mathbb{P}(B\\cap C)=0\\). \\((A\\cap B\\cap C)\\subset (B\\cap C)=\\emptyset\\), donc \\(A\\cap B\\cap C=\\emptyset\\), d’où \\(\\mathbb{P}(A\\cap B\\cap C)=0\\). 2. On calcule \\(\\mathbb{P}(A\\cup B\\cup C)\\). On utilise la formule de Poincaré : \\[\\begin{align} \\mathbb{P}(A\\cup B\\cup C) &amp;= \\mathbb{P}(A)+\\mathbb{P}(B)+\\mathbb{P}(C) \\\\ &amp; \\hspace{0.2cm} -\\mathbb{P}(A\\cap B)-\\mathbb{P}(A\\cap C)-\\mathbb{P}(B\\cap C) \\\\ &amp; \\hspace{0.2cm} + \\mathbb{P}(A\\cap B\\cap C) \\\\ &amp;= 0,4+0,06+0,25-0,06-0,1-0+0 \\\\ &amp;= 0,55 \\\\ \\end{align}\\] 3. On a a priori \\(X\\in\\{0, 1, 2, 3\\}\\). On a \\(\\mathbb{P}(X=3)=\\mathbb{P}(A\\cap B\\cap C)=0\\). \\(\\mathbb{P}(X=0)=1-\\mathbb{P}(X\\geq 1)=1-\\mathbb{P}(A\\cup B\\cup C)=1-0,55=0,45\\). Il est ensuite plus facile de calculer d’abord \\(\\mathbb{P}(X=2)\\) : \\[\\begin{align} \\mathbb{P}(X=2)&amp;=\\mathbb{P}(\\overline{A}\\cap B\\cap C)+\\mathbb{P}(A\\cap \\overline{B}\\cap C)+\\mathbb{P}(A\\cap B\\cap \\overline{C}) \\\\ &amp;= 0+\\mathbb{P}(A\\cap C)+\\mathbb{P}(A\\cap B) \\\\ &amp;= 0,16 \\\\ \\end{align}\\] et d’en déduire \\(\\mathbb{P}(X=1)\\) : \\[\\begin{align} \\mathbb{P}(X=1)&amp;=\\mathbb{P}(X\\geq 1)-\\mathbb{P}(X=2) \\text{ ; car } $\\mathbb{P}(X=3)=0$ \\\\ &amp;=0,55-0,16 \\\\ &amp;=0,39 \\\\ \\end{align}\\] 4.a. \\(\\mathbb{P}_{\\overline{A}}(M)=0\\) : si l’individu ne présente pas le facteur de risque \\(A\\), alors la probabilité qu’il soit malade est nulle. \\(\\mathbb{P}_{A\\cap B}(M)=0,06\\) : la présence simultanée des facteurs de risque \\(A\\) et \\(B\\) implique une probabilité d’être malade de \\(6\\,\\%\\). \\(\\mathbb{P}_{A\\cap C}(M)=0,05\\) : la présence simultanée des facteurs de risque \\(A\\) et \\(C\\) implique une probabilité d’être malade de \\(5\\,\\%\\). \\(\\mathbb{P}_{A\\cap \\overline{B}\\cap\\overline{C}}(M)=0\\) : si un individu présente le facteur de risque \\(A\\), mais pas les facteurs de risque \\(B\\) et \\(C\\), alors la probabilité qu’il soit malade est nulle. b. Comme \\(B\\) et \\(C\\) sont incompatibles, \\(\\{A\\cap B, A\\cap C, A\\cap\\overline{B}\\cap\\overline{C}, \\overline{A}\\}\\) est un système complet d’événements. D’après la formule des probabilités totales on a alors \\[\\begin{align} \\mathbb{P}(M)&amp;=\\mathbb{P}_{\\overline{A}}(M)\\mathbb{P}(\\overline{A})+\\mathbb{P}_{A\\cap B}(M)\\mathbb{P}(A\\cap B)+\\mathbb{P}_{A\\cap C}(M)\\mathbb{P}(A\\cap C)+\\mathbb{P}_{A\\cap\\overline{B}\\cap\\overline{C}}(M)\\mathbb{P}(A\\cap\\overline{B}\\cap\\overline{C}) \\\\ &amp;= 0+0,06\\times 0,06+0,05\\times 0,1+0 \\\\ &amp;= 0,0086 \\\\ \\end{align}\\] Exercice 2.8 (propagation d’une rumeur). Une information binaire (du type vrai/faux) se propage au sein d’une population. Lorsqu’une personne reçoit l’information : elle la retransmet telle quelle à la personne suivante avec probabilité \\(p\\) ; elle la retransmet de façon erronée à la personne suivante avec probabilité \\(1-p\\). On note \\(p_n\\) la probabilité pour que, après \\(n\\) transmissions, l’information soit correcte. On suppose que \\(p_0=1\\). 1. Donner une relation de récurrence entre \\(p_{n+1}\\) et \\(p_n\\). 2. En déduire une expression de \\(p_n\\) en fonction de \\(p\\) et de \\(n\\). 3. En déduire la valeur de \\(\\lim_{n\\to\\infty} p_n\\). Solution. On note \\(I_n\\) : l’information est correcte après \\(n\\) transmissions. On a donc \\(p_n=\\mathbb{P}(I_n)\\). 1. D’après la formule des probabilités totales : \\(\\mathbb{P}(I_{n+1})=\\mathbb{P}(I_{n+1}\\vert I_n)\\mathbb{P}(I_n)+\\mathbb{P}(I_{n+1}\\vert\\overline{I_n})\\mathbb{P}(\\overline{I_n})\\), autrement dit \\[p_{n+1}=pp_n+(1-p)(1-p_n)\\] soit encore \\[p_{n+1}=(2p-1)p_n+1-p\\] 2. On reconnait une suite arithmético-géométrique \\(p_{n+1}=ap_n+b\\), avec \\(a=2p-1\\) et \\(b=1-p\\). si \\(2p-1=1\\), autrement dit si \\(p=1\\), alors \\((p_n)_{n}\\) est une suite constante, et donc pour tout entier naturel \\(n\\) on a \\(p_n=p_0=1\\). sinon, la suite \\((p_n)_n\\) converge vers une limite \\(l\\) telle que \\(l=al+b\\), soit \\(l=\\frac{b}{1-a}=\\frac{1-p}{2(1-p)}=\\frac{1}{2}\\). On a alors \\[p_{n+1}-\\frac{1}{2}=(2p-1)\\left(p_n-\\frac{1}{2}\\right)\\] donc la suite \\((p_n-l)_n\\) est géométrique de raison \\(2p-1\\). D’où \\(p_n-l=(2p-1)^n(p_0-l)\\), et donc \\[p_n=\\frac{1}{2}+\\frac{1}{2}(2p-1)^n\\] Commentaire. Le jour du concours, vous avez tout à fait le droit d’utiliser directement la formule explicitant le terme générique d’une suite arithmético-géométrique. A minima, si (comme moi…) vous ne le connaissez pas par coeur, il faut savoir la redémontrer rapidement en utilisant la méthode ci-dessus. 3. - si \\(p=1\\), alors la suite \\((p_n)_n\\) est constante égale à 1, donc \\(\\lim\\limits_{n\\to\\infty}p_n=1\\). si \\(p=0\\), alors \\(p_n=\\frac{1}{2}(1+(-1)^n)\\). Les suites extraites \\((p_{2n})_n\\) et \\((p_{2n+1})_n\\) convergent donc respectivement vers \\(1\\) et \\(0\\) (elles sont mêmes constantes), donc la suite \\((p_n)_n\\) admet deux valeurs d’adhérence distictes : elle ne converge pas. si \\(0&lt;p&lt;1\\), alors \\(-1&lt;2p-1&lt;1\\), et donc \\(\\lim\\limits_{n\\to\\infty}(2p-1)^n=0\\) : on en déduit que \\(\\lim\\limits_{n\\to\\infty}p_n=\\frac{1}{2}\\). Remarque. Ce dernier résultat nous dit que si d’une date à la date suivante l’information n’est ni presque sûrement transmise correctement, ni presque sûrement transmise de façon erronée, alors à une date asymptotitque il y a une chance sur deux qu’elle soit vraie. Un tel résultat était prévisible, car les événements \\(I_n\\) et \\(\\overline{I_n}\\) jouent des rôles parfaitement symétriques, et il n’y a donc aucune raison que l’un des deux soit asymptotiquement plus probable que l’autre. Exercice 2.9. Le gérant d’un magasin d’informatique a reçu un lot de clés USB. 5 % des boites sont abîmées. Le gérant estime que : 60 % des boites abîmées contiennent au moins une clé défectueuse ; 98 % des boites non abîmées ne contiennent aucune clé défectueuse. Un client achète une boite du lot. On désigne par \\(A\\) l’événement : la boite est abîmée ; \\(D\\) l’événement : la boite achetée contient au moins une clé défectueuse. 1. Donner les probabilités \\(\\mathbb{P}(A)\\), \\(\\mathbb{P}(\\overline{A})\\), \\(\\mathbb{P}(D\\vert A)\\), \\(\\mathbb{P}(D\\vert\\overline{A})\\), \\(\\mathbb{P}(\\overline{D}\\vert A)\\) et \\(\\mathbb{P}(\\overline{D}\\vert\\overline{A})\\). En déduire \\(\\mathbb{P}(D)\\). 2. Le client constate qu’une des clés achetées est défectueuse. Quelle est la probabilité pour qu’il ait acheté une boite abîmée ? Solution. 1. \\(\\mathbb{P}(A)=0,05\\) ; \\(\\mathbb{P}(\\overline{A})=0,95\\) d’après ce qui précède ; \\(\\mathbb{P}(D\\vert A)=0,6\\) ; \\(\\mathbb{P}(\\overline{D}\\vert A)=0,4\\) d’après ce qui précède ; \\(\\mathbb{P}(\\overline{D}\\vert\\overline{A})=0,98\\) ; On en déduit, d’après la formule des probabilités totales et la formule de Bayes, que \\[\\begin{align} \\mathbb{P}(D)&amp;=\\mathbb{P}(D\\vert A)\\mathbb{P}(A)+\\mathbb{P}(D\\vert\\overline{A})\\mathbb{P}(\\overline{A}) \\\\ &amp;=0,6\\times 0,05+0,02\\times 0,95 \\\\ &amp;\\approx 0,049 \\\\ \\end{align}\\] 2. On veut déterminer \\(\\mathbb{P}(A\\vert D)\\). D’après la formule de Bayes : \\[\\begin{align} \\mathbb{P}(A\\vert D)&amp;=\\frac{\\mathbb{P}(D\\vert A)\\mathbb{P}(A)}{\\mathbb{P}(D)} \\\\ &amp;\\approx\\frac{0,6\\times 0,05}{0,049} \\\\ &amp;\\approx 0,61 \\\\ \\end{align}\\] Exercice 2.10 (test de dépistage). Une maladie est présente dans la population, avec une prévalence d’une personne malade sur \\(10\\,000\\). Un nouveau test de dépistage vient d’être mis au point. On constate que : lorsqu’une personne est malade, le test est positif dans \\(99\\,\\%\\) des cas ; lorsqu’une personne n’est pas malade, le test est positif dans \\(0,1\\,\\%\\) des cas. Selon vous, ce test doit-il être commercialisé ? Solution. On note \\(M\\) et \\(P\\) les événements : \\(M\\) : la personne est malade ; \\(P\\) : le test est positif. On calcule \\(\\mathbb{P}(M\\vert P)\\) avec la fomrule de Bayes : \\[\\begin{align} \\mathbb{P}(M\\vert P)&amp;=\\frac{\\mathbb{P}(P\\vert M)\\mathbb{P}(M)}{\\mathbb{P}(P\\vert M)\\mathbb{P}(M)+\\mathbb{P}(P\\vert\\overline{M})\\mathbb{P}(\\overline{M})} \\\\ &amp;= \\frac{0,99\\times 0,0001}{0,99\\times 0,0001+0,001\\times 0,9999} \\\\ &amp;\\approx 0,09 \\end{align}\\] La probabilité qu’une personne dont le test est positif soit malade est donc seulement égale à \\(9\\,\\%\\). Il faut donc éviter de commercialiser ce test. Remarque. Ce résultat qui peut paraître surprenant s’explique par le fait que la maladie étudiée est très rare (\\(1\\) cas sur \\(10\\,000\\)), et donc même en cas de test positif la probabilité que la personne soit vraiment malade reste limitée. "]]
