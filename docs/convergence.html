<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 5 Convergence | Cours de probabilités-statistiques pour le concours interne d’administrateur Insee</title>
  <meta name="description" content="Cours de probabilités et statistiques" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 5 Convergence | Cours de probabilités-statistiques pour le concours interne d’administrateur Insee" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Cours de probabilités et statistiques" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 5 Convergence | Cours de probabilités-statistiques pour le concours interne d’administrateur Insee" />
  
  <meta name="twitter:description" content="Cours de probabilités et statistiques" />
  

<meta name="author" content="Olivier Guin" />


<meta name="date" content="2024-09-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="variables-aléatoires-à-densité.html"/>
<link rel="next" href="statistique-descriptive.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Cours de probabilités et statistique pour le concours interne d'administrateur de l'Insee</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> url: your book url like https://bookdown.org/yihui/bookdown</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#généralités"><i class="fa fa-check"></i><b>1.1</b> Généralités</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#coquilles-et-erreurs"><i class="fa fa-check"></i><b>1.2</b> Coquilles et erreurs</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html"><i class="fa fa-check"></i><b>2</b> Dénombrement et probabilités</a>
<ul>
<li class="chapter" data-level="2.1" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#rappels-sur-les-opérations-ensemblistes"><i class="fa fa-check"></i><b>2.1</b> Rappels sur les opérations ensemblistes</a></li>
<li class="chapter" data-level="2.2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#dénombrement"><i class="fa fa-check"></i><b>2.2</b> Dénombrement</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#produit-cartésien-et-principe-multiplicatif"><i class="fa fa-check"></i><b>2.2.1</b> Produit cartésien et principe multiplicatif</a></li>
<li class="chapter" data-level="2.2.2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#principe-additif"><i class="fa fa-check"></i><b>2.2.2</b> Principe additif</a></li>
<li class="chapter" data-level="2.2.3" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#formule-de-poincaré"><i class="fa fa-check"></i><b>2.2.3</b> Formule de Poincaré</a></li>
<li class="chapter" data-level="2.2.4" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#dénombrement-par-bijection"><i class="fa fa-check"></i><b>2.2.4</b> Dénombrement par bijection</a></li>
<li class="chapter" data-level="2.2.5" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#permutations"><i class="fa fa-check"></i><b>2.2.5</b> Permutations</a></li>
<li class="chapter" data-level="2.2.6" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#arrangements"><i class="fa fa-check"></i><b>2.2.6</b> Arrangements</a></li>
<li class="chapter" data-level="2.2.7" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#combinaisons"><i class="fa fa-check"></i><b>2.2.7</b> Combinaisons</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#langage-et-formalisme-des-probabilités"><i class="fa fa-check"></i><b>2.3</b> Langage et formalisme des probabilités</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#lunivers-omega-dune-expérience-aléatoire"><i class="fa fa-check"></i><b>2.3.1</b> L’univers <span class="math inline">\(\Omega\)</span> d’une expérience aléatoire</a></li>
<li class="chapter" data-level="2.3.2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#lespace-probabilisable-omega-mathcala"><i class="fa fa-check"></i><b>2.3.2</b> L’espace probabilisable <span class="math inline">\((\Omega, \mathcal{A})\)</span></a></li>
<li class="chapter" data-level="2.3.3" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#lespace-probabilisé-omega-mathcala-mathbbp"><i class="fa fa-check"></i><b>2.3.3</b> L’espace probabilisé <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#indépendance"><i class="fa fa-check"></i><b>2.4</b> Indépendance</a></li>
<li class="chapter" data-level="2.5" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#probabilités-conditionnelles"><i class="fa fa-check"></i><b>2.5</b> Probabilités conditionnelles</a></li>
<li class="chapter" data-level="2.6" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#formule-des-probabilités-totales"><i class="fa fa-check"></i><b>2.6</b> Formule des probabilités totales</a></li>
<li class="chapter" data-level="2.7" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#formule-de-bayes"><i class="fa fa-check"></i><b>2.7</b> Formule de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html"><i class="fa fa-check"></i><b>3</b> Variables aléatoires discrètes</a>
<ul>
<li class="chapter" data-level="3.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#définition-et-premières-propriétés"><i class="fa fa-check"></i><b>3.1</b> Définition et premières propriétés</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#définition"><i class="fa fa-check"></i><b>3.1.1</b> Définition</a></li>
<li class="chapter" data-level="3.1.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#loi-dune-variable-aléatoire-discrète"><i class="fa fa-check"></i><b>3.1.2</b> Loi d’une variable aléatoire discrète</a></li>
<li class="chapter" data-level="3.1.3" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#calcul-de-mathbbpxin-b"><i class="fa fa-check"></i><b>3.1.3</b> Calcul de <span class="math inline">\(\mathbb{P}(X\in B)\)</span></a></li>
<li class="chapter" data-level="3.1.4" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#fonction-de-répartition"><i class="fa fa-check"></i><b>3.1.4</b> Fonction de répartition</a></li>
<li class="chapter" data-level="3.1.5" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#quantiles"><i class="fa fa-check"></i><b>3.1.5</b> Quantiles</a></li>
<li class="chapter" data-level="3.1.6" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#exemples-classiques-de-lois-discrètes"><i class="fa fa-check"></i><b>3.1.6</b> Exemples classiques de lois discrètes</a></li>
<li class="chapter" data-level="3.1.7" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#simulation-dune-variable-aléatoire-réelle"><i class="fa fa-check"></i><b>3.1.7</b> Simulation d’une variable aléatoire réelle</a></li>
<li class="chapter" data-level="3.1.8" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#moments-dune-variable-aléatoire"><i class="fa fa-check"></i><b>3.1.8</b> Moments d’une variable aléatoire</a></li>
<li class="chapter" data-level="3.1.9" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#quelques-inégalités-classiques"><i class="fa fa-check"></i><b>3.1.9</b> Quelques inégalités classiques</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#transformation-dune-variable-aléatoire-discrète"><i class="fa fa-check"></i><b>3.2</b> Transformation d’une variable aléatoire discrète</a></li>
<li class="chapter" data-level="3.3" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#vecteurs-aléatoires"><i class="fa fa-check"></i><b>3.3</b> Vecteurs aléatoires</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#couple-aléatoire-loi-conjointe-lois-marginales"><i class="fa fa-check"></i><b>3.3.1</b> Couple aléatoire : loi conjointe, lois marginales</a></li>
<li class="chapter" data-level="3.3.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#n-uplets-aléatoires"><i class="fa fa-check"></i><b>3.3.2</b> <span class="math inline">\(n-\)</span>uplets aléatoires</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#loi-conditionnelle-mathbbp_xyy_j"><i class="fa fa-check"></i><b>3.4</b> Loi conditionnelle <span class="math inline">\(\mathbb{P}_{X|Y=y_j}\)</span></a></li>
<li class="chapter" data-level="3.5" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#indépendance-de-deux-variables-aléatoires"><i class="fa fa-check"></i><b>3.5</b> Indépendance de deux variables aléatoires</a></li>
<li class="chapter" data-level="3.6" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#covariance-et-coefficient-de-corrélation-de-deux-variables-aléatoires"><i class="fa fa-check"></i><b>3.6</b> Covariance et coefficient de corrélation de deux variables aléatoires</a></li>
<li class="chapter" data-level="3.7" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#espérance-conditionnelle-mathbbeyxx"><i class="fa fa-check"></i><b>3.7</b> Espérance conditionnelle <span class="math inline">\(\mathbb{E}(Y|X=x)\)</span></a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#variance-conditionnelle"><i class="fa fa-check"></i><b>3.7.1</b> Variance conditionnelle</a></li>
<li class="chapter" data-level="3.7.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#somme-de-deux-va-indépendantes-produit-de-convolution-discret"><i class="fa fa-check"></i><b>3.7.2</b> Somme de deux VA indépendantes (produit de convolution discret)</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#annexes"><i class="fa fa-check"></i><b>3.8</b> Annexes</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#inégalité-de-cauchy-schwarz"><i class="fa fa-check"></i><b>3.8.1</b> Inégalité de Cauchy-Schwarz</a></li>
<li class="chapter" data-level="3.8.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#théorème-de-fubini-pour-les-séries-doubles"><i class="fa fa-check"></i><b>3.8.2</b> Théorème de Fubini pour les séries doubles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html"><i class="fa fa-check"></i><b>4</b> Variables aléatoires à densité</a>
<ul>
<li class="chapter" data-level="4.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#variables-aléatoires-cas-général"><i class="fa fa-check"></i><b>4.1</b> Variables aléatoires : cas général</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-générale"><i class="fa fa-check"></i><b>4.1.1</b> Définition générale</a></li>
<li class="chapter" data-level="4.1.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#loi-dune-variable-aléatoire"><i class="fa fa-check"></i><b>4.1.2</b> Loi d’une variable aléatoire</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#variables-aléatoires-réelles-continues"><i class="fa fa-check"></i><b>4.2</b> Variables aléatoires réelles continues</a></li>
<li class="chapter" data-level="4.3" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#variables-aléatoires-réelles-à-densité"><i class="fa fa-check"></i><b>4.3</b> Variables aléatoires réelles à densité</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-1"><i class="fa fa-check"></i><b>4.3.1</b> Définition</a></li>
<li class="chapter" data-level="4.3.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#fonction-de-densité"><i class="fa fa-check"></i><b>4.3.2</b> Fonction de densité</a></li>
<li class="chapter" data-level="4.3.3" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#calcul-de-mathbbpxin-i"><i class="fa fa-check"></i><b>4.3.3</b> Calcul de <span class="math inline">\(\mathbb{P}(X\in I)\)</span></a></li>
<li class="chapter" data-level="4.3.4" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#quantiles-1"><i class="fa fa-check"></i><b>4.3.4</b> Quantiles</a></li>
<li class="chapter" data-level="4.3.5" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#exemples-classiques-de-lois-à-densité"><i class="fa fa-check"></i><b>4.3.5</b> Exemples classiques de lois à densité</a></li>
<li class="chapter" data-level="4.3.6" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#moments-dune-variable-aléatoire-1"><i class="fa fa-check"></i><b>4.3.6</b> Moments d’une variable aléatoire</a></li>
<li class="chapter" data-level="4.3.7" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#quelques-inégalités-classiques-1"><i class="fa fa-check"></i><b>4.3.7</b> Quelques inégalités classiques</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#transformation-dune-variable-aléatoire-à-densité"><i class="fa fa-check"></i><b>4.4</b> Transformation d’une variable aléatoire à densité</a></li>
<li class="chapter" data-level="4.5" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#vecteurs-aléatoires-1"><i class="fa fa-check"></i><b>4.5</b> Vecteurs aléatoires</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#fonction-de-répartition-dun-couple-xy-de-variables-continues"><i class="fa fa-check"></i><b>4.5.1</b> Fonction de répartition d’un couple <span class="math inline">\((X,Y)\)</span> de variables continues</a></li>
<li class="chapter" data-level="4.5.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#couples-xy-admettant-une-densité"><i class="fa fa-check"></i><b>4.5.2</b> Couples <span class="math inline">\((X,Y)\)</span> admettant une densité</a></li>
<li class="chapter" data-level="4.5.3" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#lois-marginales"><i class="fa fa-check"></i><b>4.5.3</b> Lois marginales</a></li>
<li class="chapter" data-level="4.5.4" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#loi-conditionnelle-mathcallyx"><i class="fa fa-check"></i><b>4.5.4</b> Loi conditionnelle <span class="math inline">\(\mathcal{L}(Y|X)\)</span></a></li>
<li class="chapter" data-level="4.5.5" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#espérance-conditionnelle"><i class="fa fa-check"></i><b>4.5.5</b> Espérance conditionnelle</a></li>
<li class="chapter" data-level="4.5.6" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#loi-dun-couple-de-va-indépendantes"><i class="fa fa-check"></i><b>4.5.6</b> Loi d’un couple de VA indépendantes</a></li>
<li class="chapter" data-level="4.5.7" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#espérance-matrice-de-variance-covariance"><i class="fa fa-check"></i><b>4.5.7</b> Espérance, matrice de variance-covariance</a></li>
<li class="chapter" data-level="4.5.8" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#espérance-conditionnelle-variance-conditionnelle"><i class="fa fa-check"></i><b>4.5.8</b> Espérance conditionnelle, variance conditionnelle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="convergence.html"><a href="convergence.html"><i class="fa fa-check"></i><b>5</b> Convergence</a>
<ul>
<li class="chapter" data-level="5.1" data-path="convergence.html"><a href="convergence.html#différents-modes-de-convergence"><i class="fa fa-check"></i><b>5.1</b> Différents modes de convergence</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="convergence.html"><a href="convergence.html#convergence-en-probabilité"><i class="fa fa-check"></i><b>5.1.1</b> Convergence en probabilité</a></li>
<li class="chapter" data-level="5.1.2" data-path="convergence.html"><a href="convergence.html#convergence-dans-les-espaces-l1-et-l2"><i class="fa fa-check"></i><b>5.1.2</b> Convergence dans les espaces <span class="math inline">\(L^1\)</span> et <span class="math inline">\(L^2\)</span></a></li>
<li class="chapter" data-level="5.1.3" data-path="convergence.html"><a href="convergence.html#convergence-en-loi"><i class="fa fa-check"></i><b>5.1.3</b> Convergence en loi</a></li>
<li class="chapter" data-level="5.1.4" data-path="convergence.html"><a href="convergence.html#convergence-presque-sûre-hors-programme"><i class="fa fa-check"></i><b>5.1.4</b> Convergence presque-sûre (hors-programme ?)</a></li>
<li class="chapter" data-level="5.1.5" data-path="convergence.html"><a href="convergence.html#liens-entre-les-différents-modes-de-convergence"><i class="fa fa-check"></i><b>5.1.5</b> Liens entre les différents modes de convergence</a></li>
<li class="chapter" data-level="5.1.6" data-path="convergence.html"><a href="convergence.html#transformation-par-une-application-continue"><i class="fa fa-check"></i><b>5.1.6</b> Transformation par une application continue</a></li>
<li class="chapter" data-level="5.1.7" data-path="convergence.html"><a href="convergence.html#théorème-de-slutsky-hors-programme"><i class="fa fa-check"></i><b>5.1.7</b> Théorème de Slutsky (hors-programme ?)</a></li>
<li class="chapter" data-level="5.1.8" data-path="convergence.html"><a href="convergence.html#approximations"><i class="fa fa-check"></i><b>5.1.8</b> Approximations</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="convergence.html"><a href="convergence.html#lois-des-grands-nombres"><i class="fa fa-check"></i><b>5.2</b> Lois des grands nombres</a></li>
<li class="chapter" data-level="5.3" data-path="convergence.html"><a href="convergence.html#théorème-central-limite-tcl"><i class="fa fa-check"></i><b>5.3</b> Théorème Central Limite (TCL)</a></li>
<li class="chapter" data-level="5.4" data-path="convergence.html"><a href="convergence.html#variantes-du-tcl-hors-programme"><i class="fa fa-check"></i><b>5.4</b> Variantes du TCL (hors-programme)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html"><i class="fa fa-check"></i><b>6</b> Statistique descriptive</a>
<ul>
<li class="chapter" data-level="6.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#vocabulaire"><i class="fa fa-check"></i><b>6.1</b> Vocabulaire</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#population-individus-échantillon"><i class="fa fa-check"></i><b>6.1.1</b> Population, individus, échantillon</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#analyse-statistique-univariée"><i class="fa fa-check"></i><b>6.2</b> Analyse statistique univariée</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#notion-de-série-statistique-univariée"><i class="fa fa-check"></i><b>6.2.1</b> Notion de série statistique univariée</a></li>
<li class="chapter" data-level="6.2.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#indicateurs-dune-série-statistique-univariée"><i class="fa fa-check"></i><b>6.2.2</b> Indicateurs d’une série statistique univariée</a></li>
<li class="chapter" data-level="6.2.3" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#représentations-graphiques"><i class="fa fa-check"></i><b>6.2.3</b> Représentations graphiques</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#analyse-statistique-bivariée"><i class="fa fa-check"></i><b>6.3</b> Analyse statistique bivariée</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#notion-de-série-statistique-bivariée"><i class="fa fa-check"></i><b>6.3.1</b> Notion de série statistique bivariée</a></li>
<li class="chapter" data-level="6.3.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#indicateurs-propres-à-lanalyse-statistique-multivariée"><i class="fa fa-check"></i><b>6.3.2</b> Indicateurs propres à l’analyse statistique multivariée</a></li>
<li class="chapter" data-level="6.3.3" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#nuage-de-points"><i class="fa fa-check"></i><b>6.3.3</b> Nuage de points</a></li>
<li class="chapter" data-level="6.3.4" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#ajustement-des-moindres-carrés"><i class="fa fa-check"></i><b>6.3.4</b> Ajustement des moindres carrés</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html"><i class="fa fa-check"></i><b>7</b> Statistique inférentielle</a>
<ul>
<li class="chapter" data-level="7.1" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#estimation"><i class="fa fa-check"></i><b>7.1</b> Estimation</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#premières-définitions"><i class="fa fa-check"></i><b>7.1.1</b> Premières définitions</a></li>
<li class="chapter" data-level="7.1.2" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#convergence-dun-estimateur"><i class="fa fa-check"></i><b>7.1.2</b> Convergence d’un estimateur</a></li>
<li class="chapter" data-level="7.1.3" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#exemples-classiques"><i class="fa fa-check"></i><b>7.1.3</b> Exemples classiques</a></li>
<li class="chapter" data-level="7.1.4" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#méthodes-de-construction-des-estimateurs"><i class="fa fa-check"></i><b>7.1.4</b> Méthodes de construction des estimateurs</a></li>
<li class="chapter" data-level="7.1.5" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#compléments-hors-programme"><i class="fa fa-check"></i><b>7.1.5</b> Compléments (hors-programme)</a></li>
<li class="chapter" data-level="7.1.6" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#estimation-des-coefficients-dune-régression-linéaire"><i class="fa fa-check"></i><b>7.1.6</b> Estimation des coefficients d’une régression linéaire</a></li>
<li class="chapter" data-level="7.1.7" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#intervalles-de-confiance"><i class="fa fa-check"></i><b>7.1.7</b> Intervalles de confiance</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#tests-statistiques"><i class="fa fa-check"></i><b>7.2</b> Tests statistiques</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#définition-et-principes"><i class="fa fa-check"></i><b>7.2.1</b> Définition et principes</a></li>
<li class="chapter" data-level="7.2.2" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#tests-unilatéraux-tests-bilatéraux"><i class="fa fa-check"></i><b>7.2.2</b> Tests unilatéraux, tests bilatéraux</a></li>
<li class="chapter" data-level="7.2.3" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#exemples"><i class="fa fa-check"></i><b>7.2.3</b> Exemples</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="méthodologie.html"><a href="méthodologie.html"><i class="fa fa-check"></i><b>8</b> Méthodologie</a>
<ul>
<li class="chapter" data-level="8.1" data-path="méthodologie.html"><a href="méthodologie.html#convergence-1"><i class="fa fa-check"></i><b>8.1</b> Convergence</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="exercices.html"><a href="exercices.html"><i class="fa fa-check"></i><b>9</b> Exercices</a>
<ul>
<li class="chapter" data-level="9.1" data-path="exercices.html"><a href="exercices.html#dénombrement-et-probabilités-1"><i class="fa fa-check"></i><b>9.1</b> Dénombrement et probabilités</a></li>
<li class="chapter" data-level="9.2" data-path="exercices.html"><a href="exercices.html#variables-aléatoires-discrètes-1"><i class="fa fa-check"></i><b>9.2</b> Variables aléatoires discrètes</a></li>
<li class="chapter" data-level="9.3" data-path="exercices.html"><a href="exercices.html#variables-à-densité"><i class="fa fa-check"></i><b>9.3</b> Variables à densité</a></li>
<li class="chapter" data-level="9.4" data-path="exercices.html"><a href="exercices.html#annales-des-oraux"><i class="fa fa-check"></i><b>9.4</b> Annales des oraux</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="exercices.html"><a href="exercices.html#interne-2016"><i class="fa fa-check"></i><b>9.4.1</b> Interne, 2016</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Cours de probabilités-statistiques pour le concours interne d’administrateur Insee</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="convergence" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapitre 5</span> Convergence<a href="convergence.html#convergence" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Dans tout ce qui suit, toutes les variables aléatoires considérées sont définies sur un espace probabilisé <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span> donné, et sont à valeurs dans <span class="math inline">\(\mathbb{R}\)</span> (ou éventuellement <span class="math inline">\(\mathbb{R}^d\)</span>, avec <span class="math inline">\(d\in\mathbb{R}^{*}\)</span>).</p>
<div id="différents-modes-de-convergence" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Différents modes de convergence<a href="convergence.html#différents-modes-de-convergence" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="convergence-en-probabilité" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Convergence en probabilité<a href="convergence.html#convergence-en-probabilité" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="defbox def">
<center>
<strong>Convergence en probabilité</strong>
</center>
<p>Soient <span class="math inline">\((X_n)_{n\in\mathbb{N}}\)</span> une suite de variables aléatoires. On dit que <span class="math inline">\((X_n)_n\)</span> <strong>converge en probabilité</strong> vers une variable aléatoire <span class="math inline">\(X\)</span> lorsque :</p>
<p><span class="math display">\[\forall\varepsilon &gt;0,\,\lim\limits_{n\to +\infty}\mathbb{P}\left(|X_n-X|\geq\varepsilon\right)=0\]</span></p>
<p>
<strong>Notation :</strong> <span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}X\]</span></p>
</div>
<p></p>
<p><strong>Remarques.</strong> De façon équivalente, <span class="math inline">\((X_n)\)</span> converge en probabilité vers <span class="math inline">\(X\)</span> lorsque</p>
<p><span class="math display">\[\forall\varepsilon &gt;0,\,\lim\limits_{n\to +\infty}\mathbb{P}\left(|X_n-X|&lt;\varepsilon\right)=1\]</span></p>
<p></p>
<p><strong>Exemple.</strong> Soit <span class="math inline">\(X:\Omega\longrightarrow\mathbb{R}\)</span> une variable aléatoire. On considère la suite de variables aléatoires <span class="math inline">\((X_n)_n\)</span> définies par <span class="math inline">\(X_n=\frac{E(nX)}{n}\)</span>, où <span class="math inline">\(E(.)\)</span> désigne la fonction partie entière. Démontrons que <span class="math inline">\((X_n)_n\)</span> converge en probabilité vers <span class="math inline">\(X\)</span>.</p>
<p>On a</p>
<p><span class="math display">\[\begin{align*}
\left|X-\frac{E(nX)}{n}\right|&amp;=\left|nX-\frac{E(nX)}{n}\right| \\
&amp;\leq\frac{1}{n}
\end{align*}\]</span></p>
<p>car tout réel <span class="math inline">\(x\)</span> est à une distance au plus <span class="math inline">\(1\)</span> de sa partie entière : <span class="math inline">\(\forall x\in\mathbb{R}, |x-E(x)|\leq 1\)</span>.</p>
<p>Soit <span class="math inline">\(\varepsilon &gt;0\)</span>. Comme <span class="math inline">\(\lim\limits_{n\to +\infty}\frac{1}{n}=0\)</span>, il existe un entier naturel <span class="math inline">\(n_0\)</span> non nul tel que</p>
<p><span class="math display">\[\forall n\in\mathbb{N}, n\geq n_0\Rightarrow\frac{1}{n}&lt;\varepsilon\]</span>
et donc en particulier</p>
<p><span class="math display">\[\forall n\in\mathbb{N}, n\geq n_0\Rightarrow\left|X-\frac{E(nX)}{n}\right|&lt;\varepsilon\]</span>
d’où</p>
<p><span class="math display">\[\forall n\in\mathbb{N}, n\geq n_0\Rightarrow\mathbb{P}\left(\left|X-\frac{E(nX)}{n}\right|&lt;\varepsilon\right)=1\]</span>
et donc finalement</p>
<p><span class="math display">\[\lim\limits_{n\to +\infty}\mathbb{P}\left(\left|X-\frac{E(nX)}{n}\right|&lt;\varepsilon\right)=1\]</span>
autrement dit</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}X\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p>Les inégalités de concentration constituent souvent un outil efficace pour démontrer une convergence en probabilité :</p>
<div class="methbox def">
<center>
<strong>Inégalité de Markov pour démontrer que <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}X\)</span></strong>
</center>
<p>On suppose que :</p>
<ul>
<li>chacune des variables <span class="math inline">\(X_n\)</span> et <span class="math inline">\(X\)</span> admet une espérance</li>
<li><span class="math inline">\(\mathbb{E}(|X_n-X|^p)\underset{n \to +\infty}{\overset{}{\longrightarrow}}0\)</span>, pour un certain <span class="math inline">\(p&gt;0\)</span></li>
</ul>
<p>Le premier point permet d’écrire l’inégalité de Markov (appliquée à la variable aléatoire positive <span class="math inline">\(|X_n-X|^p\)</span>) :</p>
<p><span class="math display">\[\begin{align*}
\mathbb{P}\left(|X_n-X|\geq\varepsilon\right)&amp;=\mathbb{P}\left(|X_n-X|^p\geq\varepsilon^p\right) \\
&amp;\leq\frac{\mathbb{E}\left(|X_n-X|^p\right)}{\varepsilon^p}
\end{align*}\]</span></p>
<p>la première égalité venant du fait que l’application <span class="math inline">\(x\mapsto x^p\)</span> est strictement croissante sur <span class="math inline">\(\mathbb{R}_+\)</span>.</p>
<p>Le deuxième point permet alors de conclure que</p>
<p><span class="math display">\[\forall\varepsilon &gt;0,\, \mathbb{P}(|X_n-m|\geq\varepsilon) \underset{n \to +\infty}{\overset{}{\longrightarrow}}0\]</span></p>
<p>autrement dit que</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}X\]</span></p>
</div>
<p></p>
<p><strong>Remarque.</strong> On vient de démontrer que la convergence dans <span class="math inline">\(L^p\)</span> (ce mode de convergence est défini juste après) pour <span class="math inline">\(p&gt;0\)</span> implique la convergence en probabilité.</p>
<p></p>
<p><strong>Exemple. [Max de lois uniformes indépendantes].</strong> Soit <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires i.i.d. de loi uniforme <span class="math inline">\(\mathcal{U}([0\,;\,1])\)</span>. On pose</p>
<p><span class="math display">\[Y_n=\max(X_1,\dots,X_n)\]</span>
Démontrons que <span class="math inline">\((Y_n)_n\)</span> converge en probabilité vers <span class="math inline">\(1\)</span> en utilisant l’inégalité de Markov appliquée à la variable aléatoire positive <span class="math inline">\(1-Y_n\)</span>.</p>
<p>Pour cela, on a besoin de l’espérance de <span class="math inline">\(1-Y_n\)</span>, et donc de l’espérance de <span class="math inline">\(Y_n\)</span>. Pour calculer <span class="math inline">\(\mathbb{E}(Y_n)\)</span> on commence par calculer la fonction de répartition <span class="math inline">\(F_{Y_n}\)</span> de <span class="math inline">\(Y_n\)</span>. Soit <span class="math inline">\(y\)</span> un réel.</p>
<p>Si <span class="math inline">\(y\leq 0\)</span> on a <span class="math inline">\(F_{Y_n}(y)=0\)</span> et si <span class="math inline">\(y&gt;1\)</span> on a <span class="math inline">\(F_{Y_n}(y)=0\)</span>.</p>
<p>Soit maintenant <span class="math inline">\(y\in [0,1]\)</span>. Alors, on a</p>
<p><span class="math display">\[\begin{align*}
F_{Y_n}(y)&amp;=\mathbb{P}(Y_n\leq y) \\
&amp;=\mathbb{P}(\max(X_1,\dots, X_n)\leq y) \\
&amp;=\mathbb{P}\left(\bigcap\limits_{i=1}^n \{X_i\leq y\} \right) \\
&amp;=\prod\limits_{i=1}^n\mathbb{P}(X_i\leq x) \\
&amp;=\prod\limits_{i=1}^n x \\
&amp;=x^n
\end{align*}\]</span></p>
<p>donc la densité <span class="math inline">\(f_{Y_n}\)</span> de <span class="math inline">\(Y_n\)</span> est donnée par</p>
<p><span class="math display">\[f_{Y_n}(y)=nx^{n-1}.1_{[0,1]}(y)\]</span></p>
<p>D’où l’espérance de <span class="math inline">\(Y_n\)</span> :</p>
<p><span class="math display">\[\begin{align*}
\mathbb{E}(Y_n)&amp;=\int_0^1 y.f_{Y_n}(y)\,dy \\
&amp;=n\int_0^1 y^n\,dy \\
&amp;=\frac{n}{n+1}
\end{align*}\]</span></p>
<p>Soit <span class="math inline">\(\varepsilon &gt;0\)</span>. L’inégalité de Markov appliquée à la variable <span class="math inline">\(|Y_n-1|\)</span> donne</p>
<p><span class="math display">\[\begin{align*}
\mathbb{P}(|Y_n-1|\geq\varepsilon)\leq\frac{\mathbb{E}(1-Y_n)}{\varepsilon^2} \\
&amp;=\frac{1-\frac{n}{n+1}}{\varepsilon^2} \\
&amp;=\frac{1}{(n+1)\varepsilon^2}
\end{align*}\]</span></p>
<p>Or, <span class="math inline">\(\frac{1}{(n+1)\varepsilon^2}\underset{n \to +\infty}{\overset{}{\longrightarrow}}0\)</span>, ce qui permet de conclure que <span class="math inline">\((Y_n)_n\)</span> converge bien en probabilité vers <span class="math inline">\(1\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>
<div class="methbox def">
<center>
<strong>Inégalité de Bienaymé-Tchebytchev pour démontrer que <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}m\)</span></strong>
</center>
<p>Cette inégalité peut être utilisée pour démontrer la convergence en probabilité vers une constante. On suppose que :</p>
<ul>
<li><p>les variables aléatoires <span class="math inline">\(X_n\)</span> admettent une espérance commune <span class="math inline">\(\mathbb{E}(X_n)=m\)</span></p></li>
<li><p>chacune d’elles admet également une variance <span class="math inline">\(\mathbb{V}(X_n)\)</span></p></li>
<li><p><span class="math inline">\(\lim\limits_{n\to +\infty}\mathbb{V}(X_n)=0\)</span>.</p></li>
</ul>
<p>Les deux premiers points permettent d’écrire l’inégalité de Bienaymé-Tchebytchev :</p>
<p><span class="math display">\[\forall\varepsilon &gt;0, \,\mathbb{P}\left(|X_n-m|\geq\varepsilon\right)\leq\frac{\mathbb{V}(X_n)}{\varepsilon^2}\]</span>
Le dernier point permet de conclure que</p>
<p><span class="math display">\[\forall\varepsilon &gt;0,\, \mathbb{P}(|X_n-m|\geq\varepsilon) \underset{n \to +\infty}{\overset{}{\longrightarrow}}0\]</span></p>
<p>autrement dit que</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}m\]</span></p>
</div>
<p></p>
<p><strong>Exemple. [Convergence en probabilité de la moyenne empirique].</strong> Soit <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires i.i.d. de loi <span class="math inline">\(\mathcal{E}(\lambda)\)</span>, où <span class="math inline">\(\lambda&gt;0\)</span>. On considère, pour tout entier naturel <span class="math inline">\(n\geq 1\)</span> la moyenne empirique</p>
<p><span class="math display">\[\overline{X_n}=\frac{1}{n}\sum\limits_{i=1}^n X_i\]</span>
Démontrons que <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}\frac{1}{\lambda}\)</span>. Ce résultat est une conséquence immédiate de la loi faible des grands nombres (que l’on énonce un peu plus loin), mais ici nous allons procéder autrement en utilisant l’inégalité de Bienaymé-Tchebytchev.</p>
<p>Tout d’abord, la limite supposée <span class="math inline">\(\frac{1}{\lambda}\)</span> est une constante, ce qui incite à penser à cette inégalité. Ensuite, les <span class="math inline">\((X_n)_n\)</span> admettent toutes une espérance et une variance - ce qui confirme que nous pouvons utiliser cette inégalité - et</p>
<ul>
<li><p><span class="math inline">\(\forall n\in\mathbb{N}^*,\,\mathbb{E}(X_n)=\frac{1}{\lambda}\)</span></p></li>
<li><p><span class="math inline">\(\forall n\in\mathbb{N}^*, \mathbb{V}(X_n)=\frac{1}{\lambda^2}\)</span></p></li>
</ul>
<p>On en déduit par linéarité que <span class="math inline">\(\mathbb{E}(\overline{X_n})=m\)</span> et par indépendance des <span class="math inline">\(X_n\)</span> que</p>
<p><span class="math display">\[\begin{align*}
\mathbb{V}\left(\overline{X_n}\right)&amp;=\frac{1}{n^2}\sum\limits_{i=1}^n \mathbb{V}(X_i) \\
&amp;=\frac{1}{n^2}\sum\limits_{i=1}^n\frac{1}{\lambda^2} \\
&amp;=\frac{1}{n\lambda^2}
\end{align*}\]</span></p>
<p>L’utilisation de l’inégalité de Bienaymé-Tchebytchev donne donc, pour tout <span class="math inline">\(\varepsilon &gt;0\)</span> :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}\left(\left|\overline{X_n}-\frac{1}{\lambda}\right|\geq\varepsilon\right)&amp;\leq\frac{\mathbb{V}\left(\overline{X_n}\right)}{\varepsilon^2} \\
&amp;=\frac{1}{\varepsilon^2 n\lambda^2\varepsilon^2}
\end{align}\]</span></p>
<p>et donc</p>
<p><span class="math display">\[\lim\limits_{n\to +\infty}\mathbb{P}\left(\left|\overline{X_n}-\frac{1}{\lambda}\right|\geq\varepsilon\right)=0\]</span>
ce qui permet de conclure que <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}\frac{1}{\lambda}\)</span>.</p>
<p>Le résultat suivant fournit un critère simple pour démontrer une convergence en probabilité. Il s’agit d’une condition suffisante, qui fonctionne assez souvent en pratique.</p>
<div class="thmbox thm">
<center>
<strong>Convergence en probabilité : conditions suffisantes</strong>
</center>
<p>Soient <span class="math inline">\(a\)</span> un nombre réel et <span class="math inline">\((X_n)_{n}\)</span> une suite de variables aléatoires admettant une espérance et une variance.</p>
<p>Si</p>
<p><span class="math display">\[\mathbb{E}(X_n) \underset{n \to +\infty}{\overset{}{\longrightarrow}}a\]</span></p>
<p>et</p>
<p><span class="math display">\[\mathbb{V}(X_n) \underset{n \to +\infty}{\overset{}{\longrightarrow}}0\]</span>
alors</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}a\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong></p>
<p></p>
<p><strong>Exemple.</strong></p>
<p><strong>Parler de Markov et de Bieanymé-Tchebytchev</strong></p>
</div>
<div id="convergence-dans-les-espaces-l1-et-l2" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Convergence dans les espaces <span class="math inline">\(L^1\)</span> et <span class="math inline">\(L^2\)</span><a href="convergence.html#convergence-dans-les-espaces-l1-et-l2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A nouveau, sans que cela ne soit plus mentionné par la suite, nous supposons ici que toutes les variables aléatoires évoquées sont définies sur un même espace probabilisé <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span>.</p>
<p>Par ailleurs, ces variables sont à valeurs dans <span class="math inline">\(\mathbb{R}\)</span>. On pourrait toutefois facilement étendre les définitions qui suivent à des variables à valeurs dans <span class="math inline">\(\mathbb{R}^d\)</span> en remplaçant les valeurs absolues <span class="math inline">\(|X_n-X|\)</span> par des normes <span class="math inline">\(||X_n-X||\)</span> définies dans <span class="math inline">\(\mathbb{R}^d\)</span>.</p>
<div id="les-ensembles-l1omega-et-l2omega" class="section level4 hasAnchor" number="5.1.2.1">
<h4><span class="header-section-number">5.1.2.1</span> Les ensembles <span class="math inline">\(L^1(\Omega)\)</span> et <span class="math inline">\(L^2(\Omega)\)</span><a href="convergence.html#les-ensembles-l1omega-et-l2omega" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="defbox def">
<center>
<strong>Espaces <span class="math inline">\(L^1(\Omega)\)</span> et <span class="math inline">\(L^2(\Omega)\)</span></strong>
</center>
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire définie sur <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span> et à valeurs dans <span class="math inline">\(\mathbb{R}\)</span>.</p>
<p></p>
<center>
<strong>Espace <span class="math inline">\(L^1(\Omega)\)</span></strong>
</center>
<p>On dit que <span class="math inline">\(X\in L^1(\Omega)\)</span>, ou encore que <span class="math inline">\(X\in L^1(\Omega, \mathcal{A}, \mathbb{P})\)</span> lorsque</p>
<p><span class="math display">\[\mathbb{E}(|X|)&lt;+\infty\]</span></p>
<p>ce qui revient à dire que <span class="math inline">\(X\)</span> admet une espérance. Selon le cas (discret fini, discret infini, à densité), cette condition s’écrit aussi sous l’une des formes suivantes :</p>
<p><span class="math display">\[\sum\limits_{n=0}^N \mathbb{P}(X=x_n).|x_n|&lt;+\infty\]</span>
<span class="math display">\[\sum\limits_{n=0}^{+\infty} \mathbb{P}(X=x_n).|x_n|&lt;+\infty\]</span></p>
<p><span class="math display">\[\int_{-\infty}^{+\infty}|x|.f(x)\,dx&lt;+\infty\]</span>
avec <span class="math inline">\(f\)</span> la densité de <span class="math inline">\(X\)</span> dans le cas à densité.</p>
<center>
<strong>Espace <span class="math inline">\(L^2(\Omega)\)</span></strong>
</center>
<p>On dit que <span class="math inline">\(X\in L^2(\Omega)\)</span>, ou encore que <span class="math inline">\(X\in L^2(\Omega, \mathcal{A}, \mathbb{P})\)</span> lorsque</p>
<p><span class="math display">\[\mathbb{E}(X^2)&lt;+\infty\]</span></p>
<p>ce qui revient à dire que <span class="math inline">\(X\)</span> admet un moment d’ordre 2. Selon le cas (discret fini, discret infini, à densité), cette condition s’écrit aussi sous l’une des formes suivantes :</p>
<p><span class="math display">\[\sum\limits_{n=0}^N \mathbb{P}(X=x_n).x_n^2&lt;+\infty\]</span>
<span class="math display">\[\sum\limits_{n=0}^{+\infty} \mathbb{P}(X=x_n).x_n^2&lt;+\infty\]</span></p>
<p><span class="math display">\[\int_{-\infty}^{+\infty}x^2.f(x)\,dx&lt;+\infty\]</span></p>
<p>avec <span class="math inline">\(f\)</span> la densité de <span class="math inline">\(X\)</span> dans le cas à densité.</p>
</div>
<p></p>
<p><strong>Remarques. i.</strong> Cette définition est suffisante pour le concours</p>
<p></p>
<p><strong>ii.</strong> Plus généralement, pour tout <span class="math inline">\(p&gt;0\)</span> on peut définir l’ensemble <span class="math inline">\(L^p(\Omega)\)</span> comme l’ensemble des variables aléatoires réelles définies sur <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span> telles que</p>
<p><span class="math display">\[\mathbb{E}(|X|^p)&lt;+\infty\]</span>
et cette condition s’écrit, selon les cas, sous l’une des formes suivantes :</p>
<p><span class="math display">\[\sum\limits_{n=0}^N \mathbb{P}(X=x_n).|x_n|^p&lt;+\infty\]</span>
<span class="math display">\[\sum\limits_{n=0}^{+\infty} \mathbb{P}(X=x_n).|x_n|^p&lt;+\infty\]</span></p>
<p><span class="math display">\[\int_{-\infty}^{+\infty}|x|^p.f(x)\,dx&lt;+\infty\]</span>
</p>
<p>Le résultat qui suit est très classique :</p>
<div class="thmbox thm">
<p></p>
<p><strong>Théorème.</strong> On a l’inclusion</p>
<p><span class="math display">\[L^2(\Omega)\subset L^1(\Omega)\]</span>
autrement dit dès qu’une variable aléatoire admet un moment d’ordre <span class="math inline">\(1\)</span> (une espérance), elle admet aussi un moment d’ordre <span class="math inline">\(2\)</span> et donc une variance.</p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Soit <span class="math inline">\(X\in L^2(\Omega)\)</span>, i.e. <span class="math inline">\(\mathbb{E}(X^2)&lt;+\infty\)</span>. On a</p>
<p><span class="math display">\[(|X|-1)^2\geq 0\]</span>
d’où</p>
<p><span class="math display">\[|X|\leq\frac{1+X^2}{2}\]</span>
On déduit facilement de cette dernière inégalité que <span class="math inline">\(\mathbb{E}(|X|)&lt;+\infty\)</span>, i.e. que <span class="math inline">\(X\in L^1(\Omega)\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Remarque.</strong> On peut aussi définir une notion d’espace <span class="math inline">\(L^p(E, \mathcal{A}, \mu)\)</span> pour <span class="math inline">\((E, \mathcal{A}, \mu)\)</span> un espace mesuré (hors-programme), mais dans ce cas l’inclusion précédente n’est plus vraie en toute généralité, autrement dit l’inclusion</p>
<p><span class="math display">\[L^2(E, \mathcal{A}, \mu)\subset L^1(E, \mathcal{A}, \mu)\]</span>
n’est pas automatique pour des espaces mesurés qui ne sont pas des espaces probabilisés (en fait, elle devient fausse si la mesure n’est pas finie, i.e. si <span class="math inline">\(\mu(E)=+\infty\)</span>).</p>
<p>On peut démontrer que <span class="math inline">\(L^1(\Omega)\)</span> et <span class="math inline">\(L^2(\Omega)\)</span> sont des espaces-vectoriels :</p>
<div class="thmbox thm">
<p>
<strong>Théorème.</strong> <span class="math inline">\(L^1(\Omega)\)</span> et <span class="math inline">\(L^2(\Omega)\)</span> sont des <span class="math inline">\(\mathbb{R}\)</span>-espaces-vectoriels.</p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Il suffit de démontrer que <span class="math inline">\(L^1(\Omega)\)</span> et <span class="math inline">\(L^2(\Omega)\)</span> sont des sous-espaces-vectoriels du <span class="math inline">\(\mathbb{R}\)</span>-espace-vectoriel <span class="math inline">\(\mathbb{R}^{\Omega}\)</span> des applications de <span class="math inline">\(\Omega\)</span> dans <span class="math inline">\(\mathbb{R}\)</span>.</p>
<p>Tout d’abord, l’application <span class="math inline">\(0\)</span> qui à tout <span class="math inline">\(\omega\)</span> dans <span class="math inline">\(\Omega\)</span> associe le réel <span class="math inline">\(0\)</span> admet clairement une espérance et un moment d’ordre <span class="math inline">\(2\)</span> (tous les deux nuls), donc elle appartient à <span class="math inline">\(L^1(\Omega)\)</span> et à <span class="math inline">\(L^2(\Omega)\)</span>.</p>
<p>Soient <span class="math inline">\(X,Y\in L^1(\Omega)\)</span> et <span class="math inline">\(\lambda\in\mathbb{R}\)</span>. Alors :</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}\left(|X+\lambda Y|\right) &amp;\leq \mathbb{E}\left(|X|+|Y|\right) \\
&amp;=\mathbb{E}(|X|)+\mathbb{E}(|Y|) \\
&amp;&lt;+\infty
\end{align}\]</span></p>
<p>donc <span class="math inline">\(X+\lambda Y\in L^1(\Omega)\)</span> et <span class="math inline">\(L^1(\Omega)\)</span> est un sous-espace vectoriel de <span class="math inline">\(\mathbb{R}^{\Omega}\)</span>.</p>
<p>Soient <span class="math inline">\(X,Y\in L^2(\Omega)\)</span> et <span class="math inline">\(\lambda\in\mathbb{R}\)</span>. Alors :</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}\left((X+\lambda Y)^2\right) &amp;= \mathbb{E}\left(X^2+2\lambda XY+\lambda^2 Y^2 \right) \\
&amp;=\mathbb{E}(X^2)+2\lambda\mathbb{E}(XY)+\lambda^2\mathbb{E}(Y^2) \\
&amp;\leq\mathbb{E}(X^2)+2\lambda\sqrt{\mathbb{E}(X^2).\mathbb{E}(Y^2)}+\lambda^2\mathbb{E}(Y^2) \\
&amp; \text{(d&#39;après l&#39;inégalité de Cauchy-Schwarz)} \\
&amp;&lt;+\infty
\end{align}\]</span></p>
<p>donc <span class="math inline">\(X+\lambda Y\in L^2(\Omega)\)</span>, ce qui permet de conclure que <span class="math inline">\(L^2(\Omega)\)</span> est un sous-espace vectoriel de <span class="math inline">\(\mathbb{R}^{\Omega}\)</span>.</p>
<div class="defbox def">
<center>
<strong>Convergence en moyenne d’ordre <span class="math inline">\(1\)</span>, en moyenne d’ordre <span class="math inline">\(2\)</span></strong>
</center>
<p>Soient <span class="math inline">\(X\)</span> une variable aléatoire et <span class="math inline">\((X_n)_{n\in\mathbb{N}}\)</span> une suite de variables aléatoires.</p>
<p><strong>Convergence dans <span class="math inline">\(L^1\)</span>.</strong> On suppose que <span class="math inline">\(X\)</span> et les <span class="math inline">\(X_n\)</span> admettent des espérances : <span class="math inline">\(\mathbb{E}(|X_n|)&lt;+\infty\)</span> pour tout entier naturel <span class="math inline">\(n\)</span>, et <span class="math inline">\(\mathbb{E}(|X|)&lt;+\infty\)</span>. On dit alors que <span class="math inline">\((X_n)_n\)</span> <strong>converge vers <span class="math inline">\(X\)</span> dans <span class="math inline">\(L^1\)</span></strong>, ou que <strong><span class="math inline">\((X_n)\)</span> converge en moyenne d’ordre <span class="math inline">\(1\)</span> vers <span class="math inline">\(X\)</span></strong>, lorsque :</p>
<p><span class="math display">\[\lim\limits_{n\to +\infty}\mathbb{E}\left(|X_n-X|\right)=0\]</span></p>
<p>
<strong>Notation :</strong> <span class="math display">\[X_n \underset{n \to +\infty}{\overset{L^1}{\longrightarrow}}X\]</span></p>
<p></p>
<p><strong>Convergence dans <span class="math inline">\(L^2\)</span>.</strong> On suppose que <span class="math inline">\(X\)</span> et les <span class="math inline">\(X_n\)</span> admettent des moments d’ordre <span class="math inline">\(2\)</span> : <span class="math inline">\(\mathbb{E}(X_n^2)&lt;+\infty\)</span> pour tout entier naturel <span class="math inline">\(n\)</span>, et <span class="math inline">\(\mathbb{E}(X^2)&lt;+\infty\)</span>. On dit alors que <strong><span class="math inline">\((X_n)_n\)</span> converge vers <span class="math inline">\(X\)</span> dans <span class="math inline">\(L^2\)</span></strong>, ou que <strong><span class="math inline">\((X_n)\)</span> en moyenne d’ordre <span class="math inline">\(2\)</span> vers <span class="math inline">\(X\)</span></strong>, lorsque :</p>
<p><span class="math display">\[\lim\limits_{n\to +\infty}\mathbb{E}\left((X_n-X)^2\right)=0\]</span></p>
<p>
<strong>Notation :</strong> <span class="math display">\[X_n \underset{n \to +\infty}{\overset{L^2}{\longrightarrow}}X\]</span></p>
</div>
<p><strong>Exemples. i.</strong> Soit <span class="math inline">\(X_n\)</span> une variable aléatoire telle que</p>
<p><span class="math display">\[\mathbb{P}(X_n=0)=1-\frac{1}{n^2}\]</span>
<span class="math display">\[\mathbb{P}(X_n=n)=\frac{1}{n^2}\]</span>
Alors, <span class="math inline">\((X_n)_n\)</span> converge vers <span class="math inline">\(0\)</span> dans <span class="math inline">\(L^1(\Omega)\)</span>. En effet :</p>
<p><span class="math display">\[\begin{align*}
\mathbb{E}(|X_n|)&amp;=\mathbb{E}(X_n) \\
&amp;=0.\mathbb{P}(X_n=0)+n.\mathbb{P}(X_n=n) \\
&amp;=n\mathbb{P}(X_n=n) \\
&amp;=n.\frac{1}{n^2} \\
&amp;=\frac{1}{n}
\end{align*}\]</span></p>
<p>et donc</p>
<p><span class="math display">\[\lim\limits_{n\to +\infty}\mathbb{E}(|X_n|)=0\]</span></p>
<p><strong>ii.</strong> Soient <span class="math inline">\((p_n)_n\)</span> une suite de nombres réels de <span class="math inline">\([0\,;\,1]\)</span> et <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires telles que</p>
<p><span class="math display">\[\mathbb{P}(X_n=0)=1-p_n\]</span>
<span class="math display">\[\mathbb{P}(X_n=\sqrt{n})=p_n\]</span></p>
<p>Déterminons une condition nécessaire et suffisante pour que <span class="math inline">\((X_n)_n\)</span> converge vers <span class="math inline">\(0\)</span> dans <span class="math inline">\(L^2(\Omega)\)</span>, autrement dit pour que <span class="math inline">\(\mathbb{E}(X_n^2)\underset{n \to +\infty}{\overset{}{\longrightarrow}}0\)</span>.</p>
<p>Tout d’abord, <span class="math inline">\(X_n\)</span> a un univers fini, donc elle est dans <span class="math inline">\(L^2(\Omega)\)</span>. Ensuite :</p>
<p><span class="math display">\[\begin{align*}
\mathbb{E}(X_n^2)&amp;=(\sqrt{n})^2.p_n \\
&amp;=np_n
\end{align*}\]</span></p>
<p>Donc, <span class="math inline">\((X_n)_n\)</span> converge vers <span class="math inline">\(0\)</span> dans <span class="math inline">\(L^2(\Omega)\)</span> si et seulement si <span class="math inline">\(\lim\limits_{n\to +\infty} np_n=0\)</span>, autrement dit si <span class="math inline">\(p_n=o\left(\frac{1}{n}\right)\)</span> lorsque <span class="math inline">\(n\)</span> tend vers l’infini.</p>
<p><span class="math inline">\(\square\)</span></p>
<p>Le théorème suivant donne un lien entre convergence en moyenne quadratique (dans <span class="math inline">\(L^2\)</span>) ey convergence en moyenne d’ordre <span class="math inline">\(1\)</span> :</p>
<div class="thmbox thm">
<p>
<strong>Théorème (CV dans <span class="math inline">\(L^2\)</span> implique CV dans <span class="math inline">\(L^1\)</span>).</strong> Soit <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires réelles et <span class="math inline">\(X\)</span> une variable aléatoire réelle, toutes dans <span class="math inline">\(L^2(\Omega)\)</span>.</p>
<p>Si</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{L^2}{\longrightarrow}}X\]</span>
alors</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{L^1}{\longrightarrow}}X\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> La fonction <span class="math inline">\(x\in\mathbb{R}\mapsto x^2\)</span> est convexe, donc d’après l’inégalité de Jensen, on a</p>
<p><span class="math display">\[\left(\mathbb{E}|X_n-X|\right)^2\leq\mathbb{E}((X_n-X)^2)\]</span>
donc</p>
<p><span class="math display">\[0\leq \mathbb{E}(|X_n-X|)\leq\sqrt{\mathbb{E}\left((X_n-X)^2\right)}\]</span>
Si <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{L^2}{\longrightarrow}}X\)</span> alors le membre de droite de l’encadrement ci-dessus tend vers <span class="math inline">\(0\)</span> lorsque <span class="math inline">\(n\)</span> tend vers l’infini. D’après le théorème d’encadrement, on a donc <span class="math inline">\(\lim\limits_{n\to +\infty}\mathbb{E}\left(|X_n-X|\right)=0\)</span>, et donc <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{L^1}{\longrightarrow}}X\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>
<p><strong>Remarque.</strong> Il existe plus généralement une notion de convergence dans <span class="math inline">\(L^p\)</span>, ou convergence en moyenne d’ordre <span class="math inline">\(p\)</span>, pour <span class="math inline">\(p&gt;0\)</span>, mais seuls les cas <span class="math inline">\(p=1\)</span> et <span class="math inline">\(p=2\)</span> sont au programme.</p>
<div class="defbox def">
<center>
<strong>Convergence en moyenne d’ordre <span class="math inline">\(p\)</span> (hors-programme pour <span class="math inline">\(p\not\in\{1,2\}\)</span>)</strong>
</center>
<p>Soit <span class="math inline">\(p\)</span> un réel strictement positif. Soient <span class="math inline">\(X\)</span> une variable aléatoire et <span class="math inline">\((X_n)_{n\in\mathbb{N}}\)</span> une suite de variables aléatoires.</p>
<p>On suppose que <span class="math inline">\(X\)</span> et les <span class="math inline">\(X_n\)</span> admettent des moments d’ordre <span class="math inline">\(p\)</span> : <span class="math inline">\(\mathbb{E}(|X_n|^p)&lt;+\infty\)</span> pour tout entier naturel <span class="math inline">\(n\)</span>, et <span class="math inline">\(\mathbb{E}(|X|^p)&lt;+\infty\)</span>. On dit alors que <strong><span class="math inline">\((X_n)_n\)</span> converge vers <span class="math inline">\(X\)</span> dans <span class="math inline">\(L^p\)</span></strong>, ou que <strong><span class="math inline">\((X_n)\)</span> en moyenne d’ordre <span class="math inline">\(p\)</span> vers <span class="math inline">\(X\)</span></strong>, lorsque :</p>
<p><span class="math display">\[\lim\limits_{n\to +\infty}\mathbb{E}\left(|X_n-X|^p\right)=0\]</span></p>
<p></p>
<p><strong>Notation :</strong> <span class="math display">\[X_n \underset{n \to +\infty}{\overset{L^p}{\longrightarrow}}X\]</span></p>
</div>
</div>
</div>
<div id="convergence-en-loi" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Convergence en loi<a href="convergence.html#convergence-en-loi" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="defbox def">
<center>
<strong>Convergence en loi</strong>
</center>
<p>Soient <span class="math inline">\(X\)</span> une variable aléatoire de fonction de répartition <span class="math inline">\(F\)</span>, et <span class="math inline">\((X_n)_{n\in\mathbb{N}}\)</span> une suite de variables aléatoires de fonctions de répartition <span class="math inline">\(F_n\)</span>.</p>
<p>On dit que <span class="math inline">\((X_n)_n\)</span> <strong>converge en loi vers <span class="math inline">\(X\)</span></strong> lorsque, en tout point <span class="math inline">\(x\)</span> en lequel <span class="math inline">\(F\)</span> est continue, on a</p>
<p><span class="math display">\[\lim\limits_{n\to +\infty}F_n(x)=F(x)\]</span></p>
<p>
<strong>Notation :</strong> <span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}X\]</span></p>
</div>
<p></p>
<p><strong>Exemples. i.</strong> Pour tout entier naturel <span class="math inline">\(n\)</span>, on note <span class="math inline">\(X_n\)</span> une variable aléatoire positive de densité <span class="math inline">\(f_n\)</span> définie par <span class="math inline">\(f_n(x)=ne^{-nx}\)</span> pour <span class="math inline">\(x&gt;0\)</span>. Démontrons que <span class="math inline">\((X_n)_n\)</span> converge en loi vers <span class="math inline">\(0\)</span>.</p>
<p>On note <span class="math inline">\(F_n\)</span> la fonction de répartition de <span class="math inline">\(X_n\)</span>. On obtient alors</p>
<p><span class="math display">\[F_n(x)=(1-e^{-nx}).1_{\mathbb{R}_+^{*}}(x)\]</span>
La suite de fonctions <span class="math inline">\((F_n)_n\)</span> converge simplement vers</p>
<p><span class="math display">\[F(x)=1_{\mathbb{R}_+^{*}}(x)\]</span>
qui est la fonction de répartition de la variable aléatoire certaine égale à <span class="math inline">\(0\)</span>. Ainsi</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}0\]</span>
</p>
<p><strong>ii.</strong> Pour <span class="math inline">\(n\)</span> entier naturel, on considère la variable aléatoire certaine <span class="math inline">\(X_n=n\)</span>. Etudions la convergence en loi de la suite <span class="math inline">\((X_n)_n\)</span>.</p>
<p>On note <span class="math inline">\(F_n\)</span> la fonction de répartition de <span class="math inline">\(X_n\)</span>. On a</p>
<p><span class="math display">\[F_n(x)=1_{[n\,;\,+\infty[}(x)\]</span>
et donc la suite <span class="math inline">\((F_n)_n\)</span> converge simplement vers la fonction constante égale à <span class="math inline">\(0\)</span>. Mais cette fonction n’est pas une fonction de répartition, car <span class="math inline">\(\lim\limits_{x\to +\infty} F(x)\neq 1\)</span>.</p>
<p>Donc, la suite <span class="math inline">\((X_n)_n\)</span> ne converge pas en loi.</p>
<p></p>
<p><strong>Remarque.</strong> La convergence simple de la suite des fonctions de répartition ne suffit pas pour établir une convergence en loi. Il faut, en plus, s’assurer que la limite est bien une fonction de répartition.</p>
<p>Il existe différents critères de convergence en loi. Certaine s’appliquent uniquement à des variables discrètes avec limite discrète, d’autres à des variables absolument continues avec limite absolument continue, et d’autres enfin s’appliquent à toutes les variables aléatoires.</p>
<div class="thmbox def">
<p>
<strong>Théorème (Quelques critères de convergence en loi.)</strong></p>
<p></p>
<p><strong>i. Espérance contre des fonctions tests.</strong> La suite <span class="math inline">\((X_n)_n\)</span> converge en loi vers <span class="math inline">\(X\)</span> si et seulement si, pour toute fonction <strong>continue</strong> et <strong>bornée</strong> <span class="math inline">\(f\)</span>, on a</p>
<p><span class="math display">\[\mathbb{E}(f(X_n))\underset{n \to +\infty}{\overset{}{\longrightarrow}}\mathbb{E}(f(X))\]</span></p>
<p></p>
<p><strong>ii. Espérance contre des fonctions tests (variante).</strong> La suite <span class="math inline">\((X_n)_n\)</span> converge en loi vers <span class="math inline">\(X\)</span> si et seulement si, pour toute fonction <strong>uniformémént continue</strong> et <strong>bornée</strong> <span class="math inline">\(f\)</span>, on a</p>
<p><span class="math display">\[\mathbb{E}(f(X_n))\underset{n \to +\infty}{\overset{}{\longrightarrow}}\mathbb{E}(f(X))\]</span></p>
<p></p>
<p><strong>iii. Par les fonctions caractéristiques.</strong> Soit <span class="math inline">\(d\in\mathbb{N}^*\)</span>. On suppose <span class="math inline">\(\mathbb{R}^d\)</span> muni d’un produit scalaire <span class="math inline">\(&lt;.,.&gt;\)</span>. Pour toute variable aléatoire <span class="math inline">\(X\)</span> à valeurs dans <span class="math inline">\(\mathbb{R}^d\)</span>, on note <span class="math inline">\(\varphi_X\)</span> la <strong>fonction caractéristique de <span class="math inline">\(X\)</span></strong> :</p>
<p><span class="math display">\[\forall t\in\mathbb{R},\,\varphi_X(t)=\mathbb{E}(e^{i&lt;t,X&gt;})\]</span>
Cette fonction caractérise la loi de <span class="math inline">\(X\)</span> (i.e. <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> ont la même loi si et seulement si <span class="math inline">\(\varphi_X=\varphi_Y\)</span>), et elle caractérise la convergence en loi :</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}X\text{ si et seulement si } \varphi_{X_n}\underset{n \to +\infty}{\overset{}{\longrightarrow}}\varphi_X\]</span>
<strong>iv. Convergence en loi des variables aléatoires discrètes.</strong> si <span class="math inline">\((X_n)_n\)</span> et <span class="math inline">\(X\)</span> sont des variables aléatoires réelles discrètes, à valeurs dans un même ensemble dénombrable </p>
<p><span class="math display">\[E=\{x_k,\, k\in K\}\hspace{1cm}\text{ avec } K\subset\mathbb{Z}\]</span></p>
<p>alors</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}X\]</span></p>
<p>si, et seulement si</p>
<p><span class="math display">\[\forall k\in K,\,\mathbb{P}(X_n=x_k) \underset{n \to +\infty}{\overset{}{\longrightarrow}}\mathbb{P}(X=x_k)\]</span></p>
<p>
<strong>v. Convergence en loi des variables aléatoires à densité.</strong> Soient <span class="math inline">\((X_n)_n\)</span> et <span class="math inline">\(X\)</span> des variables aléatoires à densité. On note <span class="math inline">\(f_n\)</span> et <span class="math inline">\(f\)</span> ces densités, définies sur <span class="math inline">\(\mathbb{R}\)</span>.</p>
<p>Si</p>
<p><span class="math display">\[\forall x\in\mathbb{R},\, f_n(x) \underset{n \to +\infty}{\overset{}{\longrightarrow}}f(x)\]</span></p>
<p>alors, <span class="math inline">\((X_n)_n\)</span> converge en loi vers <span class="math inline">\(X\)</span>.</p>
</div>
<p></p>
<p><strong>Démonstration.</strong> L’assertion i. est démontrée en exercice (feuille de la session 3) pour la condition suffisante, la condition nécessaire est admise.</p>
<p>Les assertions ii. sont admises.</p>
<p>Les assertions iv. et v. sont démontrées en exercices.</p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Exemples.</strong> Voir les exercices 3, 4, 5 et 13 de la feuille de la session 3.</p>
</div>
<div id="convergence-presque-sûre-hors-programme" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Convergence presque-sûre (hors-programme ?)<a href="convergence.html#convergence-presque-sûre-hors-programme" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="defbox def">
<center>
<strong>Convergence presque sûre</strong>
</center>
<p>Soient <span class="math inline">\(X\)</span> une variable aléatoire et <span class="math inline">\((X_n)_{n\in\mathbb{N}}\)</span> une suite de variables aléatoires.</p>
<p>On dit que <span class="math inline">\((X_n)_n\)</span> <strong>converge presque sûrement vers <span class="math inline">\(X\)</span></strong> lorsque :</p>
<p><span class="math display">\[\mathbb{P}\left(\{\omega\in\Omega, X_n(\omega)\longrightarrow X(\omega)\right\})=1\]</span></p>
<p>
<strong>Notation :</strong> <span class="math display">\[X_n \underset{n \to +\infty}{\overset{p.s.}{\longrightarrow}}X\]</span></p>
</div>
</div>
<div id="liens-entre-les-différents-modes-de-convergence" class="section level3 hasAnchor" number="5.1.5">
<h3><span class="header-section-number">5.1.5</span> Liens entre les différents modes de convergence<a href="convergence.html#liens-entre-les-différents-modes-de-convergence" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="thmbox thm">
<p><strong>Liens entre les différents modes de convergence.</strong> Les liens entre les différents modes de convergence sont donnés par le schéma ci-dessous :</p>
<center>
<img src="images/modes_convergence.PNG" /><!-- -->
</center>
</div>
<p></p>
<p><strong>Remarque.</strong> D’après le schéma ci-dessus, la convergence en loi est donc le mode de convergence le plus faible. Dit autrement, pour qu’une suite de variables aléatoires converge sous un mode ou un autre, elle doit <strong>a minima</strong> converger en loi.</p>
<p>Si la convergence en probabilité implique la convergence en loi, la réciproque est fausse en général.</p>
<p>
<strong>Contre-exemple.</strong> Voir la question 2 de l’exercice 2.</p>
<p>En revanche, il existe tout de même une réciproque partielle :</p>
<div class="thmbox thm">
<p>
<strong>Théorème.</strong> Soient <span class="math inline">\(c\)</span> un réel et <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires. Si</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}c\]</span></p>
<p>alors</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}c\]</span></p>
</div>
<p>
<strong>Démonstration.</strong> Voir la question 1 de l’exercice 2.</p>
<p><span class="math inline">\(\square\)</span></p>
</div>
<div id="transformation-par-une-application-continue" class="section level3 hasAnchor" number="5.1.6">
<h3><span class="header-section-number">5.1.6</span> Transformation par une application continue<a href="convergence.html#transformation-par-une-application-continue" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Souvent, on est amené à étudier la convergence (sous un mode ou un autre) d’une variable aléatoire <span class="math inline">\(Y_n\)</span> s’exprimant comme une fonction d’une autre variable <span class="math inline">\(X_n\)</span> :</p>
<p><span class="math display">\[Y_n=f(X_n)\]</span></p>
<p>Si la fonction <span class="math inline">\(f\)</span> est continue, les choses se passent bien en général :</p>
<div class="thmbox thm">
<p>
<strong>Théorème. [Continuous mapping theorem].</strong> Soient <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires réelles (ou à valeurs dans <span class="math inline">\(\mathbb{R}^d\)</span>), <span class="math inline">\(X\)</span> une variable aléatoire réelle (ou à valeurs dans <span class="math inline">\(\mathbb{R}^d\)</span>), et <span class="math inline">\(g\)</span> une fonction continue sur <span class="math inline">\(\mathbb{R}\)</span> (ou <span class="math inline">\(\mathbb{R}^d\)</span>) et à valeurs dans <span class="math inline">\(\mathbb{R}\)</span>.</p>
<p>
<strong>i.</strong> Si <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}X\)</span> alors <span class="math inline">\(g(X_n) \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}g(X)\)</span></p>
<p>
<strong>ii.</strong> Si <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}X\)</span> alors <span class="math inline">\(g(X_n) \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}g(X)\)</span>.</p>
<p>
<strong>iii.</strong> Si <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{p.s.}{\longrightarrow}}X\)</span> alors <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{p.s.}{\longrightarrow}}g(X)\)</span></p>
<p>On résume les points i. ii. et iii. en disant que la convergence en loi, la convergence en probabilité et la convergence presque sûre sont <strong>stables par transformation continue</strong>.</p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Voir exercice 6.</p>
<p><span class="math inline">\(\square\)</span></p>
<p><strong>Exemple.</strong> Soit <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires i.i.d. de loi <span class="math inline">\(\mathcal{E}(\lambda)\)</span>. note</p>
<p><span class="math display">\[\overline{X_n}=\frac{1}{n}\sum\limits_{i=1}^n X_i\]</span></p>
<p>leur moyenne empirique, et</p>
<p><span class="math display">\[Y_n=\cos\left(\frac{1}{1+\overline{X_n}^2}\right)\]</span>
Démontrons les convergences en probabilité et en loi de la suite <span class="math inline">\((Y_n)_n\)</span>.</p>
<p>Le faire directement serait compliqué. Le mieux est de se ramener à une variable dont la convergence (en probabilité, en loi) est facile à établir. Nous avons déjà montré dans un exemple précédent que</p>
<p><span class="math display">\[\overline{X_n} \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}\frac{1}{\lambda}\]</span>
Comme la convergence en probabilité implique la convergence en loi, on en déduit que</p>
<p><span class="math display">\[\overline{X_n} \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}\frac{1}{\lambda}\]</span>
Par ailleurs, la fonction <span class="math inline">\(f\)</span> définie sur <span class="math inline">\(\mathbb{R}\)</span> par</p>
<p><span class="math display">\[f(x)=\cos\left(\frac{1}{1+x^2}\right)\]</span>
est continue. Donc, d’après le continuous mapping theorem, on a</p>
<p><span class="math display">\[Y_n\underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}\frac{1}{1+\frac{1}{\lambda^2}}=\frac{\lambda^2}{1+\lambda^2}\]</span>
et</p>
<p><span class="math display">\[Y_n\underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}\frac{1}{1+\frac{1}{\lambda^2}}=\frac{\lambda^2}{1+\lambda^2}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
</div>
<div id="théorème-de-slutsky-hors-programme" class="section level3 hasAnchor" number="5.1.7">
<h3><span class="header-section-number">5.1.7</span> Théorème de Slutsky (hors-programme ?)<a href="convergence.html#théorème-de-slutsky-hors-programme" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ce résultat est très pratique dans les exercices pour démontrer une convergence en loi. Son appartenance au programme du concours n’est cependant pas certaine (je penche plutôt pour non), donc sauf s’il est explicitement écrit dans le sujet que le résultat est admis (comme cela a déjà le cas) il semble risqué de l’utiliser. Dans tous les cas, comme l’énoncé est simple, ça ne coût pas grand chose de l’avoir en tête.</p>
<div class="thmbox thm">
<p>
<strong>Théorème de Slutsky.</strong> Si <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}X\)</span> et <span class="math inline">\(Y_n \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}c\)</span>, où <span class="math inline">\(c\)</span> est une constante, alors <span class="math inline">\((X_n, Y_n) \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}(X,c)\)</span>.</p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Admise.</p>
<p></p>
<p><strong>Remarque.</strong> Comme la convergence en loi <strong>vers une constante</strong> implique la convergence en probabilité vers cette même constante (rappel : ce n’est pas nécessairement vrai si la limite est une variable aléatoire non constante !), on pourrait de manière totalement équivalente énoncer le théorème de Slutsky en disant que si X_n X$ et <span class="math inline">\(Y_n \underset{n \to +\infty}{\overset{\mathcal{P}}{\longrightarrow}}c\)</span>, où <span class="math inline">\(c\)</span> est une constante, alors <span class="math inline">\((X_n, Y_n) \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}(X,c)\)</span>.</p>
<p>Ce théorème présente tout son intérêt lorsqu’il est couplé avec le continuous mapping theorem, car il permet alors d’en déduire le corollaire suivant :</p>
<div class="thmbox thm">
<p>
<strong>Corollaire.</strong> Si <span class="math inline">\(X_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}X\)</span> et <span class="math inline">\(Y_n \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}c\)</span>, où <span class="math inline">\(c\)</span> est une constante, alors <span class="math inline">\(X_n+Y_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}X+c\)</span>, <span class="math inline">\(X_n.Y_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}cX\)</span> et (sous réserve d’existence de tous les termes) <span class="math inline">\(\frac{X_n}{Y_n} \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}\frac{X}{c}\)</span>.</p>
</div>
<p>
<strong>Démonstration.</strong> Avec le théorème de Slutsky, on a</p>
<p><span class="math display">\[(X_n, Y_n) \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}(X,c)\]</span></p>
<p>Par ailleurs, les fonctions <span class="math inline">\((x,y)\mapsto x+y\)</span>, <span class="math inline">\((x,y)\mapsto x.y\)</span> et <span class="math inline">\((x,y)\mapsto\frac{x}{y}\)</span> sont définies et continues sur <span class="math inline">\(\mathbb{R^2}\)</span> pour les deux premières et sur <span class="math inline">\(\mathbb{R}\times\mathbb{R}^*\)</span> pour la troisième. On en déduit alors le résultat en appliquant le continuous mapping theorem.</p>
<p><span class="math inline">\(\square\)</span></p>
</div>
<div id="approximations" class="section level3 hasAnchor" number="5.1.8">
<h3><span class="header-section-number">5.1.8</span> Approximations<a href="convergence.html#approximations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="thmbox def">
<p>
<strong>Théorème. i.</strong> Soit <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires telle que, pour tout entier naturel <span class="math inline">\(n\)</span>, on ait <span class="math inline">\(X_n\sim\mathcal{B}(n, p_n)\)</span>.</p>
<p>On suppose que <span class="math inline">\(p_n\underset{n \to +\infty}{\overset{}{\longrightarrow}}0\)</span> et <span class="math inline">\(np_n\underset{n \to +\infty}{\overset{}{\longrightarrow}}\lambda\)</span>, où <span class="math inline">\(\lambda\)</span> est un réel. Alors</p>
<p><span class="math display">\[X_n \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}\mathcal{P}(\lambda)\]</span></p>
<p></p>
<p><strong>ii.</strong> Soit <span class="math inline">\((X_n)_n\)</span> une suite i.i.d. de variables aléatoires suivant une loi de Bernoulli de paramètre <span class="math inline">\(p\in ]0\,;\,1[\)</span> :</p>
<p><span class="math display">\[\forall i\in\mathbb{N},\, X_i\sim\mathcal{B}(p)\]</span></p>
<p>Pour tout entier naturel <span class="math inline">\(n\)</span>, on pose <span class="math inline">\(S_n=\sum\limits_{i=1}^n X_i\)</span>. Alors</p>
<p><span class="math display">\[\frac{S_n-np}{\sqrt{npq}} \underset{n \to +\infty}{\overset{\mathcal{L}}{\longrightarrow}}\mathcal{N}(0\,;\,1)\]</span></p>
</div>
<p> </p>
<p> Le deuxième résultat nous dit que la loi binomiale <span class="math inline">\(\mathcal{B}(n\,;\,p)\)</span> peut être approchée par la loi normale <span class="math inline">\(\mathcal{N}(np\,;\,npq)\)</span>. On considère généralement que cette approximation est bonne pour <span class="math inline">\(n\geq 30, np\geq 5\)</span> et <span class="math inline">\(nq\geq 5\)</span>.</p>
<p>L’exemple suivant montre un intérêt pratique de ces appoximations.</p>
<p>
<strong>Exemple (contrôle de fabrication).</strong> On souhaite effectuer un contrôle de fabrication sur un lot de <span class="math inline">\(1\,000\)</span> pièces. On sait que la probabilité qu’une pièce soit défectueuse est <span class="math inline">\(p=0,02\)</span>. On suppose que les pièces sont défectueuses ou non indépendamment des autres pièces.</p>
<p>On souhaite évaluer la probabilité que le lot contienne entre <span class="math inline">\(18\)</span> et <span class="math inline">\(22\)</span> pièces défectueuses.</p>
<p>On note <span class="math inline">\(X\)</span> le nombre de pièces défectueuses. Alors, <span class="math inline">\(X\)</span> suit une loi binomiale de paramètres <span class="math inline">\(n=1\,000\)</span> et <span class="math inline">\(p=0,02\)</span> :</p>
<p><span class="math display">\[X\sim\mathcal{B}(1\,000\,;\,0,02)\]</span></p>
<p>Le calcul de <span class="math inline">\(\mathbb{P}(X\in[18\,;\,22])\)</span> est trop compliqué pour être envisagé de manière exacte, on va donc fournir une valeur approchée.</p>
<p>Nous allons envisager à la fois une approximation par une loi de Poisson et par une loi normale.</p>
<p>
<strong>Approximation 1 : par une loi de Poisson.</strong> On a :</p>
<ul>
<li><span class="math inline">\(n\=1\,000\geq 30\)</span></li>
<li><span class="math inline">\(np=20\)</span>, donc <span class="math inline">\(np\)</span> n’est pas inférieur à 5</li>
</ul>
<p>Même si dans le cas présent la deuxième condition n’est pas vérifiée, nous calculons tout de même l’approximation par la loi de Poisson <span class="math inline">\(\mathcal{P}(20)\)</span>.</p>
<p>Avec une table de la loi de Poisson, on obtient, en notant <span class="math inline">\(Y\)</span> une variable aléatoire telle que <span class="math inline">\(Y\sim\mathcal{P}(20)\)</span> :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(18\leq X \leq 22) &amp;\approx\mathbb{P}(18\leq Y\leq 22) \\
&amp;\approx 0,42 \\
\end{align}\]</span></p>
<p>
<strong>Approximation 2 : par une loi normale.</strong> On a :</p>
<ul>
<li><span class="math inline">\(n=1\,000\geq 30\)</span></li>
<li><span class="math inline">\(np=20\geq 5\)</span></li>
<li><span class="math inline">\(nq=980\geq 5\)</span></li>
</ul>
<p>On peut donc approcher la loi de <span class="math inline">\(X\)</span> par la loi normale de paramètres <span class="math inline">\(np=20\)</span> et <span class="math inline">\(npq=19,6\)</span> :</p>
<p><span class="math display">\[X\approx\mathcal{N}(20\,;\,19,6)\]</span>
Pour calculer <span class="math inline">\(\mathbb{P}(X\in [18\,;\,22])\)</span>, on doit se ramener à une loi normale standard <span class="math inline">\(\mathcal{N}(0\,;\,1)\)</span> pour laquelle on dispose de tables. Pour cela, on centre et on réduit <span class="math inline">\(X\)</span> :</p>
<p><span class="math display">\[Y=\frac{X-20}{\sqrt{19,6}}\]</span>
On a donc</p>
<p><span class="math display">\[\begin{align*}
\mathbb{P}\left(18\leq X\leq 22\right)&amp;=\mathbb{P}\left(\frac{18-20}{\sqrt{19,6}}\leq Y\leq\frac{22-20}{\sqrt{19,6}}\right) \\
&amp;\approx\mathbb{P}(-0,45\leq X\leq 0,45) \\
&amp;\approx 0,35
\end{align*}\]</span></p>
<p></p>
<p><strong>Calcul avec la vraie loi binomiale.</strong> On obtient <span class="math inline">\(\mathbb{P}(18\leq X\leq 22)\approx 0,43\)</span>. Dans cet exemple, l’approximation par la loi de Poisson est donc meilleure que celle par la loi normale.</p>
</div>
</div>
<div id="lois-des-grands-nombres" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Lois des grands nombres<a href="convergence.html#lois-des-grands-nombres" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Le programme du concours mentionne deux lois des grands nombres, qui permettent de montrer la convergence de la moyenne empirique vers la moyenne théorique :</p>
<ul>
<li><p>la loi faible des grands nombres, où la convergence est une convergence en probabilités ;</p></li>
<li><p>la loi (forte) des grands nombres dans <span class="math inline">\(L^2\)</span>, où la convergence est une convergence presque sûre, donc en un sens plus fort que celle de la loi faible.</p></li>
</ul>
<div class="thmbox thm">
<p><strong>Loi faible des grands nombres (théorème de Khintchine).</strong> Soit <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires i.i.d. et admettant une espérance <span class="math inline">\(\mu=\mathbb{E}(X_1)\)</span>, i.e. <span class="math inline">\(X_1\in L^1(\Omega, \mathcal{A}, \mathbb{P})\)</span>. Alors, la moyenne empirique</p>
<p><span class="math display">\[\overline{X_n}=\frac{X_1+\dots+X_n}{n}\]</span>
converge en probabilité vers <span class="math inline">\(\mu=\mathbb{E}(X_1)\)</span>. Autrement dit :</p>
<p><span class="math display">\[\forall\varepsilon &gt;0, \mathbb{P}\left(\left|\overline{X_n}-\mu\right|\geq\varepsilon\right)\longrightarrow 0\]</span></p>
</div>
<p>La loi des grands nombres dans <span class="math inline">\(L^2\)</span> permet d’obtenir une convergence en un sens plus fort (presque sûre plutôt qu’en probabilités), au prix d’une hypothèse plus forte (variables dans <span class="math inline">\(L^2\)</span> plutôt que dans <span class="math inline">\(L^1\)</span>) :</p>
<div class="thmbox thm">
<p><strong>Loi des grands nombres dans <span class="math inline">\(L^2\)</span>.</strong> Soit <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires i.i.d. telle que <span class="math inline">\(\mathbb{E}(X_1^2)&lt;+\infty\)</span>, i.e. <span class="math inline">\(X_1\in L^2(\Omega, \mathcal{A}, \mathbb{P})\)</span>. Alors, la moyenne empirique</p>
<p><span class="math display">\[\overline{X_n}=\frac{X_1+\dots+X_n}{n}\]</span>
converge presque sûrement vers <span class="math inline">\(\mathbb{E}(X_1)\)</span>.</p>
</div>
<p>On a en fait même un peu mieux. En effet, l’hypothèse d’appartenance à <span class="math inline">\(L^2\)</span> n’est pas nécessaire pour obtenir une convergence presque sûre : une appartenance à <span class="math inline">\(L^1\)</span> est suffisante. Ce resultat est connu usuellement sous le nom de <em>loi forte des grands nombres</em>.</p>
<div class="thmbox thm">
<p><strong>Loi forte des grands nombres (hors-programme ?).</strong> Soit <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires i.i.d. telle que <span class="math inline">\(\mathbb{E}(|X_1|)&lt;+\infty\)</span>, i.e. <span class="math inline">\(X_1\in L^1(\Omega, \mathcal{A}, \mathbb{P})\)</span>. Alors, la moyenne empirique</p>
<p><span class="math display">\[\overline{X_n}=\frac{X_1+\dots+X_n}{n}\]</span>
converge presque sûrement vers <span class="math inline">\(\mathbb{E}(X_1)\)</span>.</p>
</div>
<p>Ce résultat n’étant pas mentionné explicitemnt dans la notice du concours, il est donc <em>a priori</em> hors-programme.</p>
<p></p>
<p><strong>Conséquence :</strong> sauf indication contraire de l’énoncé, pour démontrer une convergence presque sûre de la moyenne empirique vers la moyenne théorique, il faut au préalable s’assurer que les <span class="math inline">\(X_i\)</span> sont dans <span class="math inline">\(L^2\)</span> (<span class="math inline">\(L^1\)</span> ne suffit pas dans ce cadre).</p>
<ul>
<li>énoncé théorique</li>
<li>exemples avec illustration en R</li>
</ul>
</div>
<div id="théorème-central-limite-tcl" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Théorème Central Limite (TCL)<a href="convergence.html#théorème-central-limite-tcl" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="thmbox thm">
<p><strong>Théorème central limite.</strong> Soit <span class="math inline">\((X_n)_n\)</span> une suite de variables aléatoires i.i.d. admettant un moment d’ordre 2. On pose</p>
<p><span class="math display">\[\mu=\mathbb{E(X_1)}\]</span>
<span class="math display">\[\sigma^2=\mathbb{V}(X_1)\]</span>
On pose</p>
<p><span class="math display">\[S_n=X_1+\dots+X_n\]</span></p>
<p>Alors, la variable aléatoire</p>
<p><span class="math display">\[Z_n=\frac{S_n-n\mu}{\sigma\sqrt{n}}\]</span>
converge en loi vers la loi normale standard <span class="math inline">\(\mathcal{N}(0,1)\)</span>.</p>
</div>
<ul>
<li>énoncé théorique</li>
<li>exemples avec illustration en R</li>
</ul>
</div>
<div id="variantes-du-tcl-hors-programme" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Variantes du TCL (hors-programme)<a href="convergence.html#variantes-du-tcl-hors-programme" class="anchor-section" aria-label="Anchor link to header"></a></h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="variables-aléatoires-à-densité.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="statistique-descriptive.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/4_convergence.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Probabilites_Statistique.pdf", "Probabilites_Statistique.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
