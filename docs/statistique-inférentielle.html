<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 7 Statistique inférentielle | Cours de probabilités-statistiques pour le concours interne d’administrateur Insee</title>
  <meta name="description" content="Cours de probabilités et statistiques" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 7 Statistique inférentielle | Cours de probabilités-statistiques pour le concours interne d’administrateur Insee" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Cours de probabilités et statistiques" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 7 Statistique inférentielle | Cours de probabilités-statistiques pour le concours interne d’administrateur Insee" />
  
  <meta name="twitter:description" content="Cours de probabilités et statistiques" />
  

<meta name="author" content="Olivier Guin" />


<meta name="date" content="2024-03-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="statistique-descriptive.html"/>
<link rel="next" href="méthodologie.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Cours de probabilités et statistique pour le concours interne d'administrateur de l'Insee</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Présentation du cours</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#généralités"><i class="fa fa-check"></i><b>1.1</b> Généralités</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#coquilles-et-erreurs"><i class="fa fa-check"></i><b>1.2</b> Coquilles et erreurs</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html"><i class="fa fa-check"></i><b>2</b> Dénombrement et probabilités</a>
<ul>
<li class="chapter" data-level="2.1" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#rappels-sur-les-opérations-ensemblistes"><i class="fa fa-check"></i><b>2.1</b> Rappels sur les opérations ensemblistes</a></li>
<li class="chapter" data-level="2.2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#dénombrement"><i class="fa fa-check"></i><b>2.2</b> Dénombrement</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#produit-cartésien-et-principe-multiplicatif"><i class="fa fa-check"></i><b>2.2.1</b> Produit cartésien et principe multiplicatif</a></li>
<li class="chapter" data-level="2.2.2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#principe-additif"><i class="fa fa-check"></i><b>2.2.2</b> Principe additif</a></li>
<li class="chapter" data-level="2.2.3" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#formule-de-poincaré"><i class="fa fa-check"></i><b>2.2.3</b> Formule de Poincaré</a></li>
<li class="chapter" data-level="2.2.4" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#dénombrement-par-bijection"><i class="fa fa-check"></i><b>2.2.4</b> Dénombrement par bijection</a></li>
<li class="chapter" data-level="2.2.5" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#permutations"><i class="fa fa-check"></i><b>2.2.5</b> Permutations</a></li>
<li class="chapter" data-level="2.2.6" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#arrangements"><i class="fa fa-check"></i><b>2.2.6</b> Arrangements</a></li>
<li class="chapter" data-level="2.2.7" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#combinaisons"><i class="fa fa-check"></i><b>2.2.7</b> Combinaisons</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#langage-des-probabilités"><i class="fa fa-check"></i><b>2.3</b> Langage des probabilités</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#lunivers-omega-dune-expérience-aléatoire"><i class="fa fa-check"></i><b>2.3.1</b> L’univers <span class="math inline">\(\Omega\)</span> d’une expérience aléatoire</a></li>
<li class="chapter" data-level="2.3.2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#lespace-probabilisable-omega-mathcala"><i class="fa fa-check"></i><b>2.3.2</b> L’espace probabilisable <span class="math inline">\((\Omega, \mathcal{A})\)</span></a></li>
<li class="chapter" data-level="2.3.3" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#lespace-probabilisé-omega-mathcala-mathbbp"><i class="fa fa-check"></i><b>2.3.3</b> L’espace probabilisé <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span></a></li>
<li class="chapter" data-level="2.3.4" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#indépendance"><i class="fa fa-check"></i><b>2.3.4</b> Indépendance</a></li>
<li class="chapter" data-level="2.3.5" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#probabilités-conditionnelles"><i class="fa fa-check"></i><b>2.3.5</b> Probabilités conditionnelles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html"><i class="fa fa-check"></i><b>3</b> Variables aléatoires discrètes</a>
<ul>
<li class="chapter" data-level="3.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#définition-et-premières-propriétés"><i class="fa fa-check"></i><b>3.1</b> Définition et premières propriétés</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#définition"><i class="fa fa-check"></i><b>3.1.1</b> Définition</a></li>
<li class="chapter" data-level="3.1.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#loi-dune-variable-aléatoire-discrète"><i class="fa fa-check"></i><b>3.1.2</b> Loi d’une variable aléatoire discrète</a></li>
<li class="chapter" data-level="3.1.3" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#définition-de-pxin-a"><i class="fa fa-check"></i><b>3.1.3</b> Définition de <span class="math inline">\(p(X\in A)\)</span></a></li>
<li class="chapter" data-level="3.1.4" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#fonction-de-répartition-quantiles"><i class="fa fa-check"></i><b>3.1.4</b> Fonction de répartition, quantiles</a></li>
<li class="chapter" data-level="3.1.5" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#exemples-classiques"><i class="fa fa-check"></i><b>3.1.5</b> Exemples classiques :</a></li>
<li class="chapter" data-level="3.1.6" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#moments-dune-variable-aléatoire"><i class="fa fa-check"></i><b>3.1.6</b> Moments d’une variable aléatoire</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#transformation-dune-variable-aléatoire-discrète"><i class="fa fa-check"></i><b>3.2</b> Transformation d’une variable aléatoire discrète</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#définition-1"><i class="fa fa-check"></i><b>3.2.1</b> Définition</a></li>
<li class="chapter" data-level="3.2.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#théorème-de-transfert-cas-discret"><i class="fa fa-check"></i><b>3.2.2</b> Théorème de transfert (cas discret)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#vecteurs-aléatoires"><i class="fa fa-check"></i><b>3.3</b> Vecteurs aléatoires</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#définition-2"><i class="fa fa-check"></i><b>3.3.1</b> Définition</a></li>
<li class="chapter" data-level="3.3.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#loi-jointe-loi-marginales"><i class="fa fa-check"></i><b>3.3.2</b> Loi jointe, loi marginales</a></li>
<li class="chapter" data-level="3.3.3" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#loi-conditionnelle-mathcallyx"><i class="fa fa-check"></i><b>3.3.3</b> Loi conditionnelle <span class="math inline">\(\mathcal{L}(Y|X)\)</span></a></li>
<li class="chapter" data-level="3.3.4" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#loi-dun-couple-de-va-indépendantes"><i class="fa fa-check"></i><b>3.3.4</b> Loi d’un couple de VA indépendantes</a></li>
<li class="chapter" data-level="3.3.5" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#espérance-conditionnelle-variance-conditionnelle"><i class="fa fa-check"></i><b>3.3.5</b> Espérance conditionnelle, variance conditionnelle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html"><i class="fa fa-check"></i><b>4</b> Variables aléatoires à densité</a>
<ul>
<li class="chapter" data-level="4.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-et-premières-propriétés-1"><i class="fa fa-check"></i><b>4.1</b> Définition et premières propriétés</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-3"><i class="fa fa-check"></i><b>4.1.1</b> Définition</a></li>
<li class="chapter" data-level="4.1.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#loi-dune-variable-aléatoire-à-densité"><i class="fa fa-check"></i><b>4.1.2</b> Loi d’une variable aléatoire à densité</a></li>
<li class="chapter" data-level="4.1.3" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-de-pxin-a-1"><i class="fa fa-check"></i><b>4.1.3</b> Définition de <span class="math inline">\(p(X\in A)\)</span></a></li>
<li class="chapter" data-level="4.1.4" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#fonction-de-répartition-quantiles-1"><i class="fa fa-check"></i><b>4.1.4</b> Fonction de répartition, quantiles</a></li>
<li class="chapter" data-level="4.1.5" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#exemples-classiques-1"><i class="fa fa-check"></i><b>4.1.5</b> Exemples classiques :</a></li>
<li class="chapter" data-level="4.1.6" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#moments-dune-variable-aléatoire-1"><i class="fa fa-check"></i><b>4.1.6</b> Moments d’une variable aléatoire</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#transformation-dune-variable-aléatoire-à-densité"><i class="fa fa-check"></i><b>4.2</b> Transformation d’une variable aléatoire à densité</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-4"><i class="fa fa-check"></i><b>4.2.1</b> Définition</a></li>
<li class="chapter" data-level="4.2.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#théorème-de-transfert-cas-à-densité"><i class="fa fa-check"></i><b>4.2.2</b> Théorème de transfert (cas à densité)</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#vecteurs-aléatoires-1"><i class="fa fa-check"></i><b>4.3</b> Vecteurs aléatoires</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-5"><i class="fa fa-check"></i><b>4.3.1</b> Définition</a></li>
<li class="chapter" data-level="4.3.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#loi-jointe-loi-marginales-1"><i class="fa fa-check"></i><b>4.3.2</b> Loi jointe, loi marginales</a></li>
<li class="chapter" data-level="4.3.3" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#loi-conditionnelle-mathcallyx-1"><i class="fa fa-check"></i><b>4.3.3</b> Loi conditionnelle <span class="math inline">\(\mathcal{L}(Y|X)\)</span></a></li>
<li class="chapter" data-level="4.3.4" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#loi-dun-couple-de-va-indépendantes-1"><i class="fa fa-check"></i><b>4.3.4</b> Loi d’un couple de VA indépendantes</a></li>
<li class="chapter" data-level="4.3.5" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#espérance-matrice-de-variance-covariance"><i class="fa fa-check"></i><b>4.3.5</b> Espérance, matrice de variance-covariance</a></li>
<li class="chapter" data-level="4.3.6" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#espérance-conditionnelle-variance-conditionnelle-1"><i class="fa fa-check"></i><b>4.3.6</b> Espérance conditionnelle, variance conditionnelle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="convergence.html"><a href="convergence.html"><i class="fa fa-check"></i><b>5</b> Convergence</a>
<ul>
<li class="chapter" data-level="5.1" data-path="convergence.html"><a href="convergence.html#différents-modes-de-convergence"><i class="fa fa-check"></i><b>5.1</b> Différents modes de convergence</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="convergence.html"><a href="convergence.html#convergence-en-probabilité"><i class="fa fa-check"></i><b>5.1.1</b> Convergence en probabilité</a></li>
<li class="chapter" data-level="5.1.2" data-path="convergence.html"><a href="convergence.html#convergence-dans-les-espaces-lp"><i class="fa fa-check"></i><b>5.1.2</b> Convergence dans les espaces <span class="math inline">\(L^p\)</span></a></li>
<li class="chapter" data-level="5.1.3" data-path="convergence.html"><a href="convergence.html#convergence-en-loi"><i class="fa fa-check"></i><b>5.1.3</b> Convergence en loi</a></li>
<li class="chapter" data-level="5.1.4" data-path="convergence.html"><a href="convergence.html#convergence-presque-sûre-hors-prgramme"><i class="fa fa-check"></i><b>5.1.4</b> Convergence presque-sûre (hors-prgramme ?)</a></li>
<li class="chapter" data-level="5.1.5" data-path="convergence.html"><a href="convergence.html#liens-entre-les-différents-modes-de-convergence"><i class="fa fa-check"></i><b>5.1.5</b> Liens entre les différents modes de convergence</a></li>
<li class="chapter" data-level="5.1.6" data-path="convergence.html"><a href="convergence.html#approximations"><i class="fa fa-check"></i><b>5.1.6</b> Approximations</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="convergence.html"><a href="convergence.html#loi-faible-des-grands-nombres-loi-forte-des-grands-nombres"><i class="fa fa-check"></i><b>5.2</b> Loi Faible des Grands Nombres, Loi Forte des Grands Nombres</a></li>
<li class="chapter" data-level="5.3" data-path="convergence.html"><a href="convergence.html#théorème-central-limite-tcl"><i class="fa fa-check"></i><b>5.3</b> Théorème Central Limite (TCL)</a></li>
<li class="chapter" data-level="5.4" data-path="convergence.html"><a href="convergence.html#variantes-du-tcl-hors-programme"><i class="fa fa-check"></i><b>5.4</b> Variantes du TCL (hors-programme)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html"><i class="fa fa-check"></i><b>6</b> Statistique descriptive</a>
<ul>
<li class="chapter" data-level="6.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#vocabulaire"><i class="fa fa-check"></i><b>6.1</b> Vocabulaire</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#population-individus-échantillon"><i class="fa fa-check"></i><b>6.1.1</b> Population, individus, échantillon</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#analyse-statistique-univariée"><i class="fa fa-check"></i><b>6.2</b> Analyse statistique univariée</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#notion-de-série-statistique-univariée"><i class="fa fa-check"></i><b>6.2.1</b> Notion de série statistique univariée</a></li>
<li class="chapter" data-level="6.2.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#indicateurs-dune-série-statistique-univariée"><i class="fa fa-check"></i><b>6.2.2</b> Indicateurs d’une série statistique univariée</a></li>
<li class="chapter" data-level="6.2.3" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#représentations-graphiques"><i class="fa fa-check"></i><b>6.2.3</b> Représentations graphiques</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#analyse-statistique-bivariée"><i class="fa fa-check"></i><b>6.3</b> Analyse statistique bivariée</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#notion-de-série-statistique-bivariée"><i class="fa fa-check"></i><b>6.3.1</b> Notion de série statistique bivariée</a></li>
<li class="chapter" data-level="6.3.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#indicateurs-propres-à-lanalyse-statistique-multivariée"><i class="fa fa-check"></i><b>6.3.2</b> Indicateurs propres à l’analyse statistique multivariée</a></li>
<li class="chapter" data-level="6.3.3" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#nuage-de-points"><i class="fa fa-check"></i><b>6.3.3</b> Nuage de points</a></li>
<li class="chapter" data-level="6.3.4" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#ajustement-des-moindres-carrés"><i class="fa fa-check"></i><b>6.3.4</b> Ajustement des moindres carrés</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html"><i class="fa fa-check"></i><b>7</b> Statistique inférentielle</a>
<ul>
<li class="chapter" data-level="7.1" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#estimation"><i class="fa fa-check"></i><b>7.1</b> Estimation</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#premières-définitions"><i class="fa fa-check"></i><b>7.1.1</b> Premières définitions</a></li>
<li class="chapter" data-level="7.1.2" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#convergence-dun-estimateur"><i class="fa fa-check"></i><b>7.1.2</b> Convergence d’un estimateur</a></li>
<li class="chapter" data-level="7.1.3" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#exemples-classiques-2"><i class="fa fa-check"></i><b>7.1.3</b> Exemples classiques</a></li>
<li class="chapter" data-level="7.1.4" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#méthodes-de-construction-des-estimateurs"><i class="fa fa-check"></i><b>7.1.4</b> Méthodes de construction des estimateurs</a></li>
<li class="chapter" data-level="7.1.5" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#compléments-hors-programme"><i class="fa fa-check"></i><b>7.1.5</b> Compléments (hors-programme)</a></li>
<li class="chapter" data-level="7.1.6" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#estimation-des-coefficients-dune-régression-linéaire"><i class="fa fa-check"></i><b>7.1.6</b> Estimation des coefficients d’une régression linéaire</a></li>
<li class="chapter" data-level="7.1.7" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#intervalles-de-confiance"><i class="fa fa-check"></i><b>7.1.7</b> Intervalles de confiance</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#tests-statistiques"><i class="fa fa-check"></i><b>7.2</b> Tests statistiques</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#définition-et-principes"><i class="fa fa-check"></i><b>7.2.1</b> Définition et principes</a></li>
<li class="chapter" data-level="7.2.2" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#tests-unilatéraux-tests-bilatéraux"><i class="fa fa-check"></i><b>7.2.2</b> Tests unilatéraux, tests bilatéraux</a></li>
<li class="chapter" data-level="7.2.3" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#exemples"><i class="fa fa-check"></i><b>7.2.3</b> Exemples</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="méthodologie.html"><a href="méthodologie.html"><i class="fa fa-check"></i><b>8</b> Méthodologie</a>
<ul>
<li class="chapter" data-level="8.1" data-path="méthodologie.html"><a href="méthodologie.html#convergence-1"><i class="fa fa-check"></i><b>8.1</b> Convergence</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Cours de probabilités-statistiques pour le concours interne d’administrateur Insee</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistique-inférentielle" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Chapitre 7</span> Statistique inférentielle<a href="statistique-inférentielle.html#statistique-inférentielle" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="estimation" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Estimation<a href="statistique-inférentielle.html#estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>On s’intéresse à une loi probabiliste <span class="math inline">\(\mathcal{L}_{\theta}\)</span>, qui est entièrement décrite par la donnée d’un paramètre inconnu <span class="math inline">\(\theta\)</span>. Pour mieux appréhender cette loi, il serait intéressant de connaître la valeur de <span class="math inline">\(\theta\)</span>. Plutôt que de chercher à déterminer la valeur exacte de <span class="math inline">\(\theta\)</span>, on peut essayer de l’approcher. Dans le cadre de la statistique inférentielle, on suppose qu’on dispose d’un <strong>échantillon i.i.d.</strong> de <span class="math inline">\(\mathcal{L}_{\theta}\)</span>, autrement dit d’un certain nombre de réalisations <span class="math inline">\((Y_1,\dots, Y_n)\)</span> indépendantes et identiquement distribuées de la loi <span class="math inline">\(\mathcal{L}_{\theta}\)</span>.</p>
<p>La donnée d’un tel échantillon constitue un ensemble d’<strong>informations</strong> qui vont nous être utiles pour <strong>estimer</strong> le paramètre <span class="math inline">\(\theta\)</span>. on fait donc bien ici de l’<em>inférence</em> - ou encore de l’<em>induction</em> - dans le sens où on part d’observations particulières (les réalisations <span class="math inline">\(Y_1,\dots, Y_n)\)</span> pour énoncer une règle générale (le fait que ces réalisations sont issues de la loi <span class="math inline">\(\mathcal{L}_{\theta}\)</span>).</p>
<div id="premières-définitions" class="section level3 hasAnchor" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> Premières définitions<a href="statistique-inférentielle.html#premières-définitions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="defbox def">
<center>
<strong>Estimateurs</strong>
</center>
<p>Soit <span class="math inline">\(Y\)</span> une variable aléatoire de loi <span class="math inline">\(\mathcal{L}(Y)\)</span>, paramétrée par un réel <span class="math inline">\(\theta\)</span> inconnu. Soit <span class="math inline">\((Y_1,\dots, Y_n)\)</span> un échantillon i.i.d. de loi <span class="math inline">\(\mathcal{L}(Y)\)</span>. On appelle <em>estimateur</em> de <span class="math inline">\(\theta\)</span> toute fonction de <span class="math inline">\(Y_1,\dots, Y_n\)</span>, i.e. <span class="math display">\[\widehat{\theta}_n=S(Y_1,\dots, Y_n)\]</span></p>
</div>
<p>On veut estimer la moyenne d’une loi normale <span class="math inline">\(\mathcal{N}(\mu\,;\,1)\)</span>, à partir d’un échantillon d’observations i.i.d. <span class="math inline">\((Y_1,\dots, Y_n)\)</span> tirées sous cette loi. Une façon naturelle d’estimer <span class="math inline">\(\mu=\mathbb{E}(Y_1)\)</span> est de poser <span class="math inline">\(\widehat{\mu}_n=\frac{Y_1+\dots Y_n}{n}\)</span>. Ici, on estime donc une moyenne théorique par sa contrepartie <em>empirique</em>.</p>
<div class="defbox def">
<center>
<strong>Biais, erreur quadratique</strong>
</center>
<p>Soit <span class="math inline">\(\widehat{\theta}_n\)</span> un estimateur de <span class="math inline">\(\theta\)</span> admettant un moment d’ordre <span class="math inline">\(1\)</span>.</p>
<ul>
<li><p>On appelle <strong>biais</strong> de <span class="math inline">\(\widehat{\theta}_n\)</span> la quantité <span class="math inline">\(b_{\theta}(\widehat{\theta}_n)=\mathbb{E}(\widehat{\theta}_n)-\theta\)</span>.</p></li>
<li><p>Un estimateur est dit <strong>sans biais</strong> lorsque son biais est nul, i.e. <span class="math inline">\(\mathbb{E}(\widehat{\theta}_n)=\theta\)</span>.</p></li>
<li><p>Il est dit <strong>asymptotiquement sans biais</strong> lorsque son biais tend vers <span class="math inline">\(0\)</span>, i.e. <span class="math inline">\(b_{\theta}(\widehat{\theta}_n)\underset{n\to +\infty}{\longrightarrow}0\)</span>.</p></li>
<li><p>Pour un estimateur des moments d’ordre <span class="math inline">\(1\)</span> et <span class="math inline">\(2\)</span>, on appelle <strong>erreur quadratique moyenne</strong> la quantité (positive) <span class="math inline">\(\text{EQM}_{\theta}(\widehat{\theta}_n)=\mathbb{E}\left(\left(\widehat{\theta}_n-\theta\right)^2\right)\)</span></p></li>
</ul>
</div>
<p>L’erreur quadratique moyenne s’écrit à l’aide de l’espérance et de la variance :</p>
<div class="thmbox thm">
<p><strong>Théorème :</strong> Soit <span class="math inline">\(\widehat{\theta}_n\)</span> un estimateur de <span class="math inline">\(\theta\)</span> admettant des moments d’ordres <span class="math inline">\(1\)</span> et <span class="math inline">\(2\)</span>. Son erreur quadratique moyenne peut se décomposer en biais au carré/variance :</p>
<p><span class="math display">\[\text{EQM}_{\theta}(\widehat{\theta}_n)=b_{\theta}^2(\widehat{\theta}_n)+\mathbb{V}(\widehat{\theta}_n)\]</span></p>
</div>
<p>Autrement dit, réduire l’erreur (quadratique moyenne) d’un estimateur revient à essayer de réduire son biais et/ou sa variance. En pratique, uune réduction du biais implique souvent une augmentation de la variance (et vice-versa) et il faut trouver un compromis entre les deux, i.e. un estimateur pour lequel la combinaison (biais, variance) implique une faible erreur quadratique moyenne. On parle alors de <strong>compromis biais-variance</strong>.</p>
</div>
<div id="convergence-dun-estimateur" class="section level3 hasAnchor" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> Convergence d’un estimateur<a href="statistique-inférentielle.html#convergence-dun-estimateur" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="defbox def">
<center>
<strong>Estimateurs convergents</strong>
</center>
<p>Un estimateur <span class="math inline">\(\widehat{\theta}_n\)</span> de <span class="math inline">\(\theta\)</span> est dit <strong>convergent</strong> lorsqu’il converge en probabilité vers <span class="math inline">\(\theta\)</span> i.e. lorsque</p>
<p><span class="math display">\[\forall\varepsilon &gt;0, \mathbb{P}\left(|\widehat{\theta}_n-\theta|&gt;\varepsilon\right)\longrightarrow 0\]</span></p>
</div>
<p>La convergence d’un estimateur sans biais peut se montrer à l’aide du critère pratique suivant :</p>
<div class="thmbox thm">
<p>
<strong>Théorème (critère pratique de convergence) :</strong> Un estimateur <span class="math inline">\(\widehat{\theta}_n\)</span> sans biais de <span class="math inline">\(\theta\)</span> est <strong>convergent</strong> dès que sa variance tend vers <span class="math inline">\(0\)</span>, i.e. <span class="math display">\[\left(\mathbb{E}_{\theta}(\widehat{\theta}_n)=0 \text{ et } \mathbb{V}_{\theta}(\widehat{\theta}_n)\longrightarrow 0\right)\Rightarrow \left(\widehat{\theta}_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}\theta\right)\]</span></p>
</div>
<p>
<strong>Démonstration.</strong> Compte-tenu du fait que <span class="math inline">\(\widehat{\theta}_n\)</span> est un estimateur sans biais pour <span class="math inline">\(\theta\)</span>, l’inégalité de Bieanymé-Tchebychev s’écrit <span class="math inline">\(\mathbb{P}(|\widehat{\theta}_n-\theta|&gt;\varepsilon)\leq\frac{\mathbb{V}_{\theta}(\widehat{\theta}_n)}{\varepsilon^2}\)</span>, ce qui permet de conclure. <span class="math inline">\(\square\)</span></p>
<p>On peut même affaiblir un peu l’hypothèse d’absence de biais par une hypothèse de biais asymptotiquement nul :</p>
<div class="thmbox thm">
<p>
<strong>Théorème (critère pratique de convergence (suite)) :</strong> Un estimateur <span class="math inline">\(\widehat{\theta}_n\)</span> asymtotiquement sans biais de <span class="math inline">\(\theta\)</span> est <strong>convergent</strong> dès que sa variance tend vers <span class="math inline">\(0\)</span>, i.e. <span class="math display">\[\left(\mathbb{E}_{\theta}(\widehat{\theta}_n)\underset{n\to +\infty}{\longrightarrow}\theta \text{ et } \mathbb{V}_{\theta}(\widehat{\theta}_n)\longrightarrow 0\right)\Rightarrow \left(\widehat{\theta}_n \underset{n \to +\infty}{\overset{\mathbb{P}}{\longrightarrow}}\theta\right)\]</span></p>
</div>
</div>
<div id="exemples-classiques-2" class="section level3 hasAnchor" number="7.1.3">
<h3><span class="header-section-number">7.1.3</span> Exemples classiques<a href="statistique-inférentielle.html#exemples-classiques-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Quelques exemples très classiques d’estimateurs :</p>
<p>
<strong>Exemple 1 : moyenne empirique.</strong> Soit <span class="math inline">\(X_1,\dots X_n\)</span> une suite de <span class="math inline">\(VAR\)</span> i.i.d. de même loi que <span class="math inline">\(X\)</span>, admettant une espérance <span class="math inline">\(\mu\)</span>. La <em>moyenne empirique</em> est l’estimateur <span class="math display">\[\overline{X_n}=\frac{X_1+\dots + X_n}{n}\]</span></p>
<div class="thmbox thm">
<p><strong>Théorème :</strong> Quelle que soit la loi suivie par <span class="math inline">\(X\)</span>, la moyenne empirique <span class="math inline">\(\overline{X_n}\)</span> est un <strong>estimateur sans biais</strong> de l’espérance <span class="math inline">\(\mu=\mathbb{E}(X)\)</span>. Si, de plus, <span class="math inline">\(X\)</span> admet une variance <span class="math inline">\(\sigma^2\)</span>, alors <span class="math inline">\(\overline{X_n}\)</span> admet également une variance et celle-ci est donnée par <span class="math inline">\(\mathbb{V}(\overline{X_n})=\frac{\sigma^2}{n}\)</span>.</p>
</div>
<p>
<strong>Démonstration.</strong> Par linéarité de l’espérance : <span class="math inline">\(\mathbb{E}(\overline{X_n})=\frac{1}{n}\sum\limits_{i=1}^n\mathbb{E}(X_i)=\frac{1}{n}\sum\limits_{i=1}^n\mu=\mu\)</span>. Si <span class="math inline">\(X\)</span> admet une variance, alors <span class="math inline">\(\overline{X_n}\)</span> aussi et <span class="math inline">\(\mathbb{V}(\overline{X_n})=\frac{1}{n^2}\sum\limits_{i=1}^n\mathbb{V}(X_i)=\frac{\sigma^2}{n}\)</span>, par indépendance de <span class="math inline">\(X_1,\dots X_n\)</span>. <span class="math inline">\(\square\)</span></p>
<div class="thmbox thm">
<p><strong>Corollaire :</strong> La moyenne empirique est un estimateur convergent de l’espérance (lorsqu’elle existe).</p>
</div>
<p>
<strong>Démonstration.</strong> L’estimateur <span class="math inline">\(\overline{X_n}\)</span> est sans biais et <span class="math inline">\(\mathbb{V}(\overline{X_n})=\frac{\sigma^2}{n}\longrightarrow 0\)</span>. C’est donc un estimateur convergent de l’espérance. <span class="math inline">\(\square\)</span>.</p>
<p>
<strong>Exemple 2 : estimation d’une proportion.</strong> Au sein d’une population, une proportion <span class="math inline">\(p\)</span> d’individus présente une caractéristique. On suppose que la présence de cette caractéristique est distribuée de façon identique et indépendante d’un individu à l’autre suivant la loi de Bernoulli de paramètre <span class="math inline">\(p\)</span>. On peut donc estimer la proportion <span class="math inline">\(p\)</span> au niveau population par la proportion <span class="math inline">\(\widehat{p_n}\)</span> au niveau échantillon : cet estimateur est la moyenne empirique, il est sans biais et de variance (inconnue) <span class="math inline">\(\frac{p(1-p)}{n}\)</span>.</p>
<p>
<strong>Exemple 3 : variance empirique.</strong> Si <span class="math inline">\(X\)</span> admet une variance <span class="math inline">\(\sigma^2\)</span> et <span class="math inline">\(X_1,\dots, X_n\)</span> sont i.i.d. de même loi que <span class="math inline">\(X\)</span>, alors un estimateur de <span class="math inline">\(\sigma^2\)</span> est donné par la variance empirique <span class="math inline">\(S_n^{&#39;2}=\frac{1}{n}\sum\limits_{i=1}^n(X_i-\overline{X_n})^2\)</span>.</p>
<div class="thmbox thm">
<p><strong>Théorème :</strong> La variance empirique <span class="math inline">\(S_n^{&#39;2}\)</span> est un estimateur biaisé de la variance <span class="math inline">\(\sigma^2\)</span>. Plus précisément, on a</p>
<p><span class="math display">\[\mathbb{E}(S_n^{&#39;2})=\frac{n-1}{n}\sigma^2\]</span></p>
</div>
<p>
<strong>Démonstration.</strong></p>
<span class="math display">\[\begin{align}
\mathbb{E}(S_n^{&#39;2}) &amp;= \frac{1}{n}\sum\limits_{i=1}^n\mathbb{E}(X_i^2)-\frac{2\overline{X_n}}{n}\sum\limits_{i=1}^n\mathbb{E}(X_i)+\frac{1}{n}\sum\limits_{i=1}^n\mathbb{E}(\overline{X_n}^2) \\
&amp;= \mathbb{E}(X^2)-\mathbb{E}(\overline{X_n}^2)
\end{align}\]</span>
<p>Par ailleurs :</p>
<span class="math display">\[\begin{align}
\mathbb{E}(\overline{X_n}^2)&amp;=\frac{1}{n^2}\sum\limits_{i=1}^n\mathbb{E}(X_i^2)+\frac{1}{n^2}\sum\limits_{i\neq j}\mathbb{E}(X_iX_j) \\
&amp;= \frac{1}{n}^2\sum\limits_{i=1}^n\mathbb{E}(X_i^2)+\frac{1}{n^2}\sum\limits_{i\neq j}\mathbb{E}(X_i)\mathbb{E}(X_j) \\
&amp;= \frac{1}{n}\mathbb{E}(X^2)+\frac{n-1}{n}\left(\mathbb{E}(X)\right)^2
\end{align}\]</span>
<p>Avec la formule de Huygens <span class="math inline">\(\mathbb{V}(X)=\mathbb{E}(X^2)-\mathbb{E}(X)^2\)</span>, on en déduit que</p>
<p><span class="math display">\[\mathbb{E}(S_n^{&#39;2})=\frac{n-1}{n}\sigma^2\]</span> <span class="math inline">\(\square\)</span></p>
<p>
<strong>Remarque.</strong> Le biais de l’estimateur <span class="math inline">\(S_n^{&#39;2}\)</span> devient cependant très faible pour <span class="math inline">\(n\)</span> suffisamment grand. Il s’agit d’un estimateur asymptotiquement sans biais de la variance <span class="math inline">\(\sigma^2\)</span> : <span class="math inline">\(\mathbb{E}(S_n^{&#39;2})\longrightarrow \sigma^2\)</span>.</p>
<p>
<strong>Exemple 4 : variance empirique corrigée.</strong> En modifiant l’estimateur de la variance empirique par un petit facteur correctif, on obtient un estimateur sans biais de la variance. Il suffit de poser</p>
<p><span class="math display">\[S_n^2=\frac{1}{n-1}\sum\limits_{i=1}^n(X_i-\overline{X_n})^2\]</span></p>
<p>Cet estimateur s’appelle la <strong>variance empirique corrigée</strong>.</p>
<div class="thmbox thm">
<p><strong>Théorème :</strong> La variance empirique corrigée <span class="math inline">\(S_n^2=\frac{1}{n-1}\sum\limits_{i=1}^n (X_i-\overline{X_n})^2\)</span> est un estimateur sans biais de la variance <span class="math inline">\(\sigma^2=\mathbb{V}(X)\)</span> :</p>
<p><span class="math display">\[\mathbb{E}(S_n^2)=\sigma^2\]</span></p>
</div>
</div>
<div id="méthodes-de-construction-des-estimateurs" class="section level3 hasAnchor" number="7.1.4">
<h3><span class="header-section-number">7.1.4</span> Méthodes de construction des estimateurs<a href="statistique-inférentielle.html#méthodes-de-construction-des-estimateurs" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On présente ici deux méthodes classiques de construction des estimateurs ; la <strong>méthode des moments</strong> et la <strong>méthode du maximum de vraisemblance</strong>.</p>
<div id="la-méthode-des-moments" class="section level4 hasAnchor" number="7.1.4.1">
<h4><span class="header-section-number">7.1.4.1</span> La méthode des moments<a href="statistique-inférentielle.html#la-méthode-des-moments" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="methbox meth">
<center>
<strong>La méthode des moments</strong>
</center>
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire réelle de loi <span class="math inline">\(\mathcal{L}_{\theta}\)</span>, où <span class="math inline">\(\theta\)</span> est un paramètre inconnu. On considère une fonction <span class="math inline">\(f\)</span> de <span class="math inline">\(I\subset\mathbb{R}\)</span> dans <span class="math inline">\(\mathbb{R}\)</span> telle que <span class="math inline">\(f(X)\)</span> admette une espérance. Comme la loi de <span class="math inline">\(X\)</span> dépend de <span class="math inline">\(\theta\)</span>, il en est de même de <span class="math inline">\(\mathbb{E}(f(X))\)</span>. La méthode des moments suppose qu’on sait expliciter une telle dépendance, i.e. qu’on connaisse une fonction <span class="math inline">\(g\)</span> telle que</p>
<p><span class="math display">\[\mathbb{E}(f(X))=g(\theta)\]</span></p>
<p>La contrepartie empirique du membre de gauche de cette égalité est <span class="math inline">\(\frac{1}{n}\sum\limits_{i=1}^n f(X_i)\)</span>, et la méthode des moments consiste alors à résoudre l’équation en <span class="math inline">\(\widehat{\theta}\)</span> :</p>
<p><span class="math display">\[g(\widehat{\theta})=\frac{1}{n}\sum\limits_{i=1}^n f(X_i)\]</span></p>
</div>
<p>
<strong>Exemple 5 : estimation du paramètre d’une loi exponentielle.</strong> Soit <span class="math inline">\(X\sim\mathcal{E}(\lambda)\)</span>, où <span class="math inline">\(\lambda&gt;0\)</span> est un paramètre inconnu que l’on veut estimer. La variable aléatoire <span class="math inline">\(X\)</span> admet une espérance, et celle-ci est donnée par <span class="math inline">\(\mathcal{E}(X)=\frac{1}{\lambda}\)</span>. La méthode des moments consiste alors à résoudre l’équation</p>
<p><span class="math display">\[\frac{1}{\widehat{\lambda_n}}=\frac{1}{n}\sum\limits_{i=1}^n X_i\]</span></p>
<p>Cette équation est très simple, elle admet pour solution</p>
<p><span class="math display">\[\widehat{\lambda_n}=\frac{1}{\overline{X_n}}\]</span></p>
<p>C’est l’estimateur que l’on obtient par la méthode des moments.</p>
<p>
<strong>Remarque.</strong> En reprenant les notations explicitées ci-dessus, on peut identifier les fonctions <span class="math inline">\(f\)</span> et <span class="math inline">\(g\)</span> :</p>
<p><span class="math display">\[f(x)=x\]</span> <span class="math display">\[g(x)=\frac{1}{x}\]</span> et ici évidemment <span class="math inline">\(\theta=\lambda\)</span>. En général, la méthode des moments s’utilise de façon complètement intuitive sans qu’on ait même à expliciter forcément les fonctions <span class="math inline">\(f\)</span> et <span class="math inline">\(g\)</span>.</p>
</div>
<div id="la-méthode-du-maximum-de-vraisemblance" class="section level4 hasAnchor" number="7.1.4.2">
<h4><span class="header-section-number">7.1.4.2</span> La méthode du maximum de vraisemblance<a href="statistique-inférentielle.html#la-méthode-du-maximum-de-vraisemblance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Une autre méthode de construction d’estimateurs est celle du <strong>maximum de vraisemblance</strong>. L’idée générale de cette méthode est la suivante. On suppose qu’on dispose de réalisations <span class="math inline">\(x_1,\dots x_n\)</span> d’une même variable aléatoire, dont la loi appartient à une famille paramétrique <span class="math inline">\(\left\{\mathcal{L}_{\theta}\,;\,\theta\in\Theta\right\}\)</span> et on cherche à estimer <span class="math inline">\(\theta\)</span>. Si par exemple on dispose d’une série de cinq obersations <span class="math inline">\((0.12, -0.65, 1.35, 1.04, -1.19, 0.08)\)</span> et qu’on veut inférer sur <span class="math inline">\(\theta\)</span> à partir de ces observations, on est enclin à penser que la valeur <span class="math inline">\(\theta=0\)</span> est plus plausible que la valeur <span class="math inline">\(\theta=-10\)</span>. La vraisemblance est une formalisation de l’idée intuitive de plausibilité d’un paramètre à partir d’une observation ou d’un ensemble d’observations.</p>
<p>A nouveau, <span class="math inline">\(X\)</span> désigne une variable aléatoire de loi dépendant d’un paramètre inconnu <span class="math inline">\(\theta\)</span>, et <span class="math inline">\(x\)</span> une réalisation de <span class="math inline">\(X\)</span>.</p>
<p>La <em>vraisemblance</em> <span class="math inline">\(L(x,.)\)</span> est une fonction de <span class="math inline">\(\theta\)</span> définie par</p>
<p><span class="math display">\[L(x;\theta)=\left\{
\begin{array}{lll}
\mathbb{P}_{\theta}(X=x) &amp;\text{; si } X \text{ est discrète} \\
f(x;\theta) &amp;\text{; si } X \text{ est une continue de densité } f(.;\theta) \\
\end{array}
\right.\]</span></p>
<p>
<strong>Remarque :</strong> D’autres notations existent dans la littérature, comme <span class="math inline">\(L(x|\theta), \mathbb{P}(X=x|\theta), f(x|\theta)\)</span>. Ces notations viennent de la statistique bayésienne (hors programme du concours) qui envisage <span class="math inline">\(\theta\)</span> comme une variable aléatoire de distribution inconnue. Dans ce cas, la vraisemblance s’interprète comme une probabilité ou une densité de probabilité.</p>
<p>La définition précédente s’étend au cas d’un échantillon <span class="math inline">\((X_1,\dots X_n)\)</span> de VA de même loi que <span class="math inline">\(X\)</span>. Dans ce cas, on note souvent <span class="math inline">\(L_n(x;\theta)\)</span> la vraisemblance, pour faire apparaître la dépendance en <span class="math inline">\(n\)</span>. Un cas particulier important est celui où ces VA sont i.i.d. Dans ce cas, la vraisemblance est définie par</p>
<p><span class="math display">\[L_n(x;\theta)=L_n(x_1,\dots,x_n ; \theta)=\left\{
\begin{array}{lll}
\prod\limits_{i=1}^n\mathbb{P}_{\theta}(X_i=x_i) &amp;\text{; si } X \text{ est discrète} \\
\prod\limits_{i=1}^n f(x_i,\theta) &amp;\text{; si } X \text{ est une continue de densité } f(.;\theta) \\
\end{array}
\right.\]</span></p>
<p>La méthode du maximum de vraisemblance consiste juste à dire que si toute l’information dont on dispose sur la variable aléatoire <span class="math inline">\(X\)</span> est l’observation de l’échantillon <span class="math inline">\((x_1, \dots, x_n)\)</span>, alors la meilleure estimation que l’on puisse faire de <span class="math inline">\(\theta\)</span> à partir de cette information est celle qui maximise la fonction de vraisemblance. Autrement dit, on cherche la valeur de <span class="math inline">\(\theta\)</span> qui rend l’observation <span class="math inline">\((x_1,\dots, x_n)\)</span> la plus plausible. Formellement :</p>
<div class="methbox meth">
<center>
<strong>Méthode du maximum de vraisemblance</strong>
</center>
<p>Etant donné une collection de <span class="math inline">\(n\)</span> réalisations <span class="math inline">\(x=(x_1,\dots, x_n)\)</span> des VA <span class="math inline">\((X_1,\dots X_n)\)</span> de même loi <span class="math inline">\(\mathcal{L}_{\theta}\)</span> de paramètre inconnu <span class="math inline">\(\theta\)</span>, on appelle <em>estimation du maximum de vraisemblance</em> toute estimation <span class="math inline">\(\widehat{\theta}_n=\widehat{\theta}_n(x_1,\dots,x_n)\)</span> vérifiant</p>
<p><span class="math display">\[\widehat{\theta}_n\in \arg\max\limits_{\theta\in\Theta}L_n(x;\theta)\]</span>
<strong>Cas particulier :</strong> si la fonction <span class="math inline">\(\theta\mapsto L_n(x;\theta)\)</span> est deux fois dérivable sur <span class="math inline">\(\Theta\)</span>, alors on peut chercher à résoudre (en <span class="math inline">\(\theta\)</span>) le système</p>
<p><span class="math display">\[\left\{
\begin{array}{lll}
\frac{\partial}{\partial\theta}L_n(x;\theta)=0 \\
\frac{\partial^2}{\partial\theta^2}L_n(x;\theta)&lt;0 \\
\end{array}
\right.\]</span>
Les solutions de ce système fournissent des estimations par maximum de vraisemblance.</p>
</div>
<p></p>
<p><strong>Log-vraisemblance.</strong> Il est souvent plus commode de considérer la log-vraisemblance <span class="math inline">\(l_n(x;\theta)=\ln L_n(x;\theta)=\sum\limits_{i=1}^n \ln L_n(x_i;\theta)\)</span>. La fonction <span class="math inline">\(\ln\)</span> étant croissante sur <span class="math inline">\(\mathbb{R}_{+}^*\)</span>, maximiser la vraisemblance équivaut à maximiser la log-vraisemblance.</p>
<div class="methbox meth">
<center>
<strong>Maximisation de la log-vraisemblance</strong>
</center>
<p>En supposant que <span class="math inline">\(L_n(x;\theta)&gt;0\)</span> pour tout <span class="math inline">\(\theta\in\Theta\)</span>, on note <span class="math inline">\(l_n(x;\theta)=\ln L_n(x;\theta)\)</span> la log-vraisemblance. Sous les mêmes hypothèses que ci-dessus, on cherche</p>
<p><span class="math display">\[\widehat{\theta}_n\in\arg\max\limits_{\theta\in\Theta}\left(l_n(x;\theta)\right)\]</span></p>
<p></p>
<p><strong>Cas particulier :</strong> si la fonction <span class="math inline">\(\theta\mapsto L_n(x;\theta)\)</span> est deux fois dérivable sur <span class="math inline">\(\Theta\)</span>, alors la fonction <span class="math inline">\(\theta\mapsto l_n(x;\theta)\)</span> l’est aussi et on peut chercher à résoudre (en <span class="math inline">\(\theta\)</span>) le système</p>
<p><span class="math display">\[\left\{
\begin{array}{lll}
\frac{\partial}{\partial\theta}l_n(x;\theta)=0 \\
\frac{\partial^2}{\partial\theta^2}l_n(x;\theta)&lt;0 \\
\end{array}
\right.\]</span> Les solutions de ce système fournissent des estimations par maximum de vraisemblance.</p>
</div>
<p>
<strong>Exemple 6 : loi normale.</strong> <span class="math inline">\(\mathcal{N}(\mu, 1)\)</span>. On veut estimer le paramètre inconnu <span class="math inline">\(\mu\)</span> par maximum de vraisemblance. La vraisemblance est donnée par</p>
<span class="math display">\[\begin{align}
L_n(x;\mu)&amp;=\prod\limits_{i=1}^n\left(\frac{e^{-\frac{(x_i-\mu)^2}{2}}}{\sqrt{2\pi}}\right)\\
&amp;=\frac{1}{(2\pi)^{\frac{n}{2}}}e^{-\sum\limits_{i=1}^n (x_i-\mu)^2}
\end{align}\]</span>
<p>La log-vraisemblance est plus facile à manipuler :</p>
<span class="math display">\[\begin{align}
l_n(x;\mu)&amp;=\ln L_n(x;\mu) \\
&amp;= -\frac{n}{2}\ln(2\pi)-\sum\limits_{i=1}^n(x_i-\mu)^2
\end{align}\]</span>
<p>La fonction <span class="math inline">\(\mu\mapsto l_n(x;\mu)\)</span> est deux fois dérivable sur <span class="math inline">\(\mathbb{R}\)</span> et <span class="math inline">\(\frac{\partial}{\partial\mu}l_n(x;\mu)=2\sum_{i=1}^n(\mu-x_i)\)</span>. Une seule valeur de <span class="math inline">\(\mu\)</span> l’annule :</p>
<p><span class="math display">\[\widehat{\mu}_n=\frac{1}{n}\sum\limits_{i=1}^n x_i=\overline{x}_n\]</span> Par ailleurs <span class="math inline">\(\frac{\partial^2}{\partial\mu^2}l_n(x;\mu)=2n&gt;0\)</span>, et donc <span class="math inline">\(\widehat{\mu}_n\in\arg\max\limits_{\mu\in\mathbb{R}}l(x;\mu)\)</span>. Finalement, un estimateur par maximum de vraisemblance est donné par</p>
<p><span class="math display">\[\widehat{\mu}_n=\overline{X}_n=\frac{1}{n}\sum\limits_{i=1}^n X_i\]</span></p>
<p>
<strong>Remarque.</strong> Comme souvent en statistique, on commet un léger abus de notation en désignant par la même lettre l’estimateur <span class="math inline">\(\widehat{\mu}_n=\frac{X_1+\dots+X_n}{n}=\widehat{\mu}_n(X_1,\dots,X_n)\)</span> (qui est une statistique, i.e. une fonction de <span class="math inline">\((X_1,\dots,X_n\)</span>) et l’estimation <span class="math inline">\(\widehat{\mu}_n=\frac{x_1+\dots+x_n}{n}=\widehat{\mu}_n(x_1,\dots, X_n)\)</span> qui en est une réalisation. Conditionnellement à <span class="math inline">\((X_1,\dots,X_n)\)</span> (i.e. si l’on suppose que l’on observe <span class="math inline">\((X_1,\dots, X_n)\)</span>) ces deux objets sont bien les mêmes.</p>
<p>
<strong>Exemple 7 : loi exponentielle.</strong> Soit <span class="math inline">\((X_1,\dots,X_n)\)</span> un échantillon i.i.d. tiré selon une loi exponentielle <span class="math inline">\(\mathcal{E}(\lambda)\)</span> de paramètre <span class="math inline">\(\lambda&gt;0\)</span> inconnu. La vraisemblance est donnée par <span class="math display">\[\begin{align}
L_n(x;\lambda)&amp;=\prod\limits_{i=1}^n (\lambda e^{-\lambda x_i}\mathbb{1}_{x_i\geq 0}) \\
\end{align}\]</span></p>
<p>Si l’un des <span class="math inline">\(x_i\)</span> est négatif elle vaut <span class="math inline">\(0\)</span>. Sinon on calcule la log-vraisemblance</p>
<p><span class="math display">\[l_n(x;\lambda)=n\ln(\lambda)-\lambda\sum_{i=1}^n x_i\]</span></p>
<p>La fonction <span class="math inline">\(\lambda\in\mathbb{R}_{+}^*\mapsto l_n(x;\lambda)\)</span> est deux fois dérivable et <span class="math inline">\(\frac{\partial}{\partial\lambda}l_n(x;\lambda)=\frac{n}{\lambda}-\sum\limits_{i=1}^n x_i\)</span>, qui s’annule en <span class="math inline">\(\lambda=\frac{n}{\sum\limits_{i=1}^n x_i}=\frac{1}{\overline{x}_n}\)</span>. De plus, <span class="math inline">\(\frac{\partial^2}{\partial\lambda^2}l_n(x;\lambda)=-\frac{n}{\lambda^2}&lt;0\)</span> et donc à <span class="math inline">\(x\)</span> fixé, <span class="math inline">\(l_n(x;\lambda)\)</span> atteint son maximum en <span class="math inline">\(\frac{1}{\overline{x_n}}\)</span>. L’estimateur du maximum de vraisemblance est donc <span class="math inline">\(\widehat{\lambda}_n=\frac{1}{\overline{X}_n}\)</span>. On remarque qu’on retrouve ici le même estimateur que celui obtenu par la méthode des moments.</p>
</div>
</div>
<div id="compléments-hors-programme" class="section level3 hasAnchor" number="7.1.5">
<h3><span class="header-section-number">7.1.5</span> Compléments (hors-programme)<a href="statistique-inférentielle.html#compléments-hors-programme" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On présente dans cette partie les notions suivantes :</p>
<ul>
<li>information de Fisher</li>
<li>borne de Cramer-Rao</li>
<li>statistique exhaustive</li>
<li>famille exponentielle</li>
<li>amélioration d’un estimateur</li>
</ul>
<p>Ces notions ne sont pas au programme du concours, mais elles sont clairement dans sa périphérie immédiate. On les retrouve d’ailleurs dans le sujet d’interne 2022, mais leur connaissance n’est pas requise pour traiter le sujet.</p>
<div id="information-de-fisher" class="section level4 hasAnchor" number="7.1.5.1">
<h4><span class="header-section-number">7.1.5.1</span> Information de Fisher<a href="statistique-inférentielle.html#information-de-fisher" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Soient <span class="math inline">\(X\)</span> une variable aléatoire (discrète ou continue) à valeurs dans <span class="math inline">\(\mathcal{X}\)</span> de loi <span class="math inline">\(L(x;\theta)&gt;0\)</span>, avec <span class="math inline">\(\theta\in\mathbb{R}\)</span>. On fait les hypothèses suivantes :</p>
<ul>
<li>existence de <span class="math inline">\(\frac{\partial L}{\partial\theta}(x;\theta)\)</span> et de <span class="math inline">\(\frac{\partial^2}{\partial\theta^2}L(x;\theta)\)</span></li>
<li>on peut échanger tous les opérateurs de dérivation (à l’ordre <span class="math inline">\(1\)</span> et <span class="math inline">\(2\)</span>) et d’intégration</li>
</ul>
<p>On considère un échantillon i.i.d. <span class="math inline">\((X_1,\dots,X_n)\)</span> tel que chacun des <span class="math inline">\(X_i\)</span> suit la même loi que <span class="math inline">\(X\)</span>. Pour <span class="math inline">\(x=(x_1,\dots,x_n)\)</span> une réalisation de l’échantillon aléatoire <span class="math inline">\((X_1,\dots, X_n)\)</span>, On note <span class="math inline">\(L_n(x;\theta)\)</span> la vraisemblance de <span class="math inline">\((x_1,\dots, x_n)\)</span> :</p>
<p><span class="math display">\[L_n(x;\theta)=\prod\limits_{i=1}^n L(x_i;\theta)\]</span></p>
<p>On appelle alors <strong>score</strong> la quantité (aléatoire) <span class="math inline">\(\frac{\partial}{\partial\theta}\,\ln L_n(X;\theta)=\frac{\partial}{\partial\theta}\, l_n(X;\theta)\)</span>, i.e. la dérivée de la log-vraisemblance par rapport à <span class="math inline">\(\theta\)</span>.</p>
<div class="thmbox thm">
<p><strong>Théorème :</strong> On a</p>
<p><span class="math display">\[\mathbb{E}_{\theta}\left(\frac{\partial }{\partial\theta}\, l_n(X;\theta)\right)=0\]</span></p>
<p>i.e. le score est d’espérance nulle.</p>
</div>
<p>
<strong>Démonstration.</strong> On démontre cette égalité dans le cas à densité :
<span class="math display">\[\begin{align}
\mathbb{E}_{\theta}\left(\frac{\partial}{\partial\theta}\, l_n(X ; \theta)\right) &amp;= \int_{\mathbb{R}^n} \frac{\partial}{\partial\theta} \,l_n(x;\theta)\,L_n(x;\theta)\,dx \\
&amp;=\int_{\mathbb{R}^n}\frac{\frac{\partial L_n}{\partial\theta}(x;\theta)}{L_n(x;\theta)}\,L_n(x;\theta)\,dx \\
&amp;= \int_{\mathbb{R}^n} \frac{\partial L_n}{\partial\theta}(x;\theta)\,dx \\
&amp;=\frac{\partial}{\partial\theta}\int_{\mathbb{R}^n} L_n(x;\theta) \, dx \text{ (on permute intégrale et dérivée)} \\
&amp;= 0 \text{ (car } \int_{\mathbb{R}^n} L_n(x;\theta)\,dx=1\text{)} \\
\end{align}\]</span>
<span class="math inline">\(\square\)</span></p>
<p>L’information de Fisher est définie à partir du score de la façon suivante :</p>
<div class="defbox def">
<center>
<strong>Information de Fisher</strong>
</center>
<p>L’<strong>information de Fisher</strong> est la quantité définie par</p>
<p><span class="math display">\[I_n(\theta)\equiv\mathbb{E}_{\theta}\left(\left(\frac{\partial }{\partial\theta}\, l_n(X;\theta)\right)^2\right)=\mathbb{V}_{\theta}\left(\frac{\partial}{\partial\theta}l_n(X;\theta)\right)\]</span></p>
<p>Lorsque le domaine de <span class="math inline">\(X\)</span> ne dépend pas de <span class="math inline">\(\theta\)</span>, l’information de Fisher est aussi égale à</p>
<p><span class="math display">\[I_n(\theta)=-\mathbb{E}_{\theta}\left(\frac{\partial^2}{\partial\theta^2} l_n(X;\theta)\right)\]</span>
Cette dernière expression est généralement plus facile à calculer.</p>
</div>
<p>
<strong>Interprétation de l’information de Fisher.</strong> On utilise généralement l’information de Fisher lorsqu’on veut inférer sur un paramètre inconnu <span class="math inline">\(\theta\)</span> par maximum de vraisemblance. Par construction, l’estimation <span class="math inline">\(\widehat{\theta}\)</span> que l’on obtient par cette méthode est celle qui maximise la log-vraisemblance <span class="math inline">\(\ln L_n(X;\theta)\)</span>, pour une observation de <span class="math inline">\(X\)</span> donnée. L’expression <span class="math inline">\(I_n(\theta)=-\mathbb{E}_{\theta}\left(\frac{\partial^2}{\partial\theta^2}\ln L_n(X;\theta)\right)\)</span> montre que l’information de Fisher correspond (au signe près) à la courbure de la log-vraisemblance. Plus celle-ci est importante, plus la courbe présente un “pic” autour du maximum, et donc plus la valeur estimée de ce maximum est précise. Au contraire, si la courbure est faible, la courbe est aplatie autour du maximum, et donc l’estimation de <span class="math inline">\(\theta\)</span> sera moins précise. Dit autrement, l’information de Fisher quantifie le niveau d’information que nous apporte l’observation relativement au paramètre <span class="math inline">\(\theta\)</span>.</p>
<p>
<strong>Démonstration.</strong> Etant donné que <span class="math inline">\(\mathbb{E}_{\theta}\left(\frac{\partial}{\partial\theta} \,l_n(X;\theta)\right)=0\)</span> on a <span class="math inline">\(\mathbb{V}_{\theta}\left(\frac{\partial}{\partial\theta} \,l_n(X;\theta)\right)=\mathbb{E}_\theta\left(\left(\frac{\partial}{\partial\theta} \,l_n(X;\theta\right)^2\right)\)</span>, ce qui démontre la première égalité.
Pour démontrer la deuxième égalité, on dérive par rapport à <span class="math inline">\(\theta\)</span> l’égalité <span class="math inline">\(\mathbb{E}_{\theta}\left(\frac{\partial}{\partial\theta} \,l_n(X;\theta)\right)=0\)</span>. Pour cela, on utilise la permutation <span class="math inline">\(\frac{\partial}{\partial\theta}\int=\int\frac{\partial}{\partial\theta}\)</span> qui est possible car le domaine de <span class="math inline">\(X\)</span> ne dépend pas de <span class="math inline">\(\theta\)</span>. On obtient donc :</p>
<p><span class="math display">\[\begin{align}
0 &amp;= \frac{\partial}{\partial\theta}\mathbb{E}_{\theta}\left(\frac{\partial}{\partial\theta} \,l_n(X;\theta)\right) \\
&amp;= \frac{\partial}{\partial\theta}\int_{\mathbb{R}^n}\left(\frac{\partial}{\partial\theta} \,l_n(X;\theta)\right) L_n(x;\theta)\,dx \\
&amp;=\int_{\mathbb{R}^n}\frac{\partial}{\partial\theta}\left(\left(\frac{\partial}{\partial\theta} \,l_n(X;\theta)\right) L_n(x;\theta)\right)\,dx \\
&amp;=\int_{\mathbb{R}^n}\left(\frac{\partial^2}{\partial\theta^2}l_n(x;\theta)\right)L_n(x;\theta)\,dx+\int_{\mathbb{R}^n}\frac{\partial}{\partial\theta}l_n(x;\theta)\frac{\partial}{\partial\theta}L_n(x;\theta)\,dx \\
&amp;= \int_{\mathbb{R}^n}\left(\frac{\partial^2}{\partial\theta^2}l_n(x;\theta)\right)L_n(x;\theta)\,dx+\int_{\mathbb{R}^n}\left(\frac{\partial}{\partial\theta}l_n(x;\theta)\right)^2 L_n(x;\theta)\,dx \\
&amp;= \mathbb{E}_{\theta}\left(\frac{\partial^2}{\partial\theta^2} l_n(X;\theta)\right)+\mathbb{E}_{\theta}\left(\left(\frac{\partial}{\partial\theta} l_n(X;\theta)\right)^2\right)
\end{align}\]</span></p>
<p>d’où</p>
<p><span class="math display">\[\mathbb{E}_{\theta}\left(\frac{\partial^2}{\partial\theta^2} l_n(X;\theta)\right)=-\mathbb{E}_{\theta}\left(\left(\frac{\partial}{\partial\theta} l_n(X;\theta)\right)^2\right)\]</span></p>
<p>ce qui achève la démonstration.
<span class="math inline">\(\square\)</span></p>
<p>L’information de Fisher vérifie une propriété d’additivité :</p>
<div class="thmbox thm">
<p>
<strong>Théorème (additivité de l’information de Fisher) :</strong> Si l’ensemble <span class="math inline">\(\left\{x\in\mathbb{R}^n, f(x;\theta)&gt;0\right\}\)</span> ne dépend pas de <span class="math inline">\(\theta\)</span>, alors l’information de Fisher est additive, i.e.</p>
<p><span class="math display">\[I_n(\theta)=n\,I_1(\theta)\]</span></p>
</div>
<p>Si le domaine de <span class="math inline">\(X\)</span> ne dépend pas de <span class="math inline">\(\theta\)</span>, l’information de Fisher apportée par un échantillon <span class="math inline">\((X_1,\dots,X_n)\)</span> est donc égale à <span class="math inline">\(n\)</span> fois l’information de Fisher apportée par chacune des observations <span class="math inline">\(X_i\)</span>. Cela signifie que chaque observation apporte la même information de Fisher.</p>
</div>
<div id="borne-de-fréchet-darmois-cramer-rao" class="section level4 hasAnchor" number="7.1.5.2">
<h4><span class="header-section-number">7.1.5.2</span> Borne de Fréchet-Darmois-Cramer-Rao<a href="statistique-inférentielle.html#borne-de-fréchet-darmois-cramer-rao" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Sous certaines hypothèses, on peut montrer que la variance d’un estimateur sans biais ne peut être inférieure à une certaine borne, appelée borne de Fréchet-Darmois-Cramer-Rao, liée à l’information de Fisher :</p>
<div class="thmbox thm">
<p><strong>Théorème :</strong> On suppose que les hypothèses suivantes, appelées <strong>hypothèses de Cramer-Rao</strong>, sont vérifiées :</p>
<ul>
<li><p><strong>(H1) :</strong> <span class="math inline">\(\Theta\)</span> est un ouvert sur lequel <span class="math inline">\(f(x;\theta)&gt;0\)</span> et <span class="math inline">\(\theta\mapsto f(x;\theta)\)</span> est dérivable pour tout <span class="math inline">\(x\)</span></p></li>
<li><p><strong>(H2) :</strong> on peut permuter <span class="math inline">\(\int\)</span> et <span class="math inline">\(\frac{\partial}{\partial\theta}\)</span></p></li>
<li><p><strong>(H3) :</strong> <span class="math inline">\(\forall\theta\in\Theta, \, I_n(\theta)&gt;0\)</span></p></li>
<li><p><strong>(H4) :</strong> <span class="math inline">\(g:\Theta\longrightarrow\mathbb{R}\)</span> est une fonction dérivable</p></li>
</ul>
<p>Alors, pour tout estimateur <strong>sans biais</strong> <span class="math inline">\(T_n=T_n(X_1,\dots, X_n)\)</span> de <span class="math inline">\(g(\theta)\)</span> on a l’inégalité</p>
<p><span class="math display">\[\mathbb{V}_{\theta}(T_n)\geq\frac{\left(g&#39;(\theta)\right)^2}{I_n(\theta)}\]</span></p>
<p>Le nombre <span class="math inline">\(\frac{\left(g&#39;(\theta)\right)^2}{I_n(\theta)}\)</span> s’appelle la <strong>borne de Fréchet-Darmois-Cramer-Rao (FDCR)</strong>.</p>
<p>Dans le cas particulier où <span class="math inline">\(T_n=\widehat{\theta}_n\)</span> est un estimateur sans biais de <span class="math inline">\(\theta\)</span> (cas où <span class="math inline">\(g(\theta)=\theta\)</span>) on a <span class="math inline">\(\mathbb{V}_{\theta}(\widehat{\theta}_n)\geq\frac{1}{I_n(\theta)}\)</span>.</p>
</div>
<p>Ce théorème est admis.</p>
<p>La borne FDCR n’est pas nécessairement atteinte. Quand elle l’est, l’estimateur qui l’atteint est dit <strong>efficace</strong> :</p>
<div class="defbox def">
<center>
<strong>Estimateurs efficaces</strong>
</center>
<p>Un estimateur <span class="math inline">\(T_n\)</span> <em>sans biais</em> de <span class="math inline">\(g(\theta)\)</span> tel que <span class="math inline">\(\mathbb{V}_{\theta}(T_n)=\frac{\left(g&#39;(\theta)\right)^2}{I_n(\theta)}\)</span> est appelé un <strong>estimateur efficace</strong>.</p>
</div>
</div>
<div id="statistiques-exhaustives" class="section level4 hasAnchor" number="7.1.5.3">
<h4><span class="header-section-number">7.1.5.3</span> Statistiques exhaustives<a href="statistique-inférentielle.html#statistiques-exhaustives" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Tout échantillon <span class="math inline">\((X_1,\dots, X_n)\)</span> tel que <span class="math inline">\(X_i\sim\mathcal{L}_{\theta}\)</span> apporte de l’information sur le paramètre inconnu <span class="math inline">\(\theta\)</span>, et donc sur la loi inconnue <span class="math inline">\(\mathcal{L}_{\theta}\)</span>. Plutôt que de faire de l’inférence à partir de l’échantillon <span class="math inline">\((X_1,\dots, X_n)\)</span> on préfère en général utiliser une statistique <span class="math inline">\(T_n=T(X_1,\dots,X_n)\)</span>, qui est une sorte de résumé de l’échantillon tout entier. La contrepartie est qu’en général, le passage de <span class="math inline">\((X_1,\dots,X_n)\)</span> à son résumé <span class="math inline">\(T_n\)</span> génère une perte d’information sur <span class="math inline">\(\theta\)</span>. Une statistique exhaustive est une statistique qui n’engendre pas de telle perte, autrement dit elle contient toute l’information sur <span class="math inline">\(\theta\)</span> contenue dans l’échantillon <span class="math inline">\((X_1,\dots, X_n)\)</span>. On formalise cette idée de la façon suivante :</p>
<div class="defbox def">
<center>
<strong>Statistiques exhaustives</strong>
</center>
<p>Une statistique <span class="math inline">\(T_n\)</span> est dite <strong>exhaustive</strong> si la loi conditionnelle <span class="math inline">\(\mathcal{L}(X|T_n=t)\)</span> est indépendante de <span class="math inline">\(\theta\)</span>. Conditionnellement à l’observation <span class="math inline">\(T=t\)</span>, la loi de <span class="math inline">\(X\)</span> ne dépend plus de <span class="math inline">\(\theta\)</span> :</p>
<p><span class="math display">\[\mathbb{P}(X=x|T=t,\theta)=\mathbb{P}(X=x|T=t) \text{    (pour une loi discrète)}\]</span></p>
<p><span class="math display">\[f(x|T=t,\theta)=f(x|T=t) \text{    (pour une loi continue)}\]</span></p>
</div>
<p>Dit autrement, une fois que l’on sait que <span class="math inline">\(T_n=t\)</span>, ajouter la connaissance de <span class="math inline">\(X\)</span> n’apporte plus aucune information supplémentaire sur <span class="math inline">\(\theta\)</span>.</p>
<p>Cette définition n’est pas très commode à manipuler, et en pratique pour démontrer qu’une statistique est (ou n’est pas) exhaustive on utilise plutôt le théorème de factorisation de Neyman-Fisher :</p>
<div class="defbox def">
<p><strong>Théorème (factorisation de Neyman-Fisher) :</strong> Une statistique <span class="math inline">\(T_n\)</span> est exhaustive si, et seulement s’il existe deux fonctions mesurables positives <span class="math inline">\(g\)</span> et <span class="math inline">\(h\)</span> telles qu’on ait la factorisation suivante :</p>
<p><span class="math display">\[L_n(x;\theta)=g(T_n(x);\theta).h(x)\]</span></p>
</div>
<p>
<strong>Remarques : i.</strong> La notion de mesurabilité n’est pas au programme du concours. Il s’agit d’une classe très générale de fonctions, qui englobe en particulier les fonctions continues, continues par morceaux etc. Il est même assez compliqué de construire une fonction non mesurable. En pratique :</p>
<ul>
<li><p>pour démontrer qu’une statistique est exhaustive, il suffit de montrer qu’une telle décomposition existe avec <span class="math inline">\(g\)</span> et <span class="math inline">\(h\)</span> continues (car continue implique mesurable) ;</p></li>
<li><p>pour démontrer qu’une telle statistique n’est pas exhaustive, il suffit de démontrer qu’une telle décomposition avec <span class="math inline">\(g\)</span> et <span class="math inline">\(h\)</span> quelconques est impossible (elle sera en particulier impossible avec <span class="math inline">\(g\)</span> et <span class="math inline">\(h\)</span> mesurables).</p></li>
</ul>
<p>
<strong>ii.</strong> Il n’y a pas unicité du couple <span class="math inline">\((g,h)\)</span>. Par exemple, si <span class="math inline">\((g,h)\)</span> permet une factorisation, alors pour tout <span class="math inline">\(\lambda\)</span> strictement positif <span class="math inline">\(\left(\lambda g, \frac{h}{\lambda}\right)\)</span> aussi.</p>
</div>
<div id="famille-exponentielle" class="section level4 hasAnchor" number="7.1.5.4">
<h4><span class="header-section-number">7.1.5.4</span> Famille exponentielle<a href="statistique-inférentielle.html#famille-exponentielle" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Les densités suivantes assurent l’existence d’une statistique exhaustive :</p>
<div class="thmbox thm">
<p><strong>Théorème de Darmois :</strong> Soit <span class="math inline">\(\theta\in\Theta\subset\mathbb{R}\)</span>. Soit <span class="math inline">\(f(x;\theta)\)</span> une densité telle que l’ensemble <span class="math inline">\(\{x\in\mathbb{R}^n, \, f(x;\theta)&gt;0\}\)</span> ne dépend pas de <span class="math inline">\(\theta\)</span>. Alors, l’échantillon <span class="math inline">\((X_1,\dots,X_n)\)</span> admet une statistique exhaustive si et seulement si <span class="math inline">\(f(x;\theta)\)</span> est de la forme</p>
<p><span class="math display">\[f(x;\theta)=\exp\left(a(x)\alpha(\theta)+b(x)+\beta(\theta)\right)\]</span></p>
<p>Par ailleurs, si l’application <span class="math inline">\(a\)</span> est de classe <span class="math inline">\(\mathcal{C}^1\)</span>, alors <span class="math inline">\(T_n\equiv\sum\limits_{i=1}^n a(X_i)\)</span> est une statistique exhaustive.</p>
<p>La famille des densités <span class="math inline">\(f(x;\theta)\)</span> vérifiant ces propriétés s’appelle la <strong>famille exponentielle</strong>.</p>
</div>
<p>
<strong>Remarque.</strong> Ici, on convient de parler de <em>densité</em> aussi bien pour une variable discrète que pour une variable continue. Pour une variable discrète, la densité est par définition <span class="math inline">\(f(x;\theta)\equiv\mathbb{P}_{\theta}(X=x)\)</span>.</p>
<p>
<strong>Exemple (loi de Poisson).</strong> La densité d’une loi de Poisson de paramètre <span class="math inline">\(\lambda\)</span> est <span class="math inline">\(f(x;\lambda)=e^{-\lambda}\frac{\lambda^x}{x!}\mathbb{1}_{x\in\mathbb{N}}\)</span>. L’ensemble <span class="math inline">\(\left\{x\in\mathbb{R},\,f(x;\theta)&gt;0\right\}\)</span> est <span class="math inline">\(\mathbb{N}\)</span>, qui ne dépend pas de <span class="math inline">\(\lambda\)</span>. Par ailleurs :
<span class="math display">\[f(x;\lambda)=\exp\left(-\lambda+x\,\ln(\lambda)-\sum\limits_{i=1}^x \ln i\right)\]</span></p>
<p>On reconnait bien la forme générale d’une densité de la famille exponentielle, avec <span class="math inline">\(a(x)=x\)</span>, <span class="math inline">\(\alpha(\lambda)=\ln(\lambda)\)</span>, <span class="math inline">\(b(x)=\sum\limits_{i=1}^x \ln i\)</span>, <span class="math inline">\(\beta(\lambda)=-\lambda\)</span>. L’application <span class="math inline">\(a\)</span> est par ailleurs de classe <span class="math inline">\(\mathcal{C}^1\)</span>. On en déduit avec le théorème de Darmois que la statistique <span class="math inline">\(T_n=\sum\limits_{i=1}^n X_i\)</span> est une statistique exhaustive pour <span class="math inline">\(\theta\)</span>.</p>
<p>La famille exponentielle permet de construire des estimateurs <strong>efficaces</strong>.</p>
<div class="thmbox thm">
<p>
<strong>Théorème :</strong> On suppose les hypothèses de Cramer-Rao vérifiées. On suppose également que <span class="math inline">\(\theta\mapsto \frac{\partial}{\partial\theta}f(x;\theta)\)</span> est continue en <span class="math inline">\(\theta\)</span>. Soit <span class="math inline">\(T_n\)</span> un estimateur <strong>sans biais</strong> de <span class="math inline">\(g(\theta)\)</span>.</p>
<p>Alors, <span class="math inline">\(T_n\)</span> est un estimateur efficace si et seulement si la densité <span class="math inline">\(f(x;\theta)\)</span> appartient à la famille exponentielle.</p>
</div>
</div>
<div id="rao-blackwellisation-dun-estimateur" class="section level4 hasAnchor" number="7.1.5.5">
<h4><span class="header-section-number">7.1.5.5</span> Rao-Blackwellisation d’un estimateur<a href="statistique-inférentielle.html#rao-blackwellisation-dun-estimateur" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Le théorème de Rao-Blackwell montre comment améliorer un estimateur.</p>
<div class="thmbox thm">
<p><strong>Théorème de Rao-Blackwell :</strong> Soient <span class="math inline">\(T_n\)</span> une statistique exhaustive et <span class="math inline">\(S\)</span> un estimateur sans biais de <span class="math inline">\(g(\theta)\)</span>. Alors, l’estimateur <span class="math inline">\(\mathbb{E}_{\theta}(S|T_n)\)</span> est sans biais et <span class="math inline">\(\mathbb{V}_{\theta}(\mathbb{E}_{\theta}(S|T_n))\leq\mathbb{V}_{\theta}(S)\)</span>.</p>
</div>
<p>L’estimateur <span class="math inline">\(\mathbb{E}_{\theta}(S|T_n)\)</span> est dit <strong>préférable</strong> à l’estimateur <span class="math inline">\(S\)</span>.</p>
</div>
</div>
<div id="estimation-des-coefficients-dune-régression-linéaire" class="section level3 hasAnchor" number="7.1.6">
<h3><span class="header-section-number">7.1.6</span> Estimation des coefficients d’une régression linéaire<a href="statistique-inférentielle.html#estimation-des-coefficients-dune-régression-linéaire" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="présentation-du-modèle" class="section level4 hasAnchor" number="7.1.6.1">
<h4><span class="header-section-number">7.1.6.1</span> Présentation du modèle<a href="statistique-inférentielle.html#présentation-du-modèle" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont deux variables aléatoires pour lesquelles on dispose d’observations <span class="math inline">\(x_1,\dots, x_n\)</span> et <span class="math inline">\(y_1,\dots y_n\)</span>. On considère le modèle</p>
<p><span class="math display">\[Y_i=aX_i+b+u_i\]</span></p>
<p>où <span class="math inline">\((a,b)\)</span> est un couple de réels inconnus et <span class="math inline">\(u_i\)</span> est un terme d’erreur (inconnu lui aussi). Le but est d’estimer des coefficients <span class="math inline">\((a,b)\)</span> à partir de l’échantillons d’observations <span class="math inline">\((x_i, y_i)\)</span> et de donner des propriétés des estimateurs obtenus sous certaines hypothèses.</p>
<p>
<strong>Hypothèses du modèle.</strong> On fait les hypothèses suivantes :</p>
<ul>
<li><strong>(H1) :</strong> Les couples <span class="math inline">\((X_i, Y_i)\)</span> sont i.i.d.</li>
<li><strong>(H2) :</strong> Les termes d’erreur <span class="math inline">\(u_i\)</span> sont indépendants des <span class="math inline">\(X_i\)</span></li>
<li><strong>(H3) :</strong> <span class="math inline">\(\mathbb{E}(u_i|X_i)=0\)</span> (hypothèse d’exogénéité)</li>
<li><strong>(H4) :</strong> <span class="math inline">\(\mathbb{V}(u_i|X_i)=\sigma_u^2\)</span> ne dépend pas de <span class="math inline">\(X_i\)</span> (hypothèse d’homoscédasticité)</li>
<li><strong>(H5) :</strong> <span class="math inline">\(u_i|X_i\sim\mathcal{N}(0, \sigma_u^2)\)</span> (hypothèse de normalité des termes d’erreur)</li>
</ul>
<p>On présente deux approches différentes pour estimer <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> : par la méthode des moindres carrés et par maximum de vraisemblance. Bien que différentes, ces méthodes vont fournir les mêmes estimateurs.</p>
<p>Avant cela, on rappelle quelques résultats classiques de statistique descriptive.</p>
</div>
<div id="rappels-utiles" class="section level4 hasAnchor" number="7.1.6.2">
<h4><span class="header-section-number">7.1.6.2</span> Rappels utiles<a href="statistique-inférentielle.html#rappels-utiles" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Avant de présenter cette méthode, on rappelle des égalités qui àa la fois très utiles et très classiques. Il faut les connaître pour le concours et savoir les redémontrer.</p>
<div class="methbox meth">
<center>
<strong>Moyenne, covariance, variance</strong>
</center>
<p>Pour <span class="math inline">\(x=(x_1,\dots, x_n)\in\mathbb{R}^n\)</span> on note</p>
<ul>
<li><span class="math inline">\(\overline{x}_n=\frac{1}{n}\sum\limits_{i=1}^n x_i\)</span> la moyenne de <span class="math inline">\(x\)</span></li>
<li><span class="math inline">\(\sigma_x^2=\frac{1}{n}\sum\limits_{i=1}^n(x_i-\overline{x}_n)^2\)</span> la variance de <span class="math inline">\(x\)</span></li>
<li>si de plus <span class="math inline">\(y=(y_1,\dots, y_n)\)</span>, <span class="math inline">\(\sigma_{xy}=\frac{1}{n}\sum\limits_{i=1}^n (x_i-\overline{x}_n)(y_i-\overline{y}_n)\)</span> est la covariance de <span class="math inline">\(x\)</span> et <span class="math inline">\(y\)</span>.</li>
</ul>
<p>On a alors les égalités suivantes :</p>
<p><strong>1.</strong> <span class="math inline">\(\sigma_{xx}=\sigma_x^2\)</span></p>
<p><strong>2.</strong> <span class="math inline">\(\sum\limits_{i=1}^n (x_i-\overline{x}_n)=0\)</span></p>
<p><strong>3. Différentes formules de la covariance :</strong></p>
<span class="math display">\[\begin{align}
\sigma_{xy} &amp;= \frac{1}{n}\sum\limits_{i=1}^n (x_i-\overline{x}_n)(y_i-\overline{y}_n) \\
&amp;= \frac{1}{n}\sum\limits_{i=1}^n(x_i-\overline{x}_n)y_i \\
&amp;= \frac{1}{n}\sum\limits_{i=1}^n x_i(y_i-\overline{y}_n) \\
&amp;= \frac{1}{n}\sum\limits_{i=1}^n x_iy_i-\overline{x}_n\overline{y}_n
\end{align}\]</span>
<p><strong>4. Différentes formules de la variance :</strong></p>
<span class="math display">\[\begin{align}
\sigma_x^2 &amp;= \frac{1}{n}\sum\limits_{i=1}^n (x_i-\overline{x}_n)^2 \\
&amp;= \frac{1}{n}\sum\limits_{i=1}^n x_i^2-(\overline{x}_n)^2
\end{align}\]</span>
</div>
<p><strong>Démonstration.</strong></p>
<p>
<strong>1.</strong> Evidente</p>
<p><strong>2.</strong> <span class="math display">\[\begin{align}
\sum\limits_{i=1}^n (x_i-\overline{x}_n) &amp;= \sum\limits_{i=1}^n x_i -n\overline{x}_n \\
&amp;= n\overline{x}_n-n\overline{x}_n \\
&amp; =0
\end{align}\]</span></p>
<p><strong>3.</strong> <span class="math display">\[\begin{align}
\sigma_{xy} &amp;= \frac{1}{n}\sum\limits_{i=1}^n (x_i-\overline{x}_n)(y_i-\overline{y}_n) \\
&amp;=\frac{1}{n}\sum\limits_{i=1}^n (x_i-\overline{x}_n)y_i-\frac{\overline{y}_n}{n}\sum\limits_{i=1}^n (x_i-\overline{x}_n) \\
&amp;= \frac{1}{n}\sum\limits_{i=1}^n (x_i-\overline{x}_n)y_i
\end{align}\]</span></p>
<p>d’après l’égalité 2.</p>
<p>Par symétrie des rôles joués par <span class="math inline">\(x\)</span> et <span class="math inline">\(y\)</span> on a donc aussi <span class="math inline">\(\sigma_{xy}=\frac{1}{n}\sum\limits_{i=1}^n x_i(y_i-\overline{y}_n)\)</span>.</p>
<p>On montre la dernière égalité :</p>
<span class="math display">\[\begin{align}
\frac{1}{n}\sum\limits_{i=1}^n (x_i-\overline{x}_n)(y_i-\overline{y}_n) &amp;=
\frac{1}{n}\sum\limits_{i=1}^n (x_i-\overline{x}_n)y_i \\
&amp;= \frac{1}{n}\sum\limits_{i=1}^n x_iy_i-\overline{x}_n\frac{1}{n}\sum\limits_{i=1}^n y_i
\\
&amp;=\frac{1}{n}\sum\limits_{i=1}^n x_iy_i-\overline{x}_n\overline{y}_n
\end{align}\]</span>
<p><strong>4.</strong> On applique la dernière égalité de 4 dans le cas particulier où <span class="math inline">\(x=y\)</span>. On obtient alors</p>
<p><span class="math display">\[\frac{1}{n}\sum\limits_{i=1}^n (x_i-\overline{x}_n)^2=\frac{1}{n}\sum\limits_{i=1}^n x_i^2-\left(\frac{1}{n}\sum\limits_{i=1}^n x_i\right)^2\]</span> <span class="math inline">\(\square\)</span></p>
</div>
<div id="estimation-de-a-et-b-par-la-méthode-des-moindres-carrés" class="section level4 hasAnchor" number="7.1.6.3">
<h4><span class="header-section-number">7.1.6.3</span> Estimation de <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> par la méthode des moindres carrés<a href="statistique-inférentielle.html#estimation-de-a-et-b-par-la-méthode-des-moindres-carrés" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>On montre maintenant les formules des estimateurs de <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> par application de la méthode des moindres carrés :</p>
<div class="methbox meth">
<center>
<strong>Estimation de <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> par la méthode des moindres carrés</strong>
</center>
<p>La méthode des moindres carrés consiste à minimiser l’erreur quadratique globale</p>
<p><span class="math display">\[E(\alpha,\beta)\equiv\sum\limits_{i=1}^n (Y_i-\alpha X_i-\beta)^2\]</span> qui représente l’erreur globale faite en approchant <span class="math inline">\(Y_i\)</span> par <span class="math inline">\(\alpha X_i+\beta\)</span>.</p>
<p>Cette méthode fournit les estimateurs suivants de <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> :</p>
<span class="math display">\[\begin{align}
\left\{
\begin{array}{ll}
\widehat{a} &amp;= \frac{\overline{\sigma_{XY}}}{\overline{\sigma^2_X}} \\
\widehat{b} &amp;= \overline{Y}_n-\widehat{a}\overline{X}_n
\end{array}
\right.
\end{align}\]</span>
<p>où on note <span class="math inline">\(\overline{\sigma_{XY}}=\frac{1}{n}\sum\limits_{i=1}^n(X_i-\overline{X}_n)(Y_i-\overline{Y}_n)\)</span> et <span class="math inline">\(\overline{\sigma^2_X}=\overline{\sigma_{XX}}=\frac{1}{n}\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2\)</span>.</p>
</div>
<p>
<strong>Démonstration.</strong> La fonction <span class="math inline">\((\alpha, \beta)\mapsto E(\alpha, \beta)\)</span> est deux fois dérivable par rapport à chacune de ses variables. </p>
<p><strong>Conditions de premier ordre (CPO) :</strong> Les conditions du premier ordre s’écrivent</p>
<span class="math display">\[\begin{align}
\left\{
\begin{array}{ll}
\frac{\partial}{\partial\alpha} E(\alpha, \beta) &amp;=0 \\
\frac{\partial}{\partial\beta} E(\alpha, \beta) &amp;=0 \\
\end{array}
\right.
\end{align}\]</span>
<p>i.e.</p>
<span class="math display">\[\begin{align}
\left\{
\begin{array}{ll}
\sum\limits_{i=1}^n X_i Y_i-\alpha\sum\limits_{i=1}^n X_i^2-\beta\sum\limits_{i=1}^n X_i&amp;=0 \\
\sum\limits_{i=1}^n Y_i-\alpha\sum\limits_{i=1}^n X_i-n\beta &amp;= 0 \\
\end{array}
\right.
\end{align}\]</span>
<p>Il s’agit d’un système de deux équations à deux inconnues <span class="math inline">\((\alpha, \beta)\)</span>. Sa résolution donne</p>
<span class="math display">\[\begin{align}
\left\{
\begin{array}{ll}
\alpha &amp;= \frac{\frac{1}{n}\sum\limits_{i=1}^n X_iY_i-\left(\frac{1}{n}\sum\limits_{i=1}^n X_i\right)\left(\frac{1}{n}\sum\limits_{i=1}^n Y_i\right)}{\frac{1}{n}\sum\limits_{i=1}^n X_i^2-\left(\frac{1}{n}\sum\limits_{i=1}^n X_i\right)^2} \\
\beta &amp;= \overline{Y}_n-\alpha\overline{X}_n
\end{array}
\right.
\end{align}\]</span>
<p>soit encore</p>
<span class="math display">\[\begin{align}
\left\{
\begin{array}{ll}
\alpha &amp;= \frac{\overline{\sigma_{XY}}}{\overline{\sigma^2_X}} \\
\beta &amp;= \overline{Y}_n-\alpha\overline{X}_n
\end{array}
\right.
\end{align}\]</span>
<p>Par ailleurs, pour tout couple <span class="math inline">\((x, y)\)</span> de réels, la fonction <span class="math inline">\((\alpha, \beta)\mapsto (y-\alpha x-\beta)^2\)</span> est convexe. Le point critique trouvé ci-dessus est donc un minimum.</p>
<p>On en déduit le résultat.</p>
<p><span class="math inline">\(\square\)</span></p>
</div>
<div id="estimation-de-a-et-b-par-la-méthode-du-maximum-de-vraisemblance" class="section level4 hasAnchor" number="7.1.6.4">
<h4><span class="header-section-number">7.1.6.4</span> Estimation de <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> par la méthode du maximum de vraisemblance<a href="statistique-inférentielle.html#estimation-de-a-et-b-par-la-méthode-du-maximum-de-vraisemblance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La méthode par maximum de vraisemblance requiert une information supplémentaire : celle de la distribution de la variable de terme d’erreur <span class="math inline">\(u\)</span>. Or, une telle information est justement donnée ici par l’hypothèse (H5) de distribution normale du terme d’erreur.</p>
<div class="methbox meth">
<center>
<strong>Estimation de <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> par la méthode du maximum de vraisemblance.</strong>
</center>
<p>Sous l’hypothèse <span class="math inline">\((H5)\)</span> de distribution normale des termes d’erreur, la méthode par maximum de vraisemblance fournit les mêmes estimateurs <span class="math inline">\(\widehat{a}\)</span> et <span class="math inline">\(\widehat{b}\)</span> que la méthode des moindres carrés.</p>
</div>
<p>
<strong>Démonstration.</strong> La vraisemblance est donnée par</p>
<p><span class="math display">\[L_n((\alpha,\beta);u)=\prod_{i=1}^n\frac{1}{\sqrt{2\pi}\sigma_u}e^{-\frac{(Y_i-\alpha X_i-\beta)^2}{2\sigma_u^2}}\]</span></p>
<p>On passe à la log-vraisemblance, qui est plus simple à dériver</p>
<p><span class="math display">\[l_n((\alpha,\beta);u)=-n\ln(\sqrt{2\pi}\sigma_u^2)-\frac{(Y_i-\alpha X_i-\beta)^2}{2\sigma_u^2}\]</span></p>
<p>On résout alors en <span class="math inline">\((\alpha, \beta)\)</span> le système d’équations</p>
<span class="math display">\[\begin{align}
\frac{\partial l_n}{\partial\alpha}l((\alpha,\beta);u) &amp;= 0 \\
\frac{\partial l_n}{\partial\beta}l((\alpha,\beta);u) &amp;= 0 \\
\end{align}\]</span>
<p>soit</p>
<span class="math display">\[\begin{align}
\frac{X_i(Y_i-\alpha X_i-\beta)}{2\sigma_u^2} &amp;= 0 \\
\frac{Y_i-\alpha X_i-\beta}{2\sigma_u^2} &amp;= 0 \\
\end{align}\]</span>
<p>On vérifie facilement qu’on obtient le même couple de solution qu’avec la méthode des moindres carrés, et que ce couple constitue bien un maximum de la log-vraisemblance.</p>
<p><span class="math inline">\(\square\)</span></p>
<p>
<strong>Remarque :</strong> Dans des approches plus générales que celle présentée ici, aucune hypothèse n’est faite sur la distribution des termes d’erreur. Dans ce cas, la méthode par maximum de vraisemblance n’est plus applicable. On peut cependant toujours utiliser la méthode des moindres carrés.</p>
</div>
<div id="absence-de-biais-des-estimateurs-widehata-et-widehatb" class="section level4 hasAnchor" number="7.1.6.5">
<h4><span class="header-section-number">7.1.6.5</span> Absence de biais des estimateurs <span class="math inline">\(\widehat{a}\)</span> et <span class="math inline">\(\widehat{b}\)</span><a href="statistique-inférentielle.html#absence-de-biais-des-estimateurs-widehata-et-widehatb" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="thmbox thm">
<p><strong>Théorème : (absence de biais des estimateurs MCO)</strong> Les estimateurs</p>
<p><span class="math display">\[\widehat{a}=\frac{\overline{\sigma_{XY}}}{\overline{\sigma_X^2}}\]</span> et <span class="math display">\[\widehat{b}=\overline{Y}_n-\widehat{a}\overline{X}_n\]</span> sont des estimateurs <strong>sans biais</strong> de <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span>.</p>
</div>
<p>
<strong>Démonstration.</strong> On remarque d’abord qu’avec l’hypothèse d’exogénéité (H3) <span class="math inline">\(\mathbb{E}(u_i|X_i)=0\)</span> on a <span class="math inline">\(\mathbb{E}(Y_i|X_i)=aX_i+b\)</span> et donc <span class="math inline">\(\mathbb{E}(Y_i-\overline{Y}_n|X_1,\dots, X_n)=a(X_i-\overline{X}_n)\)</span>. D’où</p>
<span class="math display">\[\begin{align}
\mathbb{E}(\widehat{a}|X_1,\dots, X_n) &amp;= \mathbb{E}\left(\left.\frac{\frac{1}{n}\sum\limits_{i=1}^n (X_i-\overline{X}_n)(Y_i-\overline{Y}_n)}{\overline{\sigma_X^2}}\right|X_1,\dots, X_n\right) \\
&amp;=\frac{1}{\overline{\sigma_X^2}}\frac{1}{n}\sum\limits_{i=1}^n(X_i-\overline{X}_n)\mathbb{E}(\left. Y_i-\overline{Y}_n\right|X_1\,\dots,X_n) \\
&amp;= a\frac{1}{\overline{\sigma_X^2}}\frac{1}{n}\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2 \\
&amp; =a\frac{\overline{\sigma_X^2}}{\overline{\sigma_X^2}} \\
&amp; =a
\end{align}\]</span>
<p>Par ailleurs</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(\widehat{b}|X_1,\dots,X_n)&amp;=\mathbb{E}(\overline{Y}_n-\widehat{a}\overline{X}_n|X_1,\dots,X_n) \\
&amp;=\frac{1}{n}\sum\limits_{i=1}^n \mathbb{E}(Y_i|X_1,\dots,X_n)-\overline{X}_n\mathbb{E}(\widehat{a}|X_1,\dots,X_n) \\
&amp;=\frac{1}{n}\sum\limits_{i=1}^n (aX_i+b)-a\overline{X}_n \\
&amp;= a\overline{X}_n+b-a\overline{X}_n \\
&amp;= b
\end{align}\]</span> <span class="math inline">\(\square\)</span></p>
</div>
<div id="variance-des-estimateurs-widehata-et-widehatb" class="section level4 hasAnchor" number="7.1.6.6">
<h4><span class="header-section-number">7.1.6.6</span> Variance des estimateurs <span class="math inline">\(\widehat{a}\)</span> et <span class="math inline">\(\widehat{b}\)</span><a href="statistique-inférentielle.html#variance-des-estimateurs-widehata-et-widehatb" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="thmbox thm">
<p><strong>Théorème (variance des estimateurs MCO)</strong> Les estimateurs <span class="math inline">\(\widehat{a}\)</span> et <span class="math inline">\(\widehat{b}\)</span> ont pour variances</p>
<span class="math display">\[\begin{align}
\mathbb{V}(\widehat{a}|X_1,\dots, X_n) &amp;= \frac{\sigma_u^2}{\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2} \\
\mathbb{V}(\widehat{b}|X_1,\dots,X_n) &amp;=\sigma_u^2\left(\frac{1}{n}+ \frac{\overline{X}_n^2}{\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2}\right)
\end{align}\]</span>
</div>
<p>
<strong>Démonstration.</strong> On remarque tout d’abord que</p>
<p><span class="math display">\[\mathbb{V}(Y_i|X_1,\dots,X_n)=\sigma_u^2\]</span></p>
<p>En effet</p>
<span class="math display">\[\begin{align}
\mathbb{V}(Y_i|X_1,\dots,X_n) &amp;= \mathbb{V}(aX_i+b+u_i|X_1,\dots, X_n) \\
&amp;= \mathbb{V}(u_i|X_1,\dots,X_n) \\
&amp;= \sigma_u^2
\end{align}\]</span>
<p>Le passage de la première à la deuxième ligne vient du fait qu’à <span class="math inline">\(X_1,\dots, X_n\)</span> fixées, <span class="math inline">\(aX_i+b\)</span> est considérée comme une constante, et donc ce terme a une contribution à la variance conditionnellement à <span class="math inline">\(X_1,\dots X_n\)</span>.</p>
<p>On a donc</p>
<span class="math display">\[\begin{align}
\mathbb{V}(\widehat{a}|X_1,\dots X_n) &amp;= \mathbb{V}\left(\left.\frac{\sum\limits_{i=1}^n (X_i-\overline{X}_n)Y_i}{\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2}\right|X_1,\dots, X_n\right) \\
&amp;= \frac{\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2\mathbb{V}(Y_i|X_1,\dots,X_n)}{\left(\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2\right)^2} \\
&amp; \text{ (somme de VA i.i.d.)} \\
&amp;= \frac{\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2\sigma_u^2}{\left(\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2\right)^2} \\
&amp;= \frac{\sigma_u^2}{\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2}
\end{align}\]</span>
<p>et</p>
<span class="math display">\[\begin{align}
\mathbb{V}(\widehat{b}|X_1,\dots,X_n) &amp;= \mathbb{V}(\overline{Y}_n-\widehat{a}\overline{X}_n|X_1,\dots,X_n) \\
&amp;= \mathbb{V}(a\overline{X}_n+b+\overline{u}_n-\widehat{a}\overline{X}_n|X_1,\dots,X_n) \\
&amp;= \mathbb{V}((a-\widehat{a}\overline{X}_n)+b+\overline{u}_n|X_1,\dots, X_n) \\
&amp;= \overline{X}_n^2\underbrace{\mathbb{V}(\widehat{a}|X_1,\dots,X_n)}_{=\frac{\sigma_u^2}{\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2}}+\underbrace{\mathbb{V}(\overline{u}_n|X_1,\dots,X_n)}_{=\frac{\sigma_u^2}{n} \text{ car } u_i \text{ i.i.d. de variance } \sigma_u^2} \\
&amp;= \overline{X}_n^2\frac{\sigma_u^2}{\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2}+\frac{\sigma_u^2}{n} \\
&amp;= \sigma_u^2\left(\frac{1}{n}+\frac{\overline{X}_n^2}{\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2}\right)
\end{align}\]</span>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
</div>
<div id="résidus" class="section level4 hasAnchor" number="7.1.6.7">
<h4><span class="header-section-number">7.1.6.7</span> Résidus<a href="statistique-inférentielle.html#résidus" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La variance <span class="math inline">\(\sigma_u^2\)</span> des termes d’erreur <span class="math inline">\(u_i\)</span> n’est pas connue. Cependant, elle peut être estimée. Pour cela, on introduit la notion de <strong>résidu</strong>.</p>
<p>Le résidu <span class="math inline">\(\widehat{u}_i\)</span> est défini comme l’écart entre la vraie valeur <span class="math inline">\(Y_i\)</span> et sa prédiction <span class="math inline">\(\widehat{Y}_i=\widehat{a}X_i+\widehat{b}\)</span> :</p>
<p><span class="math display">\[\widehat{u}_i\equiv Y_i-\widehat{Y}_i\]</span> On a donc <span class="math display">\[\widehat{u}_i=Y_i-\widehat{a}X_i-\widehat{b}\]</span></p>
<p>Il s’agit d’une estimation (sans biais) de la vraie erreur</p>
<p><span class="math display">\[u_i=Y_i-aX_i-b\]</span></p>
<div class="thmbox thm">
<strong>Théorème (estimation de la variance) : </strong> <span class="math inline">\(\sigma_u^2\)</span>
</center>
<p>La variance <span class="math inline">\(\sigma_u^2\)</span> est estimée par</p>
<p><span class="math display">\[s^2=\frac{1}{n-2}\sum\limits_{i=1}^n \widehat{u}_i^2\]</span></p>
</div>
</div>
<div id="distributions-des-estimateurs-widehata-et-widehatb" class="section level4 hasAnchor" number="7.1.6.8">
<h4><span class="header-section-number">7.1.6.8</span> Distributions des estimateurs <span class="math inline">\(\widehat{a}\)</span> et <span class="math inline">\(\widehat{b}\)</span><a href="statistique-inférentielle.html#distributions-des-estimateurs-widehata-et-widehatb" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>On admet alors le résultat suivant</p>
<div class="thmbox thm">
<p><strong>Théorème :</strong> Sous l’hypothèse de normalité des termes d’erreur <span class="math inline">\(u_i\)</span>, on a</p>
<p><span class="math display">\[\frac{(n-2)s^2}{\sigma_u^2}\sim\chi^2_{(n-2)}\]</span> et les statistiques</p>
<p><span class="math display">\[\frac{\widehat{a}-a}{s\sqrt{\frac{1}{\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2}}}\]</span> et</p>
<p><span class="math display">\[\frac{\widehat{b}-b}{s\sqrt{\frac{1}{n}+\frac{\overline{X}_n^2}{\sum\limits_{i=1}^n (X_i-\overline{X}_n)^2}}}\]</span> suivent une loi de Student à <span class="math inline">\(n-2\)</span> degrés de liberté.</p>
</div>
</div>
<div id="convergence-des-estimateurs-widehata-et-widehatb" class="section level4 hasAnchor" number="7.1.6.9">
<h4><span class="header-section-number">7.1.6.9</span> Convergence des estimateurs <span class="math inline">\(\widehat{a}\)</span> et <span class="math inline">\(\widehat{b}\)</span><a href="statistique-inférentielle.html#convergence-des-estimateurs-widehata-et-widehatb" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si on suppose que les <span class="math inline">\(X_i\)</span> admettent des moments d’ordre <span class="math inline">\(1\)</span> et <span class="math inline">\(2\)</span>, alors on peut montrer que les estimateurs <span class="math inline">\(\widehat{a}\)</span> et <span class="math inline">\(\widehat{b}\)</span> sont des estimateurs convergents.</p>
<p>On sait déjà qu’ils sont sans biais, il suffit donc de démontrer que leurs variances tendent vers <span class="math inline">\(0\)</span>.</p>
<p>Or, comme <span class="math inline">\(X_i\)</span> admet des moments d’ordres <span class="math inline">\(1\)</span> et <span class="math inline">\(2\)</span> on a, conditionnellement à <span class="math inline">\(X_1,\dots,X_n\)</span> :</p>
<p><span class="math display">\[\overline{X}_n\approx\mathbb{E}(X)\]</span> et <span class="math display">\[\sum\limits_{i=1}^n(X_i-\overline{X}_n)^2\approx n\mathbb{V}(X_1)\]</span> On en déduit que</p>
<p><span class="math display">\[\mathbb{V}(\widehat{a}|X_1,\dots, X_n)\approx\frac{\sigma_u^2}{n\mathbb{V}(X_1)}\longrightarrow 0\]</span></p>
<p>et</p>
<p><span class="math display">\[\mathbb{V}(\widehat{b}|X_1,\dots,X_n)\approx\sigma_u^2\left(\frac{1}{n}+\frac{\overline{X}_n^2}{n\mathbb{V}(X_1)}\right)\longrightarrow 0\]</span></p>
<p><span class="math inline">\(\widehat{a}\)</span> et <span class="math inline">\(\widehat{b}\)</span> sont des estimateurs sans biais de <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> de variances asymptotiquement nulles. Ce sont donc des estimateurs convergents de <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span>.</p>
</div>
</div>
<div id="intervalles-de-confiance" class="section level3 hasAnchor" number="7.1.7">
<h3><span class="header-section-number">7.1.7</span> Intervalles de confiance<a href="statistique-inférentielle.html#intervalles-de-confiance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Jusqu’à présent, l’estimation était uniquement envisagée du point de vue de l’estimation <em>ponctuelle</em> : il s’agissait, à partir de l’observation d’un échantillon <span class="math inline">\((X_1,\dots,X_n)\)</span> de fournir une valeur ponctuelle <span class="math inline">\(\widehat{\theta}_n\)</span> approchant la vraie valeur inconnue d’un paramètre <span class="math inline">\(\theta\)</span>. Cependant, la valeur estimée dépend de l’échantillon tiré. En effet, si l’on tire <span class="math inline">\(1,000\)</span> échantillons différents, on va obtenir <span class="math inline">\(1\,000\)</span> estimations <span class="math inline">\(\widehat{\theta}^{(1)}_n,\dots,\widehat{\theta}^{(1\,000)}_n\)</span> <em>a priori</em> différentes également. Certaines de ces estimations peuvent être des valeurs atypiques. Se pose donc la question de la <em>confiance</em> que l’on peut accorder à l’estimation obtenue à partir d’une seule réalisation particulière <span class="math inline">\((x_1,\dots,x_n)\)</span> de l’échantillon, puisqu’en pratique c’est tout ce dont on dispose pour inférer sur <span class="math inline">\(\theta\)</span>.</p>
<p>L’approche présentée jusqu’ici ne répond pas à cette question. Le bon outil pour aborder ce problème est la notion d’<em>intervalle de confiance</em>.</p>
<div class="defbox def">
<center>
<strong>Intervalles de confiance</strong>
</center>
<p>Soit <span class="math inline">\(\theta\)</span> un paramètre inconnu et <span class="math inline">\(\alpha\)</span> un réel compris entre <span class="math inline">\(0\)</span> et <span class="math inline">\(1\)</span>. On appelle <strong>intervalle de confiance de niveau <span class="math inline">\(1-\alpha\)</span> du paramètre <span class="math inline">\(\theta\)</span></strong> tout intervalle <span class="math inline">\([a;b]\)</span> tel que <span class="math display">\[\mathbb{P}\left(\theta\in [a;b]\, \right)=1-\alpha\]</span></p>
</div>
<p>
<strong>Remarques : i.</strong> Les réels <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> dépendent de <span class="math inline">\(\theta\)</span>, du niveau de confiance <span class="math inline">\(1-\alpha\)</span>. En pratique, pour les déterminer on utilise l’échantillon <span class="math inline">\((X_1,\dots, X_n)\)</span>, ou plus précisément un résumé <span class="math inline">\(T_n\)</span> de cet échantillon, i.e. une statistique <span class="math inline">\(T_n=T_n(X_1,\dots,X_n)\)</span>. On a donc</p>
<p><span class="math display">\[\begin{align}
a &amp;= a_n(T_n\,;\,\theta\,;\,\alpha) \\
b &amp;= b_n(T_n\,;\,\theta\,;\,\alpha) \\
\end{align}\]</span></p>
<p>Ce sont donc des <strong>variables aléatoires</strong>, que l’on notera désormais plus simplement <span class="math inline">\(a_n\)</span> et <span class="math inline">\(b_n\)</span>. L’intervalle de confiance est donc lui-même un objet aléatoire.</p>
<p>
<strong>ii.</strong> Idéalement, on aimerait savoir avec certitude que <span class="math inline">\(\theta\in [a,b]\)</span>. Comme les réels <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> dépendent de l’échantillon tiré, on ne peut espérer mieux qu’une probabilité d’appartenance de <span class="math inline">\(\theta\)</span> à <span class="math inline">\([a,b]\)</span>. A défaut qu’elle soit égale à 1, on la veut proche de <span class="math inline">\(1\)</span>, autrement dit on veut <span class="math inline">\(\alpha\)</span> proche de <span class="math inline">\(0\)</span>. En pratique, on prendra souvent <span class="math inline">\(\alpha=0,05\)</span>, parfois <span class="math inline">\(\alpha=0,01\)</span>.</p>
<p><strong>iii.</strong> Le réel <span class="math inline">\(\alpha\)</span> représente un <em>risque</em> : celui de donner un intervalle de confiance qui ne contienne pas la vraie valeur de <span class="math inline">\(\theta\)</span>.</p>
<p>
<strong>iv.</strong> Réduire la valeur de <span class="math inline">\(\alpha\)</span> n’est pas gratuit. Le prix à payer est un élargissement de l’intervalle de confiance <span class="math inline">\([a,b]\)</span>, ce qui signifie des intervalles de confiance moins fins et donc moins informatifs sur la vraie valeur de <span class="math inline">\(\theta\)</span>. Inversement, si on veut des intervalles de confiance plus fins, il faut assumer un risque plus grand d’avoir un intervalle de confiance laissant échapper le vrai <span class="math inline">\(\theta\)</span>.</p>
<p>On voit maintenant une méthode générale de construction de <span class="math inline">\([a_n\,;\,b_n]\)</span>.</p>
<div class="methbox meth">
<center>
<strong>Construction d’un intervalle de confiance</strong>
</center>
<p>On cherche un couple de réels <span class="math inline">\((a_n,b_n)\)</span> tel que <span class="math display">\[\mathbb{P}\left(a_n\leq \theta\leq b_n\right)=1-\alpha\]</span>
On suppose qu’on dispose d’une statistique <span class="math inline">\(T_n\)</span> à partir de laquelle on calcule ces réels :</p>
<p><span class="math display">\[\begin{align}
a_n &amp;= a_n(T_n) \\
b_n &amp;= b_n(T_n)
\end{align}\]</span></p>
<p>On cherche alors à transformer l’écriture <span class="math inline">\(\theta\in[a_n(T_n)\,;\,b_n(T_n)]\)</span> en une écriture équivalente du type <span class="math inline">\(T_n\in[\alpha_n(\theta)\,;\,\beta_n(\theta)]\)</span>, autrement dit on veut</p>
<p><span class="math display">\[\theta\in[a_n(T_n)\,;\,b_n(T_n)]\Leftrightarrow T_n\in[\alpha_n(\theta)\,;\,\beta_n(\theta)]\]</span></p>
<p>Dans ce cas, on doit avoir</p>
<p><span class="math display">\[\mathbb{P}\left(T_n\in[\alpha_n(\theta)\,;\,\beta_n(\theta)]\right)=1-\alpha\]</span>
Il s’agit donc de trouver un couple de réels <span class="math inline">\((\alpha_n,\beta_n)=(\alpha_n(\theta),\beta_n(\theta))\)</span> tel que</p>
<p><span class="math display">\[F_{T_n}(\beta_n)-F_{T_n}(\alpha_n)=1-\alpha\]</span>
ou, de façon équivalente</p>
<p><span class="math display">\[\mathbb{P}(T_n&lt;\alpha_n)+\mathbb{P}(T_n&gt;\beta_n)=\alpha\]</span></p>
</div>
<p>
<strong>Remarque.</strong> La dernière égalité s’interprète comme un <em>risque</em> à répartir entre <span class="math inline">\(\mathbb{P}(T_n&lt;\alpha_n)\)</span> et <span class="math inline">\(\mathbb{P}(T_n&gt;\alpha_n)\)</span>.</p>
<p>Une première approche pour construire des intervalles de confiance consiste à utiliser, lorsque cela est possible, l’inégalité de Bienaymé-Tchebychev :</p>
<div class="methbox meth">
<center>
<strong>Construction d’intervalles de confiance par application de l’inégalité de Bienaymé-Tchebychev</strong>
</center>
<p>Soit <span class="math inline">\(\widehat{\theta}_n\)</span> un estimateur sans biais de <span class="math inline">\(\theta\)</span> et admettant une variance <span class="math inline">\(\sigma^2\)</span> que l’on suppose connue. On peut donc appliquer l’inégalité de Bienaymé-Tchebychev :</p>
<p><span class="math display">\[\mathbb{P}\left(|\widehat{\theta}_n-\theta|\geq\varepsilon\right)\leq\frac{\sigma^2}{\varepsilon^2}\]</span></p>
<p>soit</p>
<p><span class="math display">\[\mathbb{P}\left(|\widehat{\theta}_n-\theta|&lt;\varepsilon \right)&gt;1-\frac{\sigma^2}{\varepsilon^2}\]</span></p>
<p>On choisit <span class="math inline">\(\varepsilon\)</span> de façon à avoir <span class="math inline">\(\alpha=\frac{\sigma^2}{\varepsilon^2}\)</span>, i.e. on pose</p>
<p><span class="math display">\[\varepsilon=\frac{\sigma}{\sqrt{\alpha}}\]</span>
Par inversion des inégalités on a <span class="math inline">\(|\widehat{\theta}_n-\theta|&lt;\varepsilon\Leftrightarrow\widehat{\theta}_n-\varepsilon&lt;\theta&lt;\widehat{\theta}_n+\varepsilon\)</span>. On en déduit un intervalle de confiance de <span class="math inline">\(\theta\)</span> au niveau de confiance <span class="math inline">\(1-\alpha\)</span> :</p>
<p><span class="math display">\[IC^{1-\alpha}_m=\left[\widehat{\theta}_n-\frac{\sigma}{\sqrt{\alpha}}\,;\,\widehat{\theta}_n+\frac{\sigma}{\sqrt{\alpha}}\right]\]</span></p>
<p>Cet intervalle de confiance est bien calculable en pratique puisqu’on a supposé <span class="math inline">\(\sigma^2\)</span> connue.</p>
<p>
<strong>Exemple (moyenne empirique).</strong> Soient <span class="math inline">\(X\)</span> une VA admettant une espérance <span class="math inline">\(m\)</span> et une variance <span class="math inline">\(\sigma^2\)</span>, et <span class="math inline">\((X_1,\dots, X_n)\)</span> des VA i.i.d. de même loi que <span class="math inline">\(X\)</span>. La moyenne empirique <span class="math inline">\(\widehat{\theta}_n\equiv\overline{X}_n\)</span> est un estimateur sans biais de <span class="math inline">\(\theta\equiv m\)</span> et admettant comme variance <span class="math inline">\(\frac{\sigma^2}{n}\)</span>, on peut donc appliquer ce qui précède et obtenir un intervalle de confiance de <span class="math inline">\(m\)</span> au niveau de confiance <span class="math inline">\(1-\alpha\)</span> :</p>
<p><span class="math display">\[IC^{1-\alpha}_m=\left[\overline{X}_n-\frac{\sigma}{\sqrt{n\alpha}}\,;\,\overline{X}_n+\frac{\sigma}{\sqrt{n\alpha}}\right]\]</span></p>
</div>
<p>Pour le concours d’administrateur, il est précisé que la construction d’intervalle de confiances est abordée dans un contexte d’application du théorème central limite (<em>Construction d’un intervalle de confiance dans le cadre des modèles d’échantillonnage, dans le cas où le théorème central limite s’applique.</em>). En d’autres termes, il s’agit de se ramener - si l’on n’y est pas déjà - au cas d’une loi normale et d’en déduire un intervalle de confiance (asymptotique).</p>
<p>On commence par considérer le cas où la statistique <span class="math inline">\(T_n\)</span> est gaussienne.</p>
<div class="methbox meth">
<center>
<strong>Construction d’intervalles de confiance dans le cas gaussien</strong>
</center>
<p>Supposons que <span class="math inline">\(X\)</span> suive une loi normale :</p>
<p><span class="math display">\[X\sim\mathcal{N}(m,\sigma^2)\]</span></p>
<p>
<strong>Exemple : estimation de <span class="math inline">\(m\)</span> lorsque <span class="math inline">\(\sigma\)</span> est connu.</strong> <span class="math inline">\(m\)</span> est l’espérance de <span class="math inline">\(X\)</span>, on peut l’estimer par la moyenne empirique</p>
<p><span class="math display">\[\overline{X}_n\sim\mathcal{N}\left(m\,;\,\frac{\sigma^2}{n}\right)\]</span></p>
<ul>
<li>on commence par centrer et réduire <span class="math inline">\(\overline{X}_n\)</span> pour se ramener à une loi normale standard <span class="math inline">\(\mathcal{N}(0,1)\)</span>. On pose donc</li>
</ul>
<p><span class="math display">\[Z_n\equiv\frac{\overline{X}_n-m}{\frac{\sigma}{\sqrt{n}}}\]</span></p>
<ul>
<li>on cherche ensuite un intervalle <span class="math inline">\([-v,v]\)</span> de niveau de confiance <span class="math inline">\(1-\alpha\)</span> pour <span class="math inline">\(Z_n\)</span>. Comme <span class="math inline">\(Z_n\)</span> est symétrique par rapport à <span class="math inline">\(0\)</span>, il est plus simple de le chercher sous la forme <span class="math inline">\([-v,v]\)</span>. On résout donc, en notant <span class="math inline">\(\Phi\)</span> la fonction de répartition d’un loi normale standard et en remarquant que <span class="math inline">\(\Phi(-x)=1-\Phi(x)\)</span> :</li>
</ul>
<p><span class="math display">\[\begin{align}
\Phi(v)-\Phi(-v) &amp;= 1-\alpha  \\
2\Phi(v)-1 &amp;= 1-\alpha \\
\Phi(v) &amp;= 1-\frac{\alpha}{2} \\
v &amp;= \Phi^{-1}\left(1-\frac{\alpha}{2}\right)
\end{align}\]</span></p>
<ul>
<li>on en déduit un intervalle de confiance de niveau <span class="math inline">\(1-\alpha\)</span> pour <span class="math inline">\(m\)</span> :</li>
</ul>
<p><span class="math display">\[\begin{align}
&amp; -v\leq Z_n \leq v  \\
\text{ssi } &amp; -v\leq\frac{\overline{X}_n-m}{\frac{\sigma}{\sqrt{n}}}\leq n \\
\text{ssi } &amp; \overline{X}_n-\frac{\sigma}{\sqrt{n}}v\leq m\leq \overline{X}_n+\frac{\sigma}{\sqrt{n}}v &amp; \\
\end{align}\]</span></p>
<p>Un intervalle de confiance de <span class="math inline">\(m\)</span> au niveau <span class="math inline">\(1-\alpha\)</span> est donc</p>
<p><span class="math display">\[\text{IC}^m_{1-\alpha}\equiv\left[\overline{X}_n-\frac{\sigma}{\sqrt{n}}\Phi^{-1}\left(1-\frac{\alpha}{2}\right) \, , \,  \overline{X}_n+\frac{\sigma}{\sqrt{n}}\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\right]\]</span>
On peut calculer cet intervalle de confiance à partir de l’échantillon pusiqu’on a supposé <span class="math inline">\(\sigma\)</span> connu.</p>
</div>
<p>On considère maintenant un cas où la stastistique n’est plus gaussienne, mais où il est possible d’appliquer le théorème central-limite, et donc se ramener à une loi approximativement gaussienne. Dans ce cas, peut obtenir des <strong>intervalles de confiance asymptotiques</strong> :</p>
<div class="methbox meth">
<center>
<strong>Construction d’intervalles de confiance asymptotiques dans un cas d’application du TCL</strong>
</center>
<p>On suppose que <span class="math inline">\(X\)</span> suit une loi normale centrée :</p>
<p><span class="math display">\[X_n\sim\mathcal{N}(0,\sigma^2)\]</span></p>
<p>
<strong>Exemple : estimation de <span class="math inline">\(\sigma\)</span>.</strong> On considère la statistique</p>
<p><span class="math display">\[D_n\equiv\frac{1}{n}\sum\limits_{i=1}^n |X_i|\]</span></p>
<p>On vérifie facilement que l’intégrale <span class="math inline">\(\int_{\mathbb{R}} |x|\frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{x^2}{2\sigma^2}}\,dx\)</span> est convergente et vaut <span class="math inline">\(\sqrt{\frac{2}{\pi}}\sigma\)</span>. Ainsi, la variable aléatoire <span class="math inline">\(|X|\)</span> admet une espérance et</p>
<p><span class="math display">\[\mathbb{E}(|X|)=\sqrt{\frac{2}{\pi}}\,\sigma\]</span>
On en déduit un estimateur sans biais de <span class="math inline">\(\sigma\)</span> :</p>
<p><span class="math display">\[T_n\equiv\sqrt{\frac{\pi}{2}}\,D_n\]</span>
Avec la loi faible des grands nombres, <span class="math inline">\(T_n\)</span> est un estimateur convergent de <span class="math inline">\(\sigma\)</span>. Par ailleurs, <span class="math inline">\(|X|\)</span> admet un moment d’ordre <span class="math inline">\(2\)</span> (<span class="math inline">\(\mathbb{E}(|X|^2)=\mathbb{E}(X^2)=\sigma^2\)</span>) et</p>
<p><span class="math display">\[\begin{align}
\mathbb{V}(|X|) &amp;= \mathbb{E}(X^2)-(\mathbb{E}(|X|))^2 \\
&amp;= \left(1-\frac{2}{\pi}\right)\sigma^2
\end{align}\]</span></p>
<p>On en déduit que <span class="math inline">\(T_n\)</span> admet une variance et que</p>
<p><span class="math display">\[\mathbb{V}(T_n)=\left(\frac{\pi}{2}-1\right)\frac{\sigma^2}{n}\]</span>
Avec le théorème central limite on a l’approximation en loi</p>
<p><span class="math display">\[\frac{T_n-\sigma}{\frac{\sigma}{\sqrt{n}}\sqrt{\frac{\pi}{2}-1}}\approx\mathcal{N}(0,1)\]</span>
En posant <span class="math inline">\(u_{\alpha}=\Phi^{-1}\left(1-\frac{\alpha}{2}\right)\)</span>, avec toujours <span class="math inline">\(\Phi\)</span> la fonction de répartition de la loi normale standard, on a donc</p>
<p><span class="math display">\[\mathbb{P}\left(-u_{\alpha}\leq\sqrt{n}\frac{T_n-\sigma}{\sigma\sqrt{\frac{\pi}{2}-1}}\leq u_{\alpha}\right)\approx 1-\alpha\]</span>
Or</p>
<p><span class="math display">\[-u_{\alpha}\leq\sqrt{n}\frac{T_n-\sigma}{\sigma\sqrt{\frac{\pi}{2}-1}}\leq u_{\alpha}\Leftrightarrow \frac{T_n}{1+\frac{u_{\alpha}}{\sqrt{n}}\sqrt{\frac{\pi}{2}-1}}\leq\sigma\leq\frac{T_n}{1-\frac{u_{\alpha}}{\sqrt{n}}\sqrt{\frac{\pi}{2}-1}}\]</span>
On en déduit un intervalle de confiance asymptotique de <span class="math inline">\(\sigma\)</span> au niveau de confiance <span class="math inline">\(1-\alpha\)</span> :</p>
<p><span class="math display">\[\text{IC}^{1-\alpha}_{\sigma}\equiv\left[\frac{T_n}{1+\frac{u_{\alpha}}{\sqrt{n}}\sqrt{\frac{\pi}{2}-1}}\, ;\, \frac{T_n}{1-\frac{u_{\alpha}}{\sqrt{n}}\sqrt{\frac{\pi}{2}-1}}\right]\]</span></p>
</div>
</div>
</div>
<div id="tests-statistiques" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Tests statistiques<a href="statistique-inférentielle.html#tests-statistiques" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="définition-et-principes" class="section level3 hasAnchor" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Définition et principes<a href="statistique-inférentielle.html#définition-et-principes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On s’intéresse à un phénomène réel que l’on modélise par une variable aléatoire <span class="math inline">\(X\)</span> dont la loi est modélisée statistiquement par une famille paramétrique de distributions <span class="math inline">\(\{P_{\theta}, \theta\in\Theta\}\)</span>. On suppose que l’espace <span class="math inline">\(\Theta\)</span> de tous les paramètres possibles est partitionné en deux sous-ensembles <span class="math inline">\(\Theta_0\)</span> et <span class="math inline">\(\Theta_1\)</span>. On note <span class="math inline">\(\theta\)</span> la vraie valeur associée à la loi de <span class="math inline">\(X\)</span>. On considère alors les deux hypothèses suivantes :</p>
<p><span class="math display">\[(H_0):\,\theta\in\Theta_0\]</span>
<span class="math display">\[(H_1):\,\theta\in\Theta_1\]</span></p>
<p>L’hypothèse <span class="math inline">\((H_0)\)</span> s’appelle l’<strong>hypothèse nulle</strong> alors que l’hypothèse <span class="math inline">\((H_1)\)</span> s’appelle l’<strong>hypothèse alternative</strong>.</p>
<p>Construire un test revient à construire une partition de <span class="math inline">\(\mathbb{R}^n\)</span> :</p>
<p><span class="math display">\[\mathbb{R}^n=W\cup\overline{W}\]</span>
tel que, pour toute réalisation <span class="math inline">\((x_1,\dots,x_n)\)</span> d’un échantillon aléatoire <span class="math inline">\((X_1,\dots,X_n)\)</span> de variables aléatoires i.i.d. <span class="math inline">\(X_i\)</span> de loi <span class="math inline">\(P_{\theta}\)</span>, on suive la <strong>règle de décision</strong> suivante :</p>
<p><span class="math display">\[\hbox{Si } (x_1,\dots, x_n)\in W \hbox{ alors on rejette l&#39;hypothèse nulle } (H_0)\]</span>
<span class="math display">\[\hbox{Si } (x_1,\dots, x_n)\in \overline{W} \hbox{ alors on ne rejette pas l&#39;hypothèse nulle } (H_0)\]</span>
La partie <span class="math inline">\(W\)</span> s’appelle la <strong>région de rejet</strong> de <span class="math inline">\((H_0)\)</span>, ou encore la <strong>région critique</strong>. La partie <span class="math inline">\(\overline{W}\)</span> s’appelle la <strong>région d’acceptation</strong> de l’hypothèse nulle <span class="math inline">\((H_0)\)</span>.</p>
<p>Construire un test, c’est donc décider d’une partition particulière <span class="math inline">\((W, \overline{W})\)</span> de <span class="math inline">\(\mathbb{R}^n\)</span>.</p>
<p>Les tests constituent un outil d’aide à la décision. On en présente ici une méthodlogie générale :</p>
<div class="methbox meth">
<center>
<strong>Méthodologie des tests d’hypothèse</strong>
</center>
<p>On suit généralement les étapes suivantes :</p>
<ul>
<li>on définit l’hypothèse nulle <span class="math inline">\((H_0)\)</span> et l’hypothèse alternative <span class="math inline">\((H_1)\)</span> ;</li>
<li>on choisit une <strong>statistique de test</strong> <span class="math inline">\(T=T(X_1,\dots, X_n)\)</span> ;</li>
<li>on détermine la distribution de <span class="math inline">\(T\)</span> sous l’hypothèse nulle <span class="math inline">\((H_0)\)</span> ;</li>
<li>on choisit un <strong>niveau de significativité</strong> <span class="math inline">\(\alpha\)</span> du test, et on calcule, à partir de la distibution de <span class="math inline">\(T\)</span> obtenue à l’étape précédente, la <strong>région de rejet</strong> de <span class="math inline">\((H_0)\)</span> ;</li>
<li>on calcule, à partir des données observées <span class="math inline">\((x_1,\dots x_n)\)</span> (qui constituent une réalisation de l’échantillon aléatoire <span class="math inline">\((X_1,\dots, X_n)\)</span>) la valeur <span class="math inline">\(T(x_1,\dots, x_n)\)</span> prise par <span class="math inline">\(T\)</span> ;</li>
<li>à partir de cette dernière valeur et de la région de rejet, on prend une décision.</li>
</ul>
</div>
<p>Cette méthodologie correspond en gros à un <strong>raisonnement par l’absurde probabiliste</strong>. En effet, dans un raisonnement par l’absurde classique :</p>
<ul>
<li>on veut démontrer une certaine affirmation <span class="math inline">\(A\)</span> ;</li>
<li>sous l’hypothèse contraire <span class="math inline">\(\overline{A}\)</span>, on en déduit quelque chose que l’on sait faux ;</li>
<li>on conclut que notre hypothèse de départ <span class="math inline">\(\overline{A}\)</span> est fausse, i.e. on rejette <span class="math inline">\(\overline{A}\)</span>, ou, de façon équivalente, on conclut que <span class="math inline">\(A\)</span> est vraie.</li>
</ul>
<p>Lorsqu’on fait un test :</p>
<ul>
<li>on définit une hypothèse nulle <span class="math inline">\((H_0)\)</span>, qui est l’hypothèse que l’on aimerait pouvoir rejeter ;</li>
<li>on calcule la distribution de <span class="math inline">\(T\)</span> et on calcule par ailleurs la valeur <span class="math inline">\(T(x_1,\dots, x_n)\)</span> ;</li>
<li>si la probabilité <strong>sous l’hypothèse nulle</strong> que <span class="math inline">\(T\)</span> prenne cette valeur est très faible, i.e. en dessous d’un certain seuil (le seuil standard étant 5 %), on rejette l’hypothèse nulle. Si en revanche cette probabilité est au-dessus de ce seuil, on ne rejette pas l’hypothèse nulle.</li>
</ul>
<p>
<strong>Remarques. i</strong> En résumé, on suit donc le principe suivant : je suppose <span class="math inline">\((H_0)\)</span> vraie, j’arrive à un résultat très improbable, je conclus que <span class="math inline">\((H_0)\)</span> est fausse.</p>
<p>
<strong>ii.</strong> A la différence d’un raisonnement par l’absurde classique, cette conclusion peut toutefois être erronée. Autrement dit, il est possible de rejeter à tort <span class="math inline">\((H_0)\)</span>. Toutefois, ce risque de rejet à tort est maitrisable : il s’agit du seuil de significativité <span class="math inline">\(\alpha=\mathbb{P}(\hbox{on rejette } H_0\,|\, H_0)\)</span>. Donc, si on choisit <span class="math inline">\(\alpha\)</span> petit, ce risque -appelé <strong>risque de première espèce</strong>- sera très limité.</p>
<p>
<strong>iii.</strong> Lorsqu’on tente de faire un raisonnement par l’absurde, mais qu’on ne parvient pas à aboutir à une contradiction, il est incorrect de conclure que l’hypothèse initiale est vraie. Notre raisonnement ne nous a juste pas permis de conclure qu’elle était fausse… ce qui ne signifie pas qu’elle est vraie. Dans un tel cas, on ne peut tout simplement rien conclure. De manière analogue, si la probabilité calculée dans un test est au-dessus du seuil de significativité, il serait incorrect d’<em>accepter</em> l’hypothèse nulle. Même si on trouve parfois l’expression <em>accepter <span class="math inline">\((H_0)\)</span></em> dans la littérature, il s’agit d’un abus de langage et on lui préfèrera l’expression <em>ne pas rejeter <span class="math inline">\((H_0)\)</span></em>. Cela ne signifie pas que <span class="math inline">\((H_1)\)</span> est probablement vraie, mais plutôt que notre test ne nous a pas permis de conclure que <span class="math inline">\((H_0)\)</span> était probablement fausse, ce qui est assez différent.</p>
<p>
<strong>iv.</strong> De la même façon que l’on peut rejeter à tort l’hypothèse nulle <span class="math inline">\((H_0)\)</span>, il est possible de ne pas rejeter à tort <span class="math inline">\((H_0)\)</span>. La probabilité d’un tel événement est <span class="math inline">\(\mathbb{P}(\hbox{ne pas rejeter } H_0\,|\, H_1)\)</span>. Cette probabilité s’appelle le <strong>risque de deuxième espèce</strong>.</p>
<p>
<strong>v.</strong> Tout test présente une dyssymétrie dans sa façon de traiter <span class="math inline">\((H_0)\)</span> et <span class="math inline">\((H_1)\)</span>. Parmi les deux types d’erreurs que l’on peut commettre dans la conclusion d’un test, il y en a généralement l’une des deux que l’on veut éviter en priorité. Par exemple, un test médical peut amener deux types d’erreurs : les faux positifs et les faux négatifs. On préfère en général avoir des tests pour lesquels la probabilité de faux négatif est faible, car conclure que le patient n’est pas malade (et donc ne pas le traiter) alors qu’il l’est est en général plus ennuyeux que conclure qu’il est malade (et donc le traiter) alors qu’il ne l’est pas. On retient le plus souvent la convention suivante : l’erreur de première espèce est celle que l’on veut éviter, on veut donc maitriser le risque de première espèce <span class="math inline">\(\alpha=\mathbb{P}(\hbox{rejeter } H_0\,|\,H_0)\)</span>. On choisit un <span class="math inline">\(\alpha\)</span> petit et on en déduit une région de rejet <span class="math inline">\(W=W_{\alpha}\)</span>. La valeur <span class="math inline">\(\beta=\mathbb{P}(\hbox{ne pas rejeter } H_0\,|\, H_1)\)</span> dépend alors du choix de <span class="math inline">\(\alpha\)</span>, on ne la contrôle pas.</p>
</div>
<div id="tests-unilatéraux-tests-bilatéraux" class="section level3 hasAnchor" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Tests unilatéraux, tests bilatéraux<a href="statistique-inférentielle.html#tests-unilatéraux-tests-bilatéraux" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On note <span class="math inline">\(\theta\)</span> le paramètre inconnu associé à la loi de <span class="math inline">\(X\)</span>.</p>
<div class="defbox def">
<center>
<strong>Test bilatéral</strong>
</center>
<p>Un <strong>test bilatéral</strong> est un test dont les hypothèses nulle <span class="math inline">\((H_0)\)</span> et alternative <span class="math inline">\((H_1)\)</span> sont de la forme</p>
<p><span class="math display">\[(H_0):\,\theta=\theta_0\]</span>
<span class="math display">\[(H_1):\,\theta\neq\theta_0\]</span></p>
</div>
<p>
<strong>Exemple : tester si une pièce est équilibrée.</strong> On veut s’assurer qu’une pièce est équilibrée en utilisant un test statistique.</p>
<p>On note <span class="math inline">\(p\)</span> sa probabilité de tomber sur pile. La pièce est équilibrée si et seulement si <span class="math inline">\(p=\frac{1}{2}\)</span>.</p>
<p>On définit alors le test suivant :</p>
<p><span class="math display">\[(H_0):\,p=\frac{1}{2}\]</span>
<span class="math display">\[(H_1):\, p\neq\frac{1}{2}\]</span>
Il s’agit d’un test bilatéral.</p>
<p>De même, il existe des tests unilatéraux :</p>
<div class="defbox def">
<center>
<strong>Test unilatéral</strong>
</center>
<p>Un <strong>test unilatéral</strong> est un test dont les hypothèses nulle <span class="math inline">\((H_0)\)</span> et alternative <span class="math inline">\((H_1)\)</span> sont soit de la forme</p>
<p><span class="math display">\[(H_0):\,\theta=\theta_0\]</span>
<span class="math display">\[(H_1):\,\theta&gt;\theta_0\]</span></p>
<p>soit de la forme</p>
<p><span class="math display">\[(H_0):\,\theta=\theta_0\]</span>
<span class="math display">\[(H_1):\,\theta&lt;\theta_0\]</span></p>
</div>
<p>Un test unilatéral suppose donc connu le signe de la différence <span class="math inline">\(\theta-\theta_0\)</span>, contrairement à un test bilatéral.</p>
<p></p>
<p><strong>Exemple : tester l’efficacité d’un médicament.</strong> Le fabricant d’un médicament annonce une efficacité à <span class="math inline">\(90/,/%\)</span> pour l’un de ses produits. Sur un échantillon de 200 personnes, ce médicament a fonctionné pour 160 personnes. On souhaite déterminer si l’afformation du fabrication est exacte au seuil de significativité <span class="math inline">\(\alpha=1\,\%\)</span>.</p>
<p>On va ici prendre pour hypothèses</p>
<p><span class="math display">\[(H_0):\,p=0,9\]</span></p>
<p><span class="math display">\[(H_1):\,p&lt;0,9\]</span></p>
<p>où <span class="math inline">\(p\)</span> est la probabilité que le médicament soit efficace.</p>
<p>Il s’agit d’un test unilatéral gauche.</p>
</div>
<div id="exemples" class="section level3 hasAnchor" number="7.2.3">
<h3><span class="header-section-number">7.2.3</span> Exemples<a href="statistique-inférentielle.html#exemples" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On reprend les deux exemples précédents.</p>
<div class="methbox meth">
<center>
<strong>Exemple 1 : tester si une pièce est équilibrée.</strong>
</center>
<p>
On effectue <span class="math inline">\(n=1\,000\)</span> lancers de cette pièce. Sur ces <span class="math inline">\(10\,000\)</span> lancers, la pièce est tombée <span class="math inline">\(4\,880\)</span> fois sur pile.</p>
<p><strong>On veut déterminer si cette pièce est équilirée au seuil de significativité <span class="math inline">\(\alpha = 5\,\%\)</span>.</strong></p>
<p>Pour <span class="math inline">\(1\leq i\leq n\)</span>, on note <span class="math inline">\(X_i\in\{0,1\}\)</span> la variable aléatoire qui prend la valeur <span class="math inline">\(1\)</span> si la pièce est tombée sur pile au lancer numéro <span class="math inline">\(i\)</span>, qui prend la valeur <span class="math inline">\(0\)</span> si elle est tombée sur face. Les variables aléatoires <span class="math inline">\(X_1,\dots,X_n\)</span> sont i.i.d. de loi de Bernoulli <span class="math inline">\(\mathcal{B}(p)\)</span> où <span class="math inline">\(p\)</span> est la probabilité que la pièce tombe sur pile : <span class="math inline">\(p=\mathbb{P}(X_i=1)\)</span>. La variable aléatoire <span class="math inline">\(S_n\equiv\sum\limits_{i=1}^n X_i\)</span> suit une loi binomiale <span class="math inline">\(\mathcal{B}(n, p)\)</span>.</p>
<p>On rappelle l’énoncé du <strong>théorème de Moivre-Laplace</strong>, qui n’est qu’un cas particulier du théorème central limite :</p>
<div class="thmbox thm">
<p><strong>Théorème de Moivre-Laplace.</strong> Si la variable aléatoire <span class="math inline">\(X_n\)</span> suit une loi binomiale</p>
<p><span class="math display">\[X_n\sim\mathcal{B}(n, \,p)\]</span></p>
<p>alors la variable aléatoire <span class="math display">\[Z_n\equiv\frac{X_n-np}{\sqrt{np(1-p)}}\]</span>
converge en loi vers la loi normale standard <span class="math inline">\(\mathcal{N}(0,1)\)</span>.</p>
<p>En pratique, dès lors que les conditions suivantes sont vérifiées :</p>
<ul>
<li><span class="math inline">\(n\geq 30\)</span></li>
<li><span class="math inline">\(np\geq 5\)</span></li>
<li><span class="math inline">\(n(1-p)\geq 5\)</span>$</li>
</ul>
<p>on peut écrire l’approximation en loi</p>
<p><span class="math display">\[Z_n\equiv\frac{X_n-np}{\sqrt{np(1-p)}}\approx\mathcal{N}(0,1)\]</span></p>
</div>
<p>Sous l’hypothèse nulle <span class="math inline">\((H_0):\,p=\frac{1}{2}\)</span>, on a</p>
<p><span class="math display">\[S_n\sim\mathcal{B}\left(n, \frac{1}{2}\right)\]</span>
Les trois conditions à vérifier sont bien satisfaites :</p>
<ul>
<li><span class="math inline">\(n=10\,000\geq 30\)</span></li>
<li><span class="math inline">\(np=5\,000\geq 5\)</span></li>
<li><span class="math inline">\(n(1-p)=5\,000\geq 5\)</span></li>
</ul>
<p>si bien que</p>
<p><span class="math display">\[Z_n\equiv\frac{S_n-np}{\sqrt{np(1-p)}}\approx\mathcal{N}(0,1)\]</span>
i.e.</p>
<p><span class="math display">\[Z_n\equiv\frac{S_n-5\,000}{50}\approx\mathcal{N}(0,1)\]</span>
La variable aléatoire <span class="math inline">\(Z_n\)</span> est notre <strong>statistique de test</strong>. On vient de déterminer sa loi, on peut donc en déduire la <strong>zone de rejet</strong> de notre test. Pour une loi normale standard <span class="math inline">\(Z_n\)</span>, on a</p>
<p><span class="math display">\[\mathbb{P}\left(-1,96\leq Z_n\leq 1,96\right)\approx 0,95\]</span></p>
<p>La <strong>région d’acceptation</strong> du test au seuil de significativité <span class="math inline">\(\alpha=5\,\%\)</span> est donc <span class="math inline">\(\overline{W}=[-1,96\,;\,1,96]\)</span> et son complémentaire <span class="math inline">\(W=]-\infty\;\,-1,96[\cup]1,96\,;\,+\infty[\)</span> est donc la <strong>région de rejet</strong>.</p>
<p>On applique donc la <strong>règle de décision</strong> suivante :</p>
<p><span class="math display">\[\hbox{Si } z_n\not\in \overline{W}=[-1,96\,;\,1,96] \hbox{ on rejette l&#39;hypothèse nulle} (H_0)\]</span>
<span class="math display">\[\hbox{Si } z_n\in\overline{W}=[-1,96\,;\,1,96] \hbox{ on ne rejette pas l&#39;hypothèse nulle} (H_0)\]</span>
Or, la valeur observée de <span class="math inline">\(Z_n\)</span> sur l’échantillon tiré est <span class="math inline">\(z_n=\frac{4\,880-5\,000}{50}=-2,4\)</span>. Elle appartient à la région de rejet.</p>
<p>
<strong>Conclusion. Au seuil de significativité <span class="math inline">\(5\,\%\)</span> on rejette donc l’hypothèse nulle, ce qui revient à dire qu’on conclut que la pièce est désiquilibrée.</strong></p>
<p>
<strong>Remarque.</strong> Si on avait obtenu <span class="math inline">\(4\,920\)</span> fois pile sur nos <span class="math inline">\(5\,000\)</span> tirages, on aurait calculé <span class="math inline">\(z_n=-1,6\)</span> qui est dans la zone d’acceptation. On n’aurait donc pas rejeté l’hypothèse nulle, autrement dit on n’aurait pas rejeté l’hypothèse d’une pièce équilibrée.</p>
</div>
<div class="methbox meth">
<center>
<strong>Exemple 2 : tester l’efficacité d’un médicament.</strong>
</center>
<p>Pour <span class="math inline">\(i\)</span> compris entre <span class="math inline">\(1\)</span> et <span class="math inline">\(200\)</span>, on pose <span class="math inline">\(X_i=1\)</span> si le médicament a été efficace pour l’individu numéro <span class="math inline">\(i\)</span>, et <span class="math inline">\(X_i=0\)</span> dans le cas contraire.</p>
<p>Comme dans l’exemple 1, sous l’hypothèse nulle <span class="math inline">\((H_0):\,p=0,9\)</span> les <span class="math inline">\(X_i\)</span> sont i.i.d. et suivent une loi de Benoulli, de paramètre <span class="math inline">\(p\)</span>. On en déduit que leur somme <span class="math inline">\(S_n=\sum\limits_{i=1}^{200}X_i\)</span> suit une loi binomiale de paramètre <span class="math inline">\(np=180\)</span>. On a</p>
<ul>
<li><span class="math inline">\(n=200\geq 30\)</span></li>
<li><span class="math inline">\(np=180\geq 5\)</span></li>
<li><span class="math inline">\(n(1-p)=20\geq 5\)</span></li>
</ul>
<p>On a donc</p>
<p><span class="math display">\[Z_n\equiv\frac{S_n-180}{\sqrt{18}}\approx\mathcal{N}(0,1)\]</span>
Il s’agit de notre statistique de test.
Sur l’échantillon observé, elle prend comme valeur</p>
<p><span class="math display">\[z_n=\frac{160-180}{\sqrt{0.5}}\approx -4,71\]</span>
La région de rejet est <span class="math inline">\(W=]-\infty, t]\)</span> avec <span class="math inline">\(t\)</span> l’unique réel tel que <span class="math inline">\(\mathbb{P}(Z_n\leq t)=0,01\)</span>. Grâce à la table de la loi normale standard, on obtient <span class="math inline">\(t\approx -2,33\)</span>, donc <span class="math inline">\(W=]-\infty\,;\,-2,33]\)</span>. Ainsi, <span class="math inline">\(z_n\)</span> est dans la région de rejet. On rejette donc l’hypothèse nulle : l’affirmation du fabricant est fausse au seuil de significativité <span class="math inline">\(1\,\%\)</span>.</p>
</div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="statistique-descriptive.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="méthodologie.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/6_statistique_inférentielle.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Probabilites_Statistique.pdf", "Probabilites_Statistique.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
