<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 3 Variables aléatoires discrètes | Cours de probabilités-statistiques pour le concours interne d’administrateur Insee</title>
  <meta name="description" content="Cours de probabilités et statistiques" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 3 Variables aléatoires discrètes | Cours de probabilités-statistiques pour le concours interne d’administrateur Insee" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Cours de probabilités et statistiques" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 3 Variables aléatoires discrètes | Cours de probabilités-statistiques pour le concours interne d’administrateur Insee" />
  
  <meta name="twitter:description" content="Cours de probabilités et statistiques" />
  

<meta name="author" content="Olivier Guin" />


<meta name="date" content="2024-06-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="dénombrement-et-probabilités.html"/>
<link rel="next" href="variables-aléatoires-à-densité.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Cours de probabilités et statistique pour le concours interne d'administrateur de l'Insee</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> url: your book url like https://bookdown.org/yihui/bookdown</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#généralités"><i class="fa fa-check"></i><b>1.1</b> Généralités</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#coquilles-et-erreurs"><i class="fa fa-check"></i><b>1.2</b> Coquilles et erreurs</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html"><i class="fa fa-check"></i><b>2</b> Dénombrement et probabilités</a>
<ul>
<li class="chapter" data-level="2.1" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#rappels-sur-les-opérations-ensemblistes"><i class="fa fa-check"></i><b>2.1</b> Rappels sur les opérations ensemblistes</a></li>
<li class="chapter" data-level="2.2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#dénombrement"><i class="fa fa-check"></i><b>2.2</b> Dénombrement</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#produit-cartésien-et-principe-multiplicatif"><i class="fa fa-check"></i><b>2.2.1</b> Produit cartésien et principe multiplicatif</a></li>
<li class="chapter" data-level="2.2.2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#principe-additif"><i class="fa fa-check"></i><b>2.2.2</b> Principe additif</a></li>
<li class="chapter" data-level="2.2.3" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#formule-de-poincaré"><i class="fa fa-check"></i><b>2.2.3</b> Formule de Poincaré</a></li>
<li class="chapter" data-level="2.2.4" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#dénombrement-par-bijection"><i class="fa fa-check"></i><b>2.2.4</b> Dénombrement par bijection</a></li>
<li class="chapter" data-level="2.2.5" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#permutations"><i class="fa fa-check"></i><b>2.2.5</b> Permutations</a></li>
<li class="chapter" data-level="2.2.6" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#arrangements"><i class="fa fa-check"></i><b>2.2.6</b> Arrangements</a></li>
<li class="chapter" data-level="2.2.7" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#combinaisons"><i class="fa fa-check"></i><b>2.2.7</b> Combinaisons</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#langage-et-formalisme-des-probabilités"><i class="fa fa-check"></i><b>2.3</b> Langage et formalisme des probabilités</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#lunivers-omega-dune-expérience-aléatoire"><i class="fa fa-check"></i><b>2.3.1</b> L’univers <span class="math inline">\(\Omega\)</span> d’une expérience aléatoire</a></li>
<li class="chapter" data-level="2.3.2" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#lespace-probabilisable-omega-mathcala"><i class="fa fa-check"></i><b>2.3.2</b> L’espace probabilisable <span class="math inline">\((\Omega, \mathcal{A})\)</span></a></li>
<li class="chapter" data-level="2.3.3" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#lespace-probabilisé-omega-mathcala-mathbbp"><i class="fa fa-check"></i><b>2.3.3</b> L’espace probabilisé <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#indépendance"><i class="fa fa-check"></i><b>2.4</b> Indépendance</a></li>
<li class="chapter" data-level="2.5" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#probabilités-conditionnelles"><i class="fa fa-check"></i><b>2.5</b> Probabilités conditionnelles</a></li>
<li class="chapter" data-level="2.6" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#formule-des-probabilités-totales"><i class="fa fa-check"></i><b>2.6</b> Formule des probabilités totales</a></li>
<li class="chapter" data-level="2.7" data-path="dénombrement-et-probabilités.html"><a href="dénombrement-et-probabilités.html#formule-de-bayes"><i class="fa fa-check"></i><b>2.7</b> Formule de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html"><i class="fa fa-check"></i><b>3</b> Variables aléatoires discrètes</a>
<ul>
<li class="chapter" data-level="3.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#définition-et-premières-propriétés"><i class="fa fa-check"></i><b>3.1</b> Définition et premières propriétés</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#définition"><i class="fa fa-check"></i><b>3.1.1</b> Définition</a></li>
<li class="chapter" data-level="3.1.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#loi-dune-variable-aléatoire-discrète"><i class="fa fa-check"></i><b>3.1.2</b> Loi d’une variable aléatoire discrète</a></li>
<li class="chapter" data-level="3.1.3" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#calcul-de-mathbbpxin-b"><i class="fa fa-check"></i><b>3.1.3</b> Calcul de <span class="math inline">\(\mathbb{P}(X\in B)\)</span></a></li>
<li class="chapter" data-level="3.1.4" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#fonction-de-répartition"><i class="fa fa-check"></i><b>3.1.4</b> Fonction de répartition</a></li>
<li class="chapter" data-level="3.1.5" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#quantiles"><i class="fa fa-check"></i><b>3.1.5</b> Quantiles</a></li>
<li class="chapter" data-level="3.1.6" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#exemples-classiques-de-lois-discrètes"><i class="fa fa-check"></i><b>3.1.6</b> Exemples classiques de lois discrètes</a></li>
<li class="chapter" data-level="3.1.7" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#simulation-dune-variable-aléatoire-réelle"><i class="fa fa-check"></i><b>3.1.7</b> Simulation d’une variable aléatoire réelle</a></li>
<li class="chapter" data-level="3.1.8" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#moments-dune-variable-aléatoire"><i class="fa fa-check"></i><b>3.1.8</b> Moments d’une variable aléatoire</a></li>
<li class="chapter" data-level="3.1.9" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#quelques-inégalités-classiques"><i class="fa fa-check"></i><b>3.1.9</b> Quelques inégalités classiques</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#transformation-dune-variable-aléatoire-discrète"><i class="fa fa-check"></i><b>3.2</b> Transformation d’une variable aléatoire discrète</a></li>
<li class="chapter" data-level="3.3" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#vecteurs-aléatoires"><i class="fa fa-check"></i><b>3.3</b> Vecteurs aléatoires</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#couple-aléatoire-loi-conjointe-lois-marginales"><i class="fa fa-check"></i><b>3.3.1</b> Couple aléatoire : loi conjointe, lois marginales</a></li>
<li class="chapter" data-level="3.3.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#n-uplets-aléatoires"><i class="fa fa-check"></i><b>3.3.2</b> <span class="math inline">\(n-\)</span>uplets aléatoires</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#loi-conditionnelle-mathbbp_xyy_j"><i class="fa fa-check"></i><b>3.4</b> Loi conditionnelle <span class="math inline">\(\mathbb{P}_{X|Y=y_j}\)</span></a></li>
<li class="chapter" data-level="3.5" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#indépendance-de-deux-variables-aléatoires"><i class="fa fa-check"></i><b>3.5</b> Indépendance de deux variables aléatoires</a></li>
<li class="chapter" data-level="3.6" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#covariance-et-coefficient-de-corrélation-de-deux-variables-aléatoires"><i class="fa fa-check"></i><b>3.6</b> Covariance et coefficient de corrélation de deux variables aléatoires</a></li>
<li class="chapter" data-level="3.7" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#espérance-conditionnelle-mathbbeyxx"><i class="fa fa-check"></i><b>3.7</b> Espérance conditionnelle <span class="math inline">\(\mathbb{E}(Y|X=x)\)</span></a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#variance-conditionnelle"><i class="fa fa-check"></i><b>3.7.1</b> Variance conditionnelle</a></li>
<li class="chapter" data-level="3.7.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#somme-de-deux-va-indépendantes-produit-de-convolution-discret"><i class="fa fa-check"></i><b>3.7.2</b> Somme de deux VA indépendantes (produit de convolution discret)</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#annexes"><i class="fa fa-check"></i><b>3.8</b> Annexes</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#inégalité-de-cauchy-schwarz"><i class="fa fa-check"></i><b>3.8.1</b> Inégalité de Cauchy-Schwarz</a></li>
<li class="chapter" data-level="3.8.2" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#théorème-de-fubini-pour-les-séries-doubles"><i class="fa fa-check"></i><b>3.8.2</b> Théorème de Fubini pour les séries doubles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html"><i class="fa fa-check"></i><b>4</b> Variables aléatoires à densité</a>
<ul>
<li class="chapter" data-level="4.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-et-premières-propriétés-1"><i class="fa fa-check"></i><b>4.1</b> Définition et premières propriétés</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-1"><i class="fa fa-check"></i><b>4.1.1</b> Définition</a></li>
<li class="chapter" data-level="4.1.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#loi-dune-variable-aléatoire-à-densité"><i class="fa fa-check"></i><b>4.1.2</b> Loi d’une variable aléatoire à densité</a></li>
<li class="chapter" data-level="4.1.3" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-de-pxin-a"><i class="fa fa-check"></i><b>4.1.3</b> Définition de <span class="math inline">\(p(X\in A)\)</span></a></li>
<li class="chapter" data-level="4.1.4" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#fonction-de-répartition-quantiles"><i class="fa fa-check"></i><b>4.1.4</b> Fonction de répartition, quantiles</a></li>
<li class="chapter" data-level="4.1.5" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#exemples-classiques"><i class="fa fa-check"></i><b>4.1.5</b> Exemples classiques :</a></li>
<li class="chapter" data-level="4.1.6" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#moments-dune-variable-aléatoire-1"><i class="fa fa-check"></i><b>4.1.6</b> Moments d’une variable aléatoire</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#transformation-dune-variable-aléatoire-à-densité"><i class="fa fa-check"></i><b>4.2</b> Transformation d’une variable aléatoire à densité</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-2"><i class="fa fa-check"></i><b>4.2.1</b> Définition</a></li>
<li class="chapter" data-level="4.2.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#théorème-de-transfert-cas-à-densité"><i class="fa fa-check"></i><b>4.2.2</b> Théorème de transfert (cas à densité)</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#vecteurs-aléatoires-1"><i class="fa fa-check"></i><b>4.3</b> Vecteurs aléatoires</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#définition-3"><i class="fa fa-check"></i><b>4.3.1</b> Définition</a></li>
<li class="chapter" data-level="4.3.2" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#loi-jointe-loi-marginales"><i class="fa fa-check"></i><b>4.3.2</b> Loi jointe, loi marginales</a></li>
<li class="chapter" data-level="4.3.3" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#loi-conditionnelle-mathcallyx"><i class="fa fa-check"></i><b>4.3.3</b> Loi conditionnelle <span class="math inline">\(\mathcal{L}(Y|X)\)</span></a></li>
<li class="chapter" data-level="4.3.4" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#loi-dun-couple-de-va-indépendantes"><i class="fa fa-check"></i><b>4.3.4</b> Loi d’un couple de VA indépendantes</a></li>
<li class="chapter" data-level="4.3.5" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#espérance-matrice-de-variance-covariance"><i class="fa fa-check"></i><b>4.3.5</b> Espérance, matrice de variance-covariance</a></li>
<li class="chapter" data-level="4.3.6" data-path="variables-aléatoires-à-densité.html"><a href="variables-aléatoires-à-densité.html#espérance-conditionnelle-variance-conditionnelle"><i class="fa fa-check"></i><b>4.3.6</b> Espérance conditionnelle, variance conditionnelle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="convergence.html"><a href="convergence.html"><i class="fa fa-check"></i><b>5</b> Convergence</a>
<ul>
<li class="chapter" data-level="5.1" data-path="convergence.html"><a href="convergence.html#différents-modes-de-convergence"><i class="fa fa-check"></i><b>5.1</b> Différents modes de convergence</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="convergence.html"><a href="convergence.html#convergence-en-probabilité"><i class="fa fa-check"></i><b>5.1.1</b> Convergence en probabilité</a></li>
<li class="chapter" data-level="5.1.2" data-path="convergence.html"><a href="convergence.html#convergence-dans-les-espaces-lp"><i class="fa fa-check"></i><b>5.1.2</b> Convergence dans les espaces <span class="math inline">\(L^p\)</span></a></li>
<li class="chapter" data-level="5.1.3" data-path="convergence.html"><a href="convergence.html#convergence-en-loi"><i class="fa fa-check"></i><b>5.1.3</b> Convergence en loi</a></li>
<li class="chapter" data-level="5.1.4" data-path="convergence.html"><a href="convergence.html#convergence-presque-sûre-hors-prgramme"><i class="fa fa-check"></i><b>5.1.4</b> Convergence presque-sûre (hors-prgramme ?)</a></li>
<li class="chapter" data-level="5.1.5" data-path="convergence.html"><a href="convergence.html#liens-entre-les-différents-modes-de-convergence"><i class="fa fa-check"></i><b>5.1.5</b> Liens entre les différents modes de convergence</a></li>
<li class="chapter" data-level="5.1.6" data-path="convergence.html"><a href="convergence.html#approximations"><i class="fa fa-check"></i><b>5.1.6</b> Approximations</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="convergence.html"><a href="convergence.html#loi-faible-des-grands-nombres-loi-forte-des-grands-nombres"><i class="fa fa-check"></i><b>5.2</b> Loi Faible des Grands Nombres, Loi Forte des Grands Nombres</a></li>
<li class="chapter" data-level="5.3" data-path="convergence.html"><a href="convergence.html#théorème-central-limite-tcl"><i class="fa fa-check"></i><b>5.3</b> Théorème Central Limite (TCL)</a></li>
<li class="chapter" data-level="5.4" data-path="convergence.html"><a href="convergence.html#variantes-du-tcl-hors-programme"><i class="fa fa-check"></i><b>5.4</b> Variantes du TCL (hors-programme)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html"><i class="fa fa-check"></i><b>6</b> Statistique descriptive</a>
<ul>
<li class="chapter" data-level="6.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#vocabulaire"><i class="fa fa-check"></i><b>6.1</b> Vocabulaire</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#population-individus-échantillon"><i class="fa fa-check"></i><b>6.1.1</b> Population, individus, échantillon</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#analyse-statistique-univariée"><i class="fa fa-check"></i><b>6.2</b> Analyse statistique univariée</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#notion-de-série-statistique-univariée"><i class="fa fa-check"></i><b>6.2.1</b> Notion de série statistique univariée</a></li>
<li class="chapter" data-level="6.2.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#indicateurs-dune-série-statistique-univariée"><i class="fa fa-check"></i><b>6.2.2</b> Indicateurs d’une série statistique univariée</a></li>
<li class="chapter" data-level="6.2.3" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#représentations-graphiques"><i class="fa fa-check"></i><b>6.2.3</b> Représentations graphiques</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#analyse-statistique-bivariée"><i class="fa fa-check"></i><b>6.3</b> Analyse statistique bivariée</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#notion-de-série-statistique-bivariée"><i class="fa fa-check"></i><b>6.3.1</b> Notion de série statistique bivariée</a></li>
<li class="chapter" data-level="6.3.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#indicateurs-propres-à-lanalyse-statistique-multivariée"><i class="fa fa-check"></i><b>6.3.2</b> Indicateurs propres à l’analyse statistique multivariée</a></li>
<li class="chapter" data-level="6.3.3" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#nuage-de-points"><i class="fa fa-check"></i><b>6.3.3</b> Nuage de points</a></li>
<li class="chapter" data-level="6.3.4" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#ajustement-des-moindres-carrés"><i class="fa fa-check"></i><b>6.3.4</b> Ajustement des moindres carrés</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html"><i class="fa fa-check"></i><b>7</b> Statistique inférentielle</a>
<ul>
<li class="chapter" data-level="7.1" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#estimation"><i class="fa fa-check"></i><b>7.1</b> Estimation</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#premières-définitions"><i class="fa fa-check"></i><b>7.1.1</b> Premières définitions</a></li>
<li class="chapter" data-level="7.1.2" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#convergence-dun-estimateur"><i class="fa fa-check"></i><b>7.1.2</b> Convergence d’un estimateur</a></li>
<li class="chapter" data-level="7.1.3" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#exemples-classiques-1"><i class="fa fa-check"></i><b>7.1.3</b> Exemples classiques</a></li>
<li class="chapter" data-level="7.1.4" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#méthodes-de-construction-des-estimateurs"><i class="fa fa-check"></i><b>7.1.4</b> Méthodes de construction des estimateurs</a></li>
<li class="chapter" data-level="7.1.5" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#compléments-hors-programme"><i class="fa fa-check"></i><b>7.1.5</b> Compléments (hors-programme)</a></li>
<li class="chapter" data-level="7.1.6" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#estimation-des-coefficients-dune-régression-linéaire"><i class="fa fa-check"></i><b>7.1.6</b> Estimation des coefficients d’une régression linéaire</a></li>
<li class="chapter" data-level="7.1.7" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#intervalles-de-confiance"><i class="fa fa-check"></i><b>7.1.7</b> Intervalles de confiance</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#tests-statistiques"><i class="fa fa-check"></i><b>7.2</b> Tests statistiques</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#définition-et-principes"><i class="fa fa-check"></i><b>7.2.1</b> Définition et principes</a></li>
<li class="chapter" data-level="7.2.2" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#tests-unilatéraux-tests-bilatéraux"><i class="fa fa-check"></i><b>7.2.2</b> Tests unilatéraux, tests bilatéraux</a></li>
<li class="chapter" data-level="7.2.3" data-path="statistique-inférentielle.html"><a href="statistique-inférentielle.html#exemples"><i class="fa fa-check"></i><b>7.2.3</b> Exemples</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="méthodologie.html"><a href="méthodologie.html"><i class="fa fa-check"></i><b>8</b> Méthodologie</a>
<ul>
<li class="chapter" data-level="8.1" data-path="méthodologie.html"><a href="méthodologie.html#convergence-1"><i class="fa fa-check"></i><b>8.1</b> Convergence</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="exercices.html"><a href="exercices.html"><i class="fa fa-check"></i><b>9</b> Exercices</a>
<ul>
<li class="chapter" data-level="9.1" data-path="exercices.html"><a href="exercices.html#dénombrement-et-probabilités-1"><i class="fa fa-check"></i><b>9.1</b> Dénombrement et probabilités</a></li>
<li class="chapter" data-level="9.2" data-path="exercices.html"><a href="exercices.html#annales-des-oraux"><i class="fa fa-check"></i><b>9.2</b> Annales des oraux</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="exercices.html"><a href="exercices.html#interne-2016"><i class="fa fa-check"></i><b>9.2.1</b> Interne, 2016</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Cours de probabilités-statistiques pour le concours interne d’administrateur Insee</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="variables-aléatoires-discrètes" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapitre 3</span> Variables aléatoires discrètes<a href="variables-aléatoires-discrètes.html#variables-aléatoires-discrètes" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Supposons que vous jouiez avec un ami au jeu suivant. Votre ami lance un dé équilibré et vous convenez des règles suivantes :</p>
<ul>
<li>si le dé tombe sur <span class="math inline">\(1\)</span> ou <span class="math inline">\(2\)</span>, vous donnez <span class="math inline">\(3\)</span> euros à votre ami ;</li>
<li>si le dé tombe sur <span class="math inline">\(2\)</span> ou <span class="math inline">\(3\)</span>, votre ami vous donne <span class="math inline">\(3\)</span> euros ;</li>
<li>si le dé tombe sur <span class="math inline">\(5\)</span> ou <span class="math inline">\(6\)</span>, aucun de vous deux ne gagne ni ne perd d’argent.</li>
</ul>
<p>On note <span class="math inline">\(X\)</span> votre gain algébrique. Alors, <span class="math inline">\(X\)</span> est un nombre aléatoire dont les valeurs possibles sont <span class="math inline">\(-3, 3\)</span> et <span class="math inline">\(0\)</span>. L’expérience aléatoire qui consiste à lancer ce dé et à relever son numéro peut être modélisée par l’univers probabilisé <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span>, où <span class="math inline">\(\Omega=\{1,2,3,4,5,6\}\)</span>, <span class="math inline">\(\mathcal{A}=\mathcal{P}(\Omega)\)</span> et <span class="math inline">\(\mathbb{P}\)</span> est la mesure équirépartie : <span class="math inline">\(\forall\omega\in\Omega, \,\mathbb{P}(\{\omega\})=\frac{1}{6}\)</span>. Dans ce cas, votre gain <span class="math inline">\(X\)</span> peut être vu comme une application</p>
<p><span class="math display">\[X:\Omega=\{1,2,3,4,5,6\}\longrightarrow\{-3, 0, 3\}\]</span>
définie par</p>
<p><span class="math display">\[X(1)=X(2)=-3\]</span>
<span class="math display">\[X(3)=X(4)=3\]</span>
<span class="math display">\[X(5)=X(6)=0\]</span></p>
<p>Imaginons maintenant qu’un ami commun prenne connaissance de votre gain à ce jeu, mais sans prendre connaissance du jeu lui-même (ni les issues possibles, ni les règles définissant le gain), et encore moins du numéro du dé que vous avez obtenu. De son point de vue, l’expérience qui aboutira à l’observation de votre gain sera également une expérience aléatoire, cependant l’espace probabilisé la modélisant ne sera plus <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span> mais plutôt <span class="math inline">\((\Omega_X, \mathcal{A}_X, \mathbb{P}_X)\)</span>, où</p>
<p><span class="math display">\[\Omega_X=X(\Omega)=\{-3, 0, 3\}\]</span>
<span class="math display">\[\mathcal{A}_X=\mathcal{P}(\{-3,0,3\})\]</span>
<span class="math display">\[\mathbb{P}_X \text{ donnée par } \mathbb{P}_X(\{-3\})=\mathbb{P}_X(\{0\})=\mathbb{P}_X(\{0\})=\frac{1}{3}\]</span>
Dans ce genre de situation, on dit que <span class="math inline">\(X\)</span> est une <strong>variable aléatoire</strong>, et on appelle <strong>loi de <span class="math inline">\(X\)</span></strong> la mesure de probabilité <span class="math inline">\(\mathbb{P}_X\)</span>. D’une certaine façon, la variable aléatoire <span class="math inline">\(X\)</span> a donc transformé l’espace probabilisé de départ <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span> en un nouvel espace probabilisé <span class="math inline">\((\Omega_X, \mathcal{A}_X,\mathbb{P}_X)\)</span>. Dans la plupart des expériences aléatoires, on cherchera à mesurer une grandeur (un gain à un jeu de hasard, la durée d’attente à un feu rouge, le nombre de coquilles dans un texte, le nombre buts marqués dans un match de foot, etc.), si bien que ce qui nous intéressera ne sera pas tant l’espace de départ <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span> mais plutôt son image <span class="math inline">\((\Omega_X, \mathcal{A}_X, \mathbb{P}_X)\)</span> par cette grandeur.</p>
<p>Cela a une conséquence pratique lorsqu’on résout un exercice de probabilités mettant en scène une variable aléatoire <span class="math inline">\(X\)</span> : sauf dans des cas très simples, on n’explicitera pas <span class="math inline">\(\Omega\)</span> qu’on supposera donné (un peu à la façon de votre ami commun qui est aveugle aux numéros du dé) mais on cherchera plutôt à déterminer <span class="math inline">\(X(\Omega)\)</span>. La tribu <span class="math inline">\(\mathcal{A}_X\)</span> sera, elle, généralement passée sous silence (en pratique, on aura souvent <span class="math inline">\(\mathcal{A}_X=\mathcal{P}(X(\Omega)\)</span>). Enfin, on accordera toute l’attention sur la <strong>loi de <span class="math inline">\(X\)</span></strong>, autrement dit sur la mesure de probabilité <span class="math inline">\(\mathbb{P}_X\)</span>, à partir de laquelle on pourra calculer différents indicateurs (espérance, variance, quantiles etc.).</p>
<p>Ce chapitre s’intéresse aux <strong>variables alétoires discrètes</strong>, autrement dit les variables aléatoires dont les images forment un ensemble discret, soit parce que cet ensemble est <strong>fini</strong>, soit parce-qu’il est <strong>infini</strong> mais <strong>dénombrable</strong> (comme l’ensemble des entiers naturels ou des nombres rationnels). Le chapitre suivant traitera des <strong>variables aléatoires continues</strong> : ce sont les variables aléatoires dont l’ensemble des valeurs est <strong>continu</strong>, comme par exemple l’ensemble des nombres réels.</p>
<div id="définition-et-premières-propriétés" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Définition et premières propriétés<a href="variables-aléatoires-discrètes.html#définition-et-premières-propriétés" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="définition" class="section level3 hasAnchor" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Définition<a href="variables-aléatoires-discrètes.html#définition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="defbox def">
<center>
<strong>Variables aléatoires discrètes</strong>
</center>
<p>Soit <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span> un espace probabilisé. On appelle <strong>variable aléatoire discrète (réelle)</strong> sur <span class="math inline">\(\Omega\)</span> toute application</p>
<p><span class="math display">\[X:\Omega\longrightarrow F=X(\Omega)\subset\mathbb{R}\]</span>
où <span class="math inline">\(F=X(\Omega)\)</span> est :</p>
<ul>
<li>soit un ensemble fini : <span class="math inline">\(F=\{x_1,\dots, x_n\}\)</span></li>
<li>soit un ensemble infini dénombrable : <span class="math inline">\(F=\{x_n,\,n\in\mathbb{N}\}\)</span></li>
</ul>
<p>On dira alors que <span class="math inline">\(F\)</span> est au <em>plus dénombrable</em>, et on utilisera souvent la notation unifiée</p>
<p><span class="math display">\[F=X(\Omega)=\{x_i, \, i\in I\}, \, I\subset\mathbb{N}\]</span></p>
<p>De plus, pour tout <span class="math inline">\(\omega\in\Omega\)</span>, on dira que <span class="math inline">\(X(\omega)\)</span> est une <strong>réalisation</strong> de <span class="math inline">\(X\)</span>.</p>
</div>
<p></p>
<p><strong>Exemples. i.</strong> On reprend l’exemple des deux dés équilibrés présenté dans le chapitre précédent :</p>
<center>
<img src="images/somme_des.PNG" /><!-- -->
</center>
<p>L’expérience aléatoire associée à cette expérience aléatoire est modélisée par l’espace probabilisé <span class="math inline">\((\Omega, \mathcal{A}, \mathbb{P})\)</span>, avec <span class="math inline">\(\Omega=\{1,2,3,4,5,6\}^2\)</span>, <span class="math inline">\(\mathcal{A}=\mathcal{P}(\Omega)\)</span> et <span class="math inline">\(\mathbb{P}\)</span> la mesure de probabilité équirépartie.</p>
<p>La somme <span class="math inline">\(S\)</span> des deux numéros obtenus est une variable aléatoire</p>
<p><span class="math display">\[X:\Omega \longrightarrow X(\Omega)\]</span>
définie, pour <span class="math inline">\(\omega=(\omega_1, \omega_2)\in\Omega\)</span>, par <span class="math inline">\(S(\omega)=\omega_1+\omega_2\)</span>. On a</p>
<p><span class="math display">\[X(\Omega)=[\![2;12]\!]\]</span>
où pour tout couple d’entiers <span class="math inline">\((a,b)\)</span> tel que <span class="math inline">\(a\leq b\)</span>, <span class="math inline">\([\![a;b]\!]\)</span> désigne l’ensemble de tous les entiiers entre <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> (notation que nous réutiliserons régulièrement dans ce cours).</p>
<p>Ainsi, <span class="math inline">\(X(\Omega)\)</span> est fini, et donc <span class="math inline">\(X\)</span> est une variable aléatoire discrète.</p>
<p></p>
<p><strong>ii.</strong> Une urne contient <span class="math inline">\(4\)</span> boules blanches et <span class="math inline">\(6\)</span> boules noires. On tire une boule au hasard. Si elle est noire on s’arrête là, sinon on remet la boule dans l’urne, et on recommence jusqu’à obtenir une boule noire. On note <span class="math inline">\(N\)</span> le nombre de boules tirées. <span class="math inline">\(N\)</span> est une variable aléatoire, prenant des valeurs entières et non majorée. Ainsi <span class="math inline">\(N(\Omega)=\mathbb{N}^*\)</span> et <span class="math inline">\(N\)</span> est discrète.</p>
<p><strong>iii.</strong> Dans une file d’attente, on note <span class="math inline">\(T\)</span> le temps de passage entre deux clients. <span class="math inline">\(T\)</span> est une variable aléatoire à valeurs dans <span class="math inline">\(\mathbb{R}_+\)</span>. Elle n’est donc pas discrète, mais continue.</p>
</div>
<div id="loi-dune-variable-aléatoire-discrète" class="section level3 hasAnchor" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Loi d’une variable aléatoire discrète<a href="variables-aléatoires-discrètes.html#loi-dune-variable-aléatoire-discrète" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pour une variable aléatoire discrète (réelle) définie sur un espace probabilisé <span class="math inline">\(\left(\Omega, \, \mathcal{P}(\Omega), \, \mathbb{P}\right)\)</span>, on peut définir la <em>loi de <span class="math inline">\(X\)</span></em>.</p>
<div class="thmbox def">
<p><strong>Théorème (Loi d’une variable aléatoire discrète).</strong> Soit <span class="math inline">\(X\)</span> une variable aléatoire discrète définie sur un espace probabilisé <span class="math inline">\((\Omega,\, \mathcal{P}(\Omega),\, \mathbb{P})\)</span>, à valeurs dans <span class="math inline">\(F=X(\Omega)\)</span>. Sur l’espace probabilisable <span class="math inline">\((F,\, \mathcal{P}(F))\)</span> on peut alors définir une probabilité <span class="math inline">\(\mathbb{P}_X\)</span> en posant, pour tout <span class="math inline">\(x_i\)</span> dans <span class="math inline">\(F\)</span> :</p>
<p><span class="math display">\[\mathbb{P}_X(\{x_i\})=\mathbb{P}(X^{-1}(\{x_i\}))\]</span>
On notera plus simplement <span class="math inline">\((X=x_i)\)</span> l’événement <span class="math inline">\(X^{-1}(\{x_i\})\)</span>.</p>
<p>La loi de <span class="math inline">\(X\)</span> est donc définie par :</p>
<ul>
<li>la donnée de <span class="math inline">\(F=X(\Omega)\)</span>, i.e. l’ensemble de toutes les valeurs prises par <span class="math inline">\(X\)</span>. Cet ensemble s’appelle le <strong>support</strong> de la loi de <span class="math inline">\(X\)</span> ;</li>
<li>la donnée, pour tout <span class="math inline">\(x_i\)</span> dans <span class="math inline">\(X(\Omega)\)</span>, de la probabilité <span class="math inline">\(\mathbb{P}(X=x_i)\)</span>.</li>
</ul>
<p>Cette loi est unique à des événements de probabilité nulle près.</p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Admis.</p>
<p></p>
<p></p>
<p><strong>Remarques. i.</strong> On définit <span class="math inline">\(\mathbb{P}_X\)</span> à partir des <span class="math inline">\(\mathbb{P}_X(\{x_i\})\)</span> :</p>
<ul>
<li><p>les <span class="math inline">\(\{x_i\}\)</span> sont des éléments de (la tribu) <span class="math inline">\(\mathcal{P}(F)\)</span>, donc <span class="math inline">\(\mathbb{P}_X\)</span> est bien une mesure de probabilité sur l’espace probabilisable <span class="math inline">\((F,\,\mathcal{P}(F))\)</span> ;</p></li>
<li><p>par ailleurs, <span class="math inline">\(\mathbb{P}_X(\{x_i\})\)</span> est définie par <span class="math inline">\(\mathbb{P}(X^{-1}(\{x_i\}))\)</span> et <span class="math inline">\(X^{-1}(\{x_i\})\)</span> est un élément de la tribu <span class="math inline">\(\mathcal{P}(\Omega)\)</span> sur laquelle est définie la probabilité <span class="math inline">\(\mathbb{P}\)</span>, donc cette définition a bien un sens.</p></li>
</ul>
<p></p>
<p><strong>ii.</strong> La loi de <span class="math inline">\(X\)</span> est définie par la donnée des couples <span class="math inline">\((x_i, p_i)\)</span> tels que <span class="math inline">\(x_i\in X(\Omega)\)</span> et <span class="math inline">\(p_i=\mathbb{P}(X=x_i)\)</span>. Dans cette définition, on peut se restreindre aux couples <span class="math inline">\((x_i, p_i)\)</span> pour lesquels <span class="math inline">\(p_i&gt;0\)</span>. La loi de <span class="math inline">\(X\)</span> n’est donc pas unique au sens strict du terme, mais elle l’est bien à des événements élémentaires de probabilité nulle près. Par exemple, dans l’exercice 2 du sujet du concours interne de 2012 (exercice 2.7. de ce cours) la variable aléatoire <span class="math inline">\(X\)</span> prend <em>a priori</em> les valeurs <span class="math inline">\(0,1,2,3\)</span>, mais <em>a posteriori</em> on a <span class="math inline">\(\mathbb{P}(X=0)=0\)</span>, donc on peut enlever <span class="math inline">\(0\)</span> de <span class="math inline">\(X(\Omega)\)</span>.</p>
<p><strong>Exemple. i.</strong> On reprend l’exemple sur la somme des deux dés. On a vu que <span class="math inline">\(X(\Omega)=[\![2;12]\!]\)</span>. On calcule maintenant toutes les probablités <span class="math inline">\(\mathbb{P}(X=i)\)</span> pour <span class="math inline">\(i\in [\![2;12]\!]\)</span>. On montre en fait facilement que</p>
<p><span class="math display">\[\forall i\in [\![2;6]\!],\, \mathbb{P}(X=i)=\frac{i-1}{36}\]</span>
<span class="math display">\[\forall i\in [\![7;12]\!], \, \mathbb{P}(X=i)=\frac{13-i}{36}\]</span>
On peut vérifier la cohérence de ce résultat :</p>
<p><span class="math display">\[\begin{align}
\sum\limits_{i=2}^{6}\frac{i-1}{36}+\sum\limits_{i=7}^{12}\frac{13-i}{36} &amp;= \sum\limits_{i=1}^{5}\frac{i}{36}+\sum\limits_{i=1}^{6}\frac{i}{36} \\
&amp;= \frac{2\sum\limits_{i=1}^5 i +6}{36} \\
&amp;= \frac{6\times 5+6}{36} \\
&amp;= 1 \\
\end{align}\]</span></p>
<p></p>
<p><strong>ii.</strong> On reprend l’exemple de l’urne contenant <span class="math inline">\(4\)</span> boules blanches et <span class="math inline">\(6\)</span> boules noires. On répète des tirages successifs avec remise jusqu’à obtenir une boule noire, et <span class="math inline">\(N\geq 1\)</span> désigne le nombre de tirages. Pour <span class="math inline">\(n\in\mathbb{N}^*\)</span>, l’événement <span class="math inline">\((N=n)\)</span> est réalisé lorsque les <span class="math inline">\(n-1\)</span> premiers tirages amènent une boule blanche et le tirage numéro <span class="math inline">\(n\)</span> amène une boule noire. Les tirages étant effectués avec remise ils sont indépendants, donc</p>
<p><span class="math display">\[\mathbb{P}(N=n)=\left(\frac{2}{5}\right)^{n-1}\frac{3}{5}\]</span>
ce qui définit complètement la loi de <span class="math inline">\(N\)</span>.</p>
<p></p>
<p><strong>Remarques. i.</strong> On peut vérifier de façon immédiate que la série <span class="math inline">\(\sum\limits_{n}\mathbb{P}(N=n)\)</span> est convergente de somme <span class="math inline">\(1\)</span> : c’est, au facteur <span class="math inline">\(\frac{3}{5}\)</span> près, une série géométrique de raison <span class="math inline">\(\frac{2}{5}\in]-1;1[\)</span>, donc elle converge vers <span class="math inline">\(\frac{3}{5}\frac{1}{1-\frac{2}{5}}=1\)</span>.</p>
<p></p>
<p><strong>ii.</strong> <span class="math inline">\(N\)</span> suit une <em>loi géométrique</em> de paramètre <span class="math inline">\(p=\frac{3}{5}\)</span> (voir un peu plus loin la définition des lois géométriques).</p>
</div>
<div id="calcul-de-mathbbpxin-b" class="section level3 hasAnchor" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Calcul de <span class="math inline">\(\mathbb{P}(X\in B)\)</span><a href="variables-aléatoires-discrètes.html#calcul-de-mathbbpxin-b" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="thmbox def">
<p><strong>Théorème (calcul de <span class="math inline">\(\mathbb{P}(X\in B)\)</span>).</strong> Soit <span class="math inline">\(X:\Omega\longrightarrow X(\Omega)\)</span> une variable aléatoire discrète (réelle), avec</p>
<p><span class="math display">\[X(\Omega)=\{x_i,\,\,i\in I\} \text{, où } I\subset\mathbb{N}\]</span></p>
<p>Pour <span class="math inline">\(B\in\mathcal{P}(X(\Omega))\)</span>, on note <span class="math inline">\((X\in B)\)</span> l’événement</p>
<p><span class="math display">\[(X\in B)=X^{-1}(B)=\left\{\omega\in\Omega, X(\omega)\in B\right\}\]</span>
La probabilité d’un tel événement se calcule ainsi :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X\in B)&amp;=\mathbb{P}\left(\bigsqcup\limits_{i\in I/ x_i\in B} (X=x_i)\right) \\
&amp;=\sum\limits_{i\in I/ x_i\in B}\mathbb{P}(X=x_i)
\end{align}\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Les événements <span class="math inline">\((X=x_i)\)</span> tels que <span class="math inline">\(i\in I, x_i\in B\)</span> forment une partition de l’événement <span class="math inline">\((X\in B)\)</span>. On conclut en utilisant le fait qu’une probabilité d’une réunion disjointe d’événements <span class="math inline">\(A_i\)</span> est la somme des probablités <span class="math inline">\(\mathbb{P}(A_i)\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Exemple.</strong> Dans l’exemple précédent de l’urne, on cherche maintenant la probabilité que <span class="math inline">\(X\)</span> soit impaire. On a</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X\in 2\mathbb{N}+1) &amp;=  \sum\limits_{n=0}^{\infty}\mathbb{P}(X=2n+1) \\
&amp;=\sum\limits_{n=0}^{\infty}\left(\frac{2}{5}\right)^{2n}\frac{3}{5} \\
&amp;=\frac{3}{5}\sum\limits_{n=0}^{\infty}\left(\frac{4}{25}\right)^{n} \\
&amp;=\frac{3}{5}\frac{1}{1-\frac{4}{25}} \\
&amp;=\frac{5}{7} \\
\end{align}\]</span></p>
</div>
<div id="fonction-de-répartition" class="section level3 hasAnchor" number="3.1.4">
<h3><span class="header-section-number">3.1.4</span> Fonction de répartition<a href="variables-aléatoires-discrètes.html#fonction-de-répartition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La fonction de répartition d’une variable aléatoire discrète (ou même continue comme on le verra dans le prochain chapitre) réelle est définie par la donnée des probabilités <span class="math inline">\(\mathbb{P}(X\leq x)=\mathbb{P}(X\in ]-\infty\,;\,x])\)</span> :</p>
<div class="defbox def">
<center>
<strong>Fonction de répartition</strong>
</center>
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire discrète (réelle). On appelle <strong>fonction de répartition de <span class="math inline">\(X\)</span></strong> la fonction <span class="math inline">\(F_X\)</span> définie sur <span class="math inline">\(\mathbb{R}\)</span> par</p>
<p><span class="math display">\[\forall x\in\mathbb{R},\,F_X(x)=\mathbb{P}(X\leq x)\]</span></p>
<p>Quand le contexte le permet, on la note plus simplement <span class="math inline">\(F\)</span>.</p>
<p></p>
<p><strong>Note :</strong> cette définition de la fonction de répartition est valable pour toutes les variables aléatoires, qu’elles suivent ou non une loi discrète.</p>
</div>
<p></p>
<p><strong>Calcul pratique.</strong> On note <span class="math inline">\(x_1,\dots x_n\)</span> (resp. <span class="math inline">\(x_1,\dots, x_n, \dots\)</span>) les éléments de <span class="math inline">\(X(\Omega)\)</span> rangés dans l’ordre croissant si <span class="math inline">\(X(\Omega)\)</span> est fini (resp. infini dénombrable).</p>
<p>Soient <span class="math inline">\(x\in\mathbb{R}\)</span> et <span class="math inline">\(i_0\)</span> le plus grand entier tel que <span class="math inline">\(x_{i_0}\leq x\)</span>. Alors, d’après le théorème précédent :</p>
<p><span class="math display">\[F(x)=\sum\limits_{i=1}^{i_0}\mathbb{P}(X=x_i)\]</span></p>
<p></p>
<p><strong>Exemple.</strong> On considère une variable aléatoire <span class="math inline">\(X\)</span> telle que <span class="math inline">\(X(\Omega)=\{1,2,3,4\}\)</span> et <span class="math inline">\(\mathbb{P}(X=i)\)</span> est proportionnel à <span class="math inline">\(i\)</span>.</p>
<p>On souhaite déterminer sa fonction de répartition.</p>
<p></p>
<p>On note <span class="math inline">\(\alpha=\mathbb{P}(X=1)\)</span>. On a donc <span class="math display">\[\mathbb{P}(X=i)=\alpha\, i\]</span></p>
<p>On a donc <span class="math inline">\(\alpha\sum\limits_{i=1}^4 i=1\)</span>, soit <span class="math inline">\(\alpha=\frac{1}{10}\)</span> et donc</p>
<p><span class="math display">\[\forall i\in [\![1;4]\!],\, \mathbb{P}(X=i)=\frac{i}{10}\]</span>
La fonction de répartition <span class="math inline">\(F\)</span> de <span class="math inline">\(X\)</span> est alors donnée par</p>
<p><span class="math display">\[F(x)=\left \{
\begin{array}{lcl}
0&amp;\text{ si }&amp; x&lt;1 \\
\frac{1}{10}&amp;\text{ si }&amp; 1\leq x&lt;2 \\
\frac{3}{10}&amp;\text{ si }&amp; 2\leq x&lt;3 \\
\frac{3}{5}&amp;\text{ si }&amp; 3\leq x&lt;4 \\
1&amp;\text{ si }&amp; x\geq 4 \\
\end{array}
\right.\]</span></p>
<div class="thmbox def">
<center>
<strong>Propriétés des fonctions de répartition</strong>
</center>
<p></p>
<p>Soit <span class="math inline">\(F\)</span> la fonction de répartition d’une variable aléatoire réelle (discrète ou non). Alors :</p>
<p><strong>i.</strong> <span class="math inline">\(F\)</span> est une fonction croissante sur <span class="math inline">\(\mathbb{R}\)</span></p>
<p><strong>ii.</strong> <span class="math inline">\(F\)</span> est continue à droite</p>
<p><strong>iii.</strong> <span class="math inline">\(\lim\limits_{x\to -\infty}F(x)=0\)</span></p>
<p><strong>iv.</strong> <span class="math inline">\(\lim\limits_{x\to +\infty}F(x)=1\)</span></p>
<p></p>
<p><strong>Note :</strong> ces propriétés résultent directement de la défintion précédente, et sont donc vraies pour toutes les variables aléatoires, qu’elles soient discrètes ou non.</p>
</div>
<p></p>
<p><strong>Démonstration.</strong> On note <span class="math inline">\(X\)</span> une variable aléatoire réelle discrète ayant <span class="math inline">\(F\)</span> pour fonction de répartition.</p>
<p></p>
<p><strong>i.</strong> Soient <span class="math inline">\(x,y\)</span> deux réels tels que <span class="math inline">\(x\leq y\)</span>. Alors l’événement <span class="math inline">\(\{X\leq x\}\)</span> est inclus dans l’événement <span class="math inline">\(\{X\leq y\}\)</span>. Par croissance des probabilités on a donc <span class="math inline">\(\mathbb{P}(X\leq x)\leq\mathbb{P}(X\leq y)\)</span>, i.e. <span class="math inline">\(F(x)\leq F(y)\)</span>. On en déduit que <span class="math inline">\(F\)</span> est croissante.</p>
<p></p>
<p><strong>ii.</strong> Soit <span class="math inline">\(x\)</span> un réel. Les événements <span class="math inline">\(\left\{X\in\left]-\infty\,;\,x+\frac{1}{n}\right]\right\}\)</span> forment une suite décroissante (par rapport à <span class="math inline">\(n\)</span>) pour l’inclusion, donc d’après la propriété de continuité décroissante des probabilités, on a</p>
<p><span class="math display">\[\mathbb{P}\left(\bigcap_{n=1}^{\infty}\left\{X\in\left]-\infty\,;\,x+\frac{1}{n}\right]\right\}\right)=\lim\limits_{n\to\infty}\mathbb{P}\left(X\in\left]-\infty\,;\,x+\frac{1}{n}\right]\right)\]</span></p>
<p>i.e.</p>
<p><span class="math display">\[\mathbb{P}\left(X\in \bigcap_{n=1}^{\infty}\left]-\infty\,;\,x+\frac{1}{n}\right]\right)=\lim\limits_{n\to\infty}\mathbb{P}\left(X\in\left]-\infty\,;\,x+\frac{1}{n}\right]\right)\]</span></p>
<p>Or, <span class="math inline">\(\bigcap\limits_{n=1}^{\infty}\left]-\infty\,;\,x+\frac{1}{n}\right]=]-\infty ; x]\)</span>, donc le terme de gauche est égal à <span class="math inline">\(\mathbb{P}(X\leq x)=F(x)\)</span>. Par ailleurs le terme de droite est égal à <span class="math inline">\(\lim\limits_{n\to\infty}F\left(x+\frac{1}{n}\right)\)</span>, et donc :</p>
<p><span class="math display">\[F(x)=\lim\limits_{n\to\infty}F\left(x+\frac{1}{n}\right)\]</span>
ce qui traduit exactement la continuité à droite de <span class="math inline">\(F\)</span>.</p>
<p></p>
<p><strong>iii.</strong> La suite d’événements <span class="math inline">\(\left\{X\leq -n\right\}_n\)</span> est décroissante, donc d’après la propriété de continuité décroissante</p>
<p><span class="math display">\[\begin{align}
\lim\limits_{n\to\infty}F(-n)&amp;=\mathbb{P}\left(\bigcap\limits_{n=0}^{\infty}\{X\leq -n\}\right) \\
&amp;=\mathbb{P}(\emptyset) \\
&amp;=0 \\
\end{align}\]</span></p>
<p>Par croissance de <span class="math inline">\(F\)</span>, on en déduit que <span class="math inline">\(\lim\limits_{x\to -\infty}F(x)=0\)</span>.</p>
<p></p>
<p><strong>iv.</strong> On utilise exactement le même raisonnement avec la suite croissante <span class="math inline">\(\left\{X\geq n\right\}_n\)</span>.</p>
<p></p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Remarque.</strong> L’hypothèse d’une loi discrète n’étant utilisée nulle part dans cette démonstration, ces propriétés sont donc effectivement vraies pour toutes les lois de probabilités, discrètes ou non.</p>
<p>Nous avons montré que les fonctions de répartition (de lois discrètes ou non) étaient toujours continues à droite. Pour avoir une propriété de continuité, il faudrait donc qu’elles soient également continues à gauche (rappel d’analyse : <span class="math inline">\(f\)</span> est continue en <span class="math inline">\(a\)</span> si et seulement si elle est continue à droite et à gauche en <span class="math inline">\(a\)</span>). Mais cette propriété n’est pas vraie en toute généralité :</p>
<div class="thmbox def">
<p>
<strong>Théorème (discontinuités d’une fonction de répartition).</strong> Soit <span class="math inline">\(X\)</span> une variable aléatoire réelle (discrète ou non) définie sur un espace probabilisé <span class="math inline">\((\Omega, \, \mathcal{P}(\Omega), \, \mathbb{P})\)</span>. Pour tout réel <span class="math inline">\(x\)</span> on a :</p>
<p><span class="math display">\[F(x)=F(x^{-})+\mathbb{P}(X=x)\]</span>
où <span class="math inline">\(F(x^{-})=\lim\limits_{t\to x^{-}}F(t)\)</span>.</p>
<p>Autrement dit, la fonction de répartition de <span class="math inline">\(F\)</span> est continue partout, sauf aux points <span class="math inline">\(x\)</span> tels que <span class="math inline">\(p_x:=\mathbb{P}(X=x)&gt;0\)</span> en lesquels elle présente un saut d’amplitude <span class="math inline">\(p_x\)</span>.</p>
<p>En particulier, si <span class="math inline">\(X\)</span> est discrète sa fonction de répartition présente en chaque point <span class="math inline">\(x\)</span> de son support un saut d’amplitude <span class="math inline">\(p_x\)</span>.</p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Pour tout réel <span class="math inline">\(x\)</span> on a</p>
<p><span class="math display">\[F(x)=\mathbb{P}(X&lt;x)+\mathbb{P}(X=x)\]</span></p>
<p>Or, <span class="math inline">\((X&lt;x)=\bigcup\limits_{n=1}^{\infty} \left(X\in\left]-\infty\,;\, x-\frac{1}{n}\right]\right)\)</span>, et les événements <span class="math inline">\(\left(X\in\left]-\infty\,;\, x-\frac{1}{n}\right]\right)_{n\geq 1}\)</span> forment une suite croissante pour l’inclusion, donc par continuité croissante de <span class="math inline">\(\mathbb{P}\)</span> on a :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X&lt;x)&amp;=\mathbb{P}\left(\bigcup_{n=1}^{\infty}\left(X\in\left]-\infty\,;\,x-\frac{1}{n}\right]\right)\right) \\
&amp;=\lim\limits_{n\to\infty}\mathbb{P}\left(X\in\left]-\infty\,;\,x-\frac{1}{n}\right]\right) \\
&amp;=\lim\limits_{n\to\infty}F\left(x-\frac{1}{n}\right) \\
&amp;=F(x^{-})
\end{align}\]</span></p>
<p>ce qui montre l’égalité annoncée et permet de conclure.</p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Remarque.</strong> Les variables aléatoires ayant une fonction de répartition continue sont appelées des <em>lois continues</em>. Elles font l’objet du chapitre suivant (on se restreindra au cas où l’espace d’arrivée est l’ensemble des réels). D’après le résultat précédent, si <span class="math inline">\(X\)</span> est une variable aléatoire de loi continue on a donc <span class="math inline">\(\mathbb{P}(X=x)=0\)</span> pour tout réel <span class="math inline">\(x\)</span>.</p>
<div class="thmbox def">
<p>
<strong>Théorème (fonction de répartition et loi).</strong> Soit <span class="math inline">\(X\)</span> une variable aléatoire réelle discrète définie sur un espace probabilisé <span class="math inline">\((\Omega, \,\mathcal{P}(\Omega), \mathbb{P})\)</span> et de fonction de répartition <span class="math inline">\(F\)</span>. Alors :</p>
<ul>
<li>si <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> sont des nombres réels tels que <span class="math inline">\(a\leq b\)</span> on a</li>
</ul>
<p><span class="math display">\[\mathbb{P}(X\in]a\,;\,b])=F(b)-F(a)\]</span></p>
<ul>
<li>supposons que <span class="math inline">\(X(\Omega)=\{x_i,\,i\in I\}\)</span> avec les <span class="math inline">\(x_i\)</span> rangés dans l’ordre croissant. Alors</li>
</ul>
<p><span class="math display">\[\mathbb{P}(X=x_0)=F(x_0)\]</span>
et
<span class="math display">\[\forall i\geq 1,\, \mathbb{P}(X=x_i)=F(x_i)-F(x_{i-1})\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> On a</p>
<p><span class="math display">\[]-\infty\,;\,b]=]-\infty\,;\,a]\,\sqcup\,]a\,;\,b]\]</span></p>
<p>donc</p>
<p><span class="math display">\[F(b)=F(a)+\mathbb{P}(X\in ]a\,;\,b])\]</span>
ce qui montre la première égalité.</p>
<p>Comme <span class="math inline">\(x_0=\inf X(\Omega)\)</span>, on a <span class="math inline">\((X=x_0)=(X\leq x_0)\)</span> et donc ces deux événements ont la même probabilité, i.e. <span class="math inline">\(\mathbb{P}(X=x_0)=F(x_0)\)</span>.</p>
<p>Soit <span class="math inline">\(i\geq 1\)</span>. D’après le théorème précédent, on a</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X=x_i)&amp;=F(x_i)-F(x_i^{-}) \\
&amp;=F(x_i)-\mathbb{P}(X&lt;x_i) \\
&amp;=F(x_i)-\mathbb{P}(X\leq x_{i-1}) \\
&amp;=F(x_i)-F(x_{i-1}) \\
\end{align}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p>On déduit du résultat précédent :</p>
<div class="thmbox def">
<p><strong>Théorème.</strong> La fonction de répartition d’une variable aléatoire réelle discrète caractérise sa loi.</p>
<p>Autrement dit, si <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont deux variables aléatoires réelles discrètes, on a</p>
<p><span class="math display">\[F_X=F_Y \text{ ssi } \mathbb{P}_X=\mathbb{P}_Y\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> La loi d’une variable aléatoire réelle discrète <span class="math inline">\(X\)</span> est complètement définie par la donnée des probabilités <span class="math inline">\(\mathbb{P}(X=x_i)\)</span>, qui elles-mêmes sont complètement définies par la fonction <span class="math inline">\(F\)</span> d’après le théorème précédent, d’où le résultat.</p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Remarque.</strong> Le résultat précédent autorise donc à parler de fonction de répartition associée à une loi, ou même réciproquement de loi associée à une fonction de répartition.</p>
</div>
<div id="quantiles" class="section level3 hasAnchor" number="3.1.5">
<h3><span class="header-section-number">3.1.5</span> Quantiles<a href="variables-aléatoires-discrètes.html#quantiles" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pour définir la notion de quantile, on a besoin de définir la notion d’inverse généralisé à gauche.</p>
<div class="defbox def">
<center>
<strong>Inverse généralisé à gauche</strong>
</center>
<p></p>
<p>Soit <span class="math inline">\(F\)</span> une fonction définie sur <span class="math inline">\(\mathbb{R}\)</span> et à valeurs dans <span class="math inline">\([0,1]\)</span>, croissante et continue à droite.</p>
<p>On adopte les conventions suivantes :</p>
<p><span class="math display">\[F(-\infty)=\lim\limits_{x\to -\infty}F(x)\]</span>
<span class="math display">\[F(+\infty)=1\]</span></p>
<p><span class="math display">\[\inf\,\emptyset=+\infty\]</span>
On appelle alors <strong>fonction inverse généralisée à gauche de <span class="math inline">\(F\)</span></strong>, et on note <span class="math inline">\(F^{-1}\)</span>, la fonction définie sur <span class="math inline">\([0,1]\)</span> par</p>
<p><span class="math display">\[\forall p\in [0,1],\, F^{-1}(p)=\inf\{x\in\mathbb{R},\,F(x)\geq p\}\]</span>
Il s’agit d’une fonction croissante sur <span class="math inline">\(\mathbb{R}\)</span>.</p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Soient <span class="math inline">\(p\)</span> et <span class="math inline">\(q\)</span> deux réels tels que <span class="math inline">\(p\leq q\)</span>.</p>
<ul>
<li><p>si <span class="math inline">\(\{x\in\mathbb{R},\,F(x)\geq p\}=\emptyset\)</span>, alors <span class="math inline">\(\{x\in\mathbb{R}, \, F(x)\geq q\}=\emptyset\)</span> et donc <span class="math inline">\(F^{-1}(p)=F^{-1}(q)=+\infty\)</span>.</p></li>
<li><p>supposons maintenant que <span class="math inline">\(\{x\in\mathbb{R},\,F(x)\geq p\}\neq\emptyset\)</span> : il existe donc un réel <span class="math inline">\(x\)</span> tel que <span class="math inline">\(F^{-1}(p)=x\)</span>. On distingue deux cas :</p>
<ul>
<li><p>si <span class="math inline">\(\{x\in\mathbb{R}, \, F(x)\geq q\}=\emptyset\)</span>, alors <span class="math inline">\(F^{-1}(q)=+\infty\)</span>, et donc <span class="math inline">\(F^{-1}(p)=x&lt;+\infty=F^{-1}(q)\)</span>.</p></li>
<li><p>si <span class="math inline">\(\{x\in\mathbb{R},\,F(x)\geq q\}\neq\emptyset\)</span>, alors il existe un réel <span class="math inline">\(y\)</span> tel que <span class="math inline">\(y=F^{-1}(q)\)</span>. Par définition de <span class="math inline">\(y\)</span>, on a <span class="math inline">\(F(y)\geq q\)</span>. Mais comme <span class="math inline">\(q\geq p\)</span>, on en déduit que <span class="math inline">\(F(y)\geq p\)</span>. Par définition de <span class="math inline">\(x\)</span>, on en déduit que <span class="math inline">\(y\geq x\)</span>, i.e. que <span class="math inline">\(F^{-1}(q)\geq F^{-1}(p)\)</span>.</p></li>
</ul></li>
</ul>
<p>Ainsi, dans tous les cas, si <span class="math inline">\(p\leq q\)</span> alors <span class="math inline">\(F^{-1}(p)\leq F^{-1}(q)\)</span>, ce qui montre que <span class="math inline">\(F^{-1}\)</span> est croissante.</p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Remarque.</strong> Cette notion d’inverse généralisé à gauche permet de définir un pseudo-inverse pour des fonctions qui ne sont pas inversibles (on en verra un exemple un peu plus bas en application de la définition de la fonction quantile). Dans le cas où la fonction <span class="math inline">\(F\)</span> est strictement croissante et continue, elle est inversible, et son inverse et son inverse généralisé à gauche coïncident. Il s’agit donc bien d’une généralisation de l’inverse d’une fonction croissante et continue à droite.</p>
<p>La <strong>fonction quantile</strong> d’une variable aléatoire réelle <span class="math inline">\(X\)</span> se définit alors ainsi :</p>
<div class="defbox def">
<center>
<strong>Fonction quantile, quantiles</strong>
</center>
<p>Soient <span class="math inline">\(X\)</span> une variable aléatoire réelle (discrète ou non) et <span class="math inline">\(F\)</span> sa fonction de répartition. On appelle <strong>fonction quantile de <span class="math inline">\(X\)</span></strong> la fonction inverse généralisée à gauche <span class="math inline">\(F^{-1}\)</span> de <span class="math inline">\(F\)</span>.</p>
<p>De plus, pour tout réel <span class="math inline">\(p\)</span> dans <span class="math inline">\([0,1]\)</span>, on appelle <strong>quantile d’ordre <span class="math inline">\(p\)</span></strong> le réel <span class="math inline">\(F^{-1}(p)\)</span>.</p>
<p></p>
<p><strong>Exemples usuels de quantiles :</strong></p>
<ul>
<li><p><span class="math inline">\(m_e=F^{-1}\left(\frac{1}{2}\right)\)</span> est la <strong>médiane</strong> de <span class="math inline">\(X\)</span> ;</p></li>
<li><p><span class="math inline">\(Q_1=F^{-1}\left(\frac{1}{4}\right)\)</span> et <span class="math inline">\(Q_3=F^{-1}\left(\frac{3}{4}\right)\)</span> sont les <strong>quartiles</strong> de <span class="math inline">\(X\)</span> ;</p></li>
<li><p>pour <span class="math inline">\(i=1,\dots,9\)</span>, les <span class="math inline">\(D_i=F^{-1}\left(\frac{i}{10}\right)\)</span> sont les <strong>déciles</strong> de <span class="math inline">\(X\)</span>.</p></li>
</ul>
</div>
<p>Dans un exemple précédent, on a introduit une variable aléatoire discrète <span class="math inline">\(X\)</span> de fonction de répartition <span class="math inline">\(F\)</span> donnée par</p>
<p><span class="math display">\[F(x)=\left \{
\begin{array}{lcl}
0&amp;\text{ si }&amp; x&lt;1 \\
\frac{1}{10}&amp;\text{ si }&amp; 1\leq x&lt;2 \\
\frac{3}{10}&amp;\text{ si }&amp; 2\leq x&lt;3 \\
\frac{3}{5}&amp;\text{ si }&amp; 3\leq x&lt;4 \\
1&amp;\text{ si }&amp; x\geq 4 \\
\end{array}
\right.\]</span></p>
<p>Déterminons sa médiane et ses quartiles :</p>
<ul>
<li><p><span class="math inline">\(F(x)\geq\frac{1}{2}\Leftrightarrow x\geq 3\)</span>, donc <span class="math inline">\(m_e=3\)</span> ;</p></li>
<li><p><span class="math inline">\(F(x)\geq\frac{1}{4}\Leftrightarrow x\geq 2\)</span>, donc <span class="math inline">\(Q_1=2\)</span> ;</p></li>
<li><p><span class="math inline">\(F(x)\geq\frac{3}{4}\Leftrightarrow x\geq 4\)</span>, donc <span class="math inline">\(Q_3=4\)</span>.</p></li>
</ul>
<p></p>
<p><strong>Un intérêt des quantiles.</strong> Il est fréquent de vouloir résumer une distribution statistique à l’aide d’indicateurs. Un indicateur couramment utilisé est la moyenne. Il présente toutefois pour inconvénient majeur d’être fortement sensible aux valeurs extrêmes. Ainsi, une seule valeur atypique d’une distribution suffit à perturber considérablement la moyenne. Une alternative est alors de recourir à un quantile, comme par exemple la médiane, qui est plus robuste aux valeurs atypiques.</p>
<p></p>
</div>
<div id="exemples-classiques-de-lois-discrètes" class="section level3 hasAnchor" number="3.1.6">
<h3><span class="header-section-number">3.1.6</span> Exemples classiques de lois discrètes<a href="variables-aléatoires-discrètes.html#exemples-classiques-de-lois-discrètes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pour <span class="math inline">\(X\)</span> une variable aléatoire réelle discrète et <span class="math inline">\(\mathcal{L}\)</span> une loi de probabilité, la notation <span class="math inline">\(X\sim\mathcal{L}\)</span> signfiera que <span class="math inline">\(X\)</span> suit la loi <span class="math inline">\(\mathcal{L}\)</span>.</p>
<p><strong>Exemple 1 : loi uniforme sur un ensemble fini.</strong> La loi uniforme affecte les mêmes probabilités à tous les éléments d’un ensemble fini <span class="math inline">\(X(\Omega)=\{x_1,\dots, x_n\}\)</span> :</p>
<p><span class="math display">\[\forall 1\leq i\leq n,\, \mathbb{P}(X=x_i)=\frac{1}{n}\]</span>
C’est cette loi à laquelle on doit penser lorsqu’on parle de <em>tirer au hasard</em> parmi un ensemble fini. C’est aussi cette loi qu’on utilise si on veut modéliser un phénomène aléatoire sur un ensemble fini en l’absence de toute information sur le tirage.</p>
<p>On suppose les <span class="math inline">\(x_i\)</span> rangés dans l’ordre croissant. Alors, la fonction de répartition de cette loi est la fonction <span class="math inline">\(F\)</span> donnée par</p>
<p><span class="math display">\[F(x)=\left \{
\begin{array}{lcl}
0&amp;\text{ si }&amp; x&lt;x_1 \\
\frac{i}{n}&amp;\text{ si }&amp; x_i\leq x&lt;x_{i+1}\, \text{, avec } 1\leq i\leq n-1 \\
1&amp;\text{ si }&amp; x\geq x_n \\
\end{array}
\right.\]</span></p>
<p></p>
<p><strong>Exemple 2 : loi de Bernoulli <span class="math inline">\(\mathcal{B}(p)\)</span>.</strong> Ici, <span class="math inline">\(p\in[0,1]\)</span>. Cette loi est généralement mobilisée lorsque l’on souhaite modéliser l’issue d’une <strong>expérience de Bernoulli</strong>, autrement dit une expérience ayant deux issues nommées <em>réussite</em> et <em>échec</em>. Il s’agit donc d’une loi à deux issues, généralement notées <span class="math inline">\(0\)</span> (représentant généralement l’échec) et <span class="math inline">\(1\)</span> (représentant généralement la réussite) :</p>
<p><span class="math display">\[X(\Omega)=\{0,1\}\]</span></p>
<p>Une telle loi est définie de façon unique à partir du paramètre <span class="math inline">\(p=\mathbb{P}(X=1)\)</span>. De façon immédiate, on a <span class="math inline">\(\mathbb{P}(X=0)=1-p\)</span>. On note souvent <span class="math inline">\(q=1-p\)</span>.</p>
<p>La fonction de répartition de la loi de Benoulli <span class="math inline">\(\mathcal{B}(p)\)</span> est donnée par</p>
<p><span class="math display">\[F(x)=\left \{
\begin{array}{lcl}
0&amp;\text{ si }&amp; x&lt;0 \\
p&amp;\text{ si }&amp; 0\leq x&lt;1 \\
1&amp;\text{ si }&amp; x\geq 1 \\
\end{array}
\right.\]</span></p>
<p></p>
<p><strong>Exemple 3 : loi binomiale <span class="math inline">\(\mathcal{B}(n,p)\)</span>.</strong> <span class="math inline">\(n\)</span> est un entier naturel non nul et <span class="math inline">\(p\in [0,1]\)</span>. La loi binomiale sert à modéliser le nombre de succès lors de la répétition de <span class="math inline">\(n\)</span> expériences de Bernoulli identiques et indépendantes. On a donc</p>
<p><span class="math display">\[X(\Omega)=\{0,1,\dots, n\}\]</span></p>
<p>Les probabilités de la loi binomiale <span class="math inline">\(\mathcal{B}(n,p)\)</span> font intervenir les coefficients binomiaux <span class="math inline">\(\binom{n}{k}\)</span> :</p>
<div class="thmbox def">
<p>
<strong>Probabilités d’une loi binomiale.</strong> Soit <span class="math inline">\(X\)</span> une variable aléatoire telle que <span class="math inline">\(X\sim\mathcal{B}(n,p)\)</span>. Alors, pour tout entier <span class="math inline">\(0\leq k\leq n\)</span>, on a</p>
<p><span class="math display">\[\mathbb{P}(X=k)=\binom{n}{k}\,p^k\,(1-p)^{n-k}\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Cette formule est une conséquence de la définition de la loi <span class="math inline">\(\mathcal{B}(n,p)\)</span>. On peut écrire
<span class="math display">\[X=\sum\limits_{i=1}^n X_i\]</span>
où les <span class="math inline">\(X_i\)</span> sont des variables aléatoires de Bernoulli de paramètre <span class="math inline">\(\mathcal{B}(p)\)</span>, représentant l’issue de l’expérience de Bernoulli numéro <span class="math inline">\(i\)</span>.</p>
<p>Soit <span class="math inline">\(k\)</span> un entier tel que <span class="math inline">\(0\leq k\leq n\)</span>. Notons</p>
<p><span class="math display">\[E_k=\left\{(x_1,\dots, x_n)\in\{0,1\}^n,\, \sum\limits_{i=1}^n x_i=k\right\}\]</span></p>
<p>Pour <span class="math inline">\((x_1,\dots, x_n)\in E_k\)</span>, les événements <span class="math inline">\((X_1=x_1),\dots,(X_n=x_n)\)</span> sont indépendants, puisque les expériences de Bernoulli associées aux <span class="math inline">\(X_i\)</span> sont indépendantes. Par conséquent, on a</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X_1=x_1,\dots, X_n=x_n)&amp;=\prod\limits_{i=1}^n\mathbb{P}(X=x_i) \\
&amp;=p^k\,(1-p)^{n-k} \\
\end{align}\]</span></p>
<p>puisque le vecteur <span class="math inline">\((x_1,\dots, x_n)\)</span> est constitué de <span class="math inline">\(k\)</span> composantes égales à <span class="math inline">\(1\)</span> et <span class="math inline">\(n-k\)</span> composantes égales à <span class="math inline">\(0\)</span>.</p>
<p>Par ailleurs, <span class="math inline">\(\text{Card }(E_k)=\binom{n}{k}\)</span> donc :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X=k)&amp;=\mathbb{P}\left(\sum\limits_{i=1}^n X_i=k\right) \\
&amp;=\mathbb{P}\left(\bigsqcup\limits_{(x_1,\dots, x_n)\in E_k} (X_1=x_1,\dots, X_n=x_n)\right) \\
&amp;=\sum\limits_{(x_1,\dots,x_n)\in E_k}\mathbb{P}\left(X_1=x_1,\dots, X_n=x_n\right) \\
&amp;=\sum\limits_{(x_1,\dots, x_n)\in E_k} p^k\,(1-p)^{n-k} \\
&amp;=\text{Card }(E_k)\,p^k\,(1-p)^{n-k} \\
&amp;=\binom{n}{k}\,p^k\,(1-p)^{n-k} \\
\end{align}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Remarque.</strong> On déduit de l’expression des <span class="math inline">\(\mathbb{P}(X=k)\)</span> l’identité</p>
<p><span class="math display">\[\sum\limits_{k=0}^n\binom{n}{k}\,p^k\,(1-p)^{n-k}=1\]</span>
qui n’est autre qu’un cas particulier de la formule du binôme de Newton :</p>
<p><span class="math display">\[(p+(1-p))^n=\sum\limits_{k=0}^n\binom{n}{k}\,p^k\,(1-p)^{n-k}\]</span>
La fonction de répartition de la loi binomiale <span class="math inline">\(\mathcal{B}(n,p)\)</span> est donnée par</p>
<p><span class="math display">\[F(x)=\left \{
\begin{array}{lcl}
0&amp;\text{ si }&amp; x&lt;0 \\
\sum\limits_{k=0}^l \binom{n}{k}\,p^k\,(1-p)^{n-k} &amp;\text{ si }&amp; l\leq x&lt;l+1, \,0\leq l&lt;n \\
1&amp;\text{ si }&amp; x\geq n \\
\end{array}
\right.\]</span></p>
<p></p>
<p><strong>Exemple 4 : loi de Poisson <span class="math inline">\(\mathcal{P}(\lambda)\)</span>.</strong> <span class="math inline">\(\lambda\)</span> est un réel strictement positif. La loi de Poisson <span class="math inline">\(\mathcal{P}(\lambda)\)</span> permet de modéliser le nombre (aléatoire) <span class="math inline">\(X\)</span> d’événements se produisant sur une période <span class="math inline">\(T\)</span>, lorsqu’on sait qu’en moyenne <span class="math inline">\(\lambda\)</span> événements se produisent sur une telle période. Elle est généralement appliquée pour des événements rares (accidents, fautes dans un texte, etc.). On peut aussi l’utiliser pour des domaines spatiaux plutôt que des intervalles temporels. On a</p>
<p><span class="math display">\[X(\Omega)=\mathbb{N}\]</span>
et les probabilités <span class="math inline">\(\mathbb{P}(X=n)\)</span> pour <span class="math inline">\(n\in\mathbb{N}\)</span> sont données par la formule suivante :</p>
<div class="thmbox def">
<p>
<strong>Probabilités d’une loi de Poisson <span class="math inline">\(\mathcal{P}(\lambda)\)</span>.</strong> Soit <span class="math inline">\(X\)</span> une variable aléatoire telle que <span class="math inline">\(X\sim\mathcal{P}(\lambda)\)</span>. Alors :</p>
<p><span class="math display">\[\forall k\in\mathbb{N}, \, \mathbb{P}(X=k)=e^{-\lambda}\frac{\lambda^k}{k!}\]</span></p>
</div>
<p>
<strong>Justification de cette formule.</strong> On considère un événement qui se produit aléatoirement et de façon répétée dans le temps, selon les règles suivantes :</p>
<ul>
<li><p>sur tout intervalle de temps de longueur (petite) <span class="math inline">\(\Delta t\)</span> :</p>
<ul>
<li><p>cet événement se produit une fois avec une probabilité <span class="math inline">\(p\)</span> très petite ;</p></li>
<li><p>pour tout <span class="math inline">\(k\geq 2\)</span>, la probabilité qu’il se produise <span class="math inline">\(k\)</span> fois est négligeable ;</p></li>
</ul></li>
<li><p>sur deux intervalles de temps disjoints de longueur <span class="math inline">\(\Delta t\)</span>, les survenues (ou non) de cet événement sont indépendantes.</p></li>
</ul>
<p>On compte alors le nombre d’occurences <span class="math inline">\(X\)</span> de cet événement sur un intervalle de temps <span class="math inline">\([a\,;\,a+n\Delta t]\)</span>, avec <span class="math inline">\(a&gt;0\)</span> et <span class="math inline">\(n\)</span> un entier très grand. Pour tout entier <span class="math inline">\(k\)</span>, on note <span class="math inline">\(X_k\)</span> la variable aléatoire prenant la valeur <span class="math inline">\(1\)</span> si l’événement s’est produit sur l’intervalle de temps <span class="math inline">\([a+k\Delta t \, ; \, a+(k+1)\Delta t[\)</span> et <span class="math inline">\(0\)</span> sinon, de sorte que</p>
<p><span class="math display">\[X=\sum\limits_{k=0}^{n-1}X_k\]</span>
D’après les hypothèses faites plus haut, les variables <span class="math inline">\(X_k\)</span> suivent toutes la loi de Bernoulli <span class="math inline">\(\mathcal{B}(p)\)</span> et les événements <span class="math inline">\((X_1=\varepsilon_1),\dots,(X_n=\varepsilon_n)\)</span> sont indépendantes pour tout <span class="math inline">\((\varepsilon_1,\dots,\varepsilon_n)\in\{0,1\}^n\)</span>, donc <span class="math inline">\(X\)</span> suit une loi binomiale <span class="math inline">\(\mathcal{B}(n,p)\)</span>. Ainsi</p>
<p><span class="math display">\[\forall k\in\{0,1,\dots, n\}, \,\mathbb{P}(X=k)=\binom{n}{k}\,p^k\,(1-p)^{n-k}\]</span>
La loi de Poisson découle alors d’une approximation de la formule précédente pour de très grandes valeurs de <span class="math inline">\(n\)</span> et une très petite valeur de <span class="math inline">\(p\)</span>. En posant <span class="math inline">\(\lambda = np\)</span>, on a en effet :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X=k)&amp;=\binom{n}{k}\,\left(\frac{\lambda}{n}\right)^k\,\left(1-\frac{\lambda}{n}\right)^{n-k} \\
&amp;=\frac{n(n-1)\dots(n-k+1)}{n^k} \frac{\lambda^k}{k!}\left(1-\frac{\lambda}{n}\right)^{n-k} \\
&amp;=\left(1-\frac{1}{n}\right)\dots \left(1-\frac{k-1}{n}\right) \frac{\lambda^k}{k!}e^{(n-k)\,\log\left(1-\frac{\lambda}{n}\right)} \\
&amp;\approx \left(1-\frac{1}{n}\right)\dots \left(1-\frac{k-1}{n}\right) \frac{\lambda^k}{k!}e^{-(n-k)\,\left(\frac{\lambda}{n}+o\left(\frac{1}{n} \right)\right)} \\
&amp;\approx \left(1-\frac{1}{n}\right)\dots \left(1-\frac{k-1}{n}\right) \frac{\lambda^k}{k!}e^{-\lambda+O\left(\frac{1}{n}\right)} \\
&amp;\to \frac{\lambda^k}{k!}e^{-\lambda}\, \text{ lorsque } n\to\infty
\end{align}\]</span></p>
<p><strong>Remarque.</strong> Comme <span class="math inline">\(X\)</span> suit une loi binomiale <span class="math inline">\(\mathcal{B}(n,p)\)</span>, on a <span class="math inline">\(\mathbb{E}(X)=np\)</span>. Le paramètre <span class="math inline">\(\lambda\)</span> d’une loi de Poisson <span class="math inline">\(\mathcal{P}(\lambda)\)</span> s’interprète donc comme le nombre moyen d’événements ayant lieu pendant une période de référence.</p>
<p><strong>Exemple 5 : loi géométrique <span class="math inline">\(\mathcal{G}(p)\)</span>.</strong> <span class="math inline">\(p\)</span> est un réel appartenant à <span class="math inline">\(]0\,;\,1[\)</span> et on considère une succession d’épreuves de Bernoulli indépendantes (donc se soldant par un succès ou un échec). On dit que <span class="math inline">\(X\)</span> suit la loi géométrique de paramètre <span class="math inline">\(p\)</span> si <span class="math inline">\(X\in\mathbb{N}^{*}\)</span> est le numéro du premier succès.</p>
<div class="thmbox def">
<p><strong>Probabilités d’une loi géométrique.</strong> Soit <span class="math inline">\(X\)</span> une variable aléatoire telle que <span class="math inline">\(X\sim\mathcal{G}(p)\)</span>. Alors, pour tout entier <span class="math inline">\(k\geq 1\)</span> on a</p>
<p><span class="math display">\[\mathbb{P}(X=k)=(1-p)^{k-1}p\]</span></p>
</div>
<p>
<strong>Démonstration.</strong> Soit <span class="math inline">\(k\)</span> un entier supérieur ou égal à <span class="math inline">\(1\)</span>. Dire que <span class="math inline">\(X=k\)</span> revient à dire que les <span class="math inline">\(k-1\)</span> premières expériences se sont soldées par des échecs et que l’expérience numéro <span class="math inline">\(k\)</span> a été un succès. En notant <span class="math inline">\(S_k\)</span> l’événement <em>L’expérience numéro <span class="math inline">\(k\)</span> s’est soldée par un succès</em> et <span class="math inline">\(E_k\)</span> l’événement <em>L’expérience numéro <span class="math inline">\(k\)</span> s’est soldée par un échec</em>, on a donc</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X=k)&amp;=\mathbb{P}(S_1\cap S_2\cap\dots\cap S_{k-1}\cap E_k) \\
&amp;=\mathbb{P}(S_1)\mathbb{P}(S_2)\dots\mathbb{P}(S_{k-1})\mathbb{P}(E_k) \, \text{ par indépendance} \\
&amp;=(1-p)^{k-1}p \\
\end{align}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p><strong>Exemple 6 : loi hypergéométrique.</strong> La loi hypergéométrique est, comme la loi binomiale, utilisée dans un contexte où l’on souhaite compter le nombre de succès dans une succession d’épreuves de Bernoulli. La différence avec la loi binomiale étant que maintenant, ces épreuves de Bernoulli ne sont plus identiques ni indépendantes.</p>
<p>On suppose qu’une population de taille <span class="math inline">\(N\)</span>, exactement <span class="math inline">\(D\)</span> individus possèdent une certaine caractéristique <span class="math inline">\(\mathcal{C}\)</span> (donc <span class="math inline">\(0\leq D\leq N\)</span>). On tire un échantillon de taille <span class="math inline">\(n\)</span> dans cette population, <strong>sans remise</strong> (donc <span class="math inline">\(0\leq n\leq N\)</span>) et de façon équiprobable. On compte le nombre <span class="math inline">\(X\)</span> d’individus de l’échantillon possédant la caractéristique <span class="math inline">\(\mathcal{C}\)</span>. On dit alors que <span class="math inline">\(X\)</span> suit la <strong>loi hypergéométrique <span class="math inline">\(\mathcal{H}(N,D,n)\)</span></strong>. On a alors :</p>
<div class="thmbox def">
<p><strong>Support et probabilités d’une loi hypergéométrique.</strong> Pour <span class="math inline">\(X\sim\mathcal{H}(N,D,n)\)</span>, on a :</p>
<p></p>
<p><strong>i. Support de X.</strong> <span class="math display">\[\max(0 \,; \,n-N+D)\leq X\leq \min(n\,;\,D)\]</span></p>
<p></p>
<p><strong>ii. Probabilités.</strong> Pour tout entier <span class="math inline">\(\max(0 \,; \,n-N+D)\leq k\leq \min(n\,;\,D)\)</span> :</p>
<p><span class="math display">\[\mathbb{P}(X=k)=\frac{\binom{D}{k}\binom{N-D}{n-k}}{\binom{N}{n}}\]</span></p>
</div>
<p></p>
<p><strong>Démonstration. i.</strong> On a nécessairement :</p>
<ul>
<li><p><span class="math inline">\(0\leq X\leq n\)</span> : l’échantillon étant de taille <span class="math inline">\(n\)</span>, on tire au plus <span class="math inline">\(n\)</span> individus ayant la propriété <span class="math inline">\(\mathcal{C}\)</span> ;</p></li>
<li><p><span class="math inline">\(0\leq X\leq D\)</span> : le tirage de l’échantillon étant sans remise, on ne peut pas tirer plus d’unités ayant la propriété <span class="math inline">\(\mathcal{C}\)</span> qu’il n’y en a dans la population.</p></li>
</ul>
<p>De façon symétrique, on fait exactement le même raisonnement pour le tirage des individus n’ayant pas la propriété <span class="math inline">\(\mathcal{C}\)</span> :</p>
<ul>
<li><p><span class="math inline">\(0\leq n-X\leq n\)</span> : l’échantillon étant de taille <span class="math inline">\(n\)</span>, on tire au plus <span class="math inline">\(n\)</span> individus n’ayant pas la propriété <span class="math inline">\(\mathcal{C}\)</span>. On remarque que cet encadrement est automatiquement vérifié dès que le premier encadrement (sa version symétrique) l’est ;</p></li>
<li><p><span class="math inline">\(0\leq n-X \leq N-D\)</span> : on ne peut pas tirer plus d’individus n’ayant pas la propriété <span class="math inline">\(\mathcal{C}\)</span> qu’il n’y en a dans la population.</p></li>
</ul>
<p>Les deux premiers encadrements s’écrivent plus simplement <span class="math display">\[0\leq X\leq \min(n,D)\]</span> et le dernier encadrement s’écrit <span class="math display">\[\max(0,n-N+D)\leq X\leq n\]</span></p>
<p>Enfin, ces deux encadrements s’écrivent</p>
<p><span class="math display">\[\max(0,n-N+D)\leq X\leq\min(n,D)\]</span></p>
<p></p>
<p><strong>ii.</strong> Soit <span class="math inline">\(k\in R_X\)</span>. Dénombrons le nombre d’échantillons de taille <span class="math inline">\(n\)</span> satisfaisant la condition <span class="math inline">\(X=k\)</span>. La donnée d’un tel échantillon repose sur :</p>
<ul>
<li><p>le choix de <span class="math inline">\(k\)</span> individus parmi les <span class="math inline">\(D\)</span> ayant la caractéristique <span class="math inline">\(\mathcal{C}\)</span>, soit <span class="math inline">\(\binom{D}{k}\)</span> choix possibles ;</p></li>
<li><p>le choix de <span class="math inline">\(n-k\)</span> individus parmi les <span class="math inline">\(N-D\)</span> n’ayant pas la caractéristique <span class="math inline">\(\mathcal{C}\)</span>, soit <span class="math inline">\(\binom{N-D}{n-k}\)</span> choix possibles.</p></li>
</ul>
<p>Pour <span class="math inline">\(k\)</span> fixé, ces deux choix sont complètement indépendants, donc le nomnre <span class="math inline">\(N_k\)</span> de choix d’un tel échantillon s’obtient par produit : <span class="math inline">\(N_k=\binom{D}{k}\binom{N-D}{n-k}\)</span>. Enfin, tous ces échantillons sont équiprobables, donc</p>
<p><span class="math display">\[\mathbb{P}(X=k)=\frac{\binom{D}{k}\binom{N-D}{n-k}}{\binom{N}{n}}\]</span>
<span class="math inline">\(\square\)</span></p>
<p><strong>Exemple.</strong> Une urne contient <span class="math inline">\(20\)</span> boules, parmi lesquelles <span class="math inline">\(14\)</span> exactement sont rouges. On tire <span class="math inline">\(12\)</span> boules dans l’urne, <strong>sans remise</strong>, et on compte le nombre <span class="math inline">\(X\)</span> de boules rouges obtenues. Alors, <span class="math inline">\(X\sim\mathcal{H}(20, 8, 5)\)</span>. Le support de <span class="math inline">\(X\)</span> est <span class="math inline">\(R_X= [\![6;12]\!]\)</span> et</p>
<p><span class="math display">\[\forall k\in R_X, \, \mathbb{P}(X=k)=\frac{\binom{14}{k}\binom{6}{12-k}}{\binom{20}{12}}\]</span></p>
</div>
<div id="simulation-dune-variable-aléatoire-réelle" class="section level3 hasAnchor" number="3.1.7">
<h3><span class="header-section-number">3.1.7</span> Simulation d’une variable aléatoire réelle<a href="variables-aléatoires-discrètes.html#simulation-dune-variable-aléatoire-réelle" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="moments-dune-variable-aléatoire" class="section level3 hasAnchor" number="3.1.8">
<h3><span class="header-section-number">3.1.8</span> Moments d’une variable aléatoire<a href="variables-aléatoires-discrètes.html#moments-dune-variable-aléatoire" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="defbox def">
<center>
<strong>Espérance d’une variable aléatoire réelle discrète</strong>
</center>
<p>Soit <span class="math inline">\(X\)</span> une variable aléatoire réelle de <strong>support fini</strong> <span class="math inline">\(X(\Omega)=\{x_1,\dots,x_n\}\)</span>. On appelle <strong>espérance</strong> de <span class="math inline">\(X\)</span> le nombre réel</p>
<p><span class="math display">\[\mathbb{E}(X)=\sum\limits_{k=1}^n \mathbb{P}(X=x_k)\,x_k\]</span></p>
<p></p>
<p>Pour une variable aléatoire réelle discrète de <strong>support infini dénombrable</strong> <span class="math inline">\(X(\Omega)=\{x_1,\dots, x_n\dots\}\)</span>, l’existence d’une espérance n’est pas systématique. On dit qu’une telle variable <span class="math inline">\(X\)</span> admet une espérance finie si la série <span class="math inline">\(\sum\limits_{n}\mathbb{P}(X=x_n)\,x_n\)</span> est asbolument convergente. Dans ce cas, l’espérance <span class="math inline">\(\mathbb{E}(X)\)</span> de <span class="math inline">\(X\)</span> est la somme de cette série :</p>
<p><span class="math display">\[\mathbb{E}(X)=\sum\limits_{n=0}^{\infty}\mathbb{P}(X=x_n)\,x_n\]</span></p>
<p></p>
<p><strong>Notation unifiée.</strong> Pour ne pas avoir à distinguer le cas fini / infini dénombrable, on peut aussi utiliser une notation englobant les deux cas :</p>
<p><span class="math display">\[\mathbb{E}(X)=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,x\]</span></p>
</div>
<p></p>
<p><strong>Remarque.</strong> L’espérance d’une variable est donc une moyenne de ses valeurs, pondérée par les probabilités qui leur sont associées.</p>
<p>Cette expression de l’espérance s’écrit à partir des valeurs <span class="math inline">\(x\)</span> prises par <span class="math inline">\(X:\Omega\longrightarrow\mathbb{R}\)</span>, c’est-à-dire les éléments de l’<strong>espace d’arrivée</strong> de <span class="math inline">\(X\)</span>. On peut aussi exprimer l’espérance à partir des éléments de l’<strong>espace de départ</strong> de <span class="math inline">\(X\)</span> :</p>
<div class="defbox def">
<center>
<strong>Espérance d’une variable aléatoire réelle discrète (variante)</strong>
</center>
<p>Soit <span class="math inline">\(X:\Omega\longrightarrow\mathbb{R}\)</span> une variable aléatoire réelle discrète d’espérance finie. Alors :</p>
<p><span class="math display">\[\mathbb{E}(X)=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})X(\omega)\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> L’univers <span class="math inline">\(\Omega\)</span> peut se décomposer en</p>
<p><span class="math display">\[\Omega=\bigsqcup\limits_{x\in X(\Omega)}\bigsqcup\limits_{\omega\in X^{-1}(\{x\})}\{\omega\}\]</span>
On a donc, sous réserve d’existence :</p>
<p><span class="math display">\[\begin{align}
\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})X(\omega)&amp;=\sum\limits_{x\in X(\Omega)}\sum\limits_{\omega\in X^{-1}(\{x\})}\mathbb{P}(\{\omega\})X(\omega) \\
&amp;=\sum\limits_{x\in X(\Omega)}\left(\sum\limits_{\omega\in X^{-1}(\{x\})}\mathbb{P}(\{\omega\})\right)x \\
&amp;=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,x \\
&amp;=\mathbb{E}(X) \\
\end{align}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Exemple.</strong> Le résultat précédent énonce l’égalité suivante :</p>
<p><span class="math display">\[\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,X(\omega)=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,x\]</span>
Il nous dit que l’espérance de <span class="math inline">\(X\)</span> peut être vue comme une moyenne sur l’espace de départ de <span class="math inline">\(X\)</span>, ou comme une moyenne sur l’espace d’arrivée de <span class="math inline">\(X\)</span>. L’équivalence entre ces deux points de vue est facile à saisir sur un exemple.</p>
<p>Soient <span class="math inline">\((\Omega, \mathcal{P}(\Omega), \mathbb{P})\)</span> un espace probabilisé tel que <span class="math inline">\(\Omega=\{a,b,c,d\}\)</span> et <span class="math inline">\(X\)</span> une variable aléatoire réelle discrète sur cet espace. On donne le tableau suivant :</p>
<center>
<img src="images/probas_univers.PNG" width="80%" height="80%" />
</center>
<p>Pour calculer <span class="math inline">\(\mathbb{E}(X)\)</span>, on peut utiliser l’expression de l’espérance utilisant les éléments de l’univers <span class="math inline">\(\Omega\)</span> :</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X)&amp;=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,X(\omega) \\
&amp;=0,3\times 1+0,1\times 1+0,4\times 2+0,2\times 2 \\
&amp;=1,6 \\
\end{align}\]</span></p>
<p>Mais on peut aussi regrouper les valeurs de <span class="math inline">\(\omega\)</span> ayant des images communes par <span class="math inline">\(X\)</span>, et raisonner directement sur ces images (et leurs probabilités associées) :</p>
<center>
<img src="images/probas_image.PNG" width="50%" height="50%" />
</center>
<p>Dans ce cas, on fait plutôt le calcul :</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X)&amp;=0,4\times 1+0,6\times 2 \\
&amp;=1,6 \\
\end{align}\]</span></p>
<p>On obtient alors bien le même résultat.</p>
<p><br></p>
<p>Une application de ce résultat est le <strong>théorème de transfert</strong> :</p>
<div class="thmbox def">
<p><strong>Théorème de transfert.</strong> Soient <span class="math inline">\(X:\Omega\longrightarrow\mathbb{R}\)</span> une variable aléatoire réelle discrète et <span class="math inline">\(\phi:X(\Omega)\longrightarrow\mathbb{R}\)</span>. On suppose que <span class="math inline">\(\phi(X)\)</span> admet une espérance finie. Alors, on a</p>
<p><span class="math display">\[\mathbb{E}(\phi(X))=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\phi(x)\]</span>
En particulier, pour <span class="math inline">\(\phi(x)=x^m\)</span>, avec <span class="math inline">\(m\)</span> entier naturel, on a donc (sous réserve d’existence) :</p>
<p><span class="math display">\[\mathbb{E}(X^m)=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,x^m\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Avec les mêmes notations que pour le résultat précédent, on a</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(\phi(X))&amp;=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\phi(X(\omega)) \\
&amp;=\sum\limits_{x\in X(\Omega)}\phi(x)\sum\limits_{\omega\in X^{-1}(\{x\})}\mathbb{P}(\{\omega\}) \\
&amp;=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\phi(x) \\
\end{align}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Inteprétation du théorème de transfert.</strong> Ce résultat nous dit que pour calculer l’espérance de <span class="math inline">\(\phi(X)\)</span>, la connaissance de la loi de <span class="math inline">\(\phi(X)\)</span> - qui dans certains cas peut être couteuse à acquérir - est inutile : la loi de <span class="math inline">\(X\)</span> suffit.</p>
<p></p>
<p><strong>Exemple.</strong> Soit <span class="math inline">\(X\)</span> une variable aléatoire de support <span class="math inline">\(X(\Omega)=\mathbb{N}^*\)</span> et telle que</p>
<p><span class="math display">\[\forall n\in\mathbb{N}^*,\,\mathbb{P}(X=n)=\frac{1}{n(n+1)}\]</span>
Nous allons montrer :</p>
<ul>
<li><p>qu’on définit ainsi bien la loi de probabilité d’une variable aléatoire ;</p></li>
<li><p>que <span class="math inline">\(X\)</span> n’admet pas d’espérance finie ;</p></li>
<li><p>que <span class="math inline">\(\frac{X+1}{X}\)</span> admet une espérance finie, et que celle-ci est donnée par</p></li>
</ul>
<p><span class="math display">\[\mathbb{E}(X)=\frac{\pi^2}{6}\]</span>
Soit <span class="math inline">\(n\)</span> un entier naturel non nul. On a</p>
<p><span class="math display">\[\begin{align}
\sum\limits_{k=1}^n\frac{1}{k(k+1)}&amp;=\sum\limits_{k=1}^n\left(\frac{1}{k}-\frac{1}{k+1}\right) \\
&amp;= 1-\frac{1}{n+1} \\
&amp; \text{(somme télescopique)} \\
\end{align}\]</span></p>
<p>La série de terme général <span class="math inline">\(\frac{1}{n(n+1)}\)</span> est donc convergente, et sa somme vaut <span class="math inline">\(1\)</span> :</p>
<p><span class="math display">\[\sum\limits_{n=1}^{\infty}\frac{1}{n(n+1)}=1\]</span>
On a donc bien défini la loi d’une variable aléatoire.</p>
<p>Par ailleurs, la série de terme général <span class="math inline">\(n\,\mathbb{P}(X=n)=\frac{1}{n+1}\)</span> n’est pas (absolument) convergente, donc <span class="math inline">\(X\)</span> n’admet pas d’espérance finie.</p>
<p>Enfin, pour démontrer que <span class="math inline">\(\frac{X+1}{X}\)</span> admet une espérance finie, il suffit d’après le théorème de transfert de montrer que la série de terme <span class="math inline">\(\sum\limits_{n}\mathbb{P}(X=n)\,\frac{n+1}{n}\)</span> est convergente. Si c’est bien le cas, son espérance sera égale à la somme de cette série.</p>
<p>Or, on a :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X=n)\,\frac{n+1}{n}&amp;=\frac{1}{n(n+1)}\frac{n+1}{n} \\
&amp;=\frac{1}{n^2} \\
\end{align}\]</span></p>
<p>La série <span class="math inline">\(\sum\limits_{n}\frac{1}{n^2}\)</span> est convergente, de somme</p>
<p><span class="math display">\[\sum\limits_{n=1}^{\infty}\frac{1}{n^2}=\frac{\pi^2}{6}\]</span>
On en déduit le résultat.</p>
<p><br></p>
<p>L’espérance, vue comme un opérateur, possède les propriétés suivantes :</p>
<div class="thmbox def">
<p><strong>Propriétés de l’espérance.</strong> <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> désignent des variables aléatoires réelles discrètes admettant une espérance, <span class="math inline">\(\lambda\)</span> est un réel. On a :</p>
<p><strong>i. Espérance d’une constante.</strong> Si <span class="math inline">\(X=a\)</span> est constante, alors <span class="math inline">\(\mathbb{E}(X)=a\)</span>.</p>
<p><strong>ii. Linéarité de l’espérance.</strong> <span class="math inline">\(\mathbb{E}(X+\lambda Y)=\mathbb{E}(X)+\lambda\,\mathbb{E}(Y)\)</span></p>
<p><strong>iii. Positivité de l’espérance.</strong> Si <span class="math inline">\(X\geq 0\)</span>, alors <span class="math inline">\(\mathbb{E}(X)\geq 0\)</span>.</p>
<p><strong>iv. Croissance de l’espérance.</strong> Si <span class="math inline">\(X\leq Y\)</span>, alors <span class="math inline">\(\mathbb{E}(X)\leq\mathbb{E}(Y)\)</span>.</p>
</div>
<p></p>
<p><strong>Démonstration. i.</strong> Si <span class="math inline">\(X=a\)</span> est constante, alors elle a pour support <span class="math inline">\(R_x=\{a\}\)</span> et donc <span class="math inline">\(\mathbb{E}(X)=\mathbb{P}(X=a).a=1.a=a\)</span>.</p>
<p></p>
<p><strong>ii.</strong> Ici, il est plus simple d’utiliser la variante de la définition de l’espérance puisque dans ce cas la linéarité de l’espérance n’est rien d’autre qu’une traduction de la linéarité de l’opérateur <span class="math inline">\(\Sigma\)</span> :</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X+\lambda Y)&amp;=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\left(X(\omega)+\lambda\,Y(\omega)\right) \\
&amp;=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})X(\omega)+\lambda\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})Y(\omega) \\
&amp;=\mathbb{E}(X)+\lambda\,\mathbb{E}(Y) \\
\end{align}\]</span></p>
<p></p>
<p><strong>iii.</strong> <span class="math inline">\(X\)</span> étant positive, on a <span class="math inline">\(\mathbb{E}(X)=\sum\limits_{\omega}\mathbb{P}(\{\omega\})X(\omega)\geq 0\)</span>.</p>
<p><strong>iv.</strong> <span class="math inline">\(Y-X\geq 0\)</span> donc par positivité de l’espérance on a <span class="math inline">\(\mathbb{E}(Y-X)\geq 0\)</span>, et par linéarité on en déduit que <span class="math inline">\(\mathbb{E}(X)\leq\mathbb{E}(Y)\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>
<p><strong>Exemples. i. Espérance d’une loi uniforme finie.</strong> Sot <span class="math inline">\(X\)</span> une loi uniforme sur <span class="math inline">\(R_X=\{x_1,\dots,x_n\}\)</span>. On a donc <span class="math inline">\(\mathbb{P}(X=x_k)=\frac{1}{n}\)</span>, pour tout entier <span class="math inline">\(1\leq k\leq n\)</span>. D’où</p>
<p><span class="math display">\[\mathbb{E}(X)=\frac{1}{n}\sum\limits_{k=1}^n x_k=\overline{x_n}\]</span>
autrement dit, <span class="math inline">\(\mathbb{E}(X)\)</span> est la moyenne arithmétique des réels <span class="math inline">\(x_1,\dots, x_n\)</span>.</p>
<p></p>
<p><strong>ii. Espérance d’une loi de Bernoulli <span class="math inline">\(\mathcal{B}(p)\)</span>.</strong> On a</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X)&amp;=0\times (1-p)+1\times p \\
&amp;= p
\end{align}\]</span></p>
<p>On en profite pour signaler une égalité extrêment simple mais souvent utile en pratique :</p>
<div class="thmbox def">
<p><strong>Espérance d’une indicatrice.</strong> Pour tout événement <span class="math inline">\(A\)</span>, on note <span class="math inline">\(\mathbb{1}_A\)</span> la variable aléatoire appelée <strong>indicatrice de <span class="math inline">\(A\)</span></strong>, définie par</p>
<p><span class="math display">\[\mathbb{1}_A=
\left \{
\begin{array}{c @{=} c}
    1 &amp; \text{ si } A \text{ est réalisé } \\
    0 &amp; \text{ sinon}
\end{array}
\right.
\]</span>
autrement dit, pour tout <span class="math inline">\(\omega\in\Omega\)</span> :</p>
<p><span class="math display">\[\mathbb{1}_A(\omega)=
\left \{
\begin{array}{c @{=} c}
    1 &amp; \text{ si } \omega\in A \\
    0 &amp; \text{ sinon}
\end{array}
\right.
\]</span>
<span class="math inline">\(\mathbb{1}_A\)</span> suit une loi de Bernoulli de paramètre <span class="math inline">\(p=\mathbb{P}(A)\)</span>, donc en particulier on a</p>
<p><span class="math display">\[\mathbb{E}(\mathbb{1}_A)=\mathbb{P}(A)\]</span></p>
</div>
<p>Un exemple classique d’application de cette égalité est l’<strong>inégalité de Markov</strong>, qui est démontrée un peu plus bas.</p>
<p><strong>iii. Espérance d’une loi binomiale <span class="math inline">\(\mathcal{B}(n,p)\)</span>.</strong> Pour <span class="math inline">\(X\sim\mathcal{B}(n,p)\)</span>, on peut écrire <span class="math inline">\(X=\sum\limits_{i=1}^n X_i\)</span> avec <span class="math inline">\(X_i\sim\mathcal{B}(p)\)</span>. On a donc
<span class="math display">\[\begin{align}
\mathbb{E}\left(\sum\limits_{i=1}^n X_i\right) &amp;= \sum\limits_{i=1}^n \mathbb{E}(X_i) \\
&amp;=np \\
\end{align}\]</span></p>
<p>d’après ii.</p>
<p></p>
<p><strong>iv. Espérance d’une loi de Poisson <span class="math inline">\(\mathcal{P}(\lambda)\)</span>.</strong> Soit <span class="math inline">\(X\sim\mathcal{P}(\lambda)\)</span> avec <span class="math inline">\(\lambda&gt;0\)</span>. La série <span class="math inline">\(\sum\limits_{k}\frac{\lambda^k}{k!}k\)</span> est convergente, de somme</p>
<p><span class="math display">\[\begin{align}
\sum\limits_{k=0}^{\infty}\frac{\lambda^k}{k!}k &amp;= \sum\limits_{k=1}^{\infty}\frac{\lambda^k}{(k-1)!} \\
&amp;= \lambda \sum\limits_{k=1}^{\infty}\frac{\lambda^{k-1}}{(k-1)!} \\
&amp;= \lambda\sum\limits_{k=0}^{\infty}\frac{\lambda^k}{k!} \\
&amp;= \lambda e^{\lambda} \\
\end{align}\]</span></p>
<p>Par conséquent, <span class="math inline">\(X\)</span> admet une espérance et <span class="math inline">\(\mathbb{E}(X)=\lambda\)</span>.</p>
<p></p>
<p><strong>v. Espérance d’une loi géométrique <span class="math inline">\(\mathcal{G}(p)\)</span>.</strong> On montre que si <span class="math inline">\(X\sim\mathcal{G}(p)\)</span>, avec <span class="math inline">\(p\in ]0;1[\)</span> alors <span class="math inline">\(X\)</span> admet une espérance et <span class="math display">\[\mathbb{E}(X)=\frac{1}{p}\]</span></p>
<p>Pour cela on utilise le résultat suivant (seule l’égalité ii. est utile pour le calcul de l’espérance) :</p>
<div class="thmbox thm">
<center>
<strong>Série géométrique, séries géométriques dérivées</strong>
</center>
<p></p>
<p>Soit <span class="math inline">\(x\)</span> un réel tel que <span class="math inline">\(|x|&lt;1\)</span>. Alors :</p>
<p></p>
<p><strong>i.</strong> <span class="math inline">\(\sum\limits_{n=0}^{\infty}x^n=\frac{1}{1-x}\)</span></p>
<p></p>
<p><strong>ii.</strong> <span class="math inline">\(\sum\limits_{n=1}^{\infty}nx^{n-1}=\frac{1}{(1-x)^2}\)</span></p>
<p></p>
<p><strong>iii.</strong> <span class="math inline">\(\sum\limits_{n=2}^{\infty}n(n-1)x^{n-2}=\frac{2}{(1-x)^3}\)</span></p>
</div>
<p></p>
<p><strong>Démonstration. i.</strong> Il s’agit de la somme d’une série géométrique de raison <span class="math inline">\(x\)</span> tel que <span class="math inline">\(|x|&lt;1\)</span>. Pour <span class="math inline">\(n\)</span> un entier tel que <span class="math inline">\(n\geq 1\)</span>, on a <span class="math inline">\(\sum\limits_{k=0}^n x^k=\frac{1-x^{n+1}}{1-x}\)</span>. Comme <span class="math inline">\(|x|&lt;1\)</span> on a <span class="math inline">\(x^{n+1}\to 0\)</span> lorsque <span class="math inline">\(n\to\infty\)</span>. Donc la série <span class="math inline">\(\sum\limits_{n}x^n\)</span> est convergente, de somme <span class="math inline">\(\frac{1}{1-x}\)</span>.</p>
<p></p>
<p><strong>ii.</strong> Pour <span class="math inline">\(n\)</span> entier supérieur ou égal à <span class="math inline">\(1\)</span>, on pose <span class="math inline">\(S_n(x)=\sum\limits_{k=1}^n kx^{k-1}\)</span>. On a <span class="math inline">\(S_n=T_n^{&#39;}\)</span>, avec <span class="math inline">\(T_n(x)=\sum\limits_{k=0}^n x^k=\frac{1-x^{n+1}}{1-x}\)</span>. On a donc, pour <span class="math inline">\(x\)</span> réel tel que <span class="math inline">\(|x|&lt;1\)</span> :</p>
<p><span class="math display">\[\begin{align}
S_n(x)&amp;=T_n^{&#39;}(x) \\
&amp;=\frac{-(n+1)x^n+(n+1)x^{n+1}+1-x^{n+1}}{(1-x)^2} \\
&amp;=\frac{1-(n+1)x^n+nx^{n+1}}{(1-x)^2} \\
&amp;\to\frac{1}{(1-x)^2}\, \text{ lorsque } n\to\infty \\
\end{align}\]</span></p>
<p>par croissances comparées. La série <span class="math inline">\(\sum\limits_{n}nx^{n-1}\)</span> est donc convergente de somme <span class="math inline">\(\frac{1}{(1-x)^2}\)</span>, ce qui permet de conclure.</p>
<p></p>
<p><strong>iii.</strong> L’égalité se montre exactement de la même façon que l’égalité ii.</p>
<p><span class="math inline">\(\square\)</span></p>
<p>Avec ce qui précède, la série <span class="math inline">\(\sum\limits_{n}\mathbb{P}(X=n)n=\sum\limits_{n}p\,n\,(1-p)^{n-1}\)</span> est convergente, de somme <span class="math inline">\(\frac{p}{(1-(1-p))^2}=\frac{1}{p}\)</span>. Autrement dit, <span class="math inline">\(X\)</span> admet une espérance et <span class="math inline">\(\mathbb{E}(X)=\frac{1}{p}\)</span>.</p>
<p></p>
<p><strong>vi. Espérance d’une loi hypergéométrique <span class="math inline">\(\mathcal{H}(N,D,n)\)</span>.</strong> On note <span class="math inline">\(X\)</span> le nombre de boules blanches tirées lors de <span class="math inline">\(n\)</span> tirages successifs sans remise dans une urne contenant <span class="math inline">\(D\)</span> boules blanches et <span class="math inline">\(N-D\)</span> boules rouges. On a</p>
<p><span class="math display">\[X=\sum\limits_{i=1}^n X_i\]</span>
avec <span class="math inline">\(X_i=1\)</span> si lors du tirage numéro <span class="math inline">\(i\)</span> la boule est blanche, et <span class="math inline">\(X_i=0\)</span> si elle est rouge. On a <span class="math inline">\(X_i\sim\mathcal{B}(p_i)\)</span>, avec <span class="math inline">\(p_i=\mathbb{P}(X=i)\)</span>, et donc</p>
<p><span class="math display">\[\mathbb{E}(X)=\sum\limits_{k=1}^n\mathbb{E}(X_i)=\sum\limits_{i=1}^n p_i\]</span>
Montrons que <span class="math inline">\(p_i\)</span> est constant : <span class="math inline">\(p_i=p\)</span>. Pour cela, on note <span class="math inline">\(a_i\)</span> (resp. <span class="math inline">\(b_i\)</span>) le nombre de boules blanches (resp. rouges) restantes dans l’urne au moment du tirage numéro <span class="math inline">\(i\)</span>. Alors <span class="math inline">\(p_i=\frac{a_i}{b_i}\)</span> et :</p>
<ul>
<li><p>si <span class="math inline">\(X_i=1\)</span>, on a <span class="math inline">\((a_{i+1},b_{i+1})=(a_i-1,b_i)\)</span></p></li>
<li><p>si <span class="math inline">\(X_i=0\)</span>, on a <span class="math inline">\((a_{i+1},b_{i+1})=(a_i,b_i-1)\)</span></p></li>
</ul>
<p>D’où</p>
<p><span class="math display">\[\begin{align}
p_{i+1}&amp;=\mathbb{P}(X_{i+1}=1|X_i=1)\,p_i+\mathbb{P}(X_{i+1}=1|X_i=0)\frac{b_i}{a_i+b_i}(1-p_i) \\
&amp;=\frac{a_i-1}{a_i+b_i-1}\frac{a_i}{a_i+b_i}+\frac{a_i}{a_i+b_i-1}\frac{b_i}{a_i+b_i} \\
&amp;=\frac{a_i(a_i+b_i-1)}{(a_i+b_i-1)(a_i+b_i)} \\
&amp;=\frac{a_i}{a_i+b_i} \\
&amp;=p_i
\end{align}\]</span></p>
<p>Ainsi, <span class="math inline">\(p_i\)</span> ne dépend pas de <span class="math inline">\(i\)</span> : <span class="math inline">\(p_i=p=p_1=\frac{N}{D}\)</span>, et donc</p>
<p><span class="math display">\[\mathbb{E}(X)=np\]</span></p>
<p>Plus généralement, on peut définir la notion de <strong>moment</strong> :</p>
<div class="defbox thm">
<center>
<strong>Moments d’une variable aléatoire</strong>
</center>
<p>Soient <span class="math inline">\(X\)</span> une variable aléatoire et <span class="math inline">\(r\in\mathbb{N}\)</span>. Si <span class="math inline">\(X^r\)</span> admet une espérance finie, alors</p>
<p><span class="math display">\[m_r=\mathbb{E}(X^r)\]</span>
s’appelle <strong>moment d’ordre <span class="math inline">\(r\)</span></strong> de <span class="math inline">\(X\)</span>.</p>
<p>De même, en notant <span class="math inline">\(\mu=\mathbb{E}(X)\)</span>, si <span class="math inline">\((X-\mu)^r\)</span> admet une espérance finie alors on appelle <strong>moment centré d’ordre <span class="math inline">\(r\)</span></strong> le réel</p>
<p><span class="math display">\[\mu_r=\mathbb{E}\left((X-\mu)^r\right)\]</span>
</p>
<p><strong>Cas <span class="math inline">\(r=1\)</span> et <span class="math inline">\(r=2\)</span> (toujours sous réserve d’existence) :</strong></p>
<ul>
<li><span class="math inline">\(\mu_1=0\)</span></li>
<li><span class="math inline">\(\mu_2\)</span> s’appelle la <strong>variance</strong> de <span class="math inline">\(X\)</span>, notée <span class="math inline">\(\mathbb{V}(X)\)</span> :</li>
</ul>
<p><span class="math display">\[\mathbb{V}(X)=\mathbb{E}\left((X-\mu)^2\right)\]</span>
Si <span class="math inline">\(X\)</span> admet une variance, on appelle <strong>écart-type</strong> de <span class="math inline">\(X\)</span> le réel positif</p>
<p><span class="math display">\[\sigma_X=\sqrt{\mathbb{V}(X)}\]</span></p>
</div>
<p></p>
<p><strong>Remarques. i.</strong> La formule <span class="math inline">\(\mu_1=0\)</span> est une conséquence directe de la linéarité de l’espérance : <span class="math inline">\(\mu_1=\mathbb{E}(X-\mu)=\mathbb{E}(X)-\mu=0\)</span>.</p>
<p></p>
<p><strong>ii.</strong> L’espérance est un indicateur de position d’une variable aléatoire, alors que la variance et l’écart-type sont des indicateurs de dispersion. L’écart-type présente l’avantage sur la variance d’être de même dimension que la variable (tout comme l’espérance).</p>
<p>La formule de König-Huygens permet d’exprimer la variance à partir des moments d’ordre 1 et 2 :</p>
<div class="thmbox thm">
<center>
<strong>Formule de König-Huygens</strong>
</center>
<p>
Soit <span class="math inline">\(X\)</span> une variable aléatoire réelle discrète admettant une variance. Alors</p>
<p><span class="math display">\[\mathbb{V}(X)=\mathbb{E}(X^2)-\mathbb{E}(X)^2\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> En posant <span class="math inline">\(\mu=\mathbb{E}(X)\)</span>, on a</p>
<p><span class="math display">\[(x-\mu)^2=X^2-2\mu X+\mu^2\]</span>
En passant à l’espérance :</p>
<p><span class="math display">\[\begin{align}
\mathbb{V}(X)&amp;=\mathbb{E}(X^2)-2\mu^2+\mu^2 \\
&amp;=\mathbb{E}(X^2)-\mu^2 \\
\end{align}\]</span>
d’où le résultat.
<span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Remarque.</strong> En pratique, c’est souvent cette formule que l’on utilise pour calculer une variance, qui est plus simple que celle de la définition.</p>
<div class="thmbox thm">
<center>
<strong>Propriétés de la variance</strong>
</center>
<p>Soient <span class="math inline">\(X\)</span> une variable aléatoire réelle discrète admettant une variance, et <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> deux réels. Alors :</p>
<p></p>
<p><strong>i.</strong> <span class="math inline">\(\mathbb{V}(X)\geq 0\)</span> avec égalité si et seulement si <span class="math inline">\(X\)</span> est constante.</p>
<p></p>
<p><strong>ii.</strong> <span class="math inline">\(\mathbb{V}(aX+b)=a^2\mathbb{V}(X)\)</span>.</p>
</div>
<p></p>
<p><strong>Démonstration. i.</strong> On note <span class="math inline">\(\{x_k\,;\,k\in K\subset\mathbb{N}\}\)</span> les valeurs prises par <span class="math inline">\(X\)</span> et <span class="math inline">\(p_k=\mathbb{P}(X=x_k)&gt;0\)</span>.</p>
<p><span class="math inline">\(\mathbb{V}(X)=\sum\limits_{k\in K}p_k\,(x_k-\mu)^2=0\)</span> si et seulement si <span class="math inline">\(x_k=\mu\)</span> pour tout <span class="math inline">\(k\)</span> dans <span class="math inline">\(K\)</span>, autrement dit si et seulement si <span class="math inline">\(X\)</span> est constante, égale à son espérance <span class="math inline">\(\mu\)</span>.</p>
<p></p>
<p><strong>ii.</strong> <span class="math inline">\(\mathbb{E}(aX+b)=a\mu+b\)</span>, donc <span class="math inline">\(\left(aX+b-\mathbb{E}(aX+b)\right)^2=a^2(X-\mu)^2\)</span>, et en passant à l’espérance on en déduit que <span class="math inline">\(\mathbb{V}(aX+b)=a^2\,\mathbb{V}(X)\)</span>.</p>
<p><span class="math inline">\(\square\)</span></p>
<p><strong>Exemples. i. Variance d’une loi uniforme.</strong> Soit <span class="math inline">\(X\)</span> uniforme sur l’ensemble fini <span class="math inline">\(\{x_1,\dots,x_n\}\)</span>. Alors</p>
<p><span class="math display">\[\mathbb{E}(X^2)=\frac{1}{n}\sum\limits_{k=1}^n x_k^2\]</span>
et donc</p>
<p><span class="math display">\[\mathbb{V}(X)=\frac{1}{n}\sum\limits_{k=1}^n x_k^2-\left(\frac{1}{n}\sum\limits_{k=1}^n x_k\right)^2\]</span></p>
<p></p>
<p><strong>ii. Variance d’une loi de Bernoulli <span class="math inline">\(\mathcal{B}(p)\)</span>.</strong> Si <span class="math inline">\(X\sim\mathcal{B}(p)\)</span>, alors <span class="math inline">\(X^2=X\)</span> (car <span class="math inline">\(X\in\{0,1\}\)</span>) donc <span class="math inline">\(\mathbb{E}(X^2)=\mathbb{E}(X)=p\)</span>, d’où</p>
<p><span class="math display">\[\mathbb{V}(X)=p\,(1-p)\]</span></p>
<p></p>
<p><strong>iii. Variance d’une loi binomiale <span class="math inline">\(\mathcal{B}(n,p)\)</span>.</strong> On démontrera un peu plus loin que, si <span class="math inline">\(X\sim\mathcal{B}(n,p)\)</span>, alors</p>
<p><span class="math display">\[\mathbb{V}(X)=n\,p\,(1-p)\]</span></p>
<p></p>
<p><strong>iv. Variance d’une loi de Poisson <span class="math inline">\(\mathcal{P}(\lambda)\)</span>.</strong> Soit <span class="math inline">\(X\sim\mathcal{P}(\lambda)\)</span>. Soit <span class="math inline">\(n\geq 1\)</span> un entier. On a</p>
<p><span class="math display">\[\begin{align}
\sum\limits_{k=0}^n\frac{\lambda^k}{k!}k^2&amp;=\sum\limits_{k=2}^n\frac{\lambda^k}{k!}k(k-1)+\sum\limits_{k=2}^n\frac{\lambda^k}{k!}k \\
&amp;=\lambda^2\sum\limits_{k=2}^n\frac{\lambda^{k-2}}{(k-2)!}+\lambda\sum\limits_{k=1}^n\frac{\lambda^{k-1}}{(k-1)!} \\
&amp;=\lambda^2\sum\limits_{k=0}^{n-2}\frac{\lambda^k}{k!}+\lambda^k\sum\limits_{k=0}^{n-1}\frac{\lambda^k}{k!} \\
&amp;\to (\lambda^2+\lambda)e^{\lambda} \\
\end{align}\]</span></p>
<p>La série <span class="math inline">\(\sum\limits_{n}\frac{\lambda^n}{n!}n^2\)</span> est donc convergente de somme <span class="math inline">\((\lambda^2+\lambda)e^{\lambda}\)</span>. On en déduit que <span class="math inline">\(X^2\)</span> admet une espérance, et que</p>
<p><span class="math display">\[\mathbb{E}(X^2)=\lambda^2+\lambda\]</span></p>
<p>Comme <span class="math inline">\(\mathbb{E}(X)=\lambda\)</span>, on en déduit que</p>
<p><span class="math display">\[\mathbb{V}(X)=\lambda\]</span></p>
<p></p>
<p><strong>v. Variance d’une loi géométrique <span class="math inline">\(\mathcal{G}(p)\)</span>.</strong> Pour <span class="math inline">\(p\in ]0\,;\,1[\)</span>, on a</p>
<p><span class="math display">\[\sum\limits_{n=2}^{\infty}n(n-1)(1-p)^{n-2}=\frac{2}{p^3}\]</span></p>
<p>soit</p>
<p><span class="math display">\[\sum\limits_{n=1}^{\infty}n(n+1)(1-p)^{n-1}=\frac{2}{p^3}\]</span>
et donc</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X^2)&amp;=p\sum\limits_{n=1}^{\infty}n^2(1-p)^{n-1} \\
&amp;=\frac{2}{p^2}-p\sum\limits_{n=1}^{\infty}n(1-p)^{n-1} \\
&amp;=\frac{2}{p^2}-\mathbb{E}(X) \\
&amp;=\frac{2}{p^2}-\frac{1}{p} \\
&amp;=\frac{2-p}{p^2}
\end{align}\]</span></p>
<p>d’où</p>
<p><span class="math display">\[\begin{align}
\mathbb{V}(X)&amp;=\mathbb{E}(X^2)-\mathbb{E}(X)^2 \\
&amp;=\frac{2-p}{p^2}-\frac{1}{p^2}\\
&amp;=\frac{1-p}{p^2}
\end{align}\]</span></p>
<p></p>
<p><strong>vi. Variance d’une loi hypergéométrique <span class="math inline">\(\mathcal{H}(N,D,n)\)</span>.</strong> Si <span class="math inline">\(X\sim\mathcal{H}(N,D,n)\)</span> alors <span class="math inline">\(X\)</span> admet une variance et</p>
<p><span class="math display">\[\mathbb{V}(X)=\frac{N-n}{N-1}\times\frac{nD}{N}\left(1-\frac{D}{N}\right)\]</span></p>
<p>(formule admise pour le moment)</p>
</div>
<div id="quelques-inégalités-classiques" class="section level3 hasAnchor" number="3.1.9">
<h3><span class="header-section-number">3.1.9</span> Quelques inégalités classiques<a href="variables-aléatoires-discrètes.html#quelques-inégalités-classiques" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Les inégalités qui suivent reviennent souvent dans les exercices et problèmes du concours.</p>
<div class="thmbox thm">
<p><strong>Inégalité triangulaire.</strong> Soit <span class="math inline">\(X\)</span> une variable aléatoire réelle discrète telle que <span class="math inline">\(|X|\)</span> est d’espérance finie. Alors <span class="math inline">\(X\)</span> est d’espérance finie et</p>
<p><span class="math display">\[|\mathbb{E}(X)|\leq\mathbb{E}(|X|)\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Par définition, <span class="math inline">\(X\)</span> est d’espérance finie si et seulement si <span class="math inline">\(|X|\)</span> est d’espérance finie. On a alors :</p>
<p><span class="math display">\[\begin{align}
|\mathbb{E}(X)|&amp;=\left|\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})X(\omega)\right| \\
&amp;\leq\sum\limits_{\omega\in\Omega}|\mathbb{P}(\{\omega\})X(\omega)| \\
&amp;=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})|X(\omega)| \\
&amp;=\mathbb{E}(|X|)
\end{align}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p>L’inégalité triangulaire est un cas particulier d’une inégalité beaucoup plus générale, appelée <strong>inégalité de Jensen</strong>.</p>
<p></p>
<p><strong>Rappel (fonction convexe) :</strong> Soit <span class="math inline">\(I\subset\mathbb{R}\)</span> un intervalle. Une fonction <span class="math inline">\(\varphi:I\longrightarrow\mathbb{R}\)</span> est dite <strong>convexe</strong> si pour tout couple <span class="math inline">\((x,y)\in I^2\)</span> et pour tout réel <span class="math inline">\(t\in [0,1]\)</span> on a</p>
<p><span class="math display">\[\varphi(tx+(1-t)y)\leq t\,\varphi(x)+(1-t)\,\varphi(y)\]</span></p>
<p>Cette définition admet une interprétation graphique simple : <span class="math inline">\(\varphi\)</span> est convexe si et seulement si sa courbe représentative est située <strong>en-dessous</strong> de chacune de ses <strong>cordes</strong>.</p>
<p>On peut montrer que cette définition de la convexité est équivalente à la définition suivante : <span class="math inline">\(\varphi:I\longrightarrow\mathbb{R}\)</span> est convexe si et seulement si pour tout <span class="math inline">\(n-\)</span>uplet <span class="math inline">\((t_1,\dots t_n)\)</span> de réels positifs tels que <span class="math inline">\(t_1+\dots t_n=1\)</span>, pour tout <span class="math inline">\(n-\)</span>uplet <span class="math inline">\((x_1,\dots, x_n)\)</span> de réels, on a</p>
<p><span class="math display">\[\varphi(t_1x_1+\dots t_n x_n)\leq t_1\,\varphi(x_1)+\dots t_n\,\varphi(x_n)\]</span></p>
<p>Dans le cas où <span class="math inline">\(\varphi\)</span> est dérivable sur <span class="math inline">\(I\)</span>, elle est convexe si et seulement si sa dérivée <span class="math inline">\(\varphi^{&#39;}\)</span> est croissante sur <span class="math inline">\(I\)</span>, autrement dit si la pente de sa courbe représentative est croissante. On peut montrer que cela revient encore à dire que la courbe représentative de <span class="math inline">\(\varphi\)</span> est située <strong>au-dessus</strong> de chacune de ses tangentes.</p>
<p>Dans le cas où <span class="math inline">\(\varphi\)</span> est deux fois dérivable sur <span class="math inline">\(I\)</span>, avec ce qui précède on obtient immédiatement que <span class="math inline">\(\varphi\)</span> est convexe si et seulement si <span class="math inline">\(\varphi^{&#39;&#39;}\geq 0\)</span> sur <span class="math inline">\(I\)</span>.</p>
<p>Enfin, on dit que <span class="math inline">\(\varphi:I\longrightarrow\mathbb{R}\)</span> est <strong>concave</strong> sur <span class="math inline">\(I\)</span> si et seulement si <span class="math inline">\(-\varphi\)</span> est convexe sur <span class="math inline">\(I\)</span>.</p>
<div class="thmbox thm">
<p><strong>Inégalité de Jensen.</strong> Soient <span class="math inline">\(I\)</span> un intervalle réel, <span class="math inline">\(\varphi:I\longrightarrow\mathbb{R}\)</span> une fonction convexe et <span class="math inline">\(X:\Omega\longrightarrow I\)</span> une variable aléatoire discrète à valeurs dans <span class="math inline">\(I\)</span>, admettant une espérance et telle que <span class="math inline">\(\varphi(X)\)</span> admet une espérance. Alors</p>
<p><span class="math display">\[\varphi\left(\mathbb{E}(X)\right)\leq\mathbb{E}\left(\varphi(X)\right)\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> On démontre l’inégalité dans le cas où <span class="math inline">\(\varphi\)</span> est dérivable. Dans ce cas, la convexité de <span class="math inline">\(\varphi\)</span> signifie que la courbe représentative de <span class="math inline">\(f\)</span> est située au-dessus de chacune de ses <strong>tangentes</strong>. Pour tout réel <span class="math inline">\(a\)</span> dans <span class="math inline">\(I\)</span>, on a donc</p>
<p><span class="math display">\[\forall x\in I,\, \varphi(x)\geq \varphi(a)+(x-a)\,\varphi&#39;(a)\]</span>
et donc en particulier pour <span class="math inline">\(a=\mathbb{E}(X)\)</span> et <span class="math inline">\(x=X\)</span> on obtient</p>
<p><span class="math display">\[\varphi(X)\geq\varphi\left(\mathbb{E}(X)\right)+\left(X-\mathbb{E}(X)\right)\,\varphi&#39;\left(\mathbb{E}(X)\right)\]</span>
En passant à l’espérance, on obtient</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(\varphi(X))&amp;\geq\mathbb{E}\left(\varphi(\mathbb{E}(X))+\left(X-\mathbb{E}(X)\right)\,\varphi&#39;(\mathbb{E}(X))\right) \\
&amp;=\varphi(\mathbb{E}(X))+(\mathbb{E}(X)-\mathbb{E}(X))\,\varphi&#39;(\mathbb{E}(X)) \\
&amp;=\varphi(\mathbb{E}(X))
\end{align}\]</span></p>
<p>par croissance et linéarité de l’espérance.</p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Remarque.</strong> Dans le cas où <span class="math inline">\(X\)</span> est à support fini <span class="math inline">\(\{x_1,\dots, x_n\}\)</span> on a</p>
<p><span class="math display">\[\begin{align}
\varphi(\mathbb{E}(X))&amp;=\varphi\left(\sum\limits_{k=1}^n\mathbb{P}(X=x_k)\,x_k\right) \\
&amp;\leq\sum\limits_{k=1}^n\mathbb{P}(X=x_k)\,\varphi(x_k) \,\text{ ; par convexité} \\
&amp;=\mathbb{E}\left(\varphi(X)\right) \\
\end{align}\]</span></p>
<p>Le cas discret infini revient à étendre cette inégalité à des sommes infinies (sous réserve d’existence), autrement dit à écrire que</p>
<p><span class="math display">\[\varphi\left(\sum\limits_{k=1}^{\infty}\mathbb{P}(X=x_k)\,x_k\right)\leq\sum\limits_{k=1}^{\infty}\mathbb{P}(X=x_k)\,\varphi(x_k)\]</span>
</p>
<p><strong>Exemples. i.</strong> L’inégalité triangulaire est un cas particulier d’application de l’inégalité de Jensen à la fonction valeur absolue, qui est bien convexe sur <span class="math inline">\(\mathbb{R}\)</span>.</p>
<p></p>
<p><strong>ii.</strong> La fonction <span class="math inline">\(x\mapsto x^2\)</span> est convexe sur <span class="math inline">\(\mathbb{R}\)</span>, donc, sous réserve d’existence des espérances, on a</p>
<p><span class="math display">\[\mathbb{E}(X)^2\leq\mathbb{E}(X^2)\]</span>
Les deux inégalités qui suivent sont des <strong>inégalités de concentration</strong>. Une inégalité de concentration donne un majorant à la probabilité qu’une variable aléatoire positive s’écarte d’une certaine valeur.</p>
<p>L’inégalité de Markov est à la fois très utile et très facile à démontrer. Il faut retenir qu’elle permet de montrer l’inégalité de Bieanymé-Tchébychev.</p>
<div class="thmbox thm">
<p><strong>Inégalité de Markov.</strong> Soit <span class="math inline">\(X\)</span> une variable aléatoire <strong>positive</strong> admettant une espérance. Alors, pour tout réel <span class="math inline">\(a\)</span> positif :</p>
<p><span class="math display">\[\mathbb{P}(X\geq a)\leq\frac{\mathbb{E}(X)}{a}\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Soit <span class="math inline">\(a\)</span> un réel positif. Toute réalisation <span class="math inline">\(X(\omega)\)</span> est soit supérieure ou égale à <span class="math inline">\(a\)</span>, soit strictement inférieure à <span class="math inline">\(a\)</span>. On a donc l’égalité</p>
<p><span class="math display">\[X=X.\mathbb{1}_{X\geq a}+X.\mathbb{1}_{X&lt;a}\]</span></p>
<p>d’où</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X)&amp;=\mathbb{E}(X.\mathbb{1}_{X\geq a}+X.\mathbb{1}_{X&lt;a}) \\
&amp;=\mathbb{E}(X.\mathbb{1}_{X\geq a})+\mathbb{E}(X.\mathbb{1}_{X&lt;a}) \\
&amp;\geq a\mathbb{E}(\mathbb{1}_{X\geq a}) \\
&amp;=a\mathbb{P}(X\geq a)
\end{align}\]</span></p>
<p>d’où (puisque <span class="math inline">\(a&gt;0\)</span>) :</p>
<p><span class="math display">\[\mathbb{P}(X\geq a)\leq\frac{\mathbb{E}(X)}{a}\]</span>
<span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Exemples. i.</strong> Démontrer que pour toute variable aléatoire <span class="math inline">\(X\)</span> et pour tout réel <span class="math inline">\(a\)</span>, on a <span class="math inline">\(\mathbb{P}(X\geq a)\leq\mathbb{E}(e^{X-a})\)</span>.</p>
<p></p>
<p><strong>Solution.</strong> Posons <span class="math inline">\(Y=e^{X-a}\)</span> : il s’agit d’une variable aléatoire positive. Par ailleurs, l’événement <span class="math inline">\((X\geq a)\)</span> peut aussi s’écrire <span class="math inline">\((Y\geq 1)\)</span>. Donc, par application de l’inégalité de Markov :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X\geq a)&amp;=\mathbb{P}(Y\geq 1) \\
&amp;\leq\frac{\mathbb{E}(Y)}{1} \\
&amp;=\mathbb{E}(e^{X-a})
\end{align}\]</span></p>
<p></p>
<p><strong>ii.</strong> Soient <span class="math inline">\(X\)</span> une variable aléatoire et <span class="math inline">\(f:\mathbb{R}_+\longrightarrow\mathbb{R}_+\)</span> une fonction strictement croissante. Démontrer :</p>
<p><span class="math display">\[\forall a&gt;0,\,\mathbb{P}(|X|\geq a)\leq\frac{\mathbb{E}(f(|X|))}{f(a)}\]</span>
</p>
<p><strong>Solution.</strong> On pose <span class="math inline">\(Y=f(|X|)\)</span> : on a <span class="math inline">\(Y\geq 0\)</span>, puisque <span class="math inline">\(f\)</span> est une fonction de <span class="math inline">\(\mathbb{R}_+\)</span> dans lui-même. Comme <span class="math inline">\(f\)</span> est croissante, les événements <span class="math inline">\((|X|\geq a)\)</span> et <span class="math inline">\((Y\geq f(a))\)</span> sont égaux. D’où, par l’inégalité de Markov :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(|X|\geq a)&amp;=\mathbb{P}(Y\geq f(a)) \\
&amp;\leq\frac{\mathbb{E}(Y)}{f(a)} \\
&amp;=\frac{\mathbb{E}(f(|X|))}{f(a)}
\end{align}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p>Lorsque <span class="math inline">\(X\)</span> admet des moments d’ordres <span class="math inline">\(1\)</span> et <span class="math inline">\(2\)</span>, on peut appliquer l’<strong>inégalité de Bienaymé-Tchebychev</strong>, qui se déduit de façon immédiate de l’inégalité de Markov :</p>
<div class="thmbox thm">
<p><strong>Inégalité de Bienaymé-Tchebychev.</strong> Soit <span class="math inline">\(X\)</span> une variable aléatoire admettant une espérance et une variance. Alors, pour tout réel <span class="math inline">\(a\)</span> strictement positif :</p>
<p><span class="math display">\[\mathbb{P}\left(|X-\mathbb{E}(X)|\geq a\right)\leq\frac{\mathbb{V}(X)}{a^2}\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> On pose <span class="math inline">\(Y=\left(X-\mathbb{E}(X)\right)^2\geq 0\)</span>. On a <span class="math inline">\(|X-\mathbb{E}(X)|\geq a\Leftrightarrow Y\geq a^2\)</span>. D’après l’inégalité de Markov :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(|X-\mathbb{E}(X)|\geq a)&amp;=\mathbb{P}(Y\geq a^2) \\
&amp;\leq\frac{\mathbb{E}(Y)}{a^2} \\
&amp;=\frac{\mathbb{V}(X)}{a^2} \\
\end{align}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Interprétation.</strong> L’inégalité de Bienaymé-Tchebychev nous dit qu’une variable aléatoire ne peut s’éloigner de son espérance qu’avec une faible probabilité : <span class="math inline">\(\mathbb{P}(|X-\mathbb{E}(X)|\geq a)\)</span> est coincé entre <span class="math inline">\(0\)</span> et <span class="math inline">\(\frac{\mathbb{V}(X)}{a^2}\)</span>, qui devient de plus en plus proche de <span class="math inline">\(0\)</span> au fur et à mesure que <span class="math inline">\(a\)</span> augmente.</p>
<p></p>
<p><strong>Application de l’inégalité de Bienaymé-Tchebychev :</strong> la loi faible des grands nombres, qui sera abordée plus tard.</p>
<p></p>
<p><strong>Exemple.</strong> On joue <span class="math inline">\(1\,000\)</span> fois à pile ou face avec une pièce équilibrée. Montrer que la probabilité d’obtenir entre <span class="math inline">\(480\)</span> et <span class="math inline">\(520\)</span> faces est supérieure ou égale à <span class="math inline">\(0,375\)</span>.</p>
<p></p>
<p><strong>Solution.</strong> On note <span class="math inline">\(X\)</span> le nombre de faces obtenues. <span class="math inline">\(X\)</span> est une variable aléatoire suivant la loi de Benoulli <span class="math inline">\(\mathcal{B}\left(1\,000\,;\,\frac{1}{2}\right)\)</span>. On a <span class="math inline">\(\mathbb{E}(X)=500\)</span> et <span class="math inline">\(\mathbb{V}(X)=250\)</span>. Donc, d’après l’inégalité de Bienaymé-Tchebcychev :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}\left(X\in[480\,;\,520]\right)&amp;=\mathbb{P}(|X-\mathbb{E}(X)|\leq 20) \\
&amp;=1-\mathbb{P}(|X-\mathbb{E}(X)|&gt;20) \\
&amp;\geq 1-\mathbb{P}(|X-\mathbb{E}(X)|\geq 20) \\
&amp;\geq 1-\frac{\mathbb{V}(X)}{20^2} \\
&amp;=1-\frac{250}{400} \\
&amp;=0,375
\end{align}\]</span></p>
<p>d’où le résultat.</p>
<p>Une autre inégalité classique est l’inégalité de Cauchy-Schwarz. Elle sera présentée un peu plus bas, dans la section consacrée aux vecteurs aléatoires.</p>
</div>
</div>
<div id="transformation-dune-variable-aléatoire-discrète" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Transformation d’une variable aléatoire discrète<a href="variables-aléatoires-discrètes.html#transformation-dune-variable-aléatoire-discrète" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Il arrive souvent dans les exercices qu’on étudie des variables aléatoires s’écrivant comme fonctions de variables aléatoires plus simples, ou dont la loi est connue.</p>
<p>Soient <span class="math inline">\(D\)</span> un sous-ensemble au plus dénombrable de <span class="math inline">\(\mathbb{R}\)</span>, <span class="math inline">\(X:\Omega\longrightarrow D\)</span> une variable aléatoire réelle discrète de support <span class="math inline">\(D\)</span>, et <span class="math inline">\(\varphi:D\longrightarrow\mathbb{R}\)</span> une fonction injective. Elle réalise donc une bijection de <span class="math inline">\(D\)</span> sur <span class="math inline">\(\varphi(D)=\{\varphi(x),\,x\in D\}\)</span>.</p>
<p>On pose <span class="math inline">\(Y=\varphi(X)\)</span> : il s’agit d’une variable aléatoire réelle discrète, définie sur <span class="math inline">\(\Omega\)</span> et de support <span class="math inline">\(\varphi(D)\)</span>.</p>
<p>La loi de <span class="math inline">\(Y\)</span> se déduit facilement de celle de <span class="math inline">\(X\)</span>. Pour tout <span class="math inline">\(y\in\varphi(D)\)</span> :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(Y=y)&amp;=\mathbb{P}(\varphi(X)=y)\\
&amp;=\mathbb{P}(X=\varphi^{-1}(y))
\end{align}\]</span></p>
<p></p>
<p><strong>Exemple.</strong> Soit <span class="math inline">\(X\sim\mathcal{P}(\lambda)\)</span>, où <span class="math inline">\(\lambda&gt;0\)</span>. Déterminer la loi de <span class="math inline">\(\ln(X+1)\)</span>.</p>
<p></p>
<p><strong>Solution.</strong> <span class="math inline">\(X\)</span> est à support dans <span class="math inline">\(\mathbb{N}\)</span>, donc <span class="math inline">\(Y=\ln(X+1)\)</span> est à support dans <span class="math inline">\(\{\ln(k),\,k\in\mathbb{N}^*\}\subset\mathbb{R}_+\)</span> et, pour tout <span class="math inline">\(k\in\mathbb{N}^*\)</span> :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(\ln(X+1)=\ln k)&amp;=\mathbb{P}(X=k-1) \\
&amp;=e^{-\lambda}\frac{\lambda^{k-1}}{(k-1)!}
\end{align}\]</span></p>
</div>
<div id="vecteurs-aléatoires" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Vecteurs aléatoires<a href="variables-aléatoires-discrètes.html#vecteurs-aléatoires" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="couple-aléatoire-loi-conjointe-lois-marginales" class="section level3 hasAnchor" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Couple aléatoire : loi conjointe, lois marginales<a href="variables-aléatoires-discrètes.html#couple-aléatoire-loi-conjointe-lois-marginales" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="defbox def">
<center>
<strong>Couple de variables aléatoires, loi conjointe, lois marginales</strong>
</center>
<p>Soient <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> deux variables aléatoires réelles discrètes définies sur le même espace probabilisé <span class="math inline">\((\Omega,\mathcal{P}(\Omega),\mathbb{P})\)</span>.</p>
<p>La variable aléatoire</p>
<p><span class="math display">\[(X,Y):\omega\in\Omega\longrightarrow (X(\omega), Y(\omega))\in\mathbb{R}^2\]</span>
est également une variable aléatoire discrète.
Sa loi, appelée <strong>loi conjointe</strong> de <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span>, est définie par la donnée des probabilités <span class="math inline">\(\mathbb{P}(\{X=x\}\cap\{Y=y\})\)</span> pour tous les couples <span class="math inline">\((x,y)\in X(\Omega)\times Y(\Omega)\)</span>. Ces probabilités seront notées par la suite plus simplement <span class="math inline">\(\mathbb{P}(X=x,Y=y)\)</span>.</p>
<p>Par ailleurs, les lois de <span class="math inline">\(X\)</span> et de <span class="math inline">\(Y\)</span> sont appelées les <strong>lois marginales</strong> du couple <span class="math inline">\((X,Y)\)</span>.</p>
<p>Les lois marginales se déduisent de la loi conjointe :</p>
<p><span class="math display">\[\forall x\in X(\Omega),\, \mathbb{P}(X=x)=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(X=x, Y=y)\]</span>
<span class="math display">\[\forall y\in Y(\Omega),\, \mathbb{P}(Y=y)=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x, Y=y)\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Soit <span class="math inline">\(x\in X(\Omega)\)</span>. Les événements <span class="math inline">\((Y=y), \, y\in Y(\Omega)\)</span> forment un système complet d’événements, donc les événements <span class="math inline">\((X=x, Y=y),\, y\in Y(\Omega)\)</span> constituent une partition de l’événement <span class="math inline">\((X=x)\)</span>. D’après la formule des probabilités totales, on a donc</p>
<p><span class="math display">\[\mathbb{P}(X=x)=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(X=x,Y=y)\]</span>
En échangeant les rôles de <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span>, on obtient la deuxième formule.</p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Notation.</strong> Soient <span class="math inline">\(x_i, \, i\in I\)</span> et <span class="math inline">\(y_j,\,j\in J\)</span> les valeurs prises par <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> (avec <span class="math inline">\(I,J\subset\mathbb{N}\)</span> puisque <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont discrètes). Dans la suite, on notera souvent, pour <span class="math inline">\((i,j)\in I\times J\)</span> :</p>
<p><span class="math display">\[\begin{align}
p_{ij}&amp;=\mathbb{P}(X=x_i, Y=y_j) \\
p_{i.}&amp;=\mathbb{P}(X=x_i) \\
p_{.j}&amp;=\mathbb{P}(Y=y_j)
\end{align}\]</span></p>
<p>Avec ces notations, a donc, pour tout couple <span class="math inline">\((i,j)\in I\times J\)</span> :</p>
<p><span class="math display">\[p_{i.}=\sum\limits_{j\in J}p_{ij}\]</span>
<span class="math display">\[p_{.j}=\sum\limits_{i\in I}p_{ij}\]</span>
</p>
<p><strong>Tableau de contingence.</strong> Un tableau de contingence d’un couple de variables aléatoires contient toutes les informations sur la loi de ce couple :</p>
<center>
<img src="images/tableau_contingence.PNG" /><!-- -->
</center>
<p>On y trouve :</p>
<ul>
<li><p>la loi du couple <span class="math inline">\((X,Y)\)</span>, donnée par les cellules du tableau, en nombre <span class="math inline">\(\text{Card}(X(\Omega))\times\text{Card}(Y(\Omega))\)</span> (éventuellement infini). La probabilité <span class="math inline">\(p_{ij}=\mathbb{P}(X=i, Y=j)\)</span> se trouve dans la cellule située à la ligne <span class="math inline">\(i\)</span> et la colonne <span class="math inline">\(j\)</span> ;</p></li>
<li><p>la loi marginale <span class="math inline">\(\mathbb{P}_Y\)</span> de <span class="math inline">\(Y\)</span> sur la ligne des totaux (en bleu) ;</p></li>
<li><p>la loi marginale <span class="math inline">\(\mathbb{P}_X\)</span> de <span class="math inline">\(X\)</span> sur la colonne des totaux (en rouge).</p></li>
</ul>
<p>Ce tableau doit aussi servir de mise en garde sur le fait que, sauf cas trivial (variable(s) aléatoire(s) constante(s)) :</p>
<center>
<strong>La connaissance des lois marginales ne suffit pas à caractériser la loi du couple</strong>
</center>
<p><br></p>
<p>En effet, les lois marginales correspondent à la ligne des totaux (en bleu) et la colonne des totaux (en rouge). Or, il n’y a pas unicité des nombres <span class="math inline">\(p_{ij}\)</span> permettant de générer cette ligne et cette colonne. La connaissance des <span class="math inline">\(p_{i.}\)</span> et des <span class="math inline">\(p_{.j}\)</span> ne suffit donc pas à reconstruire les <span class="math inline">\(p_{ij}\)</span>. Le premier (contre-)exemple ci-dessous permet de s’en convaincre.</p>
<p><strong>Exemples.i.</strong> On considère les couples de variables aléatoires <span class="math inline">\((X_1, Y_1)\)</span> et <span class="math inline">\((X_2, Y_2)\)</span> dont les lois sont données par les tableaux ci-dessous :</p>
<center>
<img src="images/contingence_exemples.PNG" /><!-- -->
</center>
<p><span class="math inline">\((X_1, Y_1)\)</span> et <span class="math inline">\((X_2, Y_2)\)</span> ont les même lois marginales :</p>
<ul>
<li><span class="math inline">\(X_1\)</span> et <span class="math inline">\(X_2\)</span> ont pour support commun <span class="math inline">\(\{x_1, x_2\}\)</span> et :</li>
</ul>
<p><span class="math display">\[\mathbb{P}(X_1=x_1)=\mathbb{P}(X_2=x_1)=0,6\]</span></p>
<p><span class="math display">\[\mathbb{P}(X_1=x_2)=\mathbb{P}(X_2=x_2)=0,4\]</span></p>
<ul>
<li><span class="math inline">\(Y_1\)</span> et <span class="math inline">\(Y_2\)</span> ont pour support commun <span class="math inline">\(\{y_1, y_2\}\)</span> et :</li>
</ul>
<p><span class="math display">\[\mathbb{P}(Y_1=y_1)=\mathbb{P}(Y_2=y_1)=0,3\]</span></p>
<p><span class="math display">\[\mathbb{P}(X_1=x_2)=\mathbb{P}(X_2=x_2)=0,7\]</span></p>
<p>Pourtant, <span class="math inline">\((X_1, Y_1)\)</span> et <span class="math inline">\((X_2, Y_2)\)</span> n’ont pas les mêmes lois conjointes. Par exemple :</p>
<p><span class="math display">\[\mathbb{P}(X_1=x_1, Y_1=y_1)=0,2\]</span>
<span class="math display">\[\mathbb{P}(X_2=x_1, Y_2=y_1)=0,25\]</span></p>
<p><strong>ii.</strong> On suppose que le couple <span class="math inline">\((X,Y)\)</span> est à valeurs dans <span class="math inline">\(E=\{x_1\dots x_n\}\times\{y_1\dots y_p\}\)</span> et que</p>
<p><span class="math display">\[\forall 1\leq i\leq n, \, \forall 1\leq j\leq p,\,\mathbb{P}(X=x_i, Y=y_j)=\frac{1}{np}\]</span></p>
<p>autrement dit <span class="math inline">\((X,Y)\)</span> consiste en un tirage uniforme dans <span class="math inline">\(E\)</span>. Intuitivement, on devine que <span class="math inline">\(X\)</span> (resp. <span class="math inline">\(Y\)</span>) correspond à un tirage uniforme dans <span class="math inline">\(\{x_1,\dots,x_n\}\)</span> (resp. dans <span class="math inline">\(\{y_1,\dots y_p\}\)</span>). La démonstration est évidente :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X=x_i)&amp;=\sum\limits_{j=1}^p\mathbb{P}(X=x_i, Y=y_j) \\
&amp;=\sum\limits_{j=1}^p\frac{1}{np} \\
&amp;=\frac{1}{n}
\end{align}\]</span></p>
<p>et symétriquement on a évidemment</p>
<p><span class="math display">\[\mathbb{P}(Y=y_j)=\frac{1}{p}\]</span>
</p>
<p><strong>iii.</strong> Soient <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> deux variables aléatoires à valeurs dans <span class="math inline">\(\mathbb{N}\)</span>. On suppose que la loi conjointe de <span class="math inline">\((X,Y)\)</span> est donnée par</p>
<p><span class="math display">\[\mathbb{P}(X=i, Y=j)=\frac{a}{i!\,j!}\]</span>
avec <span class="math inline">\(a\)</span> un réel.</p>
<p>Nous allons déterminer les lois marginales de <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span>. Pour cela, on constate d’abord que la valeur de <span class="math inline">\(a\)</span> est contrainte par l’égalité</p>
<p><span class="math display">\[\sum\limits_{i=0}^{\infty}\sum\limits_{j=0}^{\infty}\mathbb{P}(X=i, Y=j)=1\]</span>
qui s’écrit</p>
<p><span class="math display">\[a\sum\limits_{i=0}^{\infty}\frac{1}{i!}.\sum\limits_{j=0}^{\infty}\frac{1}{j!}=1\]</span>
et qui permet de trouver que</p>
<p><span class="math display">\[a=\frac{1}{e^2}\]</span>
On en déduit que, pour tout entier naturel <span class="math inline">\(i\)</span>, on a :</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X=i&amp;)=\sum\limits_{j=0}^{\infty}\mathbb{P}(X=i, Y=j) \\
&amp;= \frac{1}{e^2}\sum\limits_{j=0}^{\infty}\frac{1}{i!\,j!} \\
&amp;=\frac{1}{e.i!}
\end{align}\]</span></p>
<p>On reconnaît la loi de Poisson <span class="math inline">\(\mathcal{P}(1)\)</span>.</p>
<p><span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> jouant des rôles symétriques, on a donc</p>
<p><span class="math display">\[X\sim\mathcal{P}(1)\]</span>
<span class="math display">\[Y\sim\mathcal{P}(1)\]</span></p>
</div>
<div id="n-uplets-aléatoires" class="section level3 hasAnchor" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> <span class="math inline">\(n-\)</span>uplets aléatoires<a href="variables-aléatoires-discrètes.html#n-uplets-aléatoires" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ce qui précède se généralise sans difficulté aux vecteurs aléatoires de taille quelconque, i.e. aux <span class="math inline">\(n-\)</span>uplets <span class="math inline">\((X_1,\dots,X_n)\)</span> de variables aléatoires discrètes réelles définies sur un même espace probabilisé <span class="math inline">\((\Omega, \mathcal{P}(\Omega), \mathbb{P})\)</span>.</p>
<p>La loi conjointe d’un tel vecteur est définie par la donnée de son support <span class="math inline">\(X_1(\Omega)\times\dots\times X_n(\Omega)\)</span> et des probabilités</p>
<p><span class="math display">\[\mathbb{P}(X_1=x_1,\dots,X_n=x_n)\]</span>
pour tous les <span class="math inline">\(n-\)</span>uplets <span class="math inline">\((x_1,\dots,x_n)\in X_1(\Omega)\times\dots\times X_n(\Omega)\)</span>.</p>
<p>Le vecteur <span class="math inline">\((X_1,\dots,X_n)\)</span> possède <span class="math inline">\(n\)</span> lois marginales, qui sont les lois <span class="math inline">\(\mathbb{P}_{X_1},\dots,\mathbb{P}_{X_n}\)</span> des variables <span class="math inline">\(X_1,\dots,X_n\)</span>.</p>
<p>La loi conjointe d’un vecteur de taille quelconque définit complètement les lois marginales, mais à nouveau les lois marginales ne suffisent pas à définir la loi conjointe.</p>
</div>
</div>
<div id="loi-conditionnelle-mathbbp_xyy_j" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Loi conditionnelle <span class="math inline">\(\mathbb{P}_{X|Y=y_j}\)</span><a href="variables-aléatoires-discrètes.html#loi-conditionnelle-mathbbp_xyy_j" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Soit <span class="math inline">\((X,Y)\)</span> un couple aléatoire dont la loi est donnée par le tableau de contingence suivant :</p>
<center>
<img src="images/tableau_contingence.PNG" /><!-- -->
</center>
<p>La colonne numéro <span class="math inline">\(j\)</span> fixe la valeur de <span class="math inline">\(Y\)</span> à <span class="math inline">\(Y=y_j\)</span>. Considérons la liste des probabilités apparaissant dans cette colonne :</p>
<p><span class="math display">\[p_{1j},\dots,p_{nj}\]</span>
Cette série de valeurs somme à <span class="math inline">\(p_{.j}\)</span> :</p>
<p><span class="math display">\[\sum\limits_{i\in I}p_{ij}=p_{.j}\]</span>
Donc, en divisant toutes ces probabilités par <span class="math inline">\(p_{.j}\)</span>, on obtient des nombres compris entre <span class="math inline">\(0\)</span> et <span class="math inline">\(1\)</span> et qui somment à <span class="math inline">\(1\)</span> :</p>
<p><span class="math display">\[\sum\limits_{i\in I}\frac{p_{ij}}{p_{.j}}=1\]</span>
de sorte que le vecteur <span class="math inline">\(\left(\frac{p_{1j}}{p_{.j}},\dots,\frac{p_{nj}}{p_{.j}},\dots\right)\)</span> peut s’interpréter comme une loi de probabilité. Mais ces valeurs caractérisent la distribution de <span class="math inline">\(X\)</span> lorsqu’on se place dans la colonne numéro <span class="math inline">\(j\)</span>, autrement dit lorsqu’on fait l’hypothèse <span class="math inline">\(Y=j\)</span>. Il est donc naturel d’appeler cette distribution la <strong>loi de <span class="math inline">\(X\)</span> conditionnellement à <span class="math inline">\((Y=y_j)\)</span></strong>.</p>
<p>L’ensemble des lois conditionnelles <span class="math inline">\(\mathbb{P}(X|Y=y_j)\)</span> sont données par le tableau suivant (lecture en colonnes) :</p>
<center>
<img src="images/tableau_x_sachant_y.PNG" /><!-- -->
</center>
<div class="defbox def">
<p><strong>Loi conditionnelle de <span class="math inline">\(X\)</span> sachant <span class="math inline">\(Y=y_j\)</span>.</strong> Avec les notations précédentes, et sous réserve que <span class="math inline">\(\mathbb{P}(Y=y_j)&gt;0\)</span>, on pose, pour tout <span class="math inline">\(x_i\in X(\Omega)\)</span> :</p>
<p><span class="math display">\[\mathbb{P}(X=x_i|Y=y_j)=\frac{\mathbb{P}(X=x_i, Y=y_j)}{\mathbb{P}(Y=y_j)}\]</span></p>
<p>On définit ainsi une loi de probabilité, appelée <strong>loi conditionnelle de <span class="math inline">\(X\)</span> sachant que <span class="math inline">\(Y=y_j\)</span></strong>, et notée <span class="math inline">\(\mathbb{P}_{X|Y=y_j}\)</span>.</p>
</div>
<p></p>
<p><strong>Remarques. i.</strong> De façon symétrique, on définit des lois conditionnelles <span class="math inline">\(\mathbb{P}_{Y|X=x_i}\)</span> pour toutes les valeurs de <span class="math inline">\(i\)</span> telles que <span class="math inline">\(\mathbb{P}(X=x_i)&gt;0\)</span>. Cette loi est définie par la donnée des probabilités</p>
<p><span class="math display">\[\mathbb{P}(Y=y_j|X=x_i)=\frac{\mathbb{P}(X=x_i, Y=y_j)}{\mathbb{P}(X=x_i)}\]</span>
pour tous les <span class="math inline">\(y_j\in Y(\Omega)\)</span>.</p>
<p>L’ensemble de ces lois conditionnelles <span class="math inline">\(\mathbb{P}_{Y|X=x_i}\)</span> sont représentées dans le tableau suivant (lecture en lignes) :</p>
<center>
<img src="images/tableau_y_sachant_x.PNG" /><!-- -->
</center>
<p></p>
<p><strong>ii.</strong> On peut aussi introduire la notion de loi conditionnelle en utilisant directement la définion de probabilité conditionnelle faite au chapitre précédent. Pour deux événements <span class="math inline">\(A\)</span> et <span class="math inline">\(B\)</span> tels que <span class="math inline">\(\mathbb{P}(B)&gt;0\)</span>, on définit la probabilité de <span class="math inline">\(A\)</span> sachant <span class="math inline">\(B\)</span> en posant</p>
<p><span class="math display">\[\mathbb{P}(A|B)=\frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)}\]</span>
En posant <span class="math inline">\(A=(X=x_i)\)</span> et <span class="math inline">\(B=(Y=y_j)\)</span>, on a donc</p>
<p><span class="math display">\[\mathbb{P}(X=x_i|Y=y_j)=\frac{\mathbb{P}(X=x_i, Y=y_j)}{\mathbb{P}(Y=y_j)}\]</span>
L’approche par tableau de contingence présente toutefois l’avantage d’être un peu plus intuitive.</p>
<p></p>
<p><strong>Exemples. i.</strong> On tire aléatoirement deux nombres <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> selon la règle suivante :</p>
<ul>
<li><p>tirage de <span class="math inline">\(X\)</span> selon une loi de Bernoulli de paramètre <span class="math inline">\(p\in ]0,1[\)</span> ;</p></li>
<li><p>puis tirage de <span class="math inline">\(Y\)</span> :</p>
<ul>
<li><p>si <span class="math inline">\(X=0\)</span>, on tire <span class="math inline">\(Y\)</span> selon une loi de Poisson <span class="math inline">\(\mathcal{P}(\lambda)\)</span>, avec <span class="math inline">\(\lambda&gt;0\)</span> ;</p></li>
<li><p>si <span class="math inline">\(X=1\)</span>, on tire <span class="math inline">\(Y\)</span> selon une loi uniforme sur <span class="math inline">\(\{0,1,2,3\}\)</span>.</p></li>
</ul></li>
</ul>
<p>On connait donc la loi de <span class="math inline">\(X\)</span> :
<span class="math display">\[X\sim\mathcal{B}(p)\]</span>
et on connait les lois de <span class="math inline">\(Y\)</span> sachant <span class="math inline">\(X=0\)</span> et de <span class="math inline">\(Y\)</span> sachant <span class="math inline">\(X=1\)</span> :</p>
<p><span class="math display">\[Y|X=0\sim\mathcal{P}(\lambda)\]</span>
<span class="math display">\[Y|X=1\sim\mathcal{U}\left(\{0,1,2,3\}\right)\]</span>
On peut en déduire facilement les lois <span class="math inline">\(\mathbb{P}_Y\)</span> et <span class="math inline">\(\mathbb{P}_{(X,Y)}\)</span>.</p>
<p><strong>Commençons par la loi de <span class="math inline">\(Y\)</span>.</strong></p>
<ul>
<li><strong>Support de <span class="math inline">\(Y\)</span> :</strong> <span class="math inline">\(Y(\Omega)=\mathbb{N}\)</span></li>
<li><strong>Probabilités <span class="math inline">\(\mathbb{P}(Y=j)\)</span> :</strong> pour tout entier naturel <span class="math inline">\(j\)</span>, on a</li>
</ul>
<p><span class="math display">\[\begin{align}
\mathbb{P}(Y=j)&amp;=\mathbb{P}(Y=j|X=0)\mathbb{P}(X=0)+\mathbb{P}(Y=j|X=1)\mathbb{P}(X=1) \\
&amp;=(1-p).\mathbb{P}(Y=j|X=0)+p.\mathbb{P}(Y=j|X=1)
\end{align}\]</span></p>
<p>On en déduit que :</p>
<ul>
<li>si <span class="math inline">\(0\leq j\leq 3\)</span>, alors</li>
</ul>
<p><span class="math display">\[\mathbb{P}(Y=j)=(1-p)\,e^{-\lambda}\frac{\lambda^j}{j!}+\frac{p}{4}\]</span></p>
<ul>
<li>si <span class="math inline">\(j\geq 4\)</span>, alors</li>
</ul>
<p><span class="math display">\[\mathbb{P}(Y=j)=(1-p)\,e^{-\lambda}\frac{\lambda^j}{j!}\]</span>
*On détermine maintenant la loi conjointe de <span class="math inline">\((X,Y)\)</span>**</p>
<ul>
<li><p><strong>Support de <span class="math inline">\((X,Y)\)</span> :</strong> <span class="math inline">\((X,Y)(\Omega)=\{0,1\}\times\mathbb{N}\)</span></p></li>
<li><p><strong>Probabilités <span class="math inline">\(\mathbb{P}(X=i, Y=j)\)</span> :</strong> pour <span class="math inline">\((i,j)\in\{0,1\}\times\mathbb{N}\)</span>, on a</p></li>
<li><p>pour <span class="math inline">\(i=0\)</span> :</p></li>
</ul>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X=0,Y=j)&amp;=\mathbb{P}(Y=j|X=0)\mathbb{P}(X=0) \\
&amp;= (1-p)e^{-\lambda}\frac{\lambda^j}{j!} \\
\end{align}\]</span></p>
<ul>
<li>pour <span class="math inline">\(i=1\)</span>, on a</li>
</ul>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X=1,Y=j)&amp;=\mathbb{P}(Y=j|X=1)\mathbb{P}(X=1) \\
&amp;=\left \{
\begin{array}{c @{=} c}
    \frac{p}{4} &amp; \text{ si } 0\leq j\leq 3 \\
    0 &amp; \text{ si } j\geq 4
\end{array}
\right.
\end{align}\]</span></p>
<p>On peut donner l’expression générale de <span class="math inline">\(\mathbb{P}(X=i, Y=j)\)</span> :</p>
<p><span class="math display">\[\mathbb{P}(X=i, Y=j)=i\,\frac{p}{4}.\mathbb{1}_{0\leq j\leq 3}+(1-i)(1-p)e^{-\lambda}\frac{\lambda^j}{j!}\]</span></p>
<p></p>
<p><strong>On en déduit alors la loi de <span class="math inline">\(Y\)</span>.</strong></p>
<ul>
<li><strong>Support de <span class="math inline">\(Y\)</span> :</strong> <span class="math inline">\(Y(\Omega)=\mathbb{N}\)</span></li>
<li><strong>Probabilités <span class="math inline">\(\mathbb{P}(Y=j)\)</span> :</strong> pour tout entier naturel <span class="math inline">\(j\)</span>, on a, d’après la formule des probabilités totales :</li>
</ul>
<p><span class="math display">\[\begin{align}
\mathbb{P}(Y=j)&amp;=\mathbb{P}(Y=j,X=0)+\mathbb{P}(Y=j,X=1) \\
&amp;=(1-p)e^{-\lambda}\frac{\lambda^j}{j!}+\frac{p}{4}\mathbb{1}_{0\leq j\leq 3}
\end{align}\]</span></p>
<p></p>
</div>
<div id="indépendance-de-deux-variables-aléatoires" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Indépendance de deux variables aléatoires<a href="variables-aléatoires-discrètes.html#indépendance-de-deux-variables-aléatoires" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dans un exemple précédent, on a défini la loi d’un couple aléatoire <span class="math inline">\((X,Y)\)</span> par</p>
<p><span class="math display">\[\forall (i,j)\in\mathbb{N}^2,\,\mathbb{P}(X=i, Y=j)=\frac{1}{e^2\,i!\,j!}\]</span>
et on a montré que les lois marginales sont toutes les deux égales à la loi de Poisson <span class="math inline">\(\mathcal{P}(1)\)</span> :</p>
<p><span class="math display">\[\forall i\in\mathbb{N},\,\mathbb{P}(X=i)=\mathbb{P}(Y=i)=\frac{1}{e.i!}\]</span>
On en déduit que</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X=i|Y=j)&amp;=\frac{\mathbb{P}(X=i, Y=j)}{\mathbb{P}(Y=j)}\\
&amp;=\frac{\frac{1}{e^2\,i!\,j!}}{\frac{1}{e\,j!}} \\
&amp;=\frac{1}{e\,i!} \\
&amp;=\mathbb{P}(X=i)
\end{align}\]</span></p>
<p>De façon analogue :</p>
<p><span class="math display">\[\mathbb{P}(Y=j|X=i)=\mathbb{P}(Y=j)\]</span></p>
<p>Ces deux égalités signifient :</p>
<ul>
<li><p>pour la première, que l’information de la valeur prise par <span class="math inline">\(Y\)</span> n’a aucun impact sur la loi de <span class="math inline">\(X\)</span> ;</p></li>
<li><p>pour la deuxième, que l’information de la valeur prise par <span class="math inline">\(X\)</span> n’a aucun impact sur la loi de <span class="math inline">\(Y\)</span>.</p></li>
</ul>
<p>Dans une telle situation, on dit que les variables aléatoires <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes.</p>
<p>De façon générale, l’indépendance de deux variables aléatoires est définie de façon simple par une égalité (ou plutôt une série d’égalités) :</p>
<div class="defbox def">
<center>
<strong>Indépendance de deux variables aléatoires</strong>
</center>
<p>Deux variables aléatoires réelles discrètes <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> définies sur un même espace probabilisé <span class="math inline">\((\Omega, \mathcal{P}(\Omega),\mathbb{P})\)</span> sont dites <strong>indépendantes</strong> lorsque</p>
<p><span class="math display">\[\forall (x,y)\in X(\Omega)\times Y(\Omega),\, \mathbb{P}(X=x, Y=y)=\mathbb{P}(X=x)\,\mathbb{P}(Y=y)\]</span>
<strong>Notation :</strong> <span class="math inline">\(X\perp\!\!\!\perp Y\)</span></p>
</div>
<p></p>
<p><strong>Remarques. i.</strong> Tout variable aléatoire constante est donc, selon cette définition, indépendante de n’importe quelle variable aléatoire (y compris elle-même !). En effet, soient <span class="math inline">\(X=a\)</span> (<span class="math inline">\(a\in\mathbb{R}\)</span>) une variable aléatoire constante et <span class="math inline">\(Y\)</span> une variable aléatoire quelconque.</p>
<p>On a, pour <span class="math inline">\(x\in\mathbb{R}\)</span> :</p>
<p><span class="math display">\[(X=x)=\left \{
\begin{array}{c @{=} c}
    \Omega &amp; \text{ si } x=a \\
    \emptyset &amp; \text{ si } x\neq a
\end{array}
\right.\]</span></p>
<p>donc</p>
<p><span class="math display">\[\begin{align}
\mathbb{P}(X=x)\,\mathbb{P}(Y=y)&amp;=\left \{
\begin{array}{c @{=} c}
    \mathbb{P}(Y=y) &amp; \text{ si } x=a \\
    0 &amp; \text{ si } x\neq a
\end{array}
\right. \\
&amp;=\mathbb{P}(X=x, Y=y) \\
\end{align}\]</span></p>
<p></p>
<p><strong>ii.</strong> Si deux variables aléatoires sont indépendantes, leur loi conjointe peut donc être reconstruite à partir des lois marginales. Toutefois, à l’exception du cas trivial ou l’une au moins des deux variables est constante, la connaissance du caractère indépendant ou non de ces variables ne peut être acquise à l’aide de la seule information des lois marginales : la propriété d’indépendance est bien une propriété du couple, et non une propriété des lois marginales.</p>
<p><strong>Exemples. i.</strong> On considère deux variables aléatoires sont la loi conjointe est donnée par le tableau de contingence suivant :</p>
<center>
<img src="images/tableau_exemple_loi.PNG" /><!-- -->
</center>
<p>Pour déterminer si <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont ou non indépendantes, on peut ajouter à ce tableau les probabilités marginales :</p>
<center>
<img src="images/tableau_exemple_c.PNG" /><!-- -->
</center>
<p>On constate par exemple que <span class="math inline">\(\mathbb{P}(X=1,Y=1)=0\)</span>, mais <span class="math inline">\(\mathbb{P}(X=1)\,\mathbb{P}(Y=1)\neq 0\)</span> : donc <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> ne sont donc pas indépendantes.</p>
<p></p>
<p><strong>ii.</strong> Cette fois, le couple <span class="math inline">\((X,Y)\)</span> a pour tableau de contingence :</p>
<center>
<img src="images/tableau_exemple2.PNG" /><!-- -->
</center>
<p>Comme dans l’exemple précédent, on le complète des probabilités marginales :</p>
<center>
<img src="images/tableau_exemple2_c.PNG" /><!-- -->
</center>
<p>Cette fois, on constate que chaque probabilité conjointe est égale au produit des probabilités marginales correspondantes, donc <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes.</p>
<p><br></p>
<p></p>
<p>Par définition de l’indépendance de deux variables, l’expression de chaque probabilité conjointe <span class="math inline">\(\mathbb{P}(X=x,Y=y)\)</span> peut s’écrire comme un produit de deux termes : un premier terme qui est une fonction de <span class="math inline">\(x\)</span> uniquement, et un deuxième terme qui est une fonction de <span class="math inline">\(y\)</span> uniquement. Cette possibilité de séparer en un terme en <span class="math inline">\(x\)</span> et en un terme en <span class="math inline">\(y\)</span> a pour conséquence que l’espérance d’un produit de deux variables indépendantes est le produit de leurs espérances :</p>
<div class="thmbox thm">
<p><strong>Théorème.</strong> Soient <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> deux variables aléatoires définies sur un espace probabilisé <span class="math inline">\((\Omega, \mathcal{P}(\Omega), \mathbb{P})\)</span>.</p>
<p>Si <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes, alors, sous réserve d’existence de ces espérances :</p>
<p><span class="math display">\[\mathbb{E}(XY)=\mathbb{E}(X)\,\mathbb{E}(Y)\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong></p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(XY)&amp;=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,X(\omega)\,Y(\omega) \\
&amp;=\sum\limits_{x\in X(\Omega)}\sum\limits_{y\in Y(\omega)}\mathbb{P}(X=x, Y=y)\,x\,y \\
&amp;=\sum\limits_{x\in X(\Omega)}\sum\limits_{y\in Y(\omega)}\mathbb{P}(X=x)\,\mathbb{P}(Y=y)\,x\,y \\
&amp;\text{(indépendance de } X \text{ et } Y \text{)} \\
&amp;\\
&amp;=\left(\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\, x\right).\left(\sum\limits_{y\in Y(\omega)}\mathbb{P}(Y=y)\,y\right) \\
&amp;=\mathbb{E}(X)\,\mathbb{E}(Y) \\
\end{align}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Exemple.</strong> On reprend l’exemple précédent, dans lequel nous avons montré l’indépendance entre <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span>.</p>
<p>On a :</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(X)&amp;=0,4\times 1+0,2\times 2+0,4\times 3 \\
&amp;=2 \\
\end{align}\]</span></p>
<p>et</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(Y)&amp;=0,2\times 1+0,1\times 2+0,4\times 3+0,3\times 4 \\
&amp;=2,8 \\
\end{align}\]</span></p>
<p>Par indépendance de <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span>, on en déduit que</p>
<p><span class="math display">\[\mathbb{E}(XY)=\mathbb{E}(X)\,\mathbb{E}(Y)=5,6\]</span></p>
</div>
<div id="covariance-et-coefficient-de-corrélation-de-deux-variables-aléatoires" class="section level2 hasAnchor" number="3.6">
<h2><span class="header-section-number">3.6</span> Covariance et coefficient de corrélation de deux variables aléatoires<a href="variables-aléatoires-discrètes.html#covariance-et-coefficient-de-corrélation-de-deux-variables-aléatoires" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La <strong>covariance</strong> de deux variables aléatoires mesure à quel point on s’éloigne de l’égalité <span class="math inline">\(\mathbb{E}(XY)=\mathbb{E}(X)\,\mathbb{E}(Y)\)</span>.</p>
<div class="defbox def">
<p><strong>Covariance de deux variables aléatoires.</strong> La <strong>covariance</strong> de deux variables aléatoires <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> est l’espérance, si elle existe, de <span class="math inline">\(\left(X-\mathbb{E}(X)\right).\left(Y-\mathbb{E}(Y)\right)\)</span> :</p>
<p><span class="math display">\[\text{Cov}(X,Y)=\mathbb{E}\left(\left(X-\mathbb{E}(X)\right).\left(Y-\mathbb{E}(Y)\right)\right)\]</span></p>
<p>Elle admet également pour expression :</p>
<p><span class="math display">\[\text{Cov}(X,Y)=\mathbb{E}(XY)-\mathbb{E}(X).\mathbb{E}(Y)\]</span></p>
<p>En particulier, donc, la covariance d’une variance avec elle-même est égale à sa variance :</p>
<p><span class="math display">\[\text{Cov}(X,X)=\mathbb{V}(X)\]</span></p>
<p></p>
<p><strong>Remarque. :</strong> la covariance de <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> est également parfois notée <span class="math inline">\(\sigma_{XY}\)</span>.</p>
</div>
<p></p>
<p><strong>Démonstration de la deuxième formule de la covariance.</strong> On utilise la linéarité de l’espérance :</p>
<p><span class="math display">\[\begin{align}
\text{Cov}(X,Y)&amp;=\mathbb{E}\left((X-\mathbb{E}(X)).(Y-\mathbb{E}(Y))\right) \\
&amp;=\mathbb{E}(XY)-\mathbb{E}(X)\mathbb{E}(Y)-\mathbb{E}(X)\mathbb{E}(Y)+\mathbb{E}(X)\mathbb{E}(Y) \\
&amp;=\mathbb{E}(XY)-\mathbb{E}(X)\mathbb{E}(Y) \\
\end{align}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Remarque.</strong> La deuxième expression de la covariance est généralement préférable car moins coûteuse en calculs.</p>
<p></p>
<p><strong>Interprétation de la covariance.</strong> Comme son nom l’indique, la covariance mesure à quel point, en moyenne, les (versions centrées des) variables <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> covarient. Intuitivement, dire que deux variables ont un lien (que ce lien soit causal ou non), c’est dire que les variations de l’une et celles de l’autre sont concomitantes. Au contraire, si on imagine que l’une de ces deux variables bouge beaucoup alors que l’autre reste constante, on s’attend à ce qu’elles ne soient pas liées l’une à l’autre. La covariance est une simple formalisation de cette idée.</p>
<p><br></p>
<p>La covariance présente l’inconvénient de dépendre de l’échelle des valeurs prises par <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span>. Pour neutraliser cet effet d’échelle, on peut utiliser la <strong>corrélation</strong> :</p>
<div class="defbox def">
<center>
<strong>Corrélation linéaire</strong>
</center>
<p>Soient <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> deux variables aléatoires. Sous réserve d’existence, on appelle <strong>coefficient de corrélation linéaire</strong> entre <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span>, le nombre</p>
<p><span class="math display">\[\rho_{XY}=\frac{\text{Cov}(X,Y)}{\sigma_X\,\sigma_Y}\]</span>
où <span class="math inline">\(\sigma_X\)</span> et <span class="math inline">\(\sigma_Y\)</span> sont les écarts-types de <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span>.</p>
<p>On a l’encadrement suivant :</p>
<p><span class="math display">\[-1\leq\rho_{XY}\leq 1\]</span></p>
</div>
<p>Pour démontrer cet encadrement, on peut utiliser l’inégalité de Cauchy-Schwarz dans l’espace <span class="math inline">\(L^2\)</span>. Cette inégalité, en toute généralité, s’applique dans le cadre théorique des espaces préhilbertiens : des rappels sont en annexe.</p>
<p></p>
<p><strong>L’espace <span class="math inline">\(L^2(\Omega)\)</span>.</strong> On note <span class="math inline">\(L^2(\Omega, \mathcal{P}(\Omega),\mathbb{P})\)</span>, ou plus simplement <span class="math inline">\(L^2(\Omega)\)</span>, l’ensemble des variables aléatoires <span class="math inline">\(X:(\Omega,\mathcal{P}(\Omega),\mathbb{P})\longrightarrow\mathbb{R}\)</span> telles que <span class="math inline">\(\mathbb{E}(X^2)&lt;\infty\)</span>. Cet espace peut être muni d’un produit scalaire :</p>
<p><span class="math display">\[\forall X,Y\in L^2(\Omega),\, &lt;X\,,\,Y&gt;=\mathbb{E}(XY)\]</span>
La norme associée est définie par :</p>
<p><span class="math display">\[\forall X\in L^2(\Omega),\,||X||=\sqrt{\mathbb{E}(X^2)}\]</span></p>
<p>Dans <span class="math inline">\(L^2(\Omega)\)</span>, l’inégalité de Cauchy-Schwarz prend donc la forme suivante :</p>
<div class="thmbox thm">
<p><strong>Inégalité de Cauchy-Schwarz dans <span class="math inline">\(L^2(\Omega)\)</span>.</strong> Soient <span class="math inline">\(X,Y\in L^2(\Omega)\)</span> deux variables aléatoires discrètes. Alors :</p>
<p><span class="math display">\[|\mathbb{E}(XY)|\leq\sqrt{\mathbb{E}(X^2)}\,\sqrt{\mathbb{E}(Y^2)}\]</span>
Cette inégalité s’écrit aussi :</p>
<p><span class="math display">\[\left|\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,X(\omega)\,Y(\omega)\right|\leq\sqrt{\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,X^2(\omega)}\sqrt{\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,Y^2(\omega)}\]</span>
Avec le théorème de transfert, on peut aussi écrire :</p>
<p><span class="math display">\[\left|\sum\limits_{k\in K}\sum\limits_{l\in L}\mathbb{P}(X=x_k, Y=y_l)\,x_k\,y_l\right|\leq\sqrt{\sum\limits_{k\in K}\mathbb{P}(X=x_k)\,x_k^2}\,\sqrt{\sum\limits_{l\in L}\mathbb{P}(Y=y_l)\,y_l^2}\]</span></p>
</div>
<p></p>
<p><strong>Démonstration de l’encadrement <span class="math inline">\(-1\leq\rho_{XY}\leq 1\)</span>.</strong></p>
<p>L’encadrement du coefficient de corrélation linéaire se montre alors en appliquant l’inégalité de Cauchy-Schwarz à <span class="math inline">\(X-\mathbb{E}(X)\)</span> et <span class="math inline">\(Y-\mathbb{E}(Y)\)</span>, sous réserve que ces variables sont bien dans <span class="math inline">\(L^2(\Omega)\)</span> :</p>
<p><span class="math display">\[\begin{align}
\left|\mathbb{E}((X-\mathbb{E}(X)).(Y-\mathbb{E}(Y)))\right|&amp;\leq\sqrt{\mathbb{E}(X-\mathbb{E}(X))^2}\,\sqrt{\mathbb{E}(Y-\mathbb{E}(Y))^2} \\
&amp;=\sqrt{\mathbb{V}(X)}.\sqrt{\mathbb{V}(Y)} \\
&amp;=\sigma_X\,\sigma_Y
\end{align}\]</span></p>
<p>d’où le résultat.</p>
<p><span class="math inline">\(\square\)</span></p>
<p>Nous avons vu que pour deux variables aléatoires indépendantes <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> on a <span class="math inline">\(\mathbb{E}(XY)=\mathbb{E}(X)\mathbb{E}(Y)\)</span>. On peut donc formuler ce résultat ainsi :</p>
<div class="thmbox thm">
<p>
<strong>Théorème.</strong> Soient <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> deux variables aléatoires indépendantes. Alors :</p>
<p><span class="math display">\[\text{Cov}(X,Y)=0\]</span></p>
<p>soit encore, de façon équivalente :</p>
<p><span class="math display">\[\rho_{XY}=0\]</span></p>
</div>
<p></p>
<p><strong>Remarques. i.</strong> L’indépendance implique donc la non-corrélation.</p>
<p></p>
<p><strong>ii.</strong> La réciproque est fausse : deux variables aléatoires peuvent être de corrélation nulle sans être indépendantes.</p>
<p></p>
<p><strong>iii. Interprétation du coefficient de corrélation linéaire.</strong> Le coefficient de corrélation linéaire mesure la dépendance linéaire entre deux variables. On a vu en effet que d’après l’inégalité de Cauchy-Schwarz appliquée aux variables centrées <span class="math inline">\(X-\mathbb{E}(X)\)</span> et <span class="math inline">\(Y-\mathbb{E}-Y)\)</span> on a <span class="math inline">\(-1\leq\rho_{XY}\leq 1\)</span>. Les cas d’égalité se produisent lorsque ces deux variables sont colinéaires, autrement dit :</p>
<p><span class="math display">\[\rho_{XY}=\pm 1 \Leftrightarrow\exists (a,b,c)\in\mathbb{R}^3,\, aX+bY+c=0\]</span>
Au contraire, plus <span class="math inline">\(\rho_{XY}\)</span> s’éloigne de <span class="math inline">\(-1\)</span> et <span class="math inline">\(1\)</span> et moins <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont linéairement liées. Dans le cas extrême où <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes, elles sont en particulier linéairement indépendantes, et leur coefficient de corrélation est nul.</p>
<p><strong>iv.</strong> Dire que deux variables sont non corrélées revient à dire que leur produit scalaire dans l’espace préhlibertien <span class="math inline">\(\left(L^2(\Omega), &lt;.\,,\,.&gt;\right)\)</span> est nul. On dit alors que ces deux variables sont <strong>orthogonales</strong>, ce qui est donc synonyme de “sans dépendance linéaire.”</p>
<p><br></p>
<p>Nous avons vu que l’application</p>
<p><span class="math display">\[\begin{align}
L^2(\Omega)\times L^2(\Omega)&amp;\longrightarrow\mathbb{R} \\
(X,Y)&amp;\mapsto\mathbb{E}(XY)
\end{align}\]</span></p>
<p>est un produit scalaire sur <span class="math inline">\(L^2(\Omega)\)</span>.</p>
<p>La fonction de covariance</p>
<p><span class="math display">\[\begin{align}
L^2(\Omega)\times L^2(\Omega)&amp;\longrightarrow\mathbb{R} \\
(X,Y)&amp;\mapsto\text{Cov}(XY)
\end{align}\]</span></p>
<p>n’est pas un produit scalaire, mais elle s’en approche grandement :</p>
<div class="thmbox thm">
<p>
<strong>Propriétés de la covariance.</strong> L’application</p>
<p><span class="math display">\[\begin{align}
L^2(\Omega)\times L^2(\Omega)&amp;\longrightarrow\mathbb{R} \\
(X,Y)&amp;\mapsto\text{Cov}(XY)
\end{align}\]</span></p>
<p>est :</p>
<ul>
<li><strong>bilinéaire :</strong> <span class="math inline">\(\forall (X,Y,Z)\in L^2(\Omega)\times L^2(\Omega)\times L^2(\Omega), \forall\alpha\in\mathbb{R}\)</span> :</li>
</ul>
<p><span class="math display">\[\text{Cov}(\alpha X+Y,Z)=\alpha\text{Cov}(X,Z)+\text{Cov}(Y,Z)\]</span>
<span class="math display">\[\text{Cov}(X,\alpha Y+Z)=\alpha\text{Cov}(X,Z)+\alpha\text{Cov}(Y,Z)\]</span></p>
<ul>
<li><p><strong>symétrique :</strong> <span class="math inline">\(\forall (X,Y)\in L^2(\Omega)\times L^2(\Omega), \text{Cov}(X,Y)=\text{Cov}(Y,X)\)</span></p></li>
<li><p><strong>positive :</strong> $<span class="math inline">\(X\in L^2(\Omega)\)</span> :</p></li>
</ul>
<p><span class="math display">\[\text{Cov}(X,X)\geq 0\]</span>
Sa <strong>forme quadratique</strong> associée est la fonction de variance <span class="math display">\[X\in L^2(\Omega)\mapsto\mathbb{V}(X)\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Exactement le même type de calculs que pour l’application <span class="math inline">\((X,Y)\in L^2(\Omega)\times L^2(\Omega)\mapsto\mathbb{E}(XY)\)</span> (voir annexe).</p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Remarque.</strong> Cette application est ainsi une forme bilinaire symétrique positive, mais elle n’est pas définie positive. Autrement dit, il existe <span class="math inline">\(X\in L^2(\Omega)\)</span> telle que <span class="math inline">\(\mathbb{V}(X)=0\)</span> sans pour autant que <span class="math inline">\(X\)</span> soit nulle. Il suffit de prendre <span class="math inline">\(X=a\)</span> une constante réelle non nulle. La fonction de covariance n’est donc pas un produit scalaire sur <span class="math inline">\(L^2(\Omega)\)</span>, même si elle en satisfait de nombreuses propriétés (en fait, toutes sauf une).</p>
<p>Il découle du résultat précédent une formule pour la variance d’une somme de variables aléatoires :</p>
<div class="thmbox thm">
<p>
<strong>Variance d’une somme.</strong> Soient <span class="math inline">\(X_1,\dots,X_n\)</span> des variables aléatoires réelles discrètes. La variance de leur somme est donnée par la formule</p>
<p><span class="math display">\[\mathbb{V}\left(\sum\limits_{i=1}^n X_i\right)=\sum\limits_{i=1}^n\mathbb{V}(X_i)+2\sum\limits_{1\leq i&lt;j\leq n}\text{Cov}(X_i, X_j)\]</span>
En particulier, si les variables aléatoires <span class="math inline">\(X_1,\dots, X_n\)</span> sont deux à deux indépendantes (i.e. si <span class="math inline">\(X_i\)</span> est indépendante de <span class="math inline">\(X_j\)</span> dès que <span class="math inline">\(i\neq j\)</span>), la variance de la somme est égale à la somme des variances :</p>
<p><span class="math display">\[\mathbb{V}\left(\sum\limits_{i=1}^n X_i\right)=\sum\limits_{i=1}^n\mathbb{V}(X_i)\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> La première égalité est une simple traduction du fait que la fonction de covariance est une forme bilinéaire de forme quadratique associée <span class="math inline">\(\text{Cov}(X,X)=\mathbb{V}(X)\)</span>.</p>
<p>La deuxième égalité provient du fait que la covariance de deux variables aléatoires indépendantes est nulle.</p>
<p><span class="math inline">\(\square\)</span></p>
</div>
<div id="espérance-conditionnelle-mathbbeyxx" class="section level2 hasAnchor" number="3.7">
<h2><span class="header-section-number">3.7</span> Espérance conditionnelle <span class="math inline">\(\mathbb{E}(Y|X=x)\)</span><a href="variables-aléatoires-discrètes.html#espérance-conditionnelle-mathbbeyxx" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>On a défini la loi conditionnelle <span class="math inline">\(\mathbb{P}_{Y|X=x}\)</span>. L’espérance <span class="math inline">\(\mathbb{E}(Y|X=x)\)</span>, si elle existe, est l’espérance de <span class="math inline">\(Y\)</span> sous cette loi.</p>
<div class="defbox def">
<center>
<strong>Espérance conditionnelle <span class="math inline">\(\mathbb{E}(Y|X=x)\)</span></strong>
</center>
<p>Soient <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> deux variables aléatoires réelles discrètes sur un espace probabilisé <span class="math inline">\((\Omega, \mathcal{P}(\Omega), \mathbb{P})\)</span>. Soit <span class="math inline">\(x\in X(\Omega)\)</span>. On suppose que</p>
<p><span class="math display">\[\forall y\in Y(\Omega),\,\mathbb{P}(Y|X=x)&gt;0\]</span>
L’<strong>espérance conditionnelle de <span class="math inline">\(Y\)</span> sachant <span class="math inline">\(X=x\)</span></strong>, notée <span class="math inline">\(\mathbb{E}(Y|X=x)\)</span>, est définie par</p>
<p><span class="math display">\[\mathbb{E}(Y|X=x)=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y|X=x)\,y\]</span></p>
</div>
<p></p>
<p><strong>Interprétation.</strong> L’espérance conditionnelle <span class="math inline">\(\mathbb{E}(Y|X=x)\)</span> s’interprète comme l’espérance de <span class="math inline">\(Y\)</span> dans le sous-univers <span class="math inline">\((X=X)\subset\Omega\)</span>. Elle a d’ailleurs toutes les propriétés de l’espérance : linéarité, positivité, croissance…</p>
<p></p>
<p><strong>Exemple.</strong> On reprend l’exemple du couple aléatoire <span class="math inline">\((X,Y)\)</span> de loi conjointe donnée par le tableau suivant :</p>
<center>
<img src="images/tableau_exemple_c.PNG" /><!-- -->
</center>
<p>Calculons les espérances conditionnelles <span class="math inline">\(\mathbb{E}(Y|X=i)\)</span> pour <span class="math inline">\(1\leq i\leq 3\)</span> :</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(Y|X=1)&amp;=\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=1)\,i \\
&amp;=\frac{1}{\mathbb{P}(X=1)}\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=1)\,i \\
&amp;=\frac{\frac{1}{12}\times 0+0\times 1+\frac{1}{12}\times 2}{\frac{2}{12}} \\
&amp;= 1 \\
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(Y|X=2)&amp;=\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=2)\,i \\
&amp;=\frac{1}{\mathbb{P}(X=2)}\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=2)\,i \\
&amp;=\frac{\frac{2}{12}\times 0+\frac{1}{12}\times 1+\frac{1}{12}\times 2}{\frac{4}{12}} \\
&amp;= \frac{3}{4} \\
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(Y|X=3)&amp;=\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=3)\,i \\
&amp;=\frac{1}{\mathbb{P}(X=3)}\sum\limits_{i=0}^2\mathbb{P}(Y=i|X=3)\,i \\
&amp;=\frac{\frac{3}{12}\times 0+\frac{2}{12}\times 1+\frac{1}{12}\times 2}{\frac{6}{12}} \\
&amp;= \frac{2}{3} \\
\end{align}\]</span></p>
<p><br></p>
<div class="defbox def">
<p><strong>Propriétés de l’espérance conditionnelle <span class="math inline">\(\mathbb{E}(.|X=x)\)</span>.</strong> Sous les hypothèses et notations précédentes, l’espérance conditionnelle <span class="math inline">\(\mathbb{E}(.|X=x)\)</span> possède toutes les propriétés de l’espérance :</p>
<ul>
<li><p>elle est <strong>linéaire :</strong> <span class="math inline">\(\mathbb{E}(Y+\alpha Z|X)=\mathbb{E}(Y|X)+\alpha\mathbb{E}(Z|X)\)</span></p></li>
<li><p>elle est <strong>positive :</strong> si <span class="math inline">\(Y\geq 0\)</span> alors <span class="math inline">\(\mathbb{E}(Y|X)\geq 0\)</span></p></li>
<li><p>elle est <strong>croissante :</strong> si <span class="math inline">\(Y\leq Z\)</span> alors <span class="math inline">\(\mathbb{E}(Y|X)\leq\mathbb{E}(Z|X)\)</span>.</p></li>
</ul>
</div>
<p></p>
<p><br></p>
<p>Les espérances conditionnelles permettent de reconstruire l’espérance :</p>
<div class="thmbox thm">
<p>
<strong>Théorème.</strong> Sous les hypothèses et notations précédentes, on a</p>
<p><span class="math display">\[\mathbb{E}(Y)=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\mathbb{E}(Y|X=x)\]</span>
Autrement dit, en notant <span class="math inline">\(\mathbb{E}(Y|X)\)</span> la variable aléatoire</p>
<p><span class="math display">\[\mathbb{E}(Y|X)(\omega)=\mathbb{E}(Y|X=X(\omega))\]</span>
on a</p>
<p><span class="math display">\[\mathbb{E}\left(\mathbb{E}(Y|X)\right)=\mathbb{E}(Y)\]</span></p>
</div>
<p></p>
<p><strong>Remarques. i.</strong> L’espérance conditionnelle <span class="math inline">\(\mathbb{E}(Y|X)\)</span> est donc une <strong>variable aléatoire</strong> et pas un nombre dans le cas général (elle peut l’être par exemple si <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes : exercice !). Son support est constitué des espérances conditionnelles <span class="math inline">\(\mathbb{E}(Y|X=x)\)</span> (ici ce sont bien des nombres !), pour <span class="math inline">\(x\in X(\Omega)\)</span>.</p>
<p></p>
<p><strong>ii.</strong> Pour tout <span class="math inline">\(x\in X(\Omega)\)</span>, <span class="math inline">\(\mathbb{E}(Y|X=x)=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y|X=x)\,y\)</span> est une fonction de <span class="math inline">\(x\)</span> :</p>
<p><span class="math display">\[\mathbb{E}(Y|X=x)=\phi(x)\]</span>
Donc, l’espérance conditionnelle <span class="math inline">\(\mathbb{E}(Y|X)\)</span> est une fonction de <span class="math inline">\(X\)</span> :</p>
<p><span class="math display">\[\mathbb{E}(Y|X)=\phi(X)\]</span></p>
<p></p>
<p><strong>Démonstration.</strong> On a :</p>
<p><span class="math display">\[\begin{align}
\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\mathbb{E}(Y|X=x) &amp;= \sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y|X=x)\,y \\
&amp;=\sum\limits_{x\in X(\Omega)}\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y,X=x)\,y \\
\end{align}\]</span></p>
<p>Montrons que l’on peut intervertir des deux sommes sans changer le résultat. Si <span class="math inline">\(X(\Omega)\)</span> et <span class="math inline">\(Y(\Omega)\)</span> sont des ensembles finis, il n’y a pas de problème. Sinon, on utilise le théorème de Fubini pour les séries à double indice, dont l’énoncé est rappelé en annexe. On peut appliquer ce théorème car :</p>
<ul>
<li>pour tout <span class="math inline">\(y\)</span> dans <span class="math inline">\(Y(\Omega)\)</span>, la série <span class="math inline">\(\sum\limits_{x\in X(\Omega)}\mathbb{P}(Y=y, X=x)\)</span> est convergente (et même absolument convergente car son terme générique est positif) puisque, par <span class="math inline">\(\sigma-\)</span>additivté, on a</li>
</ul>
<p><span class="math display">\[\sum\limits_{x\in X(\Omega)}\mathbb{P}(Y=y, X=x)=\mathbb{P}(Y=y)\]</span></p>
<ul>
<li><span class="math display">\[\begin{align}
\sum\limits_{y\in Y(\Omega)}\left(\sum\limits_{x\in X(\Omega)}\mathbb{P}(Y=y,X=x)\right)\,y &amp;=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y)\,y \\
&amp;=\mathbb{E}(Y) \\
\end{align}\]</span></li>
</ul>
<p>On obtient donc :</p>
<p><span class="math display">\[\begin{align}
\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\mathbb{E}(Y|X=x) &amp;=\sum\limits_{y\in Y(\Omega)}\left(\sum\limits_{x\in X(\Omega)}\mathbb{P}(Y=y,X=x)\right)\,y \\
&amp;=\mathbb{E}(Y) \\
\end{align}\]</span></p>
<p>On en déduit que :</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(\mathbb{E}(Y|X))&amp;=\sum\limits_{\omega\in\Omega}\mathbb{P}(\{\omega\})\,\mathbb{E}(Y|X=X(\omega)) \\
&amp;=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\mathbb{E}(Y|X=x) \\
&amp;=\mathbb{E}(Y)
\end{align}\]</span></p>
<p>d’après ce qui précède.</p>
<p><span class="math inline">\(\square\)</span></p>
<p></p>
<p><strong>Interprétation de ce résultat.</strong> Elle est extrêmement simple : une moyenne <span class="math inline">\(\mathbb{E}(Y)\)</span> peut s’obtenir de la façon suivante :</p>
<ul>
<li><p>dans un premier temps on calcule des moyennes par groupes : <span class="math inline">\(\mathbb{E}(Y|X=x)\)</span>. Ici, les groupes sont les événements <span class="math inline">\((X=x)\)</span>, pour <span class="math inline">\(x\in X(\Omega)\)</span>) ;</p></li>
<li><p>dans un second temps, puis on calcule la moyenne (pondérée) de ces moyennes : <span class="math inline">\(\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\mathbb{E}(Y|X=x)\)</span>.</p></li>
</ul>
<p></p>
<p><strong>Exemple.</strong> On reprend l’exemple précédent :</p>
<p><span class="math display">\[\mathbb{E}(Y|X=1)=1\]</span>
<span class="math display">\[\mathbb{E}(Y|X=2)=\frac{3}{4}\]</span>
<span class="math display">\[\mathbb{E}(Y|X=3)=\frac{2}{3}\]</span>
</p>
<p><strong>Déterminons la loi de <span class="math inline">\(Z=\mathbb{E}(Y|X)\)</span>.</strong> Son support est</p>
<p><span class="math display">\[Z(\Omega)=\left\{1,\frac{3}{4},\frac{2}{3}\right\}\]</span></p>
<p>Par ailleurs, on a</p>
<p><span class="math display">\[\mathbb{P}(Z=1)=\mathbb{P}(X=1)=\frac{2}{12}\]</span>
<span class="math display">\[\mathbb{P}\left(Z=\frac{3}{4}\right)=\mathbb{P}(X=2)=\frac{4}{12}\]</span>
<span class="math display">\[\mathbb{P}\left(Z=\frac{2}{3}\right)=\mathbb{P}(X=3)=\frac{6}{12}\]</span>
</p>
<p><strong>Calculons maintenant son espérance.</strong> On peut le faire de trois façons différentes :</p>
<ul>
<li><strong>Méthode 1 :</strong> on utilise la loi de <span class="math inline">\(Z\)</span> :</li>
</ul>
<p><span class="math display">\[\begin{align}
\mathbb{E}(Z)&amp;=\sum\limits_{z\in Z(\Omega)}\mathbb{P}(Z=z)\,z \\
&amp;=\frac{2}{12}\times 1+\frac{4}{12}\times\frac{3}{4}+\frac{6}{12}\times\frac{2}{3} \\
&amp;=\frac{3}{4} \\
\end{align}\]</span></p>
<ul>
<li><strong>Méthode 2 :</strong> on utilise l’égalité <span class="math inline">\(\mathbb{E}(Z)=\mathbb{E}(\mathbb{E}(Y|X))=\mathbb{E}(Y)\)</span> :</li>
</ul>
<p><span class="math display">\[\begin{align}
\mathbb{E}(Z)&amp;=\mathbb{E}(Y) \\
&amp;=\sum\limits_{x\in X(\Omega)}\mathbb{P}(X=x)\,\mathbb{E}(Y|X=x) \\
&amp;=\frac{2}{12}\times 1+\frac{4}{12}\times\frac{3}{4}+\frac{6}{12}\times\frac{2}{3} \\
&amp;=\frac{3}{4} \\
\end{align}\]</span></p>
<p></p>
<ul>
<li><strong>Méthode 3</strong> : on utilise l’égalité <span class="math inline">\(\mathbb{E}(Z)=\mathbb{E}(Y)\)</span>, que l’on calcule à partir de la loi de <span class="math inline">\(Y\)</span> :</li>
</ul>
<p><span class="math display">\[\begin{align}
\mathbb{E}(Z)&amp;=\mathbb{E}(Y) \\
&amp;=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y)\,y \\
&amp;=\frac{6}{12}\times 0+\frac{3}{12}\times 1+\frac{3}{12}\times 2 \\
&amp;=\frac{3}{4} \\
\end{align}\]</span></p>
<p>Les trois méthodes aboutissent bien au même résultat.</p>
<p><br></p>
<p>On termine avec une propriété intuitive de l’espérance conditionnelle. Si <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes, la connaissance de la réalisation <span class="math inline">\(x=X(\omega)\)</span> de <span class="math inline">\(X\)</span> n’a aucun impact sur la moyenne de <span class="math inline">\(Y\)</span> :</p>
<div class="thmbox thm">
<p>
<strong>Théorème.</strong> Avec les notations et hypothèses précédentes, si <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont indépendantes, alors pour toute réalisation <span class="math inline">\(x=X(\omega)\)</span> de <span class="math inline">\(X\)</span>, on a</p>
<p><span class="math display">\[\mathbb{E}(Y|X=x)=\mathbb{E}(Y)\]</span>
Autrement dit, si <span class="math inline">\(Y\)</span> est indépendante de <span class="math inline">\(X\)</span>, alors :</p>
<p><span class="math display">\[\mathbb{E}(Y|X)=\mathbb{E}(Y)\]</span></p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Elle est immédiate : soit <span class="math inline">\(x\in X(\Omega)\)</span>, alors</p>
<p><span class="math display">\[\begin{align}
\mathbb{E}(Y|X=x)&amp;=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y|X=x)\,y \\
&amp;=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y)\,y \\
&amp; \text{(car } Y \text{ est indépendante de } X \text{)} \\
&amp;=\mathbb{E}(Y)
\end{align}\]</span></p>
<p><span class="math inline">\(\square\)</span></p>
<div id="variance-conditionnelle" class="section level3 hasAnchor" number="3.7.1">
<h3><span class="header-section-number">3.7.1</span> Variance conditionnelle<a href="variables-aléatoires-discrètes.html#variance-conditionnelle" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="thmbox thm">
<center>
<strong>Variance conditionnelle</strong>
</center>
<p>Sous réserve d’existence, la variance conditionnelle de <span class="math inline">\(Y\)</span> sachant <span class="math inline">\(X=x\)</span> est définie par</p>
<p><span class="math display">\[\mathbb{V}(Y|X=x)=\mathbb{E}\left((Y-\mathbb{E}(Y|X=x))^2\right)\]</span>
soit</p>
<p><span class="math display">\[\mathbb{V}(Y|X=x)=\sum\limits_{y\in Y(\Omega)}\mathbb{P}(Y=y|X=x)\,(y-\mathbb{E}(Y|X=x))^2\]</span>
On a alors la formule de König-Huygens :</p>
<p><span class="math display">\[\mathbb{V}(Y|X=x)=\mathbb{E}(Y^2|X=x)-\mathbb{E}(Y|X=x)^2\]</span>
On peut également définir une notion de variance conditionnelle comme variable aléatoire :</p>
<p><span class="math display">\[\mathbb{V}(Y|X)=\mathbb{E}\left(\left(Y-\mathbb{E}(Y|X)\right)^2\right)\]</span>
et à nouveau on a :</p>
<p><span class="math display">\[\mathbb{V}(Y|X)=\mathbb{E}(Y^2|X)-\mathbb{E}(Y|X)^2\]</span>
Avec ces définitions, la variable aléatoire <span class="math inline">\(\mathbb{V}(Y|X)\)</span> admet pour réalisations les <span class="math inline">\(\mathbb{V}(Y|X=x)\)</span>, pour <span class="math inline">\(x\in X(\Omega)\)</span>.</p>
</div>
<p>La variance, l’espérance conditionnelle et la variance conditionnelle sont liées par la formule suivante :</p>
<div class="thmbox thm">
<p><strong>Formule de décomposition de la variance.</strong> Soient <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> deux variables aléatoires réelles discrètes. On suppose que <span class="math inline">\(Y\)</span> admet une variance finie. Alors</p>
<p><span class="math display">\[\mathbb{V}(Y)=\mathbb{E}\left(\mathbb{V}(Y|X)\right)+\mathbb{V}\left(\mathbb{E}(Y|X)\right)\]</span></p>
</div>
</div>
<div id="somme-de-deux-va-indépendantes-produit-de-convolution-discret" class="section level3 hasAnchor" number="3.7.2">
<h3><span class="header-section-number">3.7.2</span> Somme de deux VA indépendantes (produit de convolution discret)<a href="variables-aléatoires-discrètes.html#somme-de-deux-va-indépendantes-produit-de-convolution-discret" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="thmbox thm">
<p>Soient <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> deux variables aléatoires réelles discrètes <strong>indépendantes</strong> définies sur <span class="math inline">\((\Omega, \mathcal{P}(\Omega), \mathbb{P})\)</span>. La loi de leur somme <span class="math inline">\(X+Y\)</span> est donnée par</p>
<p><span class="math display">\[\forall z\in X+Y(\Omega),\,\mathbb{P}(X+Y=z)=\sum\limits_{x\in X(\Omega), z-x\in Y(\Omega)} \mathbb{P}(X=x)\,\mathbb{P}(Y=z-x)\]</span>
La fonction <span class="math display">\[z\in X+Y(\Omega)\mapsto \sum\limits_{x\in X(\Omega), z-x\in Y(\Omega)} \mathbb{P}(X=x)\,\mathbb{P}(Y=z-x)\]</span></p>
<p>s’appelle le <strong>produit de convolution</strong> de <span class="math inline">\(X\)</span> par <span class="math inline">\(Y\)</span>.</p>
</div>
</div>
</div>
<div id="annexes" class="section level2 hasAnchor" number="3.8">
<h2><span class="header-section-number">3.8</span> Annexes<a href="variables-aléatoires-discrètes.html#annexes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="inégalité-de-cauchy-schwarz" class="section level3 hasAnchor" number="3.8.1">
<h3><span class="header-section-number">3.8.1</span> Inégalité de Cauchy-Schwarz<a href="variables-aléatoires-discrètes.html#inégalité-de-cauchy-schwarz" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>L’inégalité de Cauchy-Schwarz est un résultat important d’algèbre. On rappelle d’abord la notion de <strong>produit scalaire</strong> sur un espace vectoriel.</p>
<p></p>
<p><strong>Rappel : produit scalaire.</strong> Dans un espace-vectoriel <span class="math inline">\(E\)</span>, on appelle <em>produit scalaire</em> toute application <span class="math inline">\(\phi:E\times E\longrightarrow\mathbb{R}\)</span> vérifiant les propriétés suivantes :</p>
<ul>
<li><p><strong>Bilinéarité :</strong> <span class="math inline">\(\phi\)</span> est linéaire à gauche et linéaire à droite :</p>
<ul>
<li><p><strong>Linéarité à gauche :</strong> <span class="math inline">\(\forall x,y,z\in E,\, \forall\lambda\in\mathbb{R}, \, \phi(x+\lambda y, z)=\phi(x,z)+\lambda\phi(y,z)\)</span></p></li>
<li><p><strong>linéarité à droite :</strong> <span class="math inline">\(\forall x,y,z\in E,\, \forall\lambda\in\mathbb{R}, \, \phi(x, y+\lambda z)=\phi(x,y)+\lambda\phi(x,z)\)</span></p></li>
</ul></li>
<li><p><strong>Symétrie :</strong> <span class="math inline">\(\forall x,y\in E,\, \phi(x,y)=\phi(y,x)\)</span></p></li>
<li><p><strong>Définie positive :</strong> <span class="math inline">\(\forall x\in E, \phi(x,x)\geq 0\)</span>, avec égalité si et seulement si <span class="math inline">\(x=0\)</span>.</p></li>
</ul>
<p>Une notation courante pour un produit scalaire est <span class="math inline">\(&lt;.\,,\,.&gt;\)</span>. De plus, pour <span class="math inline">\(x\in E\)</span>, on note <span class="math inline">\(||x||=\sqrt{&lt;x\,,\,x&gt;}\)</span>. Il s’agit d’une <strong>norme</strong> sur <span class="math inline">\(E\)</span>, i.e. une application de <span class="math inline">\(E\)</span> dans <span class="math inline">\(\mathbb{R}\)</span> vérifiant les propriétés suivantes :</p>
<ul>
<li><p>pour tout <span class="math inline">\(x\)</span> dans <span class="math inline">\(E\)</span>, <span class="math inline">\(||x||=0\)</span> si et seulement si <span class="math inline">\(x=0\)</span> ;</p></li>
<li><p>pour tout <span class="math inline">\(x\)</span> dans <span class="math inline">\(E\)</span> et pour tout réel <span class="math inline">\(\lambda\)</span> : <span class="math inline">\(||\lambda x||=|\lambda|.||x||\)</span> ;</p></li>
<li><p>pour tous <span class="math inline">\(x,y\)</span> dans <span class="math inline">\(E\)</span>, <span class="math inline">\(||x+y||\leq ||x||+||y||\)</span>.</p></li>
</ul>
<p>L’inégalité de Cauchy-Schwarz établit une majoration du produit scalaire (et même de sa valeur absolue) par le produit des normes :</p>
<div class="thmbox thm">
<p><strong>Inégalité de Cauchy-Schwarz.</strong> Soient <span class="math inline">\((E\,,\,&lt;\,,\,&gt;)\)</span> un espace préhilbertien réel et <span class="math inline">\(||.||\)</span> la norme associée au produit scalaire <span class="math inline">\(&lt;\,,\,&gt;\)</span>. Alors, on a</p>
<p><span class="math display">\[\forall x,y\in E,\,|&lt;x\,,y&gt;|\leq ||x||\,||y||\]</span>
avec égalité si et seulement si <span class="math inline">\(x\)</span> et <span class="math inline">\(y\)</span> sont colinéaires.</p>
</div>
<p></p>
<p><strong>Démonstration.</strong> Soient <span class="math inline">\(x,y\in E\)</span>. Pour tout réel <span class="math inline">\(t\)</span>, on a</p>
<p><span class="math display">\[\begin{align}
0&amp;\leq||x-ty||^2 \\
&amp;=||y||^2t^2-2&lt;x\,,\,y&gt;t+||x||^2 \\
\end{align}\]</span></p>
<p>On peut voir <span class="math inline">\(||y||^2t^2-2&lt;x\,,\,y&gt;t+||x||^2\)</span> comme un trinôme en <span class="math inline">\(t\)</span>, toujours positif ou nul. Par conséquent son discriminant est négatif ou nul, soit</p>
<p><span class="math display">\[4&lt;x\,,\,y&gt;^2-4||x||^2||y||^2\leq 0\]</span>
i.e.</p>
<p><span class="math display">\[|&lt;x\,,\,y&gt;|\leq ||x||\,||y||\]</span>
Le cas d’égalité signifie que ce discriminant est nul. Dans ce cas, il existe <span class="math inline">\(t\)</span> réel tel que <span class="math inline">\(x=ty\)</span>, ce qui signifie exactement que <span class="math inline">\(x\)</span> et <span class="math inline">\(y\)</span> sont colinéaires.</p>
<p><span class="math inline">\(\square\)</span></p>
<p>Dans le cadre de la théorie des probabilités, l’inégalité de Cauchy-Schwarz est souvent appliquée dans l’epace <span class="math inline">\(L^2(\Omega, \mathcal{P}(\Omega), \mathbb{P})\)</span>.</p>
</div>
<div id="théorème-de-fubini-pour-les-séries-doubles" class="section level3 hasAnchor" number="3.8.2">
<h3><span class="header-section-number">3.8.2</span> Théorème de Fubini pour les séries doubles<a href="variables-aléatoires-discrètes.html#théorème-de-fubini-pour-les-séries-doubles" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On rappelle le résultat d’analyse suivant (que l’on admet) :</p>
<div class="thmbox thm">
<p>
<strong>Théorème de Fubini pour les séries doubles.</strong> On suppose que <span class="math inline">\((a_{mn})_{(m,n),\in\mathbb{N}^2}\)</span> est une suite à double indice telle que :</p>
<ul>
<li>pour tout entier <span class="math inline">\(m\)</span>, la série <span class="math inline">\(\sum\limits_{n}a_{m,n}\)</span> est absolument convergente ;</li>
<li>la série double <span class="math inline">\(\sum\limits_{m}\sum\limits_{n}a_{m,n}\)</span> est convergente.</li>
</ul>
<p>Alors :</p>
<p><span class="math display">\[\sum\limits_{m=0}^{\infty}\sum\limits_{n=0}^{\infty}a_{m,n}=\sum\limits_{n=0}^{\infty}\sum\limits_{m=0}^{\infty}a_{m,n}\]</span>
autrement dit on peut interertir l’ordre des sommes sans modifier le résultat.</p>
</div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="dénombrement-et-probabilités.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="variables-aléatoires-à-densité.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/2_variables_aléatoires_discrètes.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Probabilites_Statistique.pdf", "Probabilites_Statistique.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
